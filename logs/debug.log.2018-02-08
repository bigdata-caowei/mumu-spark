2018-02-08 08:57:50,407 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 08:57:51,174 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 08:57:51,211 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 08:57:51,211 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 08:57:51,212 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 08:57:51,213 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 08:57:51,214 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 08:57:51,635 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 65414.
2018-02-08 08:57:51,662 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 08:57:51,713 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 08:57:51,717 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 08:57:51,717 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 08:57:51,729 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-97746720-8f30-4bad-ad70-ae70c906efb5
2018-02-08 08:57:51,761 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 08:57:51,814 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 08:57:51,927 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @3091ms
2018-02-08 08:57:52,007 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 08:57:52,021 INFO[org.spark_project.jetty.server.Server:403] - Started @3187ms
2018-02-08 08:57:52,044 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@427b5f92{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 08:57:52,045 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 08:57:52,069 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24fb6a80{/jobs,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,069 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,070 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,071 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,072 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,072 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,073 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,074 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,075 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,075 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,076 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,076 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,078 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,078 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,079 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,080 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,081 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,081 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,082 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,082 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,091 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/static,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,092 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,093 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@649725e3{/api,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,094 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,094 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,096 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 08:57:52,199 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 08:57:52,235 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65427.
2018-02-08 08:57:52,236 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:65427
2018-02-08 08:57:52,240 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 08:57:52,243 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 65427, None)
2018-02-08 08:57:52,248 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:65427 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 65427, None)
2018-02-08 08:57:52,252 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 65427, None)
2018-02-08 08:57:52,253 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 65427, None)
2018-02-08 08:57:52,457 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3b582111{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,555 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 08:57:52,557 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 08:57:52,566 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/SQL,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,567 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410e94e{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,568 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@78d39a69{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,568 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b69d40d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 08:57:52,571 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@72889280{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 08:57:53,942 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 08:57:56,323 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 186.28614 ms
2018-02-08 08:57:56,354 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.127043 ms
2018-02-08 08:57:56,376 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 08:57:56,382 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@427b5f92{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 08:57:56,384 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 08:57:56,394 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 08:57:56,402 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 08:57:56,403 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 08:57:56,409 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 08:57:56,412 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 08:57:56,415 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 08:57:56,416 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 08:57:56,417 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-aa4a0863-11e4-4c12-aaec-11646f4f9db9
2018-02-08 08:58:46,968 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 08:58:47,511 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 08:58:47,536 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 08:58:47,537 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 08:58:47,537 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 08:58:47,538 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 08:58:47,539 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 08:58:47,897 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 65476.
2018-02-08 08:58:47,944 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 08:58:47,960 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 08:58:47,963 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 08:58:47,964 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 08:58:47,972 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-f2f62304-c944-4fe7-bc45-96fb04661f01
2018-02-08 08:58:47,992 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 08:58:48,041 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 08:58:48,115 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2401ms
2018-02-08 08:58:48,179 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 08:58:48,191 INFO[org.spark_project.jetty.server.Server:403] - Started @2480ms
2018-02-08 08:58:48,209 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@5a7ceb63{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 08:58:48,210 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 08:58:48,232 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24fb6a80{/jobs,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,232 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,233 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,234 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,234 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,235 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,235 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,236 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,237 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,238 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,239 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,239 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,240 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,241 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,241 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,242 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,243 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,244 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,245 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,245 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,251 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/static,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,252 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,253 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@649725e3{/api,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,254 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,255 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,258 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 08:58:48,333 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 08:58:48,362 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65489.
2018-02-08 08:58:48,363 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:65489
2018-02-08 08:58:48,365 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 08:58:48,367 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 65489, None)
2018-02-08 08:58:48,370 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:65489 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 65489, None)
2018-02-08 08:58:48,384 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 65489, None)
2018-02-08 08:58:48,384 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 65489, None)
2018-02-08 08:58:48,543 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3b582111{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,633 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 08:58:48,636 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 08:58:48,650 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/SQL,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,651 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410e94e{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,652 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@78d39a69{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,653 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b69d40d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 08:58:48,654 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@72889280{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 08:58:49,669 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 08:58:51,607 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 211.522948 ms
2018-02-08 08:58:51,784 INFO[org.apache.spark.SparkContext:54] - Starting job: first at PCA.scala:43
2018-02-08 08:58:51,805 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (first at PCA.scala:43) with 1 output partitions
2018-02-08 08:58:51,806 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (first at PCA.scala:43)
2018-02-08 08:58:51,806 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 08:58:51,808 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 08:58:51,815 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[4] at map at PCA.scala:95), which has no missing parents
2018-02-08 08:58:52,052 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 7.8 KB, free 631.8 MB)
2018-02-08 08:58:52,086 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.1 KB, free 631.8 MB)
2018-02-08 08:58:52,089 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:65489 (size: 4.1 KB, free: 631.8 MB)
2018-02-08 08:58:52,092 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 08:58:52,106 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at PCA.scala:95) (first 15 tasks are for partitions Vector(0))
2018-02-08 08:58:52,108 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
2018-02-08 08:58:52,149 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5099 bytes)
2018-02-08 08:58:52,158 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 08:58:52,237 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.161924 ms
2018-02-08 08:58:52,269 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1202 bytes result sent to driver
2018-02-08 08:58:52,278 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 140 ms on localhost (executor driver) (1/1)
2018-02-08 08:58:52,281 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 08:58:52,287 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (first at PCA.scala:43) finished in 0.162 s
2018-02-08 08:58:52,293 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: first at PCA.scala:43, took 0.507815 s
2018-02-08 08:58:52,327 INFO[org.apache.spark.SparkContext:54] - Starting job: first at RowMatrix.scala:61
2018-02-08 08:58:52,329 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (first at RowMatrix.scala:61) with 1 output partitions
2018-02-08 08:58:52,330 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (first at RowMatrix.scala:61)
2018-02-08 08:58:52,330 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 08:58:52,330 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 08:58:52,332 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[4] at map at PCA.scala:95), which has no missing parents
2018-02-08 08:58:52,335 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 7.8 KB, free 631.8 MB)
2018-02-08 08:58:52,338 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.1 KB, free 631.8 MB)
2018-02-08 08:58:52,339 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:65489 (size: 4.1 KB, free: 631.8 MB)
2018-02-08 08:58:52,340 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 08:58:52,341 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at map at PCA.scala:95) (first 15 tasks are for partitions Vector(0))
2018-02-08 08:58:52,342 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 08:58:52,343 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5099 bytes)
2018-02-08 08:58:52,344 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
2018-02-08 08:58:52,353 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1159 bytes result sent to driver
2018-02-08 08:58:52,356 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 14 ms on localhost (executor driver) (1/1)
2018-02-08 08:58:52,356 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 08:58:52,357 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (first at RowMatrix.scala:61) finished in 0.015 s
2018-02-08 08:58:52,357 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: first at RowMatrix.scala:61, took 0.030101 s
2018-02-08 08:58:52,389 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at RowMatrix.scala:419
2018-02-08 08:58:52,390 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (treeAggregate at RowMatrix.scala:419) with 2 output partitions
2018-02-08 08:58:52,390 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (treeAggregate at RowMatrix.scala:419)
2018-02-08 08:58:52,390 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 08:58:52,391 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 08:58:52,391 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:419), which has no missing parents
2018-02-08 08:58:52,393 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 8.7 KB, free 631.8 MB)
2018-02-08 08:58:52,397 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 631.8 MB)
2018-02-08 08:58:52,399 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:65489 (size: 4.5 KB, free: 631.8 MB)
2018-02-08 08:58:52,400 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 08:58:52,400 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:419) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 08:58:52,400 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 2 tasks
2018-02-08 08:58:52,402 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5099 bytes)
2018-02-08 08:58:52,402 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 5228 bytes)
2018-02-08 08:58:52,403 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
2018-02-08 08:58:52,403 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 3)
2018-02-08 08:58:52,425 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 3). 1721 bytes result sent to driver
2018-02-08 08:58:52,425 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 1721 bytes result sent to driver
2018-02-08 08:58:52,427 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 3) in 25 ms on localhost (executor driver) (1/2)
2018-02-08 08:58:52,427 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on localhost (executor driver) (2/2)
2018-02-08 08:58:52,428 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 08:58:52,429 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (treeAggregate at RowMatrix.scala:419) finished in 0.027 s
2018-02-08 08:58:52,430 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: treeAggregate at RowMatrix.scala:419, took 0.040918 s
2018-02-08 08:58:53,034 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at RowMatrix.scala:122
2018-02-08 08:58:53,035 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (treeAggregate at RowMatrix.scala:122) with 2 output partitions
2018-02-08 08:58:53,035 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (treeAggregate at RowMatrix.scala:122)
2018-02-08 08:58:53,035 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 08:58:53,035 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 08:58:53,039 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:122), which has no missing parents
2018-02-08 08:58:53,043 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 8.7 KB, free 631.8 MB)
2018-02-08 08:58:53,046 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.5 KB, free 631.8 MB)
2018-02-08 08:58:53,047 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:65489 (size: 4.5 KB, free: 631.8 MB)
2018-02-08 08:58:53,048 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 08:58:53,049 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:122) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 08:58:53,049 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 2 tasks
2018-02-08 08:58:53,050 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5099 bytes)
2018-02-08 08:58:53,051 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 3.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 5228 bytes)
2018-02-08 08:58:53,052 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 08:58:53,052 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 3.0 (TID 5)
2018-02-08 08:58:53,070 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 08:58:53,070 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 1220 bytes result sent to driver
2018-02-08 08:58:53,071 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 08:58:53,072 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 22 ms on localhost (executor driver) (1/2)
2018-02-08 08:58:53,075 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 3.0 (TID 5). 1177 bytes result sent to driver
2018-02-08 08:58:53,076 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 3.0 (TID 5) in 26 ms on localhost (executor driver) (2/2)
2018-02-08 08:58:53,076 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 08:58:53,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (treeAggregate at RowMatrix.scala:122) finished in 0.028 s
2018-02-08 08:58:53,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: treeAggregate at RowMatrix.scala:122, took 0.043465 s
2018-02-08 08:58:53,483 WARN[com.github.fommil.netlib.LAPACK:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2018-02-08 08:58:53,484 WARN[com.github.fommil.netlib.LAPACK:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2018-02-08 08:58:53,643 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:65489 in memory (size: 4.1 KB, free: 631.8 MB)
2018-02-08 08:58:53,647 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_3_piece0 on 192.168.11.26:65489 in memory (size: 4.5 KB, free: 631.8 MB)
2018-02-08 08:58:53,648 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.11.26:65489 in memory (size: 4.5 KB, free: 631.8 MB)
2018-02-08 08:58:53,764 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.440646 ms
2018-02-08 08:58:53,780 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.707844 ms
2018-02-08 08:58:53,798 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 08:58:53,802 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@5a7ceb63{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 08:58:53,805 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 08:58:53,813 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 08:58:53,827 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 08:58:53,828 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 08:58:53,829 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 08:58:53,831 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 08:58:53,833 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 08:58:53,834 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 08:58:53,834 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-4f4311ff-9b68-4852-8465-b4a46bbe227b
2018-02-08 08:59:15,920 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 08:59:16,564 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 08:59:16,587 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 08:59:16,588 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 08:59:16,589 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 08:59:16,589 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 08:59:16,590 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 08:59:16,948 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 65514.
2018-02-08 08:59:16,967 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 08:59:17,012 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 08:59:17,015 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 08:59:17,015 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 08:59:17,024 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-132c9086-13c9-44d8-8a99-a440e9149f3e
2018-02-08 08:59:17,045 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 08:59:17,090 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 08:59:17,168 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2720ms
2018-02-08 08:59:17,232 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 08:59:17,245 INFO[org.spark_project.jetty.server.Server:403] - Started @2798ms
2018-02-08 08:59:17,263 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@1cd61bd3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 08:59:17,263 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 08:59:17,284 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c7d3c46{/jobs,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,285 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,285 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,286 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,287 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/stages,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,289 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,291 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,292 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,293 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,294 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,295 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/storage,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,296 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,296 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,297 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,298 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/environment,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,299 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,299 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/executors,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,301 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,303 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,303 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,310 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410ae9a3{/static,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,311 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c7a975a{/,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,312 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@757d6814{/api,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,312 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4eed46ee{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,313 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4fad94a7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,315 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 08:59:17,387 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 08:59:17,418 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65527.
2018-02-08 08:59:17,418 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:65527
2018-02-08 08:59:17,423 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 08:59:17,424 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 65527, None)
2018-02-08 08:59:17,433 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:65527 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 65527, None)
2018-02-08 08:59:17,438 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 65527, None)
2018-02-08 08:59:17,439 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 65527, None)
2018-02-08 08:59:17,641 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@20765ed5{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,726 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 08:59:17,726 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 08:59:17,733 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d269ed7{/SQL,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,733 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41c89d2f{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,734 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1da6ee17{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,735 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3c818ac4{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 08:59:17,736 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6bfdb014{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 08:59:18,751 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 08:59:20,211 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 08:59:20,219 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@1cd61bd3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 08:59:20,224 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 08:59:20,231 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 08:59:20,237 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 08:59:20,238 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 08:59:20,242 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 08:59:20,245 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 08:59:20,247 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 08:59:20,248 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 08:59:20,248 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-df1694af-01c3-45dc-b167-1c9ff244850b
2018-02-08 09:01:00,441 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:01:01,191 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:01:01,227 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:01:01,228 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:01:01,229 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:01:01,230 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:01:01,230 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:01:01,664 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 49381.
2018-02-08 09:01:01,691 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:01:01,739 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:01:01,743 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:01:01,744 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:01:01,755 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-8c8a070f-c117-41f0-a047-367fc67ff4a7
2018-02-08 09:01:01,823 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:01:01,887 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:01:02,003 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @3892ms
2018-02-08 09:01:02,084 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:01:02,100 INFO[org.spark_project.jetty.server.Server:403] - Started @3990ms
2018-02-08 09:01:02,127 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@427b5f92{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:01:02,127 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:01:02,157 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24fb6a80{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,158 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,159 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,160 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,160 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,161 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,162 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,163 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,165 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,166 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,166 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,167 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,168 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,168 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,169 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,169 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,170 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,171 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,171 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,172 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,182 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/static,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,183 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,184 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@649725e3{/api,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,184 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,185 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,187 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:01:02,280 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:01:02,313 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49395.
2018-02-08 09:01:02,314 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:49395
2018-02-08 09:01:02,317 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:01:02,320 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 49395, None)
2018-02-08 09:01:02,323 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:49395 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 49395, None)
2018-02-08 09:01:02,332 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 49395, None)
2018-02-08 09:01:02,333 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 49395, None)
2018-02-08 09:01:02,557 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3b582111{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,643 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:01:02,645 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:01:02,654 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,654 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410e94e{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,655 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@78d39a69{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,656 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b69d40d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:01:02,658 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@72889280{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:01:03,945 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:01:06,123 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 310.946339 ms
2018-02-08 09:01:06,153 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.212164 ms
2018-02-08 09:01:06,189 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:01:06,195 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@427b5f92{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:01:06,198 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:01:06,211 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:01:06,221 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:01:06,221 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:01:06,230 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:01:06,235 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:01:06,240 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:01:06,241 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:01:06,244 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-99178837-0e24-4c6e-b331-4d446b93b54e
2018-02-08 09:03:06,919 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:03:07,444 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:03:07,465 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:03:07,465 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:03:07,466 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:03:07,467 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:03:07,467 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:03:07,827 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 49549.
2018-02-08 09:03:07,846 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:03:07,891 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:03:07,896 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:03:07,896 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:03:07,912 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-6dfce0d2-a8bd-4981-8fa8-6ac505835f2f
2018-02-08 09:03:07,934 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:03:07,980 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:03:08,050 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2663ms
2018-02-08 09:03:08,114 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:03:08,127 INFO[org.spark_project.jetty.server.Server:403] - Started @2741ms
2018-02-08 09:03:08,145 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@28afe14a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:03:08,146 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:03:08,168 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c7d3c46{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,169 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,170 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,171 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,173 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,173 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,179 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,181 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,182 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,183 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,184 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,184 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,185 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,186 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,186 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,187 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,188 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,189 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,190 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,191 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,200 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410ae9a3{/static,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,200 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c7a975a{/,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,201 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@757d6814{/api,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,202 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4eed46ee{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,203 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4fad94a7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,205 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:03:08,276 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:03:08,309 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49562.
2018-02-08 09:03:08,310 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:49562
2018-02-08 09:03:08,313 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:03:08,319 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 49562, None)
2018-02-08 09:03:08,328 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:49562 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 49562, None)
2018-02-08 09:03:08,333 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 49562, None)
2018-02-08 09:03:08,334 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 49562, None)
2018-02-08 09:03:08,604 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@20765ed5{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,681 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:03:08,682 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:03:08,689 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d269ed7{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,690 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41c89d2f{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,690 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1da6ee17{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,691 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3c818ac4{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:08,692 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6bfdb014{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:03:09,800 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:03:11,851 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 198.721663 ms
2018-02-08 09:03:11,877 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.800324 ms
2018-02-08 09:03:11,903 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:03:11,909 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@28afe14a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:03:11,911 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:03:11,921 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:03:11,929 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:03:11,930 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:03:11,938 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:03:11,942 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:03:11,945 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:03:11,946 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:03:11,947 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-bcc14b52-cd8b-4d41-b7e5-49ae1b256543
2018-02-08 09:03:37,452 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:03:38,218 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:03:38,237 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:03:38,238 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:03:38,238 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:03:38,239 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:03:38,239 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:03:38,593 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 49608.
2018-02-08 09:03:38,610 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:03:38,656 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:03:38,659 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:03:38,659 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:03:38,669 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-a2bc562e-48e3-4138-a266-3aebdb8e35cf
2018-02-08 09:03:38,690 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:03:38,736 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:03:38,811 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @3248ms
2018-02-08 09:03:38,873 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:03:38,887 INFO[org.spark_project.jetty.server.Server:403] - Started @3324ms
2018-02-08 09:03:38,904 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@4d008d95{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:03:38,905 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:03:38,925 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c7d3c46{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,926 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,927 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,927 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,929 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,929 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,930 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,931 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,932 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,933 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,933 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,934 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,934 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,935 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,936 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,936 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,937 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,938 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,939 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,939 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,945 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410ae9a3{/static,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,946 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c7a975a{/,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,947 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@757d6814{/api,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,948 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4eed46ee{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,949 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4fad94a7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:03:38,951 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:03:39,020 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:03:39,046 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49621.
2018-02-08 09:03:39,047 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:49621
2018-02-08 09:03:39,049 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:03:39,052 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 49621, None)
2018-02-08 09:03:39,057 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:49621 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 49621, None)
2018-02-08 09:03:39,065 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 49621, None)
2018-02-08 09:03:39,066 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 49621, None)
2018-02-08 09:03:39,235 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@20765ed5{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:39,298 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:03:39,299 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:03:39,307 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d269ed7{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:03:39,308 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41c89d2f{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:39,309 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1da6ee17{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:03:39,309 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3c818ac4{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:03:39,313 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6bfdb014{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:03:40,367 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:03:42,342 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 177.825977 ms
2018-02-08 09:03:42,357 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.413122 ms
2018-02-08 09:03:42,535 INFO[org.apache.spark.SparkContext:54] - Starting job: countByValue at StringIndexer.scala:113
2018-02-08 09:03:42,801 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (countByValue at StringIndexer.scala:113)
2018-02-08 09:03:42,804 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (countByValue at StringIndexer.scala:113) with 2 output partitions
2018-02-08 09:03:42,804 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (countByValue at StringIndexer.scala:113)
2018-02-08 09:03:42,805 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 0)
2018-02-08 09:03:42,807 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 0)
2018-02-08 09:03:42,814 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 0 (MapPartitionsRDD[7] at countByValue at StringIndexer.scala:113), which has no missing parents
2018-02-08 09:03:42,976 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 12.4 KB, free 631.8 MB)
2018-02-08 09:03:43,015 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KB, free 631.8 MB)
2018-02-08 09:03:43,019 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:49621 (size: 6.1 KB, free: 631.8 MB)
2018-02-08 09:03:43,021 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:03:43,036 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[7] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:03:43,037 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 09:03:43,084 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5106 bytes)
2018-02-08 09:03:43,087 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5106 bytes)
2018-02-08 09:03:43,094 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:03:43,094 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 09:03:43,198 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.906884 ms
2018-02-08 09:03:43,357 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1487 bytes result sent to driver
2018-02-08 09:03:43,359 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1444 bytes result sent to driver
2018-02-08 09:03:43,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 298 ms on localhost (executor driver) (1/2)
2018-02-08 09:03:43,370 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 283 ms on localhost (executor driver) (2/2)
2018-02-08 09:03:43,372 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:03:43,379 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 0 (countByValue at StringIndexer.scala:113) finished in 0.322 s
2018-02-08 09:03:43,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 09:03:43,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 09:03:43,381 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 1)
2018-02-08 09:03:43,381 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 09:03:43,387 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (ShuffledRDD[8] at countByValue at StringIndexer.scala:113), which has no missing parents
2018-02-08 09:03:43,394 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 631.8 MB)
2018-02-08 09:03:43,397 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1963.0 B, free 631.8 MB)
2018-02-08 09:03:43,400 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:49621 (size: 1963.0 B, free: 631.8 MB)
2018-02-08 09:03:43,401 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:03:43,405 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[8] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:03:43,405 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 09:03:43,410 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 09:03:43,411 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 4621 bytes)
2018-02-08 09:03:43,411 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 09:03:43,411 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 3)
2018-02-08 09:03:43,428 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:03:43,428 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 2 blocks
2018-02-08 09:03:43,430 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
2018-02-08 09:03:43,430 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
2018-02-08 09:03:43,468 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 3). 1219 bytes result sent to driver
2018-02-08 09:03:43,469 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 1238 bytes result sent to driver
2018-02-08 09:03:43,471 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 3) in 60 ms on localhost (executor driver) (1/2)
2018-02-08 09:03:43,473 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 65 ms on localhost (executor driver) (2/2)
2018-02-08 09:03:43,473 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 09:03:43,474 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (countByValue at StringIndexer.scala:113) finished in 0.066 s
2018-02-08 09:03:43,481 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: countByValue at StringIndexer.scala:113, took 0.945117 s
2018-02-08 09:03:43,918 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.894083 ms
2018-02-08 09:03:43,933 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.203204 ms
2018-02-08 09:03:43,951 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:03:43,957 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@4d008d95{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:03:43,959 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:03:43,967 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:03:43,987 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:03:43,988 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:03:43,993 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:03:43,995 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:03:44,000 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:03:44,000 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:03:44,001 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-2bf18e6f-2e97-4ac7-ab02-78b89efee009
2018-02-08 09:04:22,587 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:04:23,088 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:04:23,109 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:04:23,109 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:04:23,110 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:04:23,110 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:04:23,111 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:04:23,464 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 49684.
2018-02-08 09:04:23,481 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:04:23,527 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:04:23,530 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:04:23,530 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:04:23,539 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-18aedaa9-cce9-47de-8ed1-8e9ef84dc389
2018-02-08 09:04:23,559 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:04:23,610 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:04:23,682 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2501ms
2018-02-08 09:04:23,744 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:04:23,756 INFO[org.spark_project.jetty.server.Server:403] - Started @2576ms
2018-02-08 09:04:23,773 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@167240ee{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:04:23,773 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:04:23,794 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c7d3c46{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,795 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,795 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,796 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,797 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,797 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,798 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,799 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,800 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,800 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,801 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,802 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,803 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,804 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,804 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,805 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,806 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,807 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,807 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,808 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,814 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410ae9a3{/static,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,815 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c7a975a{/,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,816 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@757d6814{/api,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,817 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4eed46ee{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,818 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4fad94a7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:04:23,820 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:04:23,889 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:04:23,911 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49697.
2018-02-08 09:04:23,912 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:49697
2018-02-08 09:04:23,913 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:04:23,914 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 49697, None)
2018-02-08 09:04:23,919 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:49697 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 49697, None)
2018-02-08 09:04:23,923 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 49697, None)
2018-02-08 09:04:23,923 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 49697, None)
2018-02-08 09:04:24,130 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@20765ed5{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:24,211 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:04:24,212 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:04:24,217 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d691f3d{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:04:24,218 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1e7f2e0f{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:24,219 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@71154f21{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:04:24,219 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2516fc68{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:04:24,223 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d140a7{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:04:25,259 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:04:27,280 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 179.929338 ms
2018-02-08 09:04:27,295 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.040963 ms
2018-02-08 09:04:27,433 INFO[org.apache.spark.SparkContext:54] - Starting job: countByValue at StringIndexer.scala:113
2018-02-08 09:04:27,672 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (countByValue at StringIndexer.scala:113)
2018-02-08 09:04:27,674 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (countByValue at StringIndexer.scala:113) with 2 output partitions
2018-02-08 09:04:27,674 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (countByValue at StringIndexer.scala:113)
2018-02-08 09:04:27,675 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 0)
2018-02-08 09:04:27,676 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 0)
2018-02-08 09:04:27,680 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 0 (MapPartitionsRDD[7] at countByValue at StringIndexer.scala:113), which has no missing parents
2018-02-08 09:04:27,791 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 12.4 KB, free 631.8 MB)
2018-02-08 09:04:27,819 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KB, free 631.8 MB)
2018-02-08 09:04:27,822 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:49697 (size: 6.1 KB, free: 631.8 MB)
2018-02-08 09:04:27,824 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:04:27,836 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[7] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:04:27,837 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 09:04:27,871 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5106 bytes)
2018-02-08 09:04:27,874 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5106 bytes)
2018-02-08 09:04:27,883 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:04:27,884 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 09:04:27,997 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.440003 ms
2018-02-08 09:04:28,063 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1487 bytes result sent to driver
2018-02-08 09:04:28,063 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1444 bytes result sent to driver
2018-02-08 09:04:28,069 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 195 ms on localhost (executor driver) (1/2)
2018-02-08 09:04:28,071 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 211 ms on localhost (executor driver) (2/2)
2018-02-08 09:04:28,072 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:04:28,076 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 0 (countByValue at StringIndexer.scala:113) finished in 0.224 s
2018-02-08 09:04:28,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 09:04:28,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 09:04:28,078 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 1)
2018-02-08 09:04:28,078 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 09:04:28,082 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (ShuffledRDD[8] at countByValue at StringIndexer.scala:113), which has no missing parents
2018-02-08 09:04:28,089 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 631.8 MB)
2018-02-08 09:04:28,092 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1963.0 B, free 631.8 MB)
2018-02-08 09:04:28,093 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:49697 (size: 1963.0 B, free: 631.8 MB)
2018-02-08 09:04:28,094 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:04:28,097 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[8] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:04:28,097 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 09:04:28,104 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 09:04:28,104 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 4621 bytes)
2018-02-08 09:04:28,105 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 3)
2018-02-08 09:04:28,105 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 09:04:28,120 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 2 blocks
2018-02-08 09:04:28,120 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:04:28,122 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 09:04:28,122 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 09:04:28,153 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 1238 bytes result sent to driver
2018-02-08 09:04:28,153 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 3). 1219 bytes result sent to driver
2018-02-08 09:04:28,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 52 ms on localhost (executor driver) (1/2)
2018-02-08 09:04:28,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 3) in 50 ms on localhost (executor driver) (2/2)
2018-02-08 09:04:28,155 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 09:04:28,156 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (countByValue at StringIndexer.scala:113) finished in 0.054 s
2018-02-08 09:04:28,163 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: countByValue at StringIndexer.scala:113, took 0.729939 s
2018-02-08 09:04:28,537 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.907844 ms
2018-02-08 09:04:28,551 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.225923 ms
2018-02-08 09:04:28,661 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.645124 ms
2018-02-08 09:04:28,673 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.102723 ms
2018-02-08 09:04:28,680 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:04:28,686 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@167240ee{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:04:28,689 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:04:28,699 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:04:28,724 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:04:28,725 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:04:28,730 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:04:28,733 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:04:28,737 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:04:28,739 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:04:28,741 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-e1317bec-9b2d-4808-b79d-44dcb59c84d6
2018-02-08 09:05:06,668 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:05:07,336 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:05:07,356 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:05:07,357 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:05:07,357 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:05:07,358 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:05:07,359 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:05:07,705 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 49746.
2018-02-08 09:05:07,721 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:05:07,764 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:05:07,767 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:05:07,767 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:05:07,776 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-4dd805ae-a667-41bc-9675-21cc4f13ac85
2018-02-08 09:05:07,796 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:05:07,842 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:05:07,913 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2618ms
2018-02-08 09:05:07,977 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:05:07,991 INFO[org.spark_project.jetty.server.Server:403] - Started @2698ms
2018-02-08 09:05:08,008 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@3c618176{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:05:08,009 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:05:08,031 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24fb6a80{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,032 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,032 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,033 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,034 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,035 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,036 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,037 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,038 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,039 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,039 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,040 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,041 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,042 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,042 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,043 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,044 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,044 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,045 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,046 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,056 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/static,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,057 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,058 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@649725e3{/api,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,059 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,060 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,062 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:05:08,134 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:05:08,159 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49759.
2018-02-08 09:05:08,160 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:49759
2018-02-08 09:05:08,161 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:05:08,170 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 49759, None)
2018-02-08 09:05:08,178 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:49759 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 49759, None)
2018-02-08 09:05:08,184 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 49759, None)
2018-02-08 09:05:08,185 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 49759, None)
2018-02-08 09:05:08,379 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3b582111{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,460 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:05:08,461 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:05:08,468 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1bdbf9be{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,468 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1da6ee17{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,470 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@15f193b8{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,472 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@304a9d7b{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:08,473 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@347bdeef{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:05:09,510 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:05:11,524 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 173.883896 ms
2018-02-08 09:05:11,538 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.253762 ms
2018-02-08 09:05:11,669 INFO[org.apache.spark.SparkContext:54] - Starting job: countByValue at StringIndexer.scala:113
2018-02-08 09:05:11,892 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (countByValue at StringIndexer.scala:113)
2018-02-08 09:05:11,893 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (countByValue at StringIndexer.scala:113) with 2 output partitions
2018-02-08 09:05:11,894 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (countByValue at StringIndexer.scala:113)
2018-02-08 09:05:11,894 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 0)
2018-02-08 09:05:11,895 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 0)
2018-02-08 09:05:11,899 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 0 (MapPartitionsRDD[7] at countByValue at StringIndexer.scala:113), which has no missing parents
2018-02-08 09:05:12,004 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 12.4 KB, free 631.8 MB)
2018-02-08 09:05:12,034 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KB, free 631.8 MB)
2018-02-08 09:05:12,037 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:49759 (size: 6.1 KB, free: 631.8 MB)
2018-02-08 09:05:12,039 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:05:12,051 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[7] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:05:12,052 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 09:05:12,085 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5106 bytes)
2018-02-08 09:05:12,087 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5106 bytes)
2018-02-08 09:05:12,093 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:05:12,093 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 09:05:12,204 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.983366 ms
2018-02-08 09:05:12,284 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1444 bytes result sent to driver
2018-02-08 09:05:12,284 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1487 bytes result sent to driver
2018-02-08 09:05:12,293 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 205 ms on localhost (executor driver) (1/2)
2018-02-08 09:05:12,294 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 219 ms on localhost (executor driver) (2/2)
2018-02-08 09:05:12,295 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:05:12,300 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 0 (countByValue at StringIndexer.scala:113) finished in 0.233 s
2018-02-08 09:05:12,300 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 09:05:12,301 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 09:05:12,301 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 1)
2018-02-08 09:05:12,301 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 09:05:12,304 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (ShuffledRDD[8] at countByValue at StringIndexer.scala:113), which has no missing parents
2018-02-08 09:05:12,310 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 631.8 MB)
2018-02-08 09:05:12,313 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1963.0 B, free 631.8 MB)
2018-02-08 09:05:12,313 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:49759 (size: 1963.0 B, free: 631.8 MB)
2018-02-08 09:05:12,314 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:05:12,316 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[8] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:05:12,316 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 09:05:12,320 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 09:05:12,321 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 4621 bytes)
2018-02-08 09:05:12,321 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 3)
2018-02-08 09:05:12,321 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 09:05:12,334 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 2 blocks
2018-02-08 09:05:12,334 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:05:12,336 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 09:05:12,336 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 09:05:12,359 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 3). 1262 bytes result sent to driver
2018-02-08 09:05:12,359 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 1238 bytes result sent to driver
2018-02-08 09:05:12,361 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 43 ms on localhost (executor driver) (1/2)
2018-02-08 09:05:12,362 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 3) in 42 ms on localhost (executor driver) (2/2)
2018-02-08 09:05:12,362 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 09:05:12,363 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (countByValue at StringIndexer.scala:113) finished in 0.045 s
2018-02-08 09:05:12,368 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: countByValue at StringIndexer.scala:113, took 0.698605 s
2018-02-08 09:05:12,787 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 19.046726 ms
2018-02-08 09:05:12,804 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.773123 ms
2018-02-08 09:05:12,824 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:05:12,828 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@3c618176{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:05:12,830 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:05:12,838 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:05:12,856 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:05:12,856 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:05:12,861 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:05:12,862 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:05:12,866 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:05:12,866 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:05:12,867 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-984307eb-7738-4fb5-8c4f-acdded18e5a8
2018-02-08 09:05:35,984 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:05:36,430 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:05:36,451 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:05:36,451 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:05:36,453 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:05:36,453 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:05:36,454 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:05:36,802 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 49802.
2018-02-08 09:05:36,848 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:05:36,865 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:05:36,867 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:05:36,868 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:05:36,876 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-678734c2-d8ac-4807-98e1-e90b7bd10162
2018-02-08 09:05:36,896 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:05:36,947 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:05:37,021 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2526ms
2018-02-08 09:05:37,086 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:05:37,098 INFO[org.spark_project.jetty.server.Server:403] - Started @2603ms
2018-02-08 09:05:37,117 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@1cd61bd3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:05:37,117 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:05:37,140 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c7d3c46{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,140 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,141 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,142 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,143 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,143 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,144 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,145 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,147 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,148 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,148 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,149 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,150 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,150 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,151 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,152 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,152 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,153 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,154 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,155 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,162 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410ae9a3{/static,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,163 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c7a975a{/,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,164 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@757d6814{/api,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,165 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4eed46ee{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,165 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4fad94a7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,167 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:05:37,239 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:05:37,264 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49815.
2018-02-08 09:05:37,265 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:49815
2018-02-08 09:05:37,266 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:05:37,268 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 49815, None)
2018-02-08 09:05:37,276 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:49815 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 49815, None)
2018-02-08 09:05:37,285 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 49815, None)
2018-02-08 09:05:37,287 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 49815, None)
2018-02-08 09:05:37,476 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@20765ed5{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,582 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:05:37,583 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:05:37,590 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d691f3d{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,590 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1e7f2e0f{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,591 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@71154f21{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,592 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2516fc68{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:05:37,593 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d140a7{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:05:38,637 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:05:38,712 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:05:38,717 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@1cd61bd3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:05:38,719 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:05:38,727 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:05:38,733 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:05:38,733 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:05:38,738 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:05:38,741 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:05:38,743 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:05:38,743 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:05:38,744 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-61348d5e-c648-40dc-b541-2cb0bf9e5a10
2018-02-08 09:06:17,485 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:06:18,122 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:06:18,147 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:06:18,147 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:06:18,148 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:06:18,149 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:06:18,150 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:06:18,528 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 49875.
2018-02-08 09:06:18,547 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:06:18,595 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:06:18,598 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:06:18,599 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:06:18,608 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-daeb12ba-2615-41d5-bddd-55adec726c80
2018-02-08 09:06:18,629 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:06:18,680 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:06:18,755 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2677ms
2018-02-08 09:06:18,826 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:06:18,840 INFO[org.spark_project.jetty.server.Server:403] - Started @2763ms
2018-02-08 09:06:18,861 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@65531ceb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:06:18,861 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:06:18,884 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c7d3c46{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,886 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,886 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,887 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,888 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,888 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,889 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,890 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,890 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,891 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,891 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,893 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,895 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,897 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,898 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,899 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,900 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,902 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,902 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,903 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,910 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410ae9a3{/static,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,911 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c7a975a{/,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,912 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@757d6814{/api,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,913 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4eed46ee{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,914 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4fad94a7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:06:18,916 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:06:18,996 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:06:19,024 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49888.
2018-02-08 09:06:19,025 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:49888
2018-02-08 09:06:19,026 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:06:19,029 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 49888, None)
2018-02-08 09:06:19,035 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:49888 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 49888, None)
2018-02-08 09:06:19,043 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 49888, None)
2018-02-08 09:06:19,043 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 49888, None)
2018-02-08 09:06:19,245 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@20765ed5{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:19,326 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:06:19,329 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:06:19,336 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d269ed7{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:06:19,338 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41c89d2f{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:19,339 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1da6ee17{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:06:19,340 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3c818ac4{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:19,342 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6bfdb014{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:06:20,522 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:06:22,899 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 220.37639 ms
2018-02-08 09:06:22,931 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.183365 ms
2018-02-08 09:06:22,953 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:06:22,958 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@65531ceb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:06:22,961 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:06:22,968 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:06:22,975 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:06:22,976 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:06:22,981 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:06:22,984 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:06:22,986 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:06:22,987 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:06:22,987 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-5e3e47db-fd0b-439b-8ec1-715a0789cdde
2018-02-08 09:06:34,566 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:06:35,098 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:06:35,118 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:06:35,118 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:06:35,119 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:06:35,120 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:06:35,120 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:06:35,466 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 49928.
2018-02-08 09:06:35,514 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:06:35,531 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:06:35,533 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:06:35,534 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:06:35,542 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-38e169dc-5f1b-463f-abcb-5230915c4675
2018-02-08 09:06:35,563 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:06:35,613 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:06:35,691 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2546ms
2018-02-08 09:06:35,752 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:06:35,765 INFO[org.spark_project.jetty.server.Server:403] - Started @2622ms
2018-02-08 09:06:35,784 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@4ede2c76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:06:35,784 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:06:35,805 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c7d3c46{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,806 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,807 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,808 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,808 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,809 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,809 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,810 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,811 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,812 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,812 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,813 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,814 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,814 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,815 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,816 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,816 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,817 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,818 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,819 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,825 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410ae9a3{/static,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,826 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c7a975a{/,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,827 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@757d6814{/api,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,828 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4eed46ee{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,828 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4fad94a7{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:06:35,830 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:06:35,902 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:06:35,932 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49941.
2018-02-08 09:06:35,933 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:49941
2018-02-08 09:06:35,935 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:06:35,937 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 49941, None)
2018-02-08 09:06:35,941 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:49941 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 49941, None)
2018-02-08 09:06:35,946 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 49941, None)
2018-02-08 09:06:35,948 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 49941, None)
2018-02-08 09:06:36,108 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@20765ed5{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:36,175 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:06:36,176 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:06:36,182 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d691f3d{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:06:36,185 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1e7f2e0f{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:36,186 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@71154f21{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:06:36,187 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2516fc68{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:06:36,189 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d140a7{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:06:37,220 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:06:38,983 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 196.619903 ms
2018-02-08 09:06:39,009 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.333444 ms
2018-02-08 09:06:39,059 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:06:39,063 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@4ede2c76{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:06:39,065 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:06:39,072 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:06:39,078 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:06:39,078 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:06:39,083 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:06:39,086 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:06:39,089 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:06:39,089 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:06:39,090 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-a61f29ed-e968-4180-8bf4-cd6977d80526
2018-02-08 09:07:00,510 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:07:01,242 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:07:01,261 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:07:01,262 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:07:01,262 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:07:01,263 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:07:01,264 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:07:01,640 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 49979.
2018-02-08 09:07:01,688 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:07:01,705 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:07:01,708 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:07:01,709 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:07:01,719 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-2ba476d1-bcdf-4221-a9e5-dd333a8780ea
2018-02-08 09:07:01,745 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:07:01,813 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:07:01,891 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2945ms
2018-02-08 09:07:01,968 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:07:01,983 INFO[org.spark_project.jetty.server.Server:403] - Started @3038ms
2018-02-08 09:07:02,002 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@427b5f92{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:07:02,003 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:07:02,025 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24fb6a80{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,025 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,026 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,028 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,028 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,029 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,029 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,031 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,032 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,033 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,033 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,034 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,035 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,036 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,037 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,037 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,038 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,039 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,039 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,040 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,047 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/static,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,048 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,050 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@649725e3{/api,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,050 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,051 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,053 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:07:02,134 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:07:02,159 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49992.
2018-02-08 09:07:02,160 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:49992
2018-02-08 09:07:02,161 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:07:02,162 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 49992, None)
2018-02-08 09:07:02,166 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:49992 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 49992, None)
2018-02-08 09:07:02,171 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 49992, None)
2018-02-08 09:07:02,172 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 49992, None)
2018-02-08 09:07:02,349 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3b582111{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,421 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:07:02,422 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:07:02,430 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,431 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410e94e{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,431 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@78d39a69{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,432 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b69d40d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:02,433 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@72889280{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:07:03,655 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:07:03,707 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:07:03,712 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@427b5f92{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:07:03,714 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:07:03,721 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:07:03,728 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:07:03,729 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:07:03,734 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:07:03,736 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:07:03,739 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:07:03,739 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:07:03,740 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-9504568a-7b7d-423c-94c8-7f476c0e1b94
2018-02-08 09:07:42,743 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:07:43,566 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:07:43,587 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:07:43,588 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:07:43,588 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:07:43,589 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:07:43,589 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:07:43,950 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 50053.
2018-02-08 09:07:43,998 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:07:44,015 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:07:44,018 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:07:44,018 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:07:44,028 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-a483cb90-8c35-47e2-a0f8-394662515e07
2018-02-08 09:07:44,054 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:07:44,158 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:07:44,272 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @3230ms
2018-02-08 09:07:44,342 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:07:44,354 INFO[org.spark_project.jetty.server.Server:403] - Started @3313ms
2018-02-08 09:07:44,374 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@163fa18a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:07:44,375 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:07:44,403 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24fb6a80{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,405 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,406 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,407 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,407 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,408 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,409 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,410 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,417 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,419 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,421 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,422 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,423 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,424 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,424 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,425 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,426 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,426 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,431 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,433 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,439 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/static,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,440 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,441 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@649725e3{/api,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,442 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,443 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,445 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:07:44,523 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:07:44,545 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50066.
2018-02-08 09:07:44,546 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:50066
2018-02-08 09:07:44,547 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:07:44,551 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 50066, None)
2018-02-08 09:07:44,555 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:50066 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 50066, None)
2018-02-08 09:07:44,560 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 50066, None)
2018-02-08 09:07:44,561 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 50066, None)
2018-02-08 09:07:44,736 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3b582111{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,796 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:07:44,797 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:07:44,802 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410e94e{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,803 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1bdbf9be{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,804 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b69d40d{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,805 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@15f193b8{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:07:44,807 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4aa3d36{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:07:46,036 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:07:48,545 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 216.371589 ms
2018-02-08 09:07:48,715 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at RowMatrix.scala:419
2018-02-08 09:07:48,733 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (treeAggregate at RowMatrix.scala:419) with 2 output partitions
2018-02-08 09:07:48,734 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (treeAggregate at RowMatrix.scala:419)
2018-02-08 09:07:48,734 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:07:48,736 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:07:48,741 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:419), which has no missing parents
2018-02-08 09:07:48,952 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 8.5 KB, free 631.8 MB)
2018-02-08 09:07:48,984 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 631.8 MB)
2018-02-08 09:07:48,986 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:50066 (size: 4.5 KB, free: 631.8 MB)
2018-02-08 09:07:48,988 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:07:49,000 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:419) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:07:49,001 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 09:07:49,035 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5083 bytes)
2018-02-08 09:07:49,037 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5196 bytes)
2018-02-08 09:07:49,043 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 09:07:49,043 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:07:49,129 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.423363 ms
2018-02-08 09:07:49,155 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1679 bytes result sent to driver
2018-02-08 09:07:49,155 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1679 bytes result sent to driver
2018-02-08 09:07:49,163 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 136 ms on localhost (executor driver) (1/2)
2018-02-08 09:07:49,165 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 128 ms on localhost (executor driver) (2/2)
2018-02-08 09:07:49,166 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:07:49,170 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (treeAggregate at RowMatrix.scala:419) finished in 0.154 s
2018-02-08 09:07:49,176 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: treeAggregate at RowMatrix.scala:419, took 0.460829 s
2018-02-08 09:07:50,045 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 34.476171 ms
2018-02-08 09:07:50,062 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.052804 ms
2018-02-08 09:07:50,079 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:07:50,083 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@163fa18a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:07:50,085 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:07:50,093 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:07:50,103 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:07:50,104 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:07:50,108 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:07:50,110 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:07:50,113 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:07:50,113 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:07:50,115 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-db5d5808-0314-4eb7-b702-725e40c56408
2018-02-08 09:08:49,893 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:08:50,640 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:08:50,665 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:08:50,665 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:08:50,666 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:08:50,666 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:08:50,667 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:08:51,018 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 50150.
2018-02-08 09:08:51,063 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:08:51,080 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:08:51,083 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:08:51,084 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:08:51,093 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-ade493f6-a56b-4e13-85d6-9deefda778fd
2018-02-08 09:08:51,114 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:08:51,160 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:08:51,233 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2889ms
2018-02-08 09:08:51,299 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:08:51,312 INFO[org.spark_project.jetty.server.Server:403] - Started @2970ms
2018-02-08 09:08:51,331 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@24bdb479{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:08:51,331 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:08:51,354 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@48c35007{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,355 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,355 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,356 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,357 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,358 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,359 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,361 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,362 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,363 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,364 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,365 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,365 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,367 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,367 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,368 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,369 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,370 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,371 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,372 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410ae9a3{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,379 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@d5ae57e{/static,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,380 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@757d6814{/,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,381 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3c0fae6c{/api,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,381 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4fad94a7{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,382 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6326d182{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,384 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:08:51,460 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:08:51,491 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50164.
2018-02-08 09:08:51,492 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:50164
2018-02-08 09:08:51,499 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:08:51,507 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 50164, None)
2018-02-08 09:08:51,526 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:50164 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 50164, None)
2018-02-08 09:08:51,530 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 50164, None)
2018-02-08 09:08:51,531 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 50164, None)
2018-02-08 09:08:51,744 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2899a8db{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,821 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:08:51,822 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:08:51,829 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41c89d2f{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,830 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d691f3d{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,830 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3c818ac4{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,831 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@71154f21{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:08:51,832 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@606fc505{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:08:52,824 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:08:55,155 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 189.88742 ms
2018-02-08 09:08:55,171 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.822083 ms
2018-02-08 09:08:55,253 INFO[org.apache.spark.SparkContext:54] - Starting job: take at Imputer.scala:141
2018-02-08 09:08:55,268 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (take at Imputer.scala:141) with 1 output partitions
2018-02-08 09:08:55,268 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (take at Imputer.scala:141)
2018-02-08 09:08:55,269 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:08:55,270 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:08:55,274 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[3] at take at Imputer.scala:141), which has no missing parents
2018-02-08 09:08:55,495 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 6.2 KB, free 631.8 MB)
2018-02-08 09:08:55,526 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.1 KB, free 631.8 MB)
2018-02-08 09:08:55,528 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:50164 (size: 3.1 KB, free: 631.8 MB)
2018-02-08 09:08:55,530 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:08:55,543 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at take at Imputer.scala:141) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:08:55,544 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
2018-02-08 09:08:55,583 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5052 bytes)
2018-02-08 09:08:55,592 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:08:55,659 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1166 bytes result sent to driver
2018-02-08 09:08:55,664 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 95 ms on localhost (executor driver) (1/1)
2018-02-08 09:08:55,666 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:08:55,671 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (take at Imputer.scala:141) finished in 0.111 s
2018-02-08 09:08:55,676 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: take at Imputer.scala:141, took 0.422528 s
2018-02-08 09:08:55,698 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.160643 ms
2018-02-08 09:08:55,920 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 23.275207 ms
2018-02-08 09:08:55,952 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.963206 ms
2018-02-08 09:08:55,991 INFO[org.apache.spark.SparkContext:54] - Starting job: first at Imputer.scala:146
2018-02-08 09:08:55,994 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (first at Imputer.scala:146)
2018-02-08 09:08:55,995 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (first at Imputer.scala:146) with 1 output partitions
2018-02-08 09:08:55,995 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (first at Imputer.scala:146)
2018-02-08 09:08:55,995 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 1)
2018-02-08 09:08:55,995 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 1)
2018-02-08 09:08:55,996 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at first at Imputer.scala:146), which has no missing parents
2018-02-08 09:08:56,009 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 10.9 KB, free 631.8 MB)
2018-02-08 09:08:56,011 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KB, free 631.8 MB)
2018-02-08 09:08:56,012 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:50164 (size: 5.2 KB, free: 631.8 MB)
2018-02-08 09:08:56,013 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:08:56,015 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at first at Imputer.scala:146) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:08:56,015 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 09:08:56,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5041 bytes)
2018-02-08 09:08:56,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 5082 bytes)
2018-02-08 09:08:56,018 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
2018-02-08 09:08:56,018 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 2)
2018-02-08 09:08:56,070 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 2). 1565 bytes result sent to driver
2018-02-08 09:08:56,070 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1565 bytes result sent to driver
2018-02-08 09:08:56,072 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 2) in 55 ms on localhost (executor driver) (1/2)
2018-02-08 09:08:56,073 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 57 ms on localhost (executor driver) (2/2)
2018-02-08 09:08:56,073 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 09:08:56,074 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (first at Imputer.scala:146) finished in 0.058 s
2018-02-08 09:08:56,074 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 09:08:56,075 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 09:08:56,075 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 2)
2018-02-08 09:08:56,076 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 09:08:56,079 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[10] at first at Imputer.scala:146), which has no missing parents
2018-02-08 09:08:56,087 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 8.1 KB, free 631.8 MB)
2018-02-08 09:08:56,089 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 631.8 MB)
2018-02-08 09:08:56,090 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:50164 (size: 4.2 KB, free: 631.8 MB)
2018-02-08 09:08:56,091 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:08:56,092 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at first at Imputer.scala:146) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:08:56,092 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 09:08:56,096 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, ANY, 4726 bytes)
2018-02-08 09:08:56,097 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 09:08:56,112 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 2 blocks
2018-02-08 09:08:56,113 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 09:08:56,129 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 1551 bytes result sent to driver
2018-02-08 09:08:56,131 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 35 ms on localhost (executor driver) (1/1)
2018-02-08 09:08:56,131 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 09:08:56,132 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (first at Imputer.scala:146) finished in 0.036 s
2018-02-08 09:08:56,133 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: first at Imputer.scala:146, took 0.140458 s
2018-02-08 09:08:56,141 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.369282 ms
2018-02-08 09:08:56,220 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 25.925768 ms
2018-02-08 09:08:56,235 INFO[org.apache.spark.SparkContext:54] - Starting job: take at Imputer.scala:141
2018-02-08 09:08:56,236 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (take at Imputer.scala:141) with 1 output partitions
2018-02-08 09:08:56,236 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (take at Imputer.scala:141)
2018-02-08 09:08:56,236 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:08:56,236 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:08:56,237 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[14] at take at Imputer.scala:141), which has no missing parents
2018-02-08 09:08:56,241 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 6.2 KB, free 631.8 MB)
2018-02-08 09:08:56,244 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.1 KB, free 631.8 MB)
2018-02-08 09:08:56,244 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:50164 (size: 3.1 KB, free: 631.8 MB)
2018-02-08 09:08:56,245 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:08:56,247 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[14] at take at Imputer.scala:141) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:08:56,247 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 09:08:56,248 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5052 bytes)
2018-02-08 09:08:56,248 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 09:08:56,255 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 1112 bytes result sent to driver
2018-02-08 09:08:56,256 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
2018-02-08 09:08:56,257 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 09:08:56,257 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (take at Imputer.scala:141) finished in 0.009 s
2018-02-08 09:08:56,258 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: take at Imputer.scala:141, took 0.022142 s
2018-02-08 09:08:56,264 INFO[org.apache.spark.SparkContext:54] - Starting job: take at Imputer.scala:141
2018-02-08 09:08:56,265 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (take at Imputer.scala:141) with 1 output partitions
2018-02-08 09:08:56,265 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (take at Imputer.scala:141)
2018-02-08 09:08:56,265 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:08:56,265 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:08:56,266 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[14] at take at Imputer.scala:141), which has no missing parents
2018-02-08 09:08:56,268 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 6.2 KB, free 631.7 MB)
2018-02-08 09:08:56,271 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.1 KB, free 631.7 MB)
2018-02-08 09:08:56,271 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:50164 (size: 3.1 KB, free: 631.8 MB)
2018-02-08 09:08:56,272 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:08:56,273 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at take at Imputer.scala:141) (first 15 tasks are for partitions Vector(1))
2018-02-08 09:08:56,273 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
2018-02-08 09:08:56,274 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 5093 bytes)
2018-02-08 09:08:56,275 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 09:08:56,280 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 1080 bytes result sent to driver
2018-02-08 09:08:56,280 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
2018-02-08 09:08:56,281 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 09:08:56,281 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (take at Imputer.scala:141) finished in 0.007 s
2018-02-08 09:08:56,281 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: take at Imputer.scala:141, took 0.017087 s
2018-02-08 09:08:56,335 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.245765 ms
2018-02-08 09:08:56,360 INFO[org.apache.spark.SparkContext:54] - Starting job: first at Imputer.scala:146
2018-02-08 09:08:56,361 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 18 (first at Imputer.scala:146)
2018-02-08 09:08:56,362 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (first at Imputer.scala:146) with 1 output partitions
2018-02-08 09:08:56,362 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (first at Imputer.scala:146)
2018-02-08 09:08:56,362 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 5)
2018-02-08 09:08:56,362 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 5)
2018-02-08 09:08:56,363 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 5 (MapPartitionsRDD[18] at first at Imputer.scala:146), which has no missing parents
2018-02-08 09:08:56,367 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 10.9 KB, free 631.7 MB)
2018-02-08 09:08:56,371 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.2 KB, free 631.7 MB)
2018-02-08 09:08:56,372 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:50164 (size: 5.2 KB, free: 631.8 MB)
2018-02-08 09:08:56,373 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:08:56,375 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[18] at first at Imputer.scala:146) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:08:56,375 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 2 tasks
2018-02-08 09:08:56,376 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5041 bytes)
2018-02-08 09:08:56,378 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 5.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 5082 bytes)
2018-02-08 09:08:56,379 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 6)
2018-02-08 09:08:56,379 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 5.0 (TID 7)
2018-02-08 09:08:56,401 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 6). 1522 bytes result sent to driver
2018-02-08 09:08:56,413 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 5.0 (TID 7). 1522 bytes result sent to driver
2018-02-08 09:08:56,417 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 6) in 41 ms on localhost (executor driver) (1/2)
2018-02-08 09:08:56,424 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 5.0 (TID 7) in 48 ms on localhost (executor driver) (2/2)
2018-02-08 09:08:56,424 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 09:08:56,427 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 5 (first at Imputer.scala:146) finished in 0.050 s
2018-02-08 09:08:56,427 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 09:08:56,427 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 09:08:56,427 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 6)
2018-02-08 09:08:56,428 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 09:08:56,429 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[21] at first at Imputer.scala:146), which has no missing parents
2018-02-08 09:08:56,440 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 8.1 KB, free 631.7 MB)
2018-02-08 09:08:56,442 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.2 KB, free 631.7 MB)
2018-02-08 09:08:56,443 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:50164 (size: 4.2 KB, free: 631.8 MB)
2018-02-08 09:08:56,444 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:08:56,445 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[21] at first at Imputer.scala:146) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:08:56,445 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
2018-02-08 09:08:56,446 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 8, localhost, executor driver, partition 0, ANY, 4726 bytes)
2018-02-08 09:08:56,446 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 8)
2018-02-08 09:08:56,449 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 2 blocks
2018-02-08 09:08:56,450 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:08:56,452 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 8). 1465 bytes result sent to driver
2018-02-08 09:08:56,453 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 8) in 8 ms on localhost (executor driver) (1/1)
2018-02-08 09:08:56,455 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 09:08:56,456 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (first at Imputer.scala:146) finished in 0.011 s
2018-02-08 09:08:56,456 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: first at Imputer.scala:146, took 0.095707 s
2018-02-08 09:08:56,524 INFO[org.apache.spark.SparkContext:54] - Starting job: head at Imputer.scala:201
2018-02-08 09:08:56,525 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (head at Imputer.scala:201) with 1 output partitions
2018-02-08 09:08:56,525 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 7 (head at Imputer.scala:201)
2018-02-08 09:08:56,525 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:08:56,525 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:08:56,526 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 7 (MapPartitionsRDD[25] at head at Imputer.scala:201), which has no missing parents
2018-02-08 09:08:56,534 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 7.1 KB, free 631.7 MB)
2018-02-08 09:08:56,536 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.9 KB, free 631.7 MB)
2018-02-08 09:08:56,538 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:50164 (size: 3.9 KB, free: 631.8 MB)
2018-02-08 09:08:56,538 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:08:56,539 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[25] at head at Imputer.scala:201) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:08:56,539 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
2018-02-08 09:08:56,540 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 4835 bytes)
2018-02-08 09:08:56,541 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 9)
2018-02-08 09:08:56,557 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.912003 ms
2018-02-08 09:08:56,560 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 9). 956 bytes result sent to driver
2018-02-08 09:08:56,561 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 9) in 22 ms on localhost (executor driver) (1/1)
2018-02-08 09:08:56,561 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-02-08 09:08:56,561 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 7 (head at Imputer.scala:201) finished in 0.022 s
2018-02-08 09:08:56,562 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: head at Imputer.scala:201, took 0.037929 s
2018-02-08 09:08:56,567 INFO[org.apache.spark.SparkContext:54] - Starting job: head at Imputer.scala:201
2018-02-08 09:08:56,568 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (head at Imputer.scala:201) with 1 output partitions
2018-02-08 09:08:56,568 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 8 (head at Imputer.scala:201)
2018-02-08 09:08:56,568 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:08:56,568 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:08:56,569 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 8 (MapPartitionsRDD[25] at head at Imputer.scala:201), which has no missing parents
2018-02-08 09:08:56,570 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 7.1 KB, free 631.7 MB)
2018-02-08 09:08:56,572 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.9 KB, free 631.7 MB)
2018-02-08 09:08:56,574 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:50164 (size: 3.9 KB, free: 631.8 MB)
2018-02-08 09:08:56,575 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:08:56,577 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[25] at head at Imputer.scala:201) (first 15 tasks are for partitions Vector(1))
2018-02-08 09:08:56,577 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 1 tasks
2018-02-08 09:08:56,579 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 5025 bytes)
2018-02-08 09:08:56,579 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 10)
2018-02-08 09:08:56,608 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 23.825608 ms
2018-02-08 09:08:56,611 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 10). 975 bytes result sent to driver
2018-02-08 09:08:56,612 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 10) in 35 ms on localhost (executor driver) (1/1)
2018-02-08 09:08:56,612 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 09:08:56,614 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 8 (head at Imputer.scala:201) finished in 0.036 s
2018-02-08 09:08:56,616 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: head at Imputer.scala:201, took 0.048712 s
2018-02-08 09:08:56,633 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.980485 ms
2018-02-08 09:08:56,779 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.919043 ms
2018-02-08 09:08:56,796 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.334725 ms
2018-02-08 09:08:56,824 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:08:56,832 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@24bdb479{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:08:56,836 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:08:56,850 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:08:56,923 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:08:56,923 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:08:56,929 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:08:56,931 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:08:56,934 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:08:56,935 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:08:56,936 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-f0e3651a-17da-4905-ba28-78a8e5852e74
2018-02-08 09:13:13,177 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:13:13,667 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:13:13,686 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:13:13,687 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:13:13,688 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:13:13,688 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:13:13,689 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:13:14,043 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 50406.
2018-02-08 09:13:14,061 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:13:14,105 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:13:14,108 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:13:14,108 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:13:14,117 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-bd91244c-7e7e-4077-b7e6-f4447123ac8a
2018-02-08 09:13:14,138 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:13:14,189 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:13:14,262 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2674ms
2018-02-08 09:13:14,328 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:13:14,341 INFO[org.spark_project.jetty.server.Server:403] - Started @2755ms
2018-02-08 09:13:14,360 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@321eba00{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:13:14,360 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:13:14,382 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@631e06ab{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,383 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,384 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,385 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,386 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,387 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,388 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,389 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,390 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,390 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,391 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,392 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,392 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,393 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,394 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410ae9a3{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,394 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@d5ae57e{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,395 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e242b4d{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,397 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@592e843a{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,399 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@423e4cbb{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,400 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@43b4fe19{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,410 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1536602f{/static,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,411 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6326d182{/,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,413 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@716a7124{/api,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,414 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@72bd06ca{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,415 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5dbe30be{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,417 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:13:14,497 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:13:14,544 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50419.
2018-02-08 09:13:14,546 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:50419
2018-02-08 09:13:14,548 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:13:14,551 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 50419, None)
2018-02-08 09:13:14,558 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:50419 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 50419, None)
2018-02-08 09:13:14,584 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 50419, None)
2018-02-08 09:13:14,584 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 50419, None)
2018-02-08 09:13:14,796 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5710768a{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,867 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:13:14,868 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:13:14,875 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@72889280{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,876 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4aa3d36{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,877 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@77e80a5e{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,878 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@240139e1{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:13:14,880 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@55f45b92{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:13:16,062 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:13:18,201 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 206.119106 ms
2018-02-08 09:13:18,225 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.959043 ms
2018-02-08 09:13:18,245 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:13:18,250 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@321eba00{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:13:18,252 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:13:18,260 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:13:18,266 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:13:18,267 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:13:18,271 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:13:18,274 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:13:18,277 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:13:18,277 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:13:18,278 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-76041049-8317-41f2-bea5-5295d82cbda8
2018-02-08 09:14:41,357 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:14:41,969 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:14:41,989 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:14:41,990 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:14:41,990 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:14:41,991 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:14:41,991 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:14:42,340 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 50518.
2018-02-08 09:14:42,384 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:14:42,401 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:14:42,404 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:14:42,405 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:14:42,414 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-32779d9c-e067-4cc7-914f-20393b03779b
2018-02-08 09:14:42,434 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:14:42,481 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:14:42,555 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2671ms
2018-02-08 09:14:42,621 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:14:42,634 INFO[org.spark_project.jetty.server.Server:403] - Started @2750ms
2018-02-08 09:14:42,651 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@1ce61929{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:14:42,651 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:14:42,674 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a3591c5{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,675 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,676 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,677 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,677 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,678 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,679 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,680 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,681 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,682 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,683 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,685 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,686 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,687 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,688 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,689 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68759011{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,690 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@305f031{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,691 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d1f7216{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,692 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6e16b8b5{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,693 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@25ddbbbb{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,700 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4ebea12c{/static,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,701 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5241cf67{/,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,702 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@77192705{/api,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,702 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@89c10b7{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,703 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4fe89c24{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:14:42,705 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:14:42,783 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:14:42,811 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50531.
2018-02-08 09:14:42,812 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:50531
2018-02-08 09:14:42,813 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:14:42,815 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 50531, None)
2018-02-08 09:14:42,822 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:50531 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 50531, None)
2018-02-08 09:14:42,825 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 50531, None)
2018-02-08 09:14:42,826 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 50531, None)
2018-02-08 09:14:42,996 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@199e4c2b{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:43,060 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:14:43,061 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:14:43,068 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2516fc68{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:14:43,069 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6bfdb014{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:43,070 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@347bdeef{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:14:43,070 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7f34a967{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:14:43,072 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@253c1256{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:14:44,040 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:14:45,198 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:14:45,202 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@1ce61929{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:14:45,205 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:14:45,212 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:14:45,221 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:14:45,221 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:14:45,226 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:14:45,229 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:14:45,231 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:14:45,232 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:14:45,233 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-7a7f52fa-964e-47ac-a297-0b21d4c842e2
2018-02-08 09:17:30,495 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:17:31,065 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:17:31,086 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:17:31,087 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:17:31,087 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:17:31,088 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:17:31,089 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:17:31,437 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 50699.
2018-02-08 09:17:31,455 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:17:31,499 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:17:31,503 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:17:31,504 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:17:31,514 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-28465674-883f-4809-815d-0d0de4d83d3c
2018-02-08 09:17:31,539 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:17:31,595 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:17:31,702 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2635ms
2018-02-08 09:17:31,767 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:17:31,780 INFO[org.spark_project.jetty.server.Server:403] - Started @2714ms
2018-02-08 09:17:31,800 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@4f07a92e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:17:31,800 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:17:31,822 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7383eae2{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,823 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@482d776b{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,824 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,825 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,825 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,826 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,827 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,829 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,830 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,831 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,831 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,832 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,832 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,833 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,833 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,834 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,835 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,836 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,838 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,839 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,844 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/static,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,845 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@235f4c10{/,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,846 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c7a975a{/api,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,846 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@52b56a3e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,847 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4eed46ee{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:17:31,848 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:17:31,927 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:17:31,954 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50714.
2018-02-08 09:17:31,955 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:50714
2018-02-08 09:17:31,956 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:17:31,958 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 50714, None)
2018-02-08 09:17:31,964 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:50714 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 50714, None)
2018-02-08 09:17:31,970 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 50714, None)
2018-02-08 09:17:31,971 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 50714, None)
2018-02-08 09:17:32,145 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1af1347d{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:32,218 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:17:32,218 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:17:32,231 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3003697{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:17:32,232 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d269ed7{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:32,233 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1bdbf9be{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:17:32,233 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1da6ee17{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:17:32,235 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2516fc68{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:17:33,302 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:17:35,405 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 201.329985 ms
2018-02-08 09:17:35,423 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.205443 ms
2018-02-08 09:17:35,578 INFO[org.apache.spark.SparkContext:54] - Starting job: countByValue at StringIndexer.scala:113
2018-02-08 09:17:35,812 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (countByValue at StringIndexer.scala:113)
2018-02-08 09:17:35,813 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (countByValue at StringIndexer.scala:113) with 2 output partitions
2018-02-08 09:17:35,814 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (countByValue at StringIndexer.scala:113)
2018-02-08 09:17:35,814 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 0)
2018-02-08 09:17:35,815 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 0)
2018-02-08 09:17:35,819 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 0 (MapPartitionsRDD[7] at countByValue at StringIndexer.scala:113), which has no missing parents
2018-02-08 09:17:35,936 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 12.5 KB, free 631.8 MB)
2018-02-08 09:17:35,966 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KB, free 631.8 MB)
2018-02-08 09:17:35,969 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:50714 (size: 6.2 KB, free: 631.8 MB)
2018-02-08 09:17:35,971 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:17:35,987 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[7] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:17:35,988 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 09:17:36,027 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5024 bytes)
2018-02-08 09:17:36,030 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5089 bytes)
2018-02-08 09:17:36,046 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 09:17:36,046 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:17:36,156 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.998724 ms
2018-02-08 09:17:36,226 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1487 bytes result sent to driver
2018-02-08 09:17:36,228 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1487 bytes result sent to driver
2018-02-08 09:17:36,239 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 226 ms on localhost (executor driver) (1/2)
2018-02-08 09:17:36,242 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 213 ms on localhost (executor driver) (2/2)
2018-02-08 09:17:36,244 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:17:36,252 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 0 (countByValue at StringIndexer.scala:113) finished in 0.248 s
2018-02-08 09:17:36,252 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 09:17:36,253 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 09:17:36,253 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 1)
2018-02-08 09:17:36,254 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 09:17:36,257 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (ShuffledRDD[8] at countByValue at StringIndexer.scala:113), which has no missing parents
2018-02-08 09:17:36,265 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 3.2 KB, free 631.8 MB)
2018-02-08 09:17:36,267 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1963.0 B, free 631.8 MB)
2018-02-08 09:17:36,268 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:50714 (size: 1963.0 B, free: 631.8 MB)
2018-02-08 09:17:36,269 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:17:36,270 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 1 (ShuffledRDD[8] at countByValue at StringIndexer.scala:113) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:17:36,271 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 09:17:36,277 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 4621 bytes)
2018-02-08 09:17:36,277 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 3, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 09:17:36,278 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 2)
2018-02-08 09:17:36,280 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 3)
2018-02-08 09:17:36,294 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 2 blocks
2018-02-08 09:17:36,294 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:17:36,296 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
2018-02-08 09:17:36,296 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
2018-02-08 09:17:36,311 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 2). 1048 bytes result sent to driver
2018-02-08 09:17:36,312 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 2) in 39 ms on localhost (executor driver) (1/2)
2018-02-08 09:17:36,317 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 3). 1228 bytes result sent to driver
2018-02-08 09:17:36,318 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 3) in 41 ms on localhost (executor driver) (2/2)
2018-02-08 09:17:36,320 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 09:17:36,321 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (countByValue at StringIndexer.scala:113) finished in 0.047 s
2018-02-08 09:17:36,328 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: countByValue at StringIndexer.scala:113, took 0.749091 s
2018-02-08 09:17:36,958 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 19.995847 ms
2018-02-08 09:17:36,973 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.127682 ms
2018-02-08 09:17:36,990 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:17:36,995 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@4f07a92e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:17:36,997 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:17:37,005 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:17:37,022 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:17:37,023 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:17:37,027 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:17:37,029 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:17:37,032 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:17:37,032 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:17:37,033 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-59c91aac-b240-416d-9f77-cf3c8e67521b
2018-02-08 09:18:15,078 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:18:15,714 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:18:15,736 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:18:15,737 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:18:15,737 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:18:15,738 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:18:15,739 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:18:16,093 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 50774.
2018-02-08 09:18:16,111 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:18:16,154 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:18:16,158 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:18:16,158 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:18:16,168 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-5829e31b-3ad1-45bc-8de9-86d84e519e83
2018-02-08 09:18:16,190 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:18:16,242 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:18:16,317 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2679ms
2018-02-08 09:18:16,380 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:18:16,393 INFO[org.spark_project.jetty.server.Server:403] - Started @2758ms
2018-02-08 09:18:16,411 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@93ca9f8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:18:16,412 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:18:16,432 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@18245eb0{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,432 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4052274f{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,433 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,434 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,435 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,436 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,436 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,437 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,438 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,438 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,439 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,440 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,440 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,441 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,442 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,442 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,443 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,444 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,445 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,445 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,452 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/static,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,453 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@743cb8e0{/,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,454 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/api,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,455 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@fd0e5b6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,455 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,457 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:18:16,538 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:18:16,565 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50787.
2018-02-08 09:18:16,566 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:50787
2018-02-08 09:18:16,567 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:18:16,569 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 50787, None)
2018-02-08 09:18:16,574 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:50787 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 50787, None)
2018-02-08 09:18:16,579 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 50787, None)
2018-02-08 09:18:16,580 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 50787, None)
2018-02-08 09:18:16,750 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@632aa1a3{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,813 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:18:16,814 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:18:16,821 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64d43929{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,822 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,823 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1e7f2e0f{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,823 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@78d39a69{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:16,825 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@304a9d7b{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:18:17,861 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:18:19,778 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 194.311742 ms
2018-02-08 09:18:19,934 INFO[org.apache.spark.SparkContext:54] - Starting job: first at ChiSqTest.scala:86
2018-02-08 09:18:19,950 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (first at ChiSqTest.scala:86) with 1 output partitions
2018-02-08 09:18:19,950 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (first at ChiSqTest.scala:86)
2018-02-08 09:18:19,951 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:18:19,952 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:18:19,956 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[4] at map at ChiSqSelector.scala:203), which has no missing parents
2018-02-08 09:18:20,147 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 8.0 KB, free 631.8 MB)
2018-02-08 09:18:20,177 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 631.8 MB)
2018-02-08 09:18:20,180 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:50787 (size: 4.2 KB, free: 631.8 MB)
2018-02-08 09:18:20,182 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:18:20,192 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at ChiSqSelector.scala:203) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:18:20,193 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
2018-02-08 09:18:20,228 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5099 bytes)
2018-02-08 09:18:20,236 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:18:20,314 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.144003 ms
2018-02-08 09:18:20,337 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
2018-02-08 09:18:20,345 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 126 ms on localhost (executor driver) (1/1)
2018-02-08 09:18:20,347 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:18:20,360 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (first at ChiSqTest.scala:86) finished in 0.147 s
2018-02-08 09:18:20,366 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: first at ChiSqTest.scala:86, took 0.432091 s
2018-02-08 09:18:20,440 INFO[org.apache.spark.SparkContext:54] - Starting job: countByValue at ChiSqTest.scala:124
2018-02-08 09:18:20,447 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 7 (countByValue at ChiSqTest.scala:124)
2018-02-08 09:18:20,450 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (countByValue at ChiSqTest.scala:124) with 2 output partitions
2018-02-08 09:18:20,451 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (countByValue at ChiSqTest.scala:124)
2018-02-08 09:18:20,451 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 1)
2018-02-08 09:18:20,451 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 1)
2018-02-08 09:18:20,452 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at countByValue at ChiSqTest.scala:124), which has no missing parents
2018-02-08 09:18:20,459 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 9.4 KB, free 631.8 MB)
2018-02-08 09:18:20,461 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.9 KB, free 631.8 MB)
2018-02-08 09:18:20,462 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:50787 (size: 4.9 KB, free: 631.8 MB)
2018-02-08 09:18:20,463 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:18:20,466 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at countByValue at ChiSqTest.scala:124) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:18:20,467 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 09:18:20,468 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5088 bytes)
2018-02-08 09:18:20,469 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 5217 bytes)
2018-02-08 09:18:20,469 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
2018-02-08 09:18:20,469 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 2)
2018-02-08 09:18:20,945 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 2). 1331 bytes result sent to driver
2018-02-08 09:18:20,945 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1331 bytes result sent to driver
2018-02-08 09:18:20,948 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 481 ms on localhost (executor driver) (1/2)
2018-02-08 09:18:20,948 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 2) in 480 ms on localhost (executor driver) (2/2)
2018-02-08 09:18:20,948 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 09:18:20,950 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (countByValue at ChiSqTest.scala:124) finished in 0.482 s
2018-02-08 09:18:20,950 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 09:18:20,951 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 09:18:20,951 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 2)
2018-02-08 09:18:20,951 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 09:18:20,954 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (ShuffledRDD[8] at countByValue at ChiSqTest.scala:124), which has no missing parents
2018-02-08 09:18:20,959 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 2.8 KB, free 631.8 MB)
2018-02-08 09:18:20,960 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1688.0 B, free 631.8 MB)
2018-02-08 09:18:20,962 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:50787 (size: 1688.0 B, free: 631.8 MB)
2018-02-08 09:18:20,962 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:18:20,963 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 2 (ShuffledRDD[8] at countByValue at ChiSqTest.scala:124) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:18:20,963 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 2 tasks
2018-02-08 09:18:20,969 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 09:18:20,969 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 4, localhost, executor driver, partition 1, ANY, 4621 bytes)
2018-02-08 09:18:20,970 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 4)
2018-02-08 09:18:20,970 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 09:18:20,987 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 2 blocks
2018-02-08 09:18:20,987 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:18:20,989 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 09:18:20,989 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 09:18:21,012 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 1697 bytes result sent to driver
2018-02-08 09:18:21,012 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 4). 1635 bytes result sent to driver
2018-02-08 09:18:21,013 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 46 ms on localhost (executor driver) (1/2)
2018-02-08 09:18:21,013 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 4) in 44 ms on localhost (executor driver) (2/2)
2018-02-08 09:18:21,014 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 09:18:21,014 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (countByValue at ChiSqTest.scala:124) finished in 0.047 s
2018-02-08 09:18:21,018 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: countByValue at ChiSqTest.scala:124, took 0.576778 s
2018-02-08 09:18:21,687 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 33.101131 ms
2018-02-08 09:18:21,708 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.343044 ms
2018-02-08 09:18:21,771 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:18:21,779 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@93ca9f8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:18:21,783 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.11.26:50787 in memory (size: 1688.0 B, free: 631.8 MB)
2018-02-08 09:18:21,785 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:18:21,788 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 97
2018-02-08 09:18:21,798 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:18:21,856 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:18:21,858 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:18:21,860 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:18:21,865 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:18:21,870 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:18:21,871 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:18:21,874 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-addff6f6-20d5-47d8-a4d1-3cd35915c761
2018-02-08 09:18:31,666 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:18:32,327 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:18:32,351 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:18:32,352 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:18:32,352 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:18:32,353 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:18:32,353 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:18:32,704 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 50822.
2018-02-08 09:18:32,723 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:18:32,778 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:18:32,781 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:18:32,781 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:18:32,791 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-ab19e195-e704-44b8-b164-cb0ce104ad9d
2018-02-08 09:18:32,812 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:18:32,859 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:18:32,931 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2674ms
2018-02-08 09:18:32,997 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:18:33,009 INFO[org.spark_project.jetty.server.Server:403] - Started @2753ms
2018-02-08 09:18:33,027 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@872a3b4{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:18:33,028 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:18:33,050 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7383eae2{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,050 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@482d776b{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,051 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,052 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,053 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,054 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,054 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,056 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,057 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,057 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,058 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,058 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,059 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,060 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,062 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,062 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,063 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,064 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,065 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,065 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,074 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/static,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,075 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@235f4c10{/,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,076 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c7a975a{/api,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,076 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@52b56a3e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,079 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4eed46ee{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,081 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:18:33,157 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:18:33,182 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50835.
2018-02-08 09:18:33,183 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:50835
2018-02-08 09:18:33,184 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:18:33,186 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 50835, None)
2018-02-08 09:18:33,188 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:50835 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 50835, None)
2018-02-08 09:18:33,196 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 50835, None)
2018-02-08 09:18:33,196 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 50835, None)
2018-02-08 09:18:33,391 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1af1347d{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,476 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:18:33,478 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:18:33,485 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41c89d2f{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,486 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d691f3d{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,486 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3c818ac4{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,487 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@71154f21{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:33,488 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@606fc505{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:18:34,522 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:18:36,292 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 187.92454 ms
2018-02-08 09:18:36,313 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.361923 ms
2018-02-08 09:18:36,638 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 0
2018-02-08 09:18:36,863 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 09:18:36,864 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 09:18:36,908 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 27.495689 ms
2018-02-08 09:18:36,940 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 26.262728 ms
2018-02-08 09:18:37,861 INFO[org.apache.spark.sql.execution.aggregate.HashAggregateExec:54] - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
2018-02-08 09:18:37,982 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 87.161948 ms
2018-02-08 09:18:38,075 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 147.253487 ms
2018-02-08 09:18:38,078 INFO[org.apache.spark.sql.execution.aggregate.HashAggregateExec:54] - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
2018-02-08 09:18:38,191 INFO[org.apache.spark.SparkContext:54] - Starting job: run at ThreadPoolExecutor.java:1142
2018-02-08 09:18:38,204 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
2018-02-08 09:18:38,205 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (run at ThreadPoolExecutor.java:1142)
2018-02-08 09:18:38,205 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:18:38,206 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:18:38,210 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[4] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-02-08 09:18:38,290 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 30.8 KB, free 631.8 MB)
2018-02-08 09:18:38,324 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.0 KB, free 631.8 MB)
2018-02-08 09:18:38,327 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:50835 (size: 9.0 KB, free: 631.8 MB)
2018-02-08 09:18:38,329 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:18:38,342 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:18:38,343 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 09:18:38,381 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5682 bytes)
2018-02-08 09:18:38,383 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 5682 bytes)
2018-02-08 09:18:38,389 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:18:38,389 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 09:18:38,495 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 26.939529 ms
2018-02-08 09:18:38,533 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1492 bytes result sent to driver
2018-02-08 09:18:38,534 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1466 bytes result sent to driver
2018-02-08 09:18:38,545 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 161 ms on localhost (executor driver) (1/2)
2018-02-08 09:18:38,548 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 178 ms on localhost (executor driver) (2/2)
2018-02-08 09:18:38,549 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:18:38,553 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (run at ThreadPoolExecutor.java:1142) finished in 0.192 s
2018-02-08 09:18:38,560 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: run at ThreadPoolExecutor.java:1142, took 0.367532 s
2018-02-08 09:18:38,599 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 16.034886 ms
2018-02-08 09:18:38,634 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 16.0 MB, free 615.8 MB)
2018-02-08 09:18:38,646 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 785.0 B, free 615.8 MB)
2018-02-08 09:18:38,647 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:50835 (size: 785.0 B, free: 631.8 MB)
2018-02-08 09:18:38,650 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from run at ThreadPoolExecutor.java:1142
2018-02-08 09:18:38,658 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:50835 in memory (size: 9.0 KB, free: 631.8 MB)
2018-02-08 09:18:38,668 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 2
2018-02-08 09:18:38,668 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 1
2018-02-08 09:18:38,820 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 138.909804 ms
2018-02-08 09:18:38,905 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:151
2018-02-08 09:18:38,909 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 9 (show at MachineLeaningSelector.java:151)
2018-02-08 09:18:38,910 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (show at MachineLeaningSelector.java:151) with 1 output partitions
2018-02-08 09:18:38,910 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (show at MachineLeaningSelector.java:151)
2018-02-08 09:18:38,911 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 1)
2018-02-08 09:18:38,911 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 1)
2018-02-08 09:18:38,912 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[9] at show at MachineLeaningSelector.java:151), which has no missing parents
2018-02-08 09:18:38,918 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 99.4 KB, free 615.7 MB)
2018-02-08 09:18:38,921 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 28.9 KB, free 615.7 MB)
2018-02-08 09:18:38,922 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:50835 (size: 28.9 KB, free: 631.8 MB)
2018-02-08 09:18:38,924 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:18:38,926 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[9] at show at MachineLeaningSelector.java:151) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:18:38,926 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 09:18:38,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5671 bytes)
2018-02-08 09:18:38,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 5671 bytes)
2018-02-08 09:18:38,928 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 3)
2018-02-08 09:18:38,928 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 09:18:38,967 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.512645 ms
2018-02-08 09:18:38,982 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 4.620481 ms
2018-02-08 09:18:39,010 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 21.464967 ms
2018-02-08 09:18:39,175 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 2712 bytes result sent to driver
2018-02-08 09:18:39,175 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 3). 2712 bytes result sent to driver
2018-02-08 09:18:39,178 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 251 ms on localhost (executor driver) (1/2)
2018-02-08 09:18:39,180 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 3) in 252 ms on localhost (executor driver) (2/2)
2018-02-08 09:18:39,180 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 09:18:39,181 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (show at MachineLeaningSelector.java:151) finished in 0.255 s
2018-02-08 09:18:39,182 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 09:18:39,183 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 09:18:39,183 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 2)
2018-02-08 09:18:39,184 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 09:18:39,188 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:151), which has no missing parents
2018-02-08 09:18:39,193 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 59.8 KB, free 615.6 MB)
2018-02-08 09:18:39,194 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.5 KB, free 615.6 MB)
2018-02-08 09:18:39,195 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:50835 (size: 20.5 KB, free: 631.8 MB)
2018-02-08 09:18:39,195 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:18:39,196 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:151) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:18:39,196 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 09:18:39,197 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,198 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 4)
2018-02-08 09:18:39,212 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,214 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 09:18:39,225 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 4). 2999 bytes result sent to driver
2018-02-08 09:18:39,226 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 4) in 30 ms on localhost (executor driver) (1/1)
2018-02-08 09:18:39,226 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 09:18:39,228 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (show at MachineLeaningSelector.java:151) finished in 0.032 s
2018-02-08 09:18:39,229 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: show at MachineLeaningSelector.java:151, took 0.323652 s
2018-02-08 09:18:39,235 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:151
2018-02-08 09:18:39,241 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 187 bytes
2018-02-08 09:18:39,244 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (show at MachineLeaningSelector.java:151) with 4 output partitions
2018-02-08 09:18:39,245 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (show at MachineLeaningSelector.java:151)
2018-02-08 09:18:39,245 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 3)
2018-02-08 09:18:39,245 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:18:39,245 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:151), which has no missing parents
2018-02-08 09:18:39,249 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 59.8 KB, free 615.5 MB)
2018-02-08 09:18:39,251 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.5 KB, free 615.5 MB)
2018-02-08 09:18:39,252 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:50835 (size: 20.5 KB, free: 631.7 MB)
2018-02-08 09:18:39,253 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:18:39,253 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:151) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2018-02-08 09:18:39,254 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 4 tasks
2018-02-08 09:18:39,255 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,255 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 4.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,256 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 09:18:39,258 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 4.0 (TID 6)
2018-02-08 09:18:39,262 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,262 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,265 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,266 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,270 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 2956 bytes result sent to driver
2018-02-08 09:18:39,270 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 4.0 (TID 6). 2956 bytes result sent to driver
2018-02-08 09:18:39,270 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 4.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,271 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 4.0 (TID 8, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,271 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 17 ms on localhost (executor driver) (1/4)
2018-02-08 09:18:39,272 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 4.0 (TID 6) in 17 ms on localhost (executor driver) (2/4)
2018-02-08 09:18:39,272 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 4.0 (TID 7)
2018-02-08 09:18:39,273 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 4.0 (TID 8)
2018-02-08 09:18:39,278 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,279 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,278 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,279 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,283 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 4.0 (TID 7). 2956 bytes result sent to driver
2018-02-08 09:18:39,283 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 4.0 (TID 8). 2956 bytes result sent to driver
2018-02-08 09:18:39,286 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 4.0 (TID 7) in 15 ms on localhost (executor driver) (3/4)
2018-02-08 09:18:39,286 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 4.0 (TID 8) in 15 ms on localhost (executor driver) (4/4)
2018-02-08 09:18:39,287 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 09:18:39,288 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (show at MachineLeaningSelector.java:151) finished in 0.034 s
2018-02-08 09:18:39,291 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: show at MachineLeaningSelector.java:151, took 0.055642 s
2018-02-08 09:18:39,295 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:151
2018-02-08 09:18:39,296 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at MachineLeaningSelector.java:151) with 20 output partitions
2018-02-08 09:18:39,296 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (show at MachineLeaningSelector.java:151)
2018-02-08 09:18:39,296 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 5)
2018-02-08 09:18:39,297 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:18:39,297 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:151), which has no missing parents
2018-02-08 09:18:39,305 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 59.8 KB, free 615.5 MB)
2018-02-08 09:18:39,308 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.5 KB, free 615.4 MB)
2018-02-08 09:18:39,309 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:50835 (size: 20.5 KB, free: 631.7 MB)
2018-02-08 09:18:39,310 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:18:39,310 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 20 missing tasks from ResultStage 6 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:151) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19))
2018-02-08 09:18:39,311 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 20 tasks
2018-02-08 09:18:39,314 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 9, localhost, executor driver, partition 5, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,314 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 6.0 (TID 10, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,315 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 9)
2018-02-08 09:18:39,315 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 6.0 (TID 10)
2018-02-08 09:18:39,321 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,321 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,322 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,322 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,327 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 9). 2999 bytes result sent to driver
2018-02-08 09:18:39,330 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 6.0 (TID 11, localhost, executor driver, partition 7, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,331 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 6.0 (TID 10). 2956 bytes result sent to driver
2018-02-08 09:18:39,332 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 9) in 18 ms on localhost (executor driver) (1/20)
2018-02-08 09:18:39,333 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 6.0 (TID 11)
2018-02-08 09:18:39,334 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 6.0 (TID 12, localhost, executor driver, partition 9, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,337 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 6.0 (TID 10) in 23 ms on localhost (executor driver) (2/20)
2018-02-08 09:18:39,338 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 6.0 (TID 12)
2018-02-08 09:18:39,339 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,339 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,343 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 6.0 (TID 11). 2956 bytes result sent to driver
2018-02-08 09:18:39,345 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,345 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,346 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 6.0 (TID 13, localhost, executor driver, partition 10, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,348 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 6.0 (TID 11) in 19 ms on localhost (executor driver) (3/20)
2018-02-08 09:18:39,350 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 6.0 (TID 12). 2956 bytes result sent to driver
2018-02-08 09:18:39,351 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 6.0 (TID 13)
2018-02-08 09:18:39,353 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 6.0 (TID 14, localhost, executor driver, partition 11, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,356 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,357 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,357 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 6.0 (TID 12) in 23 ms on localhost (executor driver) (4/20)
2018-02-08 09:18:39,359 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 6.0 (TID 14)
2018-02-08 09:18:39,363 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 6.0 (TID 13). 2956 bytes result sent to driver
2018-02-08 09:18:39,365 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,365 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,368 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 6.0 (TID 13) in 20 ms on localhost (executor driver) (5/20)
2018-02-08 09:18:39,369 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 6.0 (TID 14). 2999 bytes result sent to driver
2018-02-08 09:18:39,370 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 6.0 (TID 15, localhost, executor driver, partition 12, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,370 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 6.0 (TID 15)
2018-02-08 09:18:39,371 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 6.0 (TID 14) in 19 ms on localhost (executor driver) (6/20)
2018-02-08 09:18:39,374 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 6.0 (TID 16, localhost, executor driver, partition 13, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,374 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 6.0 (TID 16)
2018-02-08 09:18:39,382 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,382 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,386 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,386 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,391 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 6.0 (TID 15). 2956 bytes result sent to driver
2018-02-08 09:18:39,393 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 6.0 (TID 17, localhost, executor driver, partition 14, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,394 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 6.0 (TID 15) in 24 ms on localhost (executor driver) (7/20)
2018-02-08 09:18:39,394 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 6.0 (TID 17)
2018-02-08 09:18:39,403 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,403 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,408 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 6.0 (TID 17). 2999 bytes result sent to driver
2018-02-08 09:18:39,407 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 6.0 (TID 16). 2999 bytes result sent to driver
2018-02-08 09:18:39,409 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 6.0 (TID 18, localhost, executor driver, partition 15, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,409 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 6.0 (TID 19, localhost, executor driver, partition 16, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,415 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 6.0 (TID 18)
2018-02-08 09:18:39,415 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 6.0 (TID 17) in 22 ms on localhost (executor driver) (8/20)
2018-02-08 09:18:39,415 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 6.0 (TID 16) in 42 ms on localhost (executor driver) (9/20)
2018-02-08 09:18:39,416 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 6.0 (TID 19)
2018-02-08 09:18:39,422 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,422 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,430 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 6.0 (TID 19). 2999 bytes result sent to driver
2018-02-08 09:18:39,432 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,432 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,444 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 6.0 (TID 18). 2999 bytes result sent to driver
2018-02-08 09:18:39,445 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 6.0 (TID 20, localhost, executor driver, partition 17, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,451 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 6.0 (TID 21, localhost, executor driver, partition 18, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,454 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 6.0 (TID 19) in 45 ms on localhost (executor driver) (10/20)
2018-02-08 09:18:39,455 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 6.0 (TID 18) in 47 ms on localhost (executor driver) (11/20)
2018-02-08 09:18:39,454 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 6.0 (TID 20)
2018-02-08 09:18:39,456 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 6.0 (TID 21)
2018-02-08 09:18:39,463 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,463 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,465 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,465 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,474 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 6.0 (TID 20). 3042 bytes result sent to driver
2018-02-08 09:18:39,475 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 6.0 (TID 22, localhost, executor driver, partition 19, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,476 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 6.0 (TID 22)
2018-02-08 09:18:39,476 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 6.0 (TID 20) in 31 ms on localhost (executor driver) (12/20)
2018-02-08 09:18:39,480 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,480 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,490 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 6.0 (TID 22). 2956 bytes result sent to driver
2018-02-08 09:18:39,491 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 6.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,491 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 6.0 (TID 22) in 16 ms on localhost (executor driver) (13/20)
2018-02-08 09:18:39,493 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 6.0 (TID 23)
2018-02-08 09:18:39,494 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 6.0 (TID 21). 3042 bytes result sent to driver
2018-02-08 09:18:39,496 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 6.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,496 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 6.0 (TID 21) in 46 ms on localhost (executor driver) (14/20)
2018-02-08 09:18:39,505 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 6.0 (TID 24)
2018-02-08 09:18:39,499 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,511 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 11 ms
2018-02-08 09:18:39,522 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 6.0 (TID 23). 2956 bytes result sent to driver
2018-02-08 09:18:39,524 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,524 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,534 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 6.0 (TID 24). 2999 bytes result sent to driver
2018-02-08 09:18:39,536 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 6.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,536 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 6.0 (TID 26, localhost, executor driver, partition 23, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,536 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 6.0 (TID 23) in 45 ms on localhost (executor driver) (15/20)
2018-02-08 09:18:39,537 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 6.0 (TID 24) in 42 ms on localhost (executor driver) (16/20)
2018-02-08 09:18:39,539 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 6.0 (TID 25)
2018-02-08 09:18:39,547 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,547 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,548 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 6.0 (TID 26)
2018-02-08 09:18:39,552 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 6.0 (TID 25). 2999 bytes result sent to driver
2018-02-08 09:18:39,556 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,557 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,559 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 6.0 (TID 27, localhost, executor driver, partition 24, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,560 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 6.0 (TID 25) in 25 ms on localhost (executor driver) (17/20)
2018-02-08 09:18:39,562 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 6.0 (TID 27)
2018-02-08 09:18:39,563 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 6.0 (TID 26). 2956 bytes result sent to driver
2018-02-08 09:18:39,565 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 6.0 (TID 28, localhost, executor driver, partition 8, ANY, 4726 bytes)
2018-02-08 09:18:39,566 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 6.0 (TID 26) in 30 ms on localhost (executor driver) (18/20)
2018-02-08 09:18:39,567 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,568 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,567 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 6.0 (TID 28)
2018-02-08 09:18:39,573 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 6.0 (TID 27). 2999 bytes result sent to driver
2018-02-08 09:18:39,574 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 6.0 (TID 27) in 19 ms on localhost (executor driver) (19/20)
2018-02-08 09:18:39,576 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,576 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,601 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 6.0 (TID 28). 3021 bytes result sent to driver
2018-02-08 09:18:39,602 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 6.0 (TID 28) in 37 ms on localhost (executor driver) (20/20)
2018-02-08 09:18:39,602 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 09:18:39,604 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (show at MachineLeaningSelector.java:151) finished in 0.289 s
2018-02-08 09:18:39,605 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at MachineLeaningSelector.java:151, took 0.309062 s
2018-02-08 09:18:39,610 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:151
2018-02-08 09:18:39,611 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (show at MachineLeaningSelector.java:151) with 100 output partitions
2018-02-08 09:18:39,611 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 8 (show at MachineLeaningSelector.java:151)
2018-02-08 09:18:39,611 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 7)
2018-02-08 09:18:39,612 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:18:39,614 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 8 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:151), which has no missing parents
2018-02-08 09:18:39,625 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 59.8 KB, free 615.4 MB)
2018-02-08 09:18:39,632 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.5 KB, free 615.4 MB)
2018-02-08 09:18:39,633 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:50835 (size: 20.5 KB, free: 631.7 MB)
2018-02-08 09:18:39,633 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:18:39,634 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 100 missing tasks from ResultStage 8 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:151) (first 15 tasks are for partitions Vector(25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39))
2018-02-08 09:18:39,634 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 100 tasks
2018-02-08 09:18:39,635 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 29, localhost, executor driver, partition 25, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,636 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 8.0 (TID 30, localhost, executor driver, partition 26, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,636 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 29)
2018-02-08 09:18:39,636 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 8.0 (TID 30)
2018-02-08 09:18:39,641 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,642 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,648 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,649 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,649 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 29). 2999 bytes result sent to driver
2018-02-08 09:18:39,649 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 8.0 (TID 31, localhost, executor driver, partition 27, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,650 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 29) in 15 ms on localhost (executor driver) (1/100)
2018-02-08 09:18:39,655 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 8.0 (TID 31)
2018-02-08 09:18:39,656 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 8.0 (TID 30). 2956 bytes result sent to driver
2018-02-08 09:18:39,658 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 8.0 (TID 32, localhost, executor driver, partition 28, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,658 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 8.0 (TID 30) in 22 ms on localhost (executor driver) (2/100)
2018-02-08 09:18:39,659 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 8.0 (TID 32)
2018-02-08 09:18:39,662 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,662 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,669 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 8.0 (TID 31). 2999 bytes result sent to driver
2018-02-08 09:18:39,669 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,670 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,670 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 8.0 (TID 33, localhost, executor driver, partition 29, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,670 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 8.0 (TID 31) in 21 ms on localhost (executor driver) (3/100)
2018-02-08 09:18:39,671 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 8.0 (TID 33)
2018-02-08 09:18:39,673 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 8.0 (TID 32). 2999 bytes result sent to driver
2018-02-08 09:18:39,674 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 8.0 (TID 34, localhost, executor driver, partition 30, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,681 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,682 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,681 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 8.0 (TID 32) in 24 ms on localhost (executor driver) (4/100)
2018-02-08 09:18:39,682 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 8.0 (TID 34)
2018-02-08 09:18:39,687 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 8.0 (TID 33). 2999 bytes result sent to driver
2018-02-08 09:18:39,688 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,689 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,691 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 8.0 (TID 35, localhost, executor driver, partition 31, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,696 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 8.0 (TID 34). 2999 bytes result sent to driver
2018-02-08 09:18:39,697 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 8.0 (TID 36, localhost, executor driver, partition 32, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,698 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 8.0 (TID 33) in 28 ms on localhost (executor driver) (5/100)
2018-02-08 09:18:39,700 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 8.0 (TID 34) in 26 ms on localhost (executor driver) (6/100)
2018-02-08 09:18:39,700 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 8.0 (TID 35)
2018-02-08 09:18:39,700 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 8.0 (TID 36)
2018-02-08 09:18:39,704 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,705 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,705 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,706 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:18:39,716 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 8.0 (TID 35). 2956 bytes result sent to driver
2018-02-08 09:18:39,717 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 8.0 (TID 37, localhost, executor driver, partition 33, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,717 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 8.0 (TID 37)
2018-02-08 09:18:39,717 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 8.0 (TID 35) in 26 ms on localhost (executor driver) (7/100)
2018-02-08 09:18:39,720 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 8.0 (TID 36). 2999 bytes result sent to driver
2018-02-08 09:18:39,721 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 8.0 (TID 38, localhost, executor driver, partition 34, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,721 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 8.0 (TID 36) in 24 ms on localhost (executor driver) (8/100)
2018-02-08 09:18:39,722 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 8.0 (TID 38)
2018-02-08 09:18:39,722 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,722 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,729 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,730 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,732 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 8.0 (TID 37). 2999 bytes result sent to driver
2018-02-08 09:18:39,736 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 8.0 (TID 39, localhost, executor driver, partition 35, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,736 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 8.0 (TID 39)
2018-02-08 09:18:39,737 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 8.0 (TID 37) in 20 ms on localhost (executor driver) (9/100)
2018-02-08 09:18:39,742 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 8.0 (TID 38). 2999 bytes result sent to driver
2018-02-08 09:18:39,742 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,743 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,742 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 8.0 (TID 40, localhost, executor driver, partition 36, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,745 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 8.0 (TID 38) in 25 ms on localhost (executor driver) (10/100)
2018-02-08 09:18:39,745 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 8.0 (TID 40)
2018-02-08 09:18:39,749 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 8.0 (TID 39). 2999 bytes result sent to driver
2018-02-08 09:18:39,751 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,751 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,751 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 8.0 (TID 41, localhost, executor driver, partition 37, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,753 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 8.0 (TID 39) in 17 ms on localhost (executor driver) (11/100)
2018-02-08 09:18:39,754 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 8.0 (TID 41)
2018-02-08 09:18:39,756 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 8.0 (TID 40). 2999 bytes result sent to driver
2018-02-08 09:18:39,758 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 8.0 (TID 42, localhost, executor driver, partition 39, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,759 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 8.0 (TID 40) in 17 ms on localhost (executor driver) (12/100)
2018-02-08 09:18:39,759 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,760 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,760 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 8.0 (TID 42)
2018-02-08 09:18:39,764 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 8.0 (TID 41). 2956 bytes result sent to driver
2018-02-08 09:18:39,765 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 8.0 (TID 43, localhost, executor driver, partition 40, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,766 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,766 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,766 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 8.0 (TID 41) in 15 ms on localhost (executor driver) (13/100)
2018-02-08 09:18:39,767 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 8.0 (TID 43)
2018-02-08 09:18:39,773 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 8.0 (TID 42). 2956 bytes result sent to driver
2018-02-08 09:18:39,774 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 8.0 (TID 44, localhost, executor driver, partition 41, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,774 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 8.0 (TID 42) in 16 ms on localhost (executor driver) (14/100)
2018-02-08 09:18:39,774 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 8.0 (TID 44)
2018-02-08 09:18:39,776 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,776 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,779 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,779 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,783 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 8.0 (TID 44). 2956 bytes result sent to driver
2018-02-08 09:18:39,784 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 8.0 (TID 45, localhost, executor driver, partition 42, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,784 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 8.0 (TID 44) in 10 ms on localhost (executor driver) (15/100)
2018-02-08 09:18:39,784 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 8.0 (TID 45)
2018-02-08 09:18:39,790 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 8.0 (TID 43). 2999 bytes result sent to driver
2018-02-08 09:18:39,791 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,791 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,791 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 8.0 (TID 46, localhost, executor driver, partition 43, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,792 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 8.0 (TID 43) in 27 ms on localhost (executor driver) (16/100)
2018-02-08 09:18:39,793 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 8.0 (TID 46)
2018-02-08 09:18:39,796 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 8.0 (TID 45). 2956 bytes result sent to driver
2018-02-08 09:18:39,797 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 8.0 (TID 47, localhost, executor driver, partition 44, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,798 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 8.0 (TID 45) in 14 ms on localhost (executor driver) (17/100)
2018-02-08 09:18:39,800 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 8.0 (TID 47)
2018-02-08 09:18:39,801 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,816 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 15 ms
2018-02-08 09:18:39,816 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,817 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,822 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 8.0 (TID 46). 2999 bytes result sent to driver
2018-02-08 09:18:39,823 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 8.0 (TID 47). 2999 bytes result sent to driver
2018-02-08 09:18:39,824 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 8.0 (TID 48, localhost, executor driver, partition 45, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,824 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 8.0 (TID 49, localhost, executor driver, partition 46, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,825 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 8.0 (TID 46) in 34 ms on localhost (executor driver) (18/100)
2018-02-08 09:18:39,826 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 8.0 (TID 47) in 29 ms on localhost (executor driver) (19/100)
2018-02-08 09:18:39,828 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 8.0 (TID 48)
2018-02-08 09:18:39,828 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 8.0 (TID 49)
2018-02-08 09:18:39,888 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,889 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,893 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,893 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,898 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 8.0 (TID 49). 2999 bytes result sent to driver
2018-02-08 09:18:39,904 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 8.0 (TID 48). 3042 bytes result sent to driver
2018-02-08 09:18:39,905 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 8.0 (TID 50, localhost, executor driver, partition 47, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 8.0 (TID 51, localhost, executor driver, partition 48, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,907 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 8.0 (TID 50)
2018-02-08 09:18:39,908 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 8.0 (TID 48) in 85 ms on localhost (executor driver) (20/100)
2018-02-08 09:18:39,908 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 8.0 (TID 49) in 84 ms on localhost (executor driver) (21/100)
2018-02-08 09:18:39,908 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 8.0 (TID 51)
2018-02-08 09:18:39,918 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,918 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,918 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,918 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,922 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 8.0 (TID 51). 2956 bytes result sent to driver
2018-02-08 09:18:39,923 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 8.0 (TID 52, localhost, executor driver, partition 49, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,925 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 8.0 (TID 50). 2999 bytes result sent to driver
2018-02-08 09:18:39,926 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 8.0 (TID 52)
2018-02-08 09:18:39,926 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 8.0 (TID 51) in 20 ms on localhost (executor driver) (22/100)
2018-02-08 09:18:39,927 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 8.0 (TID 53, localhost, executor driver, partition 50, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 8.0 (TID 50) in 24 ms on localhost (executor driver) (23/100)
2018-02-08 09:18:39,928 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 8.0 (TID 53)
2018-02-08 09:18:39,931 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,931 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,931 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,932 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,941 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 8.0 (TID 52). 2956 bytes result sent to driver
2018-02-08 09:18:39,941 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 8.0 (TID 53). 2956 bytes result sent to driver
2018-02-08 09:18:39,943 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 8.0 (TID 54, localhost, executor driver, partition 51, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,943 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 8.0 (TID 54)
2018-02-08 09:18:39,943 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 8.0 (TID 55, localhost, executor driver, partition 52, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,944 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 8.0 (TID 52) in 21 ms on localhost (executor driver) (24/100)
2018-02-08 09:18:39,945 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 8.0 (TID 53) in 18 ms on localhost (executor driver) (25/100)
2018-02-08 09:18:39,945 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 8.0 (TID 55)
2018-02-08 09:18:39,950 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,950 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,952 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,952 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,956 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 8.0 (TID 55). 2999 bytes result sent to driver
2018-02-08 09:18:39,956 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 8.0 (TID 56, localhost, executor driver, partition 53, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,957 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 8.0 (TID 55) in 14 ms on localhost (executor driver) (26/100)
2018-02-08 09:18:39,958 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 8.0 (TID 56)
2018-02-08 09:18:39,963 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 8.0 (TID 54). 2956 bytes result sent to driver
2018-02-08 09:18:39,963 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 8.0 (TID 57, localhost, executor driver, partition 54, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,964 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 8.0 (TID 54) in 22 ms on localhost (executor driver) (27/100)
2018-02-08 09:18:39,966 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 8.0 (TID 57)
2018-02-08 09:18:39,966 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,966 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,969 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,969 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,971 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 8.0 (TID 56). 2956 bytes result sent to driver
2018-02-08 09:18:39,972 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 8.0 (TID 58, localhost, executor driver, partition 55, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,973 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 8.0 (TID 57). 2956 bytes result sent to driver
2018-02-08 09:18:39,973 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 8.0 (TID 58)
2018-02-08 09:18:39,973 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 8.0 (TID 56) in 17 ms on localhost (executor driver) (28/100)
2018-02-08 09:18:39,974 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 8.0 (TID 59, localhost, executor driver, partition 56, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,975 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 8.0 (TID 57) in 12 ms on localhost (executor driver) (29/100)
2018-02-08 09:18:39,976 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 8.0 (TID 59)
2018-02-08 09:18:39,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:39,980 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,981 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,982 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 8.0 (TID 58). 2956 bytes result sent to driver
2018-02-08 09:18:39,983 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 8.0 (TID 60, localhost, executor driver, partition 57, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,985 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 8.0 (TID 58) in 13 ms on localhost (executor driver) (30/100)
2018-02-08 09:18:39,986 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 8.0 (TID 59). 2956 bytes result sent to driver
2018-02-08 09:18:39,986 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 8.0 (TID 60)
2018-02-08 09:18:39,987 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 8.0 (TID 61, localhost, executor driver, partition 58, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:39,987 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 8.0 (TID 59) in 13 ms on localhost (executor driver) (31/100)
2018-02-08 09:18:39,990 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 8.0 (TID 61)
2018-02-08 09:18:39,991 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,992 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,997 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:39,998 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:39,998 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 8.0 (TID 60). 2956 bytes result sent to driver
2018-02-08 09:18:40,003 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 8.0 (TID 62, localhost, executor driver, partition 59, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,003 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 8.0 (TID 61). 2956 bytes result sent to driver
2018-02-08 09:18:40,004 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 8.0 (TID 62)
2018-02-08 09:18:40,007 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 8.0 (TID 60) in 23 ms on localhost (executor driver) (32/100)
2018-02-08 09:18:40,008 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 8.0 (TID 63, localhost, executor driver, partition 60, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,009 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 8.0 (TID 61) in 23 ms on localhost (executor driver) (33/100)
2018-02-08 09:18:40,009 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 8.0 (TID 63)
2018-02-08 09:18:40,010 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,010 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,014 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,014 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,020 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 8.0 (TID 62). 2956 bytes result sent to driver
2018-02-08 09:18:40,024 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 8.0 (TID 64, localhost, executor driver, partition 61, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,026 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 8.0 (TID 62) in 24 ms on localhost (executor driver) (34/100)
2018-02-08 09:18:40,027 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 8.0 (TID 64)
2018-02-08 09:18:40,034 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,034 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,043 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 8.0 (TID 64). 2956 bytes result sent to driver
2018-02-08 09:18:40,053 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 8.0 (TID 65, localhost, executor driver, partition 62, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,054 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 8.0 (TID 64) in 31 ms on localhost (executor driver) (35/100)
2018-02-08 09:18:40,054 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 8.0 (TID 65)
2018-02-08 09:18:40,050 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 8.0 (TID 63). 2956 bytes result sent to driver
2018-02-08 09:18:40,056 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 8.0 (TID 66, localhost, executor driver, partition 63, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,056 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 8.0 (TID 63) in 48 ms on localhost (executor driver) (36/100)
2018-02-08 09:18:40,057 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 8.0 (TID 66)
2018-02-08 09:18:40,059 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,062 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:18:40,070 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 8.0 (TID 65). 2999 bytes result sent to driver
2018-02-08 09:18:40,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 8.0 (TID 67, localhost, executor driver, partition 64, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,071 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 8.0 (TID 67)
2018-02-08 09:18:40,071 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 8.0 (TID 65) in 18 ms on localhost (executor driver) (37/100)
2018-02-08 09:18:40,078 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,078 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:18:40,082 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,082 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,083 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 8.0 (TID 66). 2956 bytes result sent to driver
2018-02-08 09:18:40,091 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 8.0 (TID 67). 2999 bytes result sent to driver
2018-02-08 09:18:40,092 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 8.0 (TID 68, localhost, executor driver, partition 65, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,097 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 8.0 (TID 69, localhost, executor driver, partition 66, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,098 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 8.0 (TID 66) in 42 ms on localhost (executor driver) (38/100)
2018-02-08 09:18:40,102 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 8.0 (TID 67) in 32 ms on localhost (executor driver) (39/100)
2018-02-08 09:18:40,103 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 8.0 (TID 68)
2018-02-08 09:18:40,103 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 8.0 (TID 69)
2018-02-08 09:18:40,110 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,111 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,119 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,119 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,120 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 8.0 (TID 68). 2956 bytes result sent to driver
2018-02-08 09:18:40,128 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 8.0 (TID 69). 2956 bytes result sent to driver
2018-02-08 09:18:40,129 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 8.0 (TID 70, localhost, executor driver, partition 67, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,130 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 8.0 (TID 71, localhost, executor driver, partition 68, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,130 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 8.0 (TID 70)
2018-02-08 09:18:40,131 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 8.0 (TID 68) in 40 ms on localhost (executor driver) (40/100)
2018-02-08 09:18:40,131 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 8.0 (TID 69) in 34 ms on localhost (executor driver) (41/100)
2018-02-08 09:18:40,131 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 8.0 (TID 71)
2018-02-08 09:18:40,135 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,135 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,136 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,136 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,143 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 8.0 (TID 70). 2956 bytes result sent to driver
2018-02-08 09:18:40,144 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 8.0 (TID 71). 2999 bytes result sent to driver
2018-02-08 09:18:40,145 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 8.0 (TID 72, localhost, executor driver, partition 69, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,146 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 8.0 (TID 73, localhost, executor driver, partition 70, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,147 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 8.0 (TID 71) in 17 ms on localhost (executor driver) (42/100)
2018-02-08 09:18:40,147 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 8.0 (TID 73)
2018-02-08 09:18:40,148 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 8.0 (TID 70) in 19 ms on localhost (executor driver) (43/100)
2018-02-08 09:18:40,154 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,154 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,162 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 8.0 (TID 72)
2018-02-08 09:18:40,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,176 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 8.0 (TID 72). 2956 bytes result sent to driver
2018-02-08 09:18:40,176 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 8.0 (TID 74, localhost, executor driver, partition 71, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 8.0 (TID 72) in 32 ms on localhost (executor driver) (44/100)
2018-02-08 09:18:40,177 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 8.0 (TID 74)
2018-02-08 09:18:40,180 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,182 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,186 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 8.0 (TID 74). 2956 bytes result sent to driver
2018-02-08 09:18:40,187 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 8.0 (TID 75, localhost, executor driver, partition 72, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,187 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 8.0 (TID 75)
2018-02-08 09:18:40,187 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 8.0 (TID 74) in 11 ms on localhost (executor driver) (45/100)
2018-02-08 09:18:40,192 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,193 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,197 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 8.0 (TID 75). 3042 bytes result sent to driver
2018-02-08 09:18:40,198 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 8.0 (TID 76, localhost, executor driver, partition 73, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,198 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 8.0 (TID 75) in 11 ms on localhost (executor driver) (46/100)
2018-02-08 09:18:40,198 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 8.0 (TID 76)
2018-02-08 09:18:40,201 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,202 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,206 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 8.0 (TID 76). 2956 bytes result sent to driver
2018-02-08 09:18:40,208 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 8.0 (TID 77, localhost, executor driver, partition 74, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,209 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 8.0 (TID 77)
2018-02-08 09:18:40,209 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 8.0 (TID 76) in 11 ms on localhost (executor driver) (47/100)
2018-02-08 09:18:40,215 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 8.0 (TID 73). 2956 bytes result sent to driver
2018-02-08 09:18:40,216 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 8.0 (TID 78, localhost, executor driver, partition 75, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,217 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 8.0 (TID 73) in 71 ms on localhost (executor driver) (48/100)
2018-02-08 09:18:40,217 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 8.0 (TID 78)
2018-02-08 09:18:40,218 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,219 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,225 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 8.0 (TID 77). 2999 bytes result sent to driver
2018-02-08 09:18:40,227 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,227 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:18:40,232 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 8.0 (TID 78). 2999 bytes result sent to driver
2018-02-08 09:18:40,233 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 8.0 (TID 79, localhost, executor driver, partition 76, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,234 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 8.0 (TID 80, localhost, executor driver, partition 77, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,235 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 8.0 (TID 77) in 28 ms on localhost (executor driver) (49/100)
2018-02-08 09:18:40,239 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 8.0 (TID 78) in 23 ms on localhost (executor driver) (50/100)
2018-02-08 09:18:40,239 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 8.0 (TID 79)
2018-02-08 09:18:40,241 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 8.0 (TID 80)
2018-02-08 09:18:40,247 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,248 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,250 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,250 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,260 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 8.0 (TID 80). 2956 bytes result sent to driver
2018-02-08 09:18:40,262 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 8.0 (TID 81, localhost, executor driver, partition 78, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,263 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 8.0 (TID 81)
2018-02-08 09:18:40,263 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 8.0 (TID 80) in 30 ms on localhost (executor driver) (51/100)
2018-02-08 09:18:40,265 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 8.0 (TID 79). 2956 bytes result sent to driver
2018-02-08 09:18:40,265 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 8.0 (TID 82, localhost, executor driver, partition 80, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,265 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,266 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,272 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 8.0 (TID 82)
2018-02-08 09:18:40,272 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 8.0 (TID 79) in 39 ms on localhost (executor driver) (52/100)
2018-02-08 09:18:40,276 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,276 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,278 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 8.0 (TID 81). 2956 bytes result sent to driver
2018-02-08 09:18:40,279 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 8.0 (TID 83, localhost, executor driver, partition 81, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,280 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 8.0 (TID 81) in 18 ms on localhost (executor driver) (53/100)
2018-02-08 09:18:40,281 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 8.0 (TID 83)
2018-02-08 09:18:40,289 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,289 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,290 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 8.0 (TID 82). 2956 bytes result sent to driver
2018-02-08 09:18:40,291 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 8.0 (TID 84, localhost, executor driver, partition 82, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,292 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 8.0 (TID 82) in 27 ms on localhost (executor driver) (54/100)
2018-02-08 09:18:40,293 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 8.0 (TID 84)
2018-02-08 09:18:40,295 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 8.0 (TID 83). 2956 bytes result sent to driver
2018-02-08 09:18:40,299 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,299 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,299 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 8.0 (TID 85, localhost, executor driver, partition 83, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,302 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 8.0 (TID 85)
2018-02-08 09:18:40,302 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 8.0 (TID 83) in 23 ms on localhost (executor driver) (55/100)
2018-02-08 09:18:40,305 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,305 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,313 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 8.0 (TID 84). 2999 bytes result sent to driver
2018-02-08 09:18:40,314 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 8.0 (TID 86, localhost, executor driver, partition 85, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,314 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 8.0 (TID 84) in 23 ms on localhost (executor driver) (56/100)
2018-02-08 09:18:40,314 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 8.0 (TID 86)
2018-02-08 09:18:40,319 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,319 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,323 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 8.0 (TID 85). 2956 bytes result sent to driver
2018-02-08 09:18:40,324 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 8.0 (TID 86). 2999 bytes result sent to driver
2018-02-08 09:18:40,325 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 8.0 (TID 87, localhost, executor driver, partition 86, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,325 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 8.0 (TID 85) in 26 ms on localhost (executor driver) (57/100)
2018-02-08 09:18:40,325 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 8.0 (TID 87)
2018-02-08 09:18:40,326 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 8.0 (TID 88, localhost, executor driver, partition 87, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,327 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 8.0 (TID 86) in 12 ms on localhost (executor driver) (58/100)
2018-02-08 09:18:40,328 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 8.0 (TID 88)
2018-02-08 09:18:40,329 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,330 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,337 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,338 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,337 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 8.0 (TID 87). 2956 bytes result sent to driver
2018-02-08 09:18:40,338 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 8.0 (TID 89, localhost, executor driver, partition 88, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,339 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 8.0 (TID 87) in 15 ms on localhost (executor driver) (59/100)
2018-02-08 09:18:40,340 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 8.0 (TID 89)
2018-02-08 09:18:40,342 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 8.0 (TID 88). 2999 bytes result sent to driver
2018-02-08 09:18:40,343 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 8.0 (TID 90, localhost, executor driver, partition 89, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,344 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 8.0 (TID 88) in 18 ms on localhost (executor driver) (60/100)
2018-02-08 09:18:40,344 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,344 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,344 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 8.0 (TID 90)
2018-02-08 09:18:40,347 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 8.0 (TID 89). 2956 bytes result sent to driver
2018-02-08 09:18:40,350 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 8.0 (TID 91, localhost, executor driver, partition 90, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,350 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,350 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,350 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 8.0 (TID 91)
2018-02-08 09:18:40,350 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 8.0 (TID 89) in 12 ms on localhost (executor driver) (61/100)
2018-02-08 09:18:40,353 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 8.0 (TID 90). 2956 bytes result sent to driver
2018-02-08 09:18:40,354 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 8.0 (TID 92, localhost, executor driver, partition 91, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,355 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 8.0 (TID 90) in 12 ms on localhost (executor driver) (62/100)
2018-02-08 09:18:40,355 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,355 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,355 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 8.0 (TID 92)
2018-02-08 09:18:40,358 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 8.0 (TID 91). 2956 bytes result sent to driver
2018-02-08 09:18:40,358 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,358 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,359 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 8.0 (TID 93, localhost, executor driver, partition 92, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,359 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 8.0 (TID 91) in 12 ms on localhost (executor driver) (63/100)
2018-02-08 09:18:40,359 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 8.0 (TID 93)
2018-02-08 09:18:40,362 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 8.0 (TID 92). 2956 bytes result sent to driver
2018-02-08 09:18:40,362 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 8.0 (TID 94, localhost, executor driver, partition 93, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,363 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 8.0 (TID 92) in 9 ms on localhost (executor driver) (64/100)
2018-02-08 09:18:40,363 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,363 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,363 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 8.0 (TID 94)
2018-02-08 09:18:40,368 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 8.0 (TID 93). 2999 bytes result sent to driver
2018-02-08 09:18:40,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 8.0 (TID 95, localhost, executor driver, partition 94, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 8.0 (TID 93) in 11 ms on localhost (executor driver) (65/100)
2018-02-08 09:18:40,370 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 8.0 (TID 95)
2018-02-08 09:18:40,373 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,373 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,373 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,373 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,378 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 8.0 (TID 95). 2956 bytes result sent to driver
2018-02-08 09:18:40,379 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 8.0 (TID 96, localhost, executor driver, partition 95, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,380 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 8.0 (TID 95) in 12 ms on localhost (executor driver) (66/100)
2018-02-08 09:18:40,380 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 8.0 (TID 96)
2018-02-08 09:18:40,380 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 8.0 (TID 94). 2999 bytes result sent to driver
2018-02-08 09:18:40,384 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 8.0 (TID 97, localhost, executor driver, partition 96, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,384 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 8.0 (TID 94) in 22 ms on localhost (executor driver) (67/100)
2018-02-08 09:18:40,385 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 8.0 (TID 97)
2018-02-08 09:18:40,386 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,386 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,389 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,389 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,393 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 8.0 (TID 97). 2956 bytes result sent to driver
2018-02-08 09:18:40,393 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 8.0 (TID 96). 2956 bytes result sent to driver
2018-02-08 09:18:40,393 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 8.0 (TID 98, localhost, executor driver, partition 97, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,394 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 8.0 (TID 98)
2018-02-08 09:18:40,394 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 8.0 (TID 99, localhost, executor driver, partition 98, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,395 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 8.0 (TID 97) in 12 ms on localhost (executor driver) (68/100)
2018-02-08 09:18:40,395 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 8.0 (TID 96) in 16 ms on localhost (executor driver) (69/100)
2018-02-08 09:18:40,396 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 8.0 (TID 99)
2018-02-08 09:18:40,397 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,398 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,399 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,399 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,402 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 8.0 (TID 98). 2999 bytes result sent to driver
2018-02-08 09:18:40,403 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 8.0 (TID 99). 2999 bytes result sent to driver
2018-02-08 09:18:40,404 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 8.0 (TID 100, localhost, executor driver, partition 99, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,405 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 8.0 (TID 100)
2018-02-08 09:18:40,405 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 8.0 (TID 101, localhost, executor driver, partition 100, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,405 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 8.0 (TID 99) in 11 ms on localhost (executor driver) (70/100)
2018-02-08 09:18:40,405 INFO[org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 8.0 (TID 101)
2018-02-08 09:18:40,408 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,408 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,408 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 8.0 (TID 98) in 15 ms on localhost (executor driver) (71/100)
2018-02-08 09:18:40,408 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,410 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:18:40,416 INFO[org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 8.0 (TID 101). 2999 bytes result sent to driver
2018-02-08 09:18:40,417 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 8.0 (TID 102, localhost, executor driver, partition 101, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,418 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 8.0 (TID 100). 2999 bytes result sent to driver
2018-02-08 09:18:40,418 INFO[org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 8.0 (TID 102)
2018-02-08 09:18:40,418 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 8.0 (TID 101) in 13 ms on localhost (executor driver) (72/100)
2018-02-08 09:18:40,419 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 8.0 (TID 103, localhost, executor driver, partition 102, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,420 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 8.0 (TID 100) in 16 ms on localhost (executor driver) (73/100)
2018-02-08 09:18:40,420 INFO[org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 8.0 (TID 103)
2018-02-08 09:18:40,421 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,422 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,424 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,424 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,426 INFO[org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 8.0 (TID 102). 2956 bytes result sent to driver
2018-02-08 09:18:40,430 INFO[org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 8.0 (TID 103). 2999 bytes result sent to driver
2018-02-08 09:18:40,433 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 8.0 (TID 104, localhost, executor driver, partition 103, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,449 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 8.0 (TID 105, localhost, executor driver, partition 104, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,450 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 8.0 (TID 102) in 33 ms on localhost (executor driver) (74/100)
2018-02-08 09:18:40,450 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 8.0 (TID 103) in 31 ms on localhost (executor driver) (75/100)
2018-02-08 09:18:40,451 INFO[org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 8.0 (TID 104)
2018-02-08 09:18:40,460 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,460 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,464 INFO[org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 8.0 (TID 105)
2018-02-08 09:18:40,468 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,468 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,475 INFO[org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 8.0 (TID 104). 2956 bytes result sent to driver
2018-02-08 09:18:40,476 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 8.0 (TID 106, localhost, executor driver, partition 105, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,476 INFO[org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 8.0 (TID 105). 2956 bytes result sent to driver
2018-02-08 09:18:40,476 INFO[org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 8.0 (TID 106)
2018-02-08 09:18:40,476 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 8.0 (TID 104) in 44 ms on localhost (executor driver) (76/100)
2018-02-08 09:18:40,480 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 8.0 (TID 107, localhost, executor driver, partition 106, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,483 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,483 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,487 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 8.0 (TID 105) in 38 ms on localhost (executor driver) (77/100)
2018-02-08 09:18:40,488 INFO[org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 8.0 (TID 107)
2018-02-08 09:18:40,488 INFO[org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 8.0 (TID 106). 2956 bytes result sent to driver
2018-02-08 09:18:40,490 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 8.0 (TID 108, localhost, executor driver, partition 107, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,491 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 8.0 (TID 106) in 15 ms on localhost (executor driver) (78/100)
2018-02-08 09:18:40,491 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,491 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,492 INFO[org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 8.0 (TID 108)
2018-02-08 09:18:40,501 INFO[org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 8.0 (TID 107). 2999 bytes result sent to driver
2018-02-08 09:18:40,502 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 8.0 (TID 109, localhost, executor driver, partition 108, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,503 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 8.0 (TID 107) in 24 ms on localhost (executor driver) (79/100)
2018-02-08 09:18:40,503 INFO[org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 8.0 (TID 109)
2018-02-08 09:18:40,507 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,508 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,517 INFO[org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 8.0 (TID 109). 2999 bytes result sent to driver
2018-02-08 09:18:40,520 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 8.0 (TID 110, localhost, executor driver, partition 109, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,523 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 8.0 (TID 109) in 22 ms on localhost (executor driver) (80/100)
2018-02-08 09:18:40,523 INFO[org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 8.0 (TID 110)
2018-02-08 09:18:40,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,531 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,537 INFO[org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 8.0 (TID 110). 2956 bytes result sent to driver
2018-02-08 09:18:40,543 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 8.0 (TID 111, localhost, executor driver, partition 110, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,544 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 8.0 (TID 110) in 24 ms on localhost (executor driver) (81/100)
2018-02-08 09:18:40,544 INFO[org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 8.0 (TID 111)
2018-02-08 09:18:40,548 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,548 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,565 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,565 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,566 INFO[org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 8.0 (TID 111). 2956 bytes result sent to driver
2018-02-08 09:18:40,566 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 8.0 (TID 112, localhost, executor driver, partition 111, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,567 INFO[org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 8.0 (TID 112)
2018-02-08 09:18:40,567 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 8.0 (TID 111) in 25 ms on localhost (executor driver) (82/100)
2018-02-08 09:18:40,570 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,570 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,575 INFO[org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 8.0 (TID 108). 2956 bytes result sent to driver
2018-02-08 09:18:40,576 INFO[org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 8.0 (TID 112). 2956 bytes result sent to driver
2018-02-08 09:18:40,576 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 8.0 (TID 113, localhost, executor driver, partition 112, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,576 INFO[org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 8.0 (TID 113)
2018-02-08 09:18:40,576 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 8.0 (TID 108) in 87 ms on localhost (executor driver) (83/100)
2018-02-08 09:18:40,577 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 8.0 (TID 114, localhost, executor driver, partition 113, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,578 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 8.0 (TID 112) in 12 ms on localhost (executor driver) (84/100)
2018-02-08 09:18:40,578 INFO[org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 8.0 (TID 114)
2018-02-08 09:18:40,579 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,579 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,583 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,583 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,583 INFO[org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 8.0 (TID 113). 2999 bytes result sent to driver
2018-02-08 09:18:40,585 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 8.0 (TID 115, localhost, executor driver, partition 114, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,585 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 8.0 (TID 113) in 9 ms on localhost (executor driver) (85/100)
2018-02-08 09:18:40,586 INFO[org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 8.0 (TID 115)
2018-02-08 09:18:40,587 INFO[org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 8.0 (TID 114). 2956 bytes result sent to driver
2018-02-08 09:18:40,591 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 8.0 (TID 116, localhost, executor driver, partition 116, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,592 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 8.0 (TID 114) in 16 ms on localhost (executor driver) (86/100)
2018-02-08 09:18:40,592 INFO[org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 8.0 (TID 116)
2018-02-08 09:18:40,592 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,593 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,595 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,596 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,596 INFO[org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 8.0 (TID 115). 2956 bytes result sent to driver
2018-02-08 09:18:40,599 INFO[org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 8.0 (TID 116). 2999 bytes result sent to driver
2018-02-08 09:18:40,599 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 8.0 (TID 117, localhost, executor driver, partition 117, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,600 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 8.0 (TID 118, localhost, executor driver, partition 118, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,600 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 8.0 (TID 115) in 16 ms on localhost (executor driver) (87/100)
2018-02-08 09:18:40,601 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 8.0 (TID 116) in 10 ms on localhost (executor driver) (88/100)
2018-02-08 09:18:40,601 INFO[org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 8.0 (TID 117)
2018-02-08 09:18:40,603 INFO[org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 8.0 (TID 118)
2018-02-08 09:18:40,604 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,604 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,609 INFO[org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 8.0 (TID 117). 2956 bytes result sent to driver
2018-02-08 09:18:40,609 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 8.0 (TID 119, localhost, executor driver, partition 119, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,610 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 8.0 (TID 117) in 11 ms on localhost (executor driver) (89/100)
2018-02-08 09:18:40,609 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,610 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,611 INFO[org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 8.0 (TID 119)
2018-02-08 09:18:40,615 INFO[org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 8.0 (TID 118). 2956 bytes result sent to driver
2018-02-08 09:18:40,616 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 8.0 (TID 120, localhost, executor driver, partition 120, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,616 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,617 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,618 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 8.0 (TID 118) in 17 ms on localhost (executor driver) (90/100)
2018-02-08 09:18:40,618 INFO[org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 8.0 (TID 120)
2018-02-08 09:18:40,620 INFO[org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 8.0 (TID 119). 2999 bytes result sent to driver
2018-02-08 09:18:40,623 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 8.0 (TID 121, localhost, executor driver, partition 122, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,625 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,625 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,625 INFO[org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 8.0 (TID 121)
2018-02-08 09:18:40,625 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 8.0 (TID 119) in 16 ms on localhost (executor driver) (91/100)
2018-02-08 09:18:40,628 INFO[org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 8.0 (TID 120). 2956 bytes result sent to driver
2018-02-08 09:18:40,631 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 8.0 (TID 122, localhost, executor driver, partition 123, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,632 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 8.0 (TID 120) in 16 ms on localhost (executor driver) (92/100)
2018-02-08 09:18:40,633 INFO[org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 8.0 (TID 122)
2018-02-08 09:18:40,636 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,636 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,641 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,641 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,642 INFO[org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 8.0 (TID 122). 2956 bytes result sent to driver
2018-02-08 09:18:40,642 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 8.0 (TID 123, localhost, executor driver, partition 124, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,643 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 8.0 (TID 122) in 12 ms on localhost (executor driver) (93/100)
2018-02-08 09:18:40,643 INFO[org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 8.0 (TID 123)
2018-02-08 09:18:40,649 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,649 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,656 INFO[org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 8.0 (TID 123). 2956 bytes result sent to driver
2018-02-08 09:18:40,657 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 8.0 (TID 124, localhost, executor driver, partition 38, ANY, 4726 bytes)
2018-02-08 09:18:40,659 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 8.0 (TID 124)
2018-02-08 09:18:40,659 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 8.0 (TID 123) in 17 ms on localhost (executor driver) (94/100)
2018-02-08 09:18:40,663 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,664 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,671 INFO[org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 8.0 (TID 121). 2956 bytes result sent to driver
2018-02-08 09:18:40,672 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 8.0 (TID 125, localhost, executor driver, partition 79, ANY, 4726 bytes)
2018-02-08 09:18:40,673 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 8.0 (TID 124). 3014 bytes result sent to driver
2018-02-08 09:18:40,674 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 8.0 (TID 121) in 52 ms on localhost (executor driver) (95/100)
2018-02-08 09:18:40,674 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 8.0 (TID 125)
2018-02-08 09:18:40,675 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 8.0 (TID 126, localhost, executor driver, partition 84, ANY, 4726 bytes)
2018-02-08 09:18:40,678 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 8.0 (TID 124) in 21 ms on localhost (executor driver) (96/100)
2018-02-08 09:18:40,679 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,679 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,683 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 8.0 (TID 126)
2018-02-08 09:18:40,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,698 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 8.0 (TID 125). 3021 bytes result sent to driver
2018-02-08 09:18:40,699 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 8.0 (TID 127, localhost, executor driver, partition 115, ANY, 4726 bytes)
2018-02-08 09:18:40,703 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 8.0 (TID 126). 3021 bytes result sent to driver
2018-02-08 09:18:40,703 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 8.0 (TID 125) in 31 ms on localhost (executor driver) (97/100)
2018-02-08 09:18:40,705 INFO[org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 8.0 (TID 127)
2018-02-08 09:18:40,708 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 8.0 (TID 128, localhost, executor driver, partition 121, ANY, 4726 bytes)
2018-02-08 09:18:40,710 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 8.0 (TID 126) in 35 ms on localhost (executor driver) (98/100)
2018-02-08 09:18:40,712 INFO[org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 8.0 (TID 128)
2018-02-08 09:18:40,713 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,713 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,721 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,721 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,735 INFO[org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 8.0 (TID 127). 3014 bytes result sent to driver
2018-02-08 09:18:40,742 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 8.0 (TID 127) in 43 ms on localhost (executor driver) (99/100)
2018-02-08 09:18:40,759 INFO[org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 8.0 (TID 128). 3021 bytes result sent to driver
2018-02-08 09:18:40,760 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 8.0 (TID 128) in 52 ms on localhost (executor driver) (100/100)
2018-02-08 09:18:40,760 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 09:18:40,760 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 8 (show at MachineLeaningSelector.java:151) finished in 1.125 s
2018-02-08 09:18:40,761 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: show at MachineLeaningSelector.java:151, took 1.151284 s
2018-02-08 09:18:40,769 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:151
2018-02-08 09:18:40,771 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (show at MachineLeaningSelector.java:151) with 75 output partitions
2018-02-08 09:18:40,771 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 10 (show at MachineLeaningSelector.java:151)
2018-02-08 09:18:40,771 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 9)
2018-02-08 09:18:40,771 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:18:40,772 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 10 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:151), which has no missing parents
2018-02-08 09:18:40,779 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 59.8 KB, free 615.3 MB)
2018-02-08 09:18:40,784 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 20.5 KB, free 615.3 MB)
2018-02-08 09:18:40,785 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:50835 (size: 20.5 KB, free: 631.7 MB)
2018-02-08 09:18:40,785 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:18:40,787 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 75 missing tasks from ResultStage 10 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:151) (first 15 tasks are for partitions Vector(125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139))
2018-02-08 09:18:40,787 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 75 tasks
2018-02-08 09:18:40,788 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 129, localhost, executor driver, partition 125, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,789 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 10.0 (TID 130, localhost, executor driver, partition 126, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,789 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 129)
2018-02-08 09:18:40,789 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 10.0 (TID 130)
2018-02-08 09:18:40,794 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,794 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,795 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,795 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,802 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 129). 2999 bytes result sent to driver
2018-02-08 09:18:40,802 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 10.0 (TID 131, localhost, executor driver, partition 127, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,803 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 10.0 (TID 130). 2999 bytes result sent to driver
2018-02-08 09:18:40,803 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 129) in 15 ms on localhost (executor driver) (1/75)
2018-02-08 09:18:40,803 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 10.0 (TID 131)
2018-02-08 09:18:40,806 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 10.0 (TID 132, localhost, executor driver, partition 128, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,807 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 10.0 (TID 130) in 18 ms on localhost (executor driver) (2/75)
2018-02-08 09:18:40,808 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 10.0 (TID 132)
2018-02-08 09:18:40,810 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,811 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:18:40,811 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,815 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 09:18:40,816 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 10.0 (TID 131). 2956 bytes result sent to driver
2018-02-08 09:18:40,817 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 10.0 (TID 133, localhost, executor driver, partition 129, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,818 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 10.0 (TID 131) in 16 ms on localhost (executor driver) (3/75)
2018-02-08 09:18:40,819 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 10.0 (TID 133)
2018-02-08 09:18:40,819 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 10.0 (TID 132). 2999 bytes result sent to driver
2018-02-08 09:18:40,822 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 10.0 (TID 134, localhost, executor driver, partition 130, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,823 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 10.0 (TID 132) in 17 ms on localhost (executor driver) (4/75)
2018-02-08 09:18:40,823 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 10.0 (TID 134)
2018-02-08 09:18:40,824 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,824 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,827 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,829 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:18:40,829 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 10.0 (TID 133). 2956 bytes result sent to driver
2018-02-08 09:18:40,830 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 10.0 (TID 135, localhost, executor driver, partition 131, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,831 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 10.0 (TID 133) in 14 ms on localhost (executor driver) (5/75)
2018-02-08 09:18:40,832 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 10.0 (TID 135)
2018-02-08 09:18:40,832 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 10.0 (TID 134). 2956 bytes result sent to driver
2018-02-08 09:18:40,833 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 10.0 (TID 136, localhost, executor driver, partition 133, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,834 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 10.0 (TID 134) in 12 ms on localhost (executor driver) (6/75)
2018-02-08 09:18:40,835 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,835 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,838 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 10.0 (TID 136)
2018-02-08 09:18:40,840 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 10.0 (TID 135). 2999 bytes result sent to driver
2018-02-08 09:18:40,841 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 10.0 (TID 137, localhost, executor driver, partition 134, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,842 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,843 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,843 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 10.0 (TID 135) in 13 ms on localhost (executor driver) (7/75)
2018-02-08 09:18:40,843 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 10.0 (TID 137)
2018-02-08 09:18:40,848 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 10.0 (TID 136). 2956 bytes result sent to driver
2018-02-08 09:18:40,848 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 10.0 (TID 138, localhost, executor driver, partition 135, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,849 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 10.0 (TID 136) in 16 ms on localhost (executor driver) (8/75)
2018-02-08 09:18:40,849 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 10.0 (TID 138)
2018-02-08 09:18:40,853 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,853 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,868 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,870 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 10.0 (TID 138). 2956 bytes result sent to driver
2018-02-08 09:18:40,871 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:18:40,875 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 10.0 (TID 137). 2999 bytes result sent to driver
2018-02-08 09:18:40,876 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 10.0 (TID 139, localhost, executor driver, partition 136, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,880 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 10.0 (TID 139)
2018-02-08 09:18:40,880 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 10.0 (TID 140, localhost, executor driver, partition 138, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,881 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 10.0 (TID 137) in 40 ms on localhost (executor driver) (9/75)
2018-02-08 09:18:40,881 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 10.0 (TID 140)
2018-02-08 09:18:40,883 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,883 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,885 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,885 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,888 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 10.0 (TID 140). 2956 bytes result sent to driver
2018-02-08 09:18:40,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 10.0 (TID 138) in 41 ms on localhost (executor driver) (10/75)
2018-02-08 09:18:40,890 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 10.0 (TID 141, localhost, executor driver, partition 139, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,891 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 10.0 (TID 140) in 11 ms on localhost (executor driver) (11/75)
2018-02-08 09:18:40,891 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 10.0 (TID 141)
2018-02-08 09:18:40,891 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 10.0 (TID 139). 2956 bytes result sent to driver
2018-02-08 09:18:40,895 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 10.0 (TID 142, localhost, executor driver, partition 140, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,895 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 10.0 (TID 139) in 19 ms on localhost (executor driver) (12/75)
2018-02-08 09:18:40,896 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 10.0 (TID 142)
2018-02-08 09:18:40,901 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,902 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,905 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 10.0 (TID 141). 2999 bytes result sent to driver
2018-02-08 09:18:40,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 10.0 (TID 143, localhost, executor driver, partition 141, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,907 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 10.0 (TID 142). 2956 bytes result sent to driver
2018-02-08 09:18:40,907 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 10.0 (TID 143)
2018-02-08 09:18:40,907 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 10.0 (TID 141) in 17 ms on localhost (executor driver) (13/75)
2018-02-08 09:18:40,907 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 10.0 (TID 144, localhost, executor driver, partition 142, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,915 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,915 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,915 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 10.0 (TID 144)
2018-02-08 09:18:40,920 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 10.0 (TID 143). 2956 bytes result sent to driver
2018-02-08 09:18:40,915 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 10.0 (TID 142) in 21 ms on localhost (executor driver) (14/75)
2018-02-08 09:18:40,920 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,920 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 10.0 (TID 145, localhost, executor driver, partition 143, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,921 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 10.0 (TID 143) in 15 ms on localhost (executor driver) (15/75)
2018-02-08 09:18:40,920 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,927 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 10.0 (TID 145)
2018-02-08 09:18:40,933 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,934 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:40,938 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 10.0 (TID 144). 2956 bytes result sent to driver
2018-02-08 09:18:40,939 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 10.0 (TID 145). 2956 bytes result sent to driver
2018-02-08 09:18:40,939 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 10.0 (TID 146, localhost, executor driver, partition 144, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,940 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 10.0 (TID 144) in 33 ms on localhost (executor driver) (16/75)
2018-02-08 09:18:40,940 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 10.0 (TID 146)
2018-02-08 09:18:40,940 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 10.0 (TID 147, localhost, executor driver, partition 145, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,943 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 10.0 (TID 145) in 23 ms on localhost (executor driver) (17/75)
2018-02-08 09:18:40,944 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 10.0 (TID 147)
2018-02-08 09:18:40,952 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,952 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,953 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,953 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:40,993 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 10.0 (TID 146). 3042 bytes result sent to driver
2018-02-08 09:18:40,993 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 10.0 (TID 148, localhost, executor driver, partition 146, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,995 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 10.0 (TID 146) in 56 ms on localhost (executor driver) (18/75)
2018-02-08 09:18:40,995 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 10.0 (TID 147). 2999 bytes result sent to driver
2018-02-08 09:18:40,995 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 10.0 (TID 148)
2018-02-08 09:18:40,997 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 10.0 (TID 149, localhost, executor driver, partition 147, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:40,998 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 10.0 (TID 147) in 58 ms on localhost (executor driver) (19/75)
2018-02-08 09:18:40,999 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 10.0 (TID 149)
2018-02-08 09:18:40,999 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:40,999 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,003 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 10.0 (TID 148). 2956 bytes result sent to driver
2018-02-08 09:18:41,003 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,003 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 10.0 (TID 150, localhost, executor driver, partition 148, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,003 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,003 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 10.0 (TID 148) in 10 ms on localhost (executor driver) (20/75)
2018-02-08 09:18:41,004 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 10.0 (TID 150)
2018-02-08 09:18:41,007 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 10.0 (TID 149). 2999 bytes result sent to driver
2018-02-08 09:18:41,008 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 10.0 (TID 151, localhost, executor driver, partition 149, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,009 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 10.0 (TID 151)
2018-02-08 09:18:41,009 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 10.0 (TID 149) in 12 ms on localhost (executor driver) (21/75)
2018-02-08 09:18:41,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,013 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,013 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,014 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 10.0 (TID 150). 2956 bytes result sent to driver
2018-02-08 09:18:41,014 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 10.0 (TID 152, localhost, executor driver, partition 150, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,015 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 10.0 (TID 150) in 12 ms on localhost (executor driver) (22/75)
2018-02-08 09:18:41,016 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 10.0 (TID 152)
2018-02-08 09:18:41,016 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 10.0 (TID 151). 2956 bytes result sent to driver
2018-02-08 09:18:41,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 10.0 (TID 153, localhost, executor driver, partition 151, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 10.0 (TID 151) in 9 ms on localhost (executor driver) (23/75)
2018-02-08 09:18:41,017 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 10.0 (TID 153)
2018-02-08 09:18:41,019 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,021 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:18:41,020 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,021 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,024 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 10.0 (TID 153). 2956 bytes result sent to driver
2018-02-08 09:18:41,024 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 10.0 (TID 152). 2956 bytes result sent to driver
2018-02-08 09:18:41,024 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 10.0 (TID 154, localhost, executor driver, partition 152, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,025 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 10.0 (TID 155, localhost, executor driver, partition 153, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,025 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 10.0 (TID 154)
2018-02-08 09:18:41,025 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 10.0 (TID 155)
2018-02-08 09:18:41,029 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,029 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,030 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,031 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,036 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 10.0 (TID 155). 2956 bytes result sent to driver
2018-02-08 09:18:41,038 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 10.0 (TID 154). 2999 bytes result sent to driver
2018-02-08 09:18:41,025 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 10.0 (TID 152) in 11 ms on localhost (executor driver) (24/75)
2018-02-08 09:18:41,040 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 10.0 (TID 156, localhost, executor driver, partition 154, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,040 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 10.0 (TID 156)
2018-02-08 09:18:41,040 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 10.0 (TID 157, localhost, executor driver, partition 155, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,042 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 10.0 (TID 155) in 17 ms on localhost (executor driver) (25/75)
2018-02-08 09:18:41,042 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 10.0 (TID 157)
2018-02-08 09:18:41,043 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,043 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,045 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 10.0 (TID 154) in 21 ms on localhost (executor driver) (26/75)
2018-02-08 09:18:41,046 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 10.0 (TID 153) in 30 ms on localhost (executor driver) (27/75)
2018-02-08 09:18:41,046 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,046 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,049 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 10.0 (TID 157). 2956 bytes result sent to driver
2018-02-08 09:18:41,050 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 10.0 (TID 158, localhost, executor driver, partition 156, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,050 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 10.0 (TID 157) in 10 ms on localhost (executor driver) (28/75)
2018-02-08 09:18:41,050 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 10.0 (TID 158)
2018-02-08 09:18:41,052 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 10.0 (TID 156). 2999 bytes result sent to driver
2018-02-08 09:18:41,052 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 10.0 (TID 159, localhost, executor driver, partition 157, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,052 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 10.0 (TID 156) in 13 ms on localhost (executor driver) (29/75)
2018-02-08 09:18:41,053 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,054 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,061 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 10.0 (TID 158). 2999 bytes result sent to driver
2018-02-08 09:18:41,062 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 10.0 (TID 160, localhost, executor driver, partition 158, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,063 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 10.0 (TID 158) in 12 ms on localhost (executor driver) (30/75)
2018-02-08 09:18:41,064 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 10.0 (TID 160)
2018-02-08 09:18:41,071 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,071 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,073 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 10.0 (TID 159)
2018-02-08 09:18:41,074 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 10.0 (TID 160). 2999 bytes result sent to driver
2018-02-08 09:18:41,079 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,079 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,081 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 10.0 (TID 161, localhost, executor driver, partition 159, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,081 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 10.0 (TID 160) in 19 ms on localhost (executor driver) (31/75)
2018-02-08 09:18:41,083 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 10.0 (TID 159). 2956 bytes result sent to driver
2018-02-08 09:18:41,084 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 10.0 (TID 161)
2018-02-08 09:18:41,087 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 10.0 (TID 162, localhost, executor driver, partition 160, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,088 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 10.0 (TID 159) in 36 ms on localhost (executor driver) (32/75)
2018-02-08 09:18:41,090 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,091 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,092 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 10.0 (TID 162)
2018-02-08 09:18:41,094 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 10.0 (TID 161). 2956 bytes result sent to driver
2018-02-08 09:18:41,095 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,096 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,097 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 10.0 (TID 163, localhost, executor driver, partition 161, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,097 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 10.0 (TID 161) in 16 ms on localhost (executor driver) (33/75)
2018-02-08 09:18:41,098 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 10.0 (TID 163)
2018-02-08 09:18:41,098 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 10.0 (TID 162). 2999 bytes result sent to driver
2018-02-08 09:18:41,103 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 10.0 (TID 164, localhost, executor driver, partition 162, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,105 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,106 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,106 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 10.0 (TID 162) in 19 ms on localhost (executor driver) (34/75)
2018-02-08 09:18:41,106 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 10.0 (TID 164)
2018-02-08 09:18:41,110 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 10.0 (TID 163). 2956 bytes result sent to driver
2018-02-08 09:18:41,110 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,110 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,111 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 10.0 (TID 165, localhost, executor driver, partition 163, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,111 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 10.0 (TID 163) in 14 ms on localhost (executor driver) (35/75)
2018-02-08 09:18:41,113 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 10.0 (TID 164). 2956 bytes result sent to driver
2018-02-08 09:18:41,113 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 10.0 (TID 165)
2018-02-08 09:18:41,119 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,119 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,119 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 10.0 (TID 166, localhost, executor driver, partition 164, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,120 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 10.0 (TID 164) in 17 ms on localhost (executor driver) (36/75)
2018-02-08 09:18:41,120 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 10.0 (TID 166)
2018-02-08 09:18:41,123 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,123 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,128 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 10.0 (TID 166). 2999 bytes result sent to driver
2018-02-08 09:18:41,129 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 10.0 (TID 167, localhost, executor driver, partition 165, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,129 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 10.0 (TID 166) in 10 ms on localhost (executor driver) (37/75)
2018-02-08 09:18:41,129 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 10.0 (TID 167)
2018-02-08 09:18:41,136 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,136 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,141 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 10.0 (TID 165). 2999 bytes result sent to driver
2018-02-08 09:18:41,142 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 10.0 (TID 168, localhost, executor driver, partition 166, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,142 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 10.0 (TID 165) in 32 ms on localhost (executor driver) (38/75)
2018-02-08 09:18:41,142 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 10.0 (TID 168)
2018-02-08 09:18:41,144 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 10.0 (TID 167). 2956 bytes result sent to driver
2018-02-08 09:18:41,145 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 10.0 (TID 169, localhost, executor driver, partition 167, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,145 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 10.0 (TID 167) in 16 ms on localhost (executor driver) (39/75)
2018-02-08 09:18:41,145 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,145 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,146 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 10.0 (TID 169)
2018-02-08 09:18:41,154 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,154 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,155 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 10.0 (TID 168). 2999 bytes result sent to driver
2018-02-08 09:18:41,155 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 10.0 (TID 170, localhost, executor driver, partition 168, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,157 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 10.0 (TID 169). 2956 bytes result sent to driver
2018-02-08 09:18:41,157 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 10.0 (TID 170)
2018-02-08 09:18:41,157 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 10.0 (TID 168) in 15 ms on localhost (executor driver) (40/75)
2018-02-08 09:18:41,158 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 10.0 (TID 171, localhost, executor driver, partition 169, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,159 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 10.0 (TID 169) in 14 ms on localhost (executor driver) (41/75)
2018-02-08 09:18:41,159 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 10.0 (TID 171)
2018-02-08 09:18:41,164 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,164 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,165 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,165 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,169 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 10.0 (TID 171). 2999 bytes result sent to driver
2018-02-08 09:18:41,170 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 10.0 (TID 170). 2999 bytes result sent to driver
2018-02-08 09:18:41,170 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 10.0 (TID 172, localhost, executor driver, partition 170, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,171 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 10.0 (TID 173, localhost, executor driver, partition 171, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,171 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 10.0 (TID 172)
2018-02-08 09:18:41,171 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 10.0 (TID 173)
2018-02-08 09:18:41,171 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 10.0 (TID 170) in 16 ms on localhost (executor driver) (42/75)
2018-02-08 09:18:41,174 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,174 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,175 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,175 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,177 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 10.0 (TID 172). 2999 bytes result sent to driver
2018-02-08 09:18:41,178 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 10.0 (TID 171) in 19 ms on localhost (executor driver) (43/75)
2018-02-08 09:18:41,178 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 10.0 (TID 174, localhost, executor driver, partition 172, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,178 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 10.0 (TID 173). 2999 bytes result sent to driver
2018-02-08 09:18:41,179 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 10.0 (TID 172) in 9 ms on localhost (executor driver) (44/75)
2018-02-08 09:18:41,179 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 10.0 (TID 174)
2018-02-08 09:18:41,179 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 10.0 (TID 175, localhost, executor driver, partition 173, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,180 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 10.0 (TID 173) in 10 ms on localhost (executor driver) (45/75)
2018-02-08 09:18:41,180 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 10.0 (TID 175)
2018-02-08 09:18:41,184 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,187 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:18:41,188 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 10.0 (TID 174). 2956 bytes result sent to driver
2018-02-08 09:18:41,190 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 10.0 (TID 176, localhost, executor driver, partition 174, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,191 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 10.0 (TID 174) in 13 ms on localhost (executor driver) (46/75)
2018-02-08 09:18:41,191 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 10.0 (TID 176)
2018-02-08 09:18:41,191 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 10.0 (TID 175). 2956 bytes result sent to driver
2018-02-08 09:18:41,192 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 10.0 (TID 177, localhost, executor driver, partition 175, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,194 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 10.0 (TID 175) in 15 ms on localhost (executor driver) (47/75)
2018-02-08 09:18:41,195 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 10.0 (TID 177)
2018-02-08 09:18:41,195 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,195 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,199 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,199 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,201 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 10.0 (TID 176). 2956 bytes result sent to driver
2018-02-08 09:18:41,202 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 10.0 (TID 178, localhost, executor driver, partition 176, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,202 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 10.0 (TID 177). 2956 bytes result sent to driver
2018-02-08 09:18:41,202 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 10.0 (TID 176) in 13 ms on localhost (executor driver) (48/75)
2018-02-08 09:18:41,202 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 10.0 (TID 178)
2018-02-08 09:18:41,203 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 10.0 (TID 179, localhost, executor driver, partition 177, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,203 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 10.0 (TID 177) in 11 ms on localhost (executor driver) (49/75)
2018-02-08 09:18:41,203 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 10.0 (TID 179)
2018-02-08 09:18:41,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,208 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 10.0 (TID 178). 2999 bytes result sent to driver
2018-02-08 09:18:41,209 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 10.0 (TID 180, localhost, executor driver, partition 178, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,209 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 10.0 (TID 178) in 8 ms on localhost (executor driver) (50/75)
2018-02-08 09:18:41,209 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 09:18:41,209 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 10.0 (TID 180)
2018-02-08 09:18:41,212 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 10.0 (TID 179). 2956 bytes result sent to driver
2018-02-08 09:18:41,213 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,213 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,214 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 10.0 (TID 181, localhost, executor driver, partition 179, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,215 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 10.0 (TID 179) in 13 ms on localhost (executor driver) (51/75)
2018-02-08 09:18:41,216 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 10.0 (TID 181)
2018-02-08 09:18:41,217 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 10.0 (TID 180). 2956 bytes result sent to driver
2018-02-08 09:18:41,217 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 10.0 (TID 182, localhost, executor driver, partition 180, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,218 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 10.0 (TID 180) in 10 ms on localhost (executor driver) (52/75)
2018-02-08 09:18:41,218 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 10.0 (TID 182)
2018-02-08 09:18:41,219 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,219 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,221 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,221 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,223 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 10.0 (TID 181). 2999 bytes result sent to driver
2018-02-08 09:18:41,224 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 10.0 (TID 183, localhost, executor driver, partition 181, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,224 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 10.0 (TID 182). 2999 bytes result sent to driver
2018-02-08 09:18:41,224 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 10.0 (TID 184, localhost, executor driver, partition 182, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,225 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 10.0 (TID 181) in 11 ms on localhost (executor driver) (53/75)
2018-02-08 09:18:41,225 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 10.0 (TID 183)
2018-02-08 09:18:41,225 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 10.0 (TID 182) in 8 ms on localhost (executor driver) (54/75)
2018-02-08 09:18:41,225 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 10.0 (TID 184)
2018-02-08 09:18:41,228 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,228 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,229 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,229 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,232 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 10.0 (TID 183). 2956 bytes result sent to driver
2018-02-08 09:18:41,233 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 10.0 (TID 184). 2999 bytes result sent to driver
2018-02-08 09:18:41,233 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 10.0 (TID 185, localhost, executor driver, partition 183, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,234 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 10.0 (TID 186, localhost, executor driver, partition 184, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,234 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 10.0 (TID 183) in 10 ms on localhost (executor driver) (55/75)
2018-02-08 09:18:41,235 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 10.0 (TID 184) in 11 ms on localhost (executor driver) (56/75)
2018-02-08 09:18:41,235 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 10.0 (TID 185)
2018-02-08 09:18:41,235 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 10.0 (TID 186)
2018-02-08 09:18:41,239 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,239 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,239 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,240 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,242 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 10.0 (TID 185). 2956 bytes result sent to driver
2018-02-08 09:18:41,243 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 10.0 (TID 187, localhost, executor driver, partition 185, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,244 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 10.0 (TID 185) in 11 ms on localhost (executor driver) (57/75)
2018-02-08 09:18:41,244 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 10.0 (TID 186). 2999 bytes result sent to driver
2018-02-08 09:18:41,245 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 10.0 (TID 187)
2018-02-08 09:18:41,245 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 10.0 (TID 188, localhost, executor driver, partition 186, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,245 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 10.0 (TID 186) in 11 ms on localhost (executor driver) (58/75)
2018-02-08 09:18:41,248 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,248 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,251 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 10.0 (TID 187). 2956 bytes result sent to driver
2018-02-08 09:18:41,251 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 10.0 (TID 189, localhost, executor driver, partition 187, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,252 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 10.0 (TID 187) in 9 ms on localhost (executor driver) (59/75)
2018-02-08 09:18:41,252 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 10.0 (TID 189)
2018-02-08 09:18:41,255 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,255 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,258 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 10.0 (TID 188)
2018-02-08 09:18:41,258 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 10.0 (TID 189). 2999 bytes result sent to driver
2018-02-08 09:18:41,259 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 10.0 (TID 190, localhost, executor driver, partition 188, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,259 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 10.0 (TID 189) in 8 ms on localhost (executor driver) (60/75)
2018-02-08 09:18:41,259 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 10.0 (TID 190)
2018-02-08 09:18:41,264 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,264 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,267 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 10.0 (TID 188). 2956 bytes result sent to driver
2018-02-08 09:18:41,268 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 10.0 (TID 191, localhost, executor driver, partition 189, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,268 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 10.0 (TID 188) in 23 ms on localhost (executor driver) (61/75)
2018-02-08 09:18:41,269 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 10.0 (TID 191)
2018-02-08 09:18:41,273 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,274 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,278 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 10.0 (TID 191). 2999 bytes result sent to driver
2018-02-08 09:18:41,278 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 10.0 (TID 192, localhost, executor driver, partition 190, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,279 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 10.0 (TID 191) in 11 ms on localhost (executor driver) (62/75)
2018-02-08 09:18:41,279 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 10.0 (TID 192)
2018-02-08 09:18:41,282 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,282 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,287 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 10.0 (TID 192). 2999 bytes result sent to driver
2018-02-08 09:18:41,288 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 10.0 (TID 193, localhost, executor driver, partition 191, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,289 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 10.0 (TID 192) in 11 ms on localhost (executor driver) (63/75)
2018-02-08 09:18:41,289 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 10.0 (TID 193)
2018-02-08 09:18:41,290 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,290 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,292 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,292 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,297 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 10.0 (TID 193). 2956 bytes result sent to driver
2018-02-08 09:18:41,298 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 10.0 (TID 194, localhost, executor driver, partition 192, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,299 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 10.0 (TID 193) in 11 ms on localhost (executor driver) (64/75)
2018-02-08 09:18:41,299 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 10.0 (TID 194)
2018-02-08 09:18:41,303 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,303 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,306 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 10.0 (TID 190). 2956 bytes result sent to driver
2018-02-08 09:18:41,307 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 10.0 (TID 195, localhost, executor driver, partition 193, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,307 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 10.0 (TID 194). 2956 bytes result sent to driver
2018-02-08 09:18:41,307 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 10.0 (TID 195)
2018-02-08 09:18:41,307 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 10.0 (TID 190) in 48 ms on localhost (executor driver) (65/75)
2018-02-08 09:18:41,314 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 10.0 (TID 196, localhost, executor driver, partition 194, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,315 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,315 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,316 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 10.0 (TID 194) in 18 ms on localhost (executor driver) (66/75)
2018-02-08 09:18:41,317 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 10.0 (TID 196)
2018-02-08 09:18:41,318 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 10.0 (TID 195). 2956 bytes result sent to driver
2018-02-08 09:18:41,319 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 10.0 (TID 197, localhost, executor driver, partition 195, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,320 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,322 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 10.0 (TID 195) in 14 ms on localhost (executor driver) (67/75)
2018-02-08 09:18:41,322 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:18:41,326 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 10.0 (TID 197)
2018-02-08 09:18:41,329 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 10.0 (TID 196). 2956 bytes result sent to driver
2018-02-08 09:18:41,329 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 10.0 (TID 198, localhost, executor driver, partition 196, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,330 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,330 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,330 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 10.0 (TID 198)
2018-02-08 09:18:41,330 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 10.0 (TID 196) in 16 ms on localhost (executor driver) (68/75)
2018-02-08 09:18:41,335 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 10.0 (TID 197). 2999 bytes result sent to driver
2018-02-08 09:18:41,337 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 10.0 (TID 199, localhost, executor driver, partition 197, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,337 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,338 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 10.0 (TID 197) in 20 ms on localhost (executor driver) (69/75)
2018-02-08 09:18:41,338 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,338 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 10.0 (TID 199)
2018-02-08 09:18:41,342 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 10.0 (TID 198). 2999 bytes result sent to driver
2018-02-08 09:18:41,343 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 10.0 (TID 200, localhost, executor driver, partition 198, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,344 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 10.0 (TID 198) in 15 ms on localhost (executor driver) (70/75)
2018-02-08 09:18:41,344 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 10.0 (TID 200)
2018-02-08 09:18:41,344 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,344 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,350 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,350 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:18:41,351 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 10.0 (TID 199). 2956 bytes result sent to driver
2018-02-08 09:18:41,353 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 10.0 (TID 200). 2999 bytes result sent to driver
2018-02-08 09:18:41,353 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 10.0 (TID 201, localhost, executor driver, partition 199, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:18:41,354 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 10.0 (TID 202, localhost, executor driver, partition 132, ANY, 4726 bytes)
2018-02-08 09:18:41,354 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 10.0 (TID 199) in 18 ms on localhost (executor driver) (71/75)
2018-02-08 09:18:41,354 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 10.0 (TID 202)
2018-02-08 09:18:41,354 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 10.0 (TID 200) in 11 ms on localhost (executor driver) (72/75)
2018-02-08 09:18:41,354 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 10.0 (TID 201)
2018-02-08 09:18:41,356 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,356 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,359 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:18:41,359 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:18:41,375 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 10.0 (TID 201). 2956 bytes result sent to driver
2018-02-08 09:18:41,377 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 10.0 (TID 203, localhost, executor driver, partition 137, ANY, 4726 bytes)
2018-02-08 09:18:41,379 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 10.0 (TID 202). 3021 bytes result sent to driver
2018-02-08 09:18:41,380 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 10.0 (TID 201) in 27 ms on localhost (executor driver) (73/75)
2018-02-08 09:18:41,380 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 10.0 (TID 203)
2018-02-08 09:18:41,381 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 10.0 (TID 202) in 27 ms on localhost (executor driver) (74/75)
2018-02-08 09:18:41,383 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:18:41,384 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:18:41,387 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 10.0 (TID 203). 2978 bytes result sent to driver
2018-02-08 09:18:41,388 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 10.0 (TID 203) in 10 ms on localhost (executor driver) (75/75)
2018-02-08 09:18:41,388 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 09:18:41,388 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 10 (show at MachineLeaningSelector.java:151) finished in 0.600 s
2018-02-08 09:18:41,388 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: show at MachineLeaningSelector.java:151, took 0.619801 s
2018-02-08 09:18:41,405 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 5.801602 ms
2018-02-08 09:18:41,527 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 31.644811 ms
2018-02-08 09:18:41,597 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 29.73857 ms
2018-02-08 09:18:41,610 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.248003 ms
2018-02-08 09:18:41,669 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:154
2018-02-08 09:18:41,671 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (show at MachineLeaningSelector.java:154) with 2 output partitions
2018-02-08 09:18:41,671 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 11 (show at MachineLeaningSelector.java:154)
2018-02-08 09:18:41,671 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:18:41,671 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:18:41,672 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 11 (MapPartitionsRDD[17] at show at MachineLeaningSelector.java:154), which has no missing parents
2018-02-08 09:18:41,676 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 27.6 KB, free 615.3 MB)
2018-02-08 09:18:41,679 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 615.2 MB)
2018-02-08 09:18:41,679 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:50835 (size: 9.4 KB, free: 631.7 MB)
2018-02-08 09:18:41,680 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:18:41,680 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[17] at show at MachineLeaningSelector.java:154) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:18:41,680 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 2 tasks
2018-02-08 09:18:41,681 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 5196 bytes)
2018-02-08 09:18:41,681 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 11.0 (TID 205, localhost, executor driver, partition 1, PROCESS_LOCAL, 5196 bytes)
2018-02-08 09:18:41,681 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 204)
2018-02-08 09:18:41,681 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 11.0 (TID 205)
2018-02-08 09:18:41,707 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 204). 3341 bytes result sent to driver
2018-02-08 09:18:41,707 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 11.0 (TID 205). 3298 bytes result sent to driver
2018-02-08 09:18:41,709 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 11.0 (TID 205) in 28 ms on localhost (executor driver) (1/2)
2018-02-08 09:18:41,710 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 204) in 29 ms on localhost (executor driver) (2/2)
2018-02-08 09:18:41,710 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 09:18:41,711 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 11 (show at MachineLeaningSelector.java:154) finished in 0.030 s
2018-02-08 09:18:41,711 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: show at MachineLeaningSelector.java:154, took 0.041553 s
2018-02-08 09:18:41,729 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.317124 ms
2018-02-08 09:18:41,737 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:18:41,744 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@872a3b4{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:18:41,750 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:18:41,768 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:18:41,971 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:18:41,971 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:18:41,973 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:18:41,976 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:18:41,979 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:18:41,979 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:18:41,981 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-489a91b8-881f-415f-a6c8-8b2094bf12a2
2018-02-08 09:18:54,855 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:18:55,342 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:18:55,361 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:18:55,361 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:18:55,362 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:18:55,362 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:18:55,363 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:18:55,715 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 50874.
2018-02-08 09:18:55,733 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:18:55,775 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:18:55,779 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:18:55,779 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:18:55,788 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-eb29a5b4-b578-4544-aaa6-f211bf8d31cb
2018-02-08 09:18:55,809 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:18:55,861 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:18:55,930 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2649ms
2018-02-08 09:18:55,991 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:18:56,004 INFO[org.spark_project.jetty.server.Server:403] - Started @2724ms
2018-02-08 09:18:56,023 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@42f3156d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:18:56,023 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:18:56,045 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@18245eb0{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,046 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4052274f{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,047 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,048 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,048 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,049 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,050 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,051 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,052 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,053 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,054 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,054 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,055 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,056 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,057 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,058 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,059 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,059 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,060 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,061 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,069 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/static,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,070 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@743cb8e0{/,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,071 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/api,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,073 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@fd0e5b6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,073 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,075 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:18:56,153 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:18:56,178 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50888.
2018-02-08 09:18:56,179 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:50888
2018-02-08 09:18:56,180 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:18:56,186 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 50888, None)
2018-02-08 09:18:56,192 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:50888 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 50888, None)
2018-02-08 09:18:56,204 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 50888, None)
2018-02-08 09:18:56,205 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 50888, None)
2018-02-08 09:18:56,393 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@632aa1a3{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,478 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:18:56,478 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:18:56,487 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64d43929{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,488 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,489 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1e7f2e0f{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,489 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@78d39a69{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:18:56,493 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@304a9d7b{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:18:57,528 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:18:59,405 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 196.827903 ms
2018-02-08 09:18:59,426 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.985923 ms
2018-02-08 09:18:59,548 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 31.14273 ms
2018-02-08 09:18:59,581 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 27.405129 ms
2018-02-08 09:19:00,462 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 2
2018-02-08 09:19:00,462 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 1
2018-02-08 09:19:00,463 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 0
2018-02-08 09:19:00,597 INFO[org.apache.spark.sql.execution.aggregate.HashAggregateExec:54] - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
2018-02-08 09:19:00,706 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 83.938907 ms
2018-02-08 09:19:00,802 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 168.366773 ms
2018-02-08 09:19:00,810 INFO[org.apache.spark.sql.execution.aggregate.HashAggregateExec:54] - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
2018-02-08 09:19:00,951 INFO[org.apache.spark.SparkContext:54] - Starting job: run at ThreadPoolExecutor.java:1142
2018-02-08 09:19:00,965 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
2018-02-08 09:19:00,965 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (run at ThreadPoolExecutor.java:1142)
2018-02-08 09:19:00,966 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:19:00,967 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:00,971 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[4] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-02-08 09:19:01,072 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 31.4 KB, free 631.8 MB)
2018-02-08 09:19:01,099 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.1 KB, free 631.8 MB)
2018-02-08 09:19:01,102 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:50888 (size: 9.1 KB, free: 631.8 MB)
2018-02-08 09:19:01,104 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:01,115 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:19:01,116 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 09:19:01,155 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5510 bytes)
2018-02-08 09:19:01,158 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 6050 bytes)
2018-02-08 09:19:01,169 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:19:01,170 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 09:19:01,318 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 23.132487 ms
2018-02-08 09:19:01,341 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1506 bytes result sent to driver
2018-02-08 09:19:01,341 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1668 bytes result sent to driver
2018-02-08 09:19:01,348 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 204 ms on localhost (executor driver) (1/2)
2018-02-08 09:19:01,351 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 194 ms on localhost (executor driver) (2/2)
2018-02-08 09:19:01,352 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:19:01,356 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (run at ThreadPoolExecutor.java:1142) finished in 0.221 s
2018-02-08 09:19:01,360 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: run at ThreadPoolExecutor.java:1142, took 0.408489 s
2018-02-08 09:19:01,394 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 16.800645 ms
2018-02-08 09:19:01,410 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 16.0 MB, free 615.8 MB)
2018-02-08 09:19:01,422 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1160.0 B, free 615.8 MB)
2018-02-08 09:19:01,423 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:50888 (size: 1160.0 B, free: 631.8 MB)
2018-02-08 09:19:01,424 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from run at ThreadPoolExecutor.java:1142
2018-02-08 09:19:01,606 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 136.220524 ms
2018-02-08 09:19:01,726 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:195
2018-02-08 09:19:01,729 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:50888 in memory (size: 9.1 KB, free: 631.8 MB)
2018-02-08 09:19:01,733 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 9 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:01,734 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (show at MachineLeaningSelector.java:195) with 1 output partitions
2018-02-08 09:19:01,734 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:01,734 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 1)
2018-02-08 09:19:01,735 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 1)
2018-02-08 09:19:01,736 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[9] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:01,745 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 100.1 KB, free 615.7 MB)
2018-02-08 09:19:01,748 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.2 KB, free 615.7 MB)
2018-02-08 09:19:01,749 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:50888 (size: 29.2 KB, free: 631.8 MB)
2018-02-08 09:19:01,750 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:01,753 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[9] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:19:01,753 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 09:19:01,757 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5499 bytes)
2018-02-08 09:19:01,758 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 6039 bytes)
2018-02-08 09:19:01,760 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 09:19:01,760 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 3)
2018-02-08 09:19:01,803 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.800645 ms
2018-02-08 09:19:01,839 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.412165 ms
2018-02-08 09:19:01,875 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 28.695369 ms
2018-02-08 09:19:01,995 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 2712 bytes result sent to driver
2018-02-08 09:19:01,996 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 3). 2712 bytes result sent to driver
2018-02-08 09:19:02,000 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 3) in 242 ms on localhost (executor driver) (1/2)
2018-02-08 09:19:02,000 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 247 ms on localhost (executor driver) (2/2)
2018-02-08 09:19:02,000 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 09:19:02,002 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (show at MachineLeaningSelector.java:195) finished in 0.249 s
2018-02-08 09:19:02,003 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 09:19:02,004 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 09:19:02,005 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 2)
2018-02-08 09:19:02,005 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 09:19:02,008 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:02,013 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 60.5 KB, free 615.6 MB)
2018-02-08 09:19:02,015 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.5 KB, free 615.6 MB)
2018-02-08 09:19:02,016 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:50888 (size: 20.5 KB, free: 631.8 MB)
2018-02-08 09:19:02,016 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:02,017 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:19:02,017 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 09:19:02,019 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,020 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 4)
2018-02-08 09:19:02,038 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,040 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
2018-02-08 09:19:02,060 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 4). 2999 bytes result sent to driver
2018-02-08 09:19:02,064 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 4) in 46 ms on localhost (executor driver) (1/1)
2018-02-08 09:19:02,065 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 09:19:02,067 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (show at MachineLeaningSelector.java:195) finished in 0.049 s
2018-02-08 09:19:02,069 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: show at MachineLeaningSelector.java:195, took 0.341534 s
2018-02-08 09:19:02,094 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:195
2018-02-08 09:19:02,109 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 174 bytes
2018-02-08 09:19:02,112 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (show at MachineLeaningSelector.java:195) with 4 output partitions
2018-02-08 09:19:02,112 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:02,113 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 3)
2018-02-08 09:19:02,114 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:02,116 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:02,121 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 60.5 KB, free 615.5 MB)
2018-02-08 09:19:02,126 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.4 KB, free 615.5 MB)
2018-02-08 09:19:02,129 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:50888 (size: 20.4 KB, free: 631.7 MB)
2018-02-08 09:19:02,144 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:02,145 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2018-02-08 09:19:02,153 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 4 tasks
2018-02-08 09:19:02,158 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,159 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 4.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,159 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 09:19:02,159 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 4.0 (TID 6)
2018-02-08 09:19:02,166 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,166 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,175 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 2999 bytes result sent to driver
2018-02-08 09:19:02,175 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 4.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,175 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,181 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 4.0 (TID 7)
2018-02-08 09:19:02,181 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 4.0 (TID 6). 2956 bytes result sent to driver
2018-02-08 09:19:02,183 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 25 ms on localhost (executor driver) (1/4)
2018-02-08 09:19:02,187 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,188 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,192 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 4.0 (TID 8, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,195 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 4.0 (TID 7). 2999 bytes result sent to driver
2018-02-08 09:19:02,195 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 4.0 (TID 8)
2018-02-08 09:19:02,195 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 4.0 (TID 6) in 36 ms on localhost (executor driver) (2/4)
2018-02-08 09:19:02,200 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,200 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,201 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 4.0 (TID 7) in 26 ms on localhost (executor driver) (3/4)
2018-02-08 09:19:02,206 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 4.0 (TID 8). 2956 bytes result sent to driver
2018-02-08 09:19:02,207 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 4.0 (TID 8) in 16 ms on localhost (executor driver) (4/4)
2018-02-08 09:19:02,208 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 09:19:02,208 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (show at MachineLeaningSelector.java:195) finished in 0.055 s
2018-02-08 09:19:02,209 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: show at MachineLeaningSelector.java:195, took 0.115030 s
2018-02-08 09:19:02,214 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:195
2018-02-08 09:19:02,215 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at MachineLeaningSelector.java:195) with 20 output partitions
2018-02-08 09:19:02,215 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:02,216 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 5)
2018-02-08 09:19:02,216 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:02,216 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:02,224 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 60.5 KB, free 615.5 MB)
2018-02-08 09:19:02,227 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.4 KB, free 615.4 MB)
2018-02-08 09:19:02,228 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:50888 (size: 20.4 KB, free: 631.7 MB)
2018-02-08 09:19:02,229 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:02,230 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 20 missing tasks from ResultStage 6 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19))
2018-02-08 09:19:02,230 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 20 tasks
2018-02-08 09:19:02,234 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 9, localhost, executor driver, partition 5, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,234 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 6.0 (TID 10, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,235 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 9)
2018-02-08 09:19:02,235 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 6.0 (TID 10)
2018-02-08 09:19:02,241 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,242 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:19:02,241 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,242 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,248 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 9). 2956 bytes result sent to driver
2018-02-08 09:19:02,251 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 6.0 (TID 10). 2999 bytes result sent to driver
2018-02-08 09:19:02,255 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 6.0 (TID 11, localhost, executor driver, partition 7, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,256 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 6.0 (TID 12, localhost, executor driver, partition 8, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,260 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 9) in 27 ms on localhost (executor driver) (1/20)
2018-02-08 09:19:02,262 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 6.0 (TID 10) in 28 ms on localhost (executor driver) (2/20)
2018-02-08 09:19:02,264 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 6.0 (TID 11)
2018-02-08 09:19:02,270 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 6.0 (TID 12)
2018-02-08 09:19:02,276 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,276 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,280 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 6.0 (TID 11). 2956 bytes result sent to driver
2018-02-08 09:19:02,285 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 6.0 (TID 13, localhost, executor driver, partition 9, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,285 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 6.0 (TID 11) in 30 ms on localhost (executor driver) (3/20)
2018-02-08 09:19:02,287 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 6.0 (TID 13)
2018-02-08 09:19:02,293 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,294 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,318 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 6.0 (TID 13). 3042 bytes result sent to driver
2018-02-08 09:19:02,319 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 6.0 (TID 14, localhost, executor driver, partition 10, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,319 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 6.0 (TID 14)
2018-02-08 09:19:02,320 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 6.0 (TID 13) in 38 ms on localhost (executor driver) (4/20)
2018-02-08 09:19:02,325 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,325 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,333 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,334 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,335 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 6.0 (TID 12). 2999 bytes result sent to driver
2018-02-08 09:19:02,336 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 6.0 (TID 15, localhost, executor driver, partition 11, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,337 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 6.0 (TID 12) in 81 ms on localhost (executor driver) (5/20)
2018-02-08 09:19:02,338 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 6.0 (TID 15)
2018-02-08 09:19:02,346 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,346 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,354 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 6.0 (TID 15). 2999 bytes result sent to driver
2018-02-08 09:19:02,354 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 6.0 (TID 16, localhost, executor driver, partition 12, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,355 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 6.0 (TID 15) in 19 ms on localhost (executor driver) (6/20)
2018-02-08 09:19:02,355 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 6.0 (TID 16)
2018-02-08 09:19:02,360 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,360 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,360 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 6.0 (TID 14). 2956 bytes result sent to driver
2018-02-08 09:19:02,361 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 6.0 (TID 17, localhost, executor driver, partition 14, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,365 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 6.0 (TID 14) in 46 ms on localhost (executor driver) (7/20)
2018-02-08 09:19:02,366 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 6.0 (TID 16). 2999 bytes result sent to driver
2018-02-08 09:19:02,367 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 6.0 (TID 18, localhost, executor driver, partition 15, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,367 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 6.0 (TID 16) in 13 ms on localhost (executor driver) (8/20)
2018-02-08 09:19:02,368 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 6.0 (TID 18)
2018-02-08 09:19:02,373 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,374 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,377 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 6.0 (TID 18). 2956 bytes result sent to driver
2018-02-08 09:19:02,378 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 6.0 (TID 19, localhost, executor driver, partition 16, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,379 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 6.0 (TID 18) in 12 ms on localhost (executor driver) (9/20)
2018-02-08 09:19:02,380 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 6.0 (TID 19)
2018-02-08 09:19:02,383 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 6.0 (TID 17)
2018-02-08 09:19:02,385 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,386 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,387 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,387 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,393 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 6.0 (TID 19). 2956 bytes result sent to driver
2018-02-08 09:19:02,395 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 6.0 (TID 17). 2956 bytes result sent to driver
2018-02-08 09:19:02,396 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 6.0 (TID 20, localhost, executor driver, partition 17, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,396 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 6.0 (TID 21, localhost, executor driver, partition 18, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 6.0 (TID 19) in 19 ms on localhost (executor driver) (10/20)
2018-02-08 09:19:02,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 6.0 (TID 17) in 36 ms on localhost (executor driver) (11/20)
2018-02-08 09:19:02,398 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 6.0 (TID 20)
2018-02-08 09:19:02,400 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 6.0 (TID 21)
2018-02-08 09:19:02,402 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,402 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,404 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,404 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,408 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 6.0 (TID 20). 2956 bytes result sent to driver
2018-02-08 09:19:02,409 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 6.0 (TID 22, localhost, executor driver, partition 19, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,410 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 6.0 (TID 21). 2956 bytes result sent to driver
2018-02-08 09:19:02,410 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 6.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,410 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 6.0 (TID 22)
2018-02-08 09:19:02,412 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 6.0 (TID 21) in 16 ms on localhost (executor driver) (12/20)
2018-02-08 09:19:02,414 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 6.0 (TID 20) in 20 ms on localhost (executor driver) (13/20)
2018-02-08 09:19:02,415 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 6.0 (TID 23)
2018-02-08 09:19:02,415 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,416 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,419 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 6.0 (TID 22). 2999 bytes result sent to driver
2018-02-08 09:19:02,420 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 6.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,420 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 6.0 (TID 22) in 11 ms on localhost (executor driver) (14/20)
2018-02-08 09:19:02,421 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 6.0 (TID 24)
2018-02-08 09:19:02,425 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,425 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,429 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,430 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 09:19:02,434 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 6.0 (TID 23). 2956 bytes result sent to driver
2018-02-08 09:19:02,434 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 6.0 (TID 24). 2999 bytes result sent to driver
2018-02-08 09:19:02,435 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 6.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,436 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 6.0 (TID 26, localhost, executor driver, partition 23, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,436 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 6.0 (TID 23) in 26 ms on localhost (executor driver) (15/20)
2018-02-08 09:19:02,436 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 6.0 (TID 26)
2018-02-08 09:19:02,436 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 6.0 (TID 25)
2018-02-08 09:19:02,443 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,443 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,447 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,447 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,448 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 6.0 (TID 26). 2999 bytes result sent to driver
2018-02-08 09:19:02,448 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 6.0 (TID 24) in 28 ms on localhost (executor driver) (16/20)
2018-02-08 09:19:02,451 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 6.0 (TID 27, localhost, executor driver, partition 24, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,452 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 6.0 (TID 26) in 17 ms on localhost (executor driver) (17/20)
2018-02-08 09:19:02,453 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 6.0 (TID 27)
2018-02-08 09:19:02,453 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 6.0 (TID 25). 2999 bytes result sent to driver
2018-02-08 09:19:02,457 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 6.0 (TID 28, localhost, executor driver, partition 13, ANY, 4726 bytes)
2018-02-08 09:19:02,458 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,458 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,460 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 6.0 (TID 25) in 25 ms on localhost (executor driver) (18/20)
2018-02-08 09:19:02,461 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 6.0 (TID 28)
2018-02-08 09:19:02,462 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 6.0 (TID 27). 2999 bytes result sent to driver
2018-02-08 09:19:02,466 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 6.0 (TID 27) in 15 ms on localhost (executor driver) (19/20)
2018-02-08 09:19:02,466 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,466 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,491 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 6.0 (TID 28). 3017 bytes result sent to driver
2018-02-08 09:19:02,492 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 6.0 (TID 28) in 35 ms on localhost (executor driver) (20/20)
2018-02-08 09:19:02,492 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 09:19:02,492 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (show at MachineLeaningSelector.java:195) finished in 0.259 s
2018-02-08 09:19:02,494 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at MachineLeaningSelector.java:195, took 0.278860 s
2018-02-08 09:19:02,500 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:195
2018-02-08 09:19:02,511 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (show at MachineLeaningSelector.java:195) with 100 output partitions
2018-02-08 09:19:02,511 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 8 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:02,511 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 7)
2018-02-08 09:19:02,512 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:02,513 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 8 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:02,542 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 60.5 KB, free 615.4 MB)
2018-02-08 09:19:02,549 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.4 KB, free 615.4 MB)
2018-02-08 09:19:02,550 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:50888 (size: 20.4 KB, free: 631.7 MB)
2018-02-08 09:19:02,551 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:02,553 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 100 missing tasks from ResultStage 8 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39))
2018-02-08 09:19:02,553 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 100 tasks
2018-02-08 09:19:02,559 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 29, localhost, executor driver, partition 25, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,559 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 8.0 (TID 30, localhost, executor driver, partition 26, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,560 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 29)
2018-02-08 09:19:02,563 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 8.0 (TID 30)
2018-02-08 09:19:02,564 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,564 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,569 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,569 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,572 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 29). 2956 bytes result sent to driver
2018-02-08 09:19:02,575 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 8.0 (TID 31, localhost, executor driver, partition 27, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,576 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 29) in 19 ms on localhost (executor driver) (1/100)
2018-02-08 09:19:02,577 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 8.0 (TID 31)
2018-02-08 09:19:02,578 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 8.0 (TID 30). 2999 bytes result sent to driver
2018-02-08 09:19:02,582 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,582 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,582 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 8.0 (TID 32, localhost, executor driver, partition 28, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,585 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 8.0 (TID 31). 2999 bytes result sent to driver
2018-02-08 09:19:02,586 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 8.0 (TID 33, localhost, executor driver, partition 29, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,589 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 8.0 (TID 30) in 30 ms on localhost (executor driver) (2/100)
2018-02-08 09:19:02,590 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 8.0 (TID 31) in 15 ms on localhost (executor driver) (3/100)
2018-02-08 09:19:02,590 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 8.0 (TID 33)
2018-02-08 09:19:02,589 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 8.0 (TID 32)
2018-02-08 09:19:02,593 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,594 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,596 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,596 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,618 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 8.0 (TID 32). 2999 bytes result sent to driver
2018-02-08 09:19:02,623 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 8.0 (TID 33). 2956 bytes result sent to driver
2018-02-08 09:19:02,623 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 8.0 (TID 34, localhost, executor driver, partition 30, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,624 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 8.0 (TID 34)
2018-02-08 09:19:02,625 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 8.0 (TID 35, localhost, executor driver, partition 31, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,626 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 8.0 (TID 33) in 40 ms on localhost (executor driver) (4/100)
2018-02-08 09:19:02,626 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 8.0 (TID 35)
2018-02-08 09:19:02,628 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,628 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,629 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,629 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,631 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 8.0 (TID 32) in 49 ms on localhost (executor driver) (5/100)
2018-02-08 09:19:02,634 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 8.0 (TID 35). 2956 bytes result sent to driver
2018-02-08 09:19:02,636 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 8.0 (TID 34). 2999 bytes result sent to driver
2018-02-08 09:19:02,637 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 8.0 (TID 36, localhost, executor driver, partition 32, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,637 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 8.0 (TID 37, localhost, executor driver, partition 33, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,637 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 8.0 (TID 36)
2018-02-08 09:19:02,638 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 8.0 (TID 34) in 15 ms on localhost (executor driver) (6/100)
2018-02-08 09:19:02,638 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 8.0 (TID 35) in 13 ms on localhost (executor driver) (7/100)
2018-02-08 09:19:02,638 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 8.0 (TID 37)
2018-02-08 09:19:02,643 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,643 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,647 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 8.0 (TID 37). 2999 bytes result sent to driver
2018-02-08 09:19:02,648 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 8.0 (TID 38, localhost, executor driver, partition 34, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,649 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 8.0 (TID 37) in 12 ms on localhost (executor driver) (8/100)
2018-02-08 09:19:02,649 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 8.0 (TID 38)
2018-02-08 09:19:02,655 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,656 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,656 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,657 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,661 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 8.0 (TID 36). 2999 bytes result sent to driver
2018-02-08 09:19:02,662 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 8.0 (TID 39, localhost, executor driver, partition 35, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,663 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 8.0 (TID 36) in 27 ms on localhost (executor driver) (9/100)
2018-02-08 09:19:02,664 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 8.0 (TID 39)
2018-02-08 09:19:02,669 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,669 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,671 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 8.0 (TID 38). 2999 bytes result sent to driver
2018-02-08 09:19:02,672 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 8.0 (TID 40, localhost, executor driver, partition 36, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,672 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 8.0 (TID 39). 2956 bytes result sent to driver
2018-02-08 09:19:02,673 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 8.0 (TID 40)
2018-02-08 09:19:02,674 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 8.0 (TID 38) in 26 ms on localhost (executor driver) (10/100)
2018-02-08 09:19:02,677 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,677 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,677 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 8.0 (TID 41, localhost, executor driver, partition 37, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,680 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 8.0 (TID 39) in 19 ms on localhost (executor driver) (11/100)
2018-02-08 09:19:02,681 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 8.0 (TID 41)
2018-02-08 09:19:02,681 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 8.0 (TID 40). 2999 bytes result sent to driver
2018-02-08 09:19:02,685 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 8.0 (TID 42, localhost, executor driver, partition 38, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,687 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,687 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,689 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 8.0 (TID 40) in 17 ms on localhost (executor driver) (12/100)
2018-02-08 09:19:02,691 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 8.0 (TID 42)
2018-02-08 09:19:02,691 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 8.0 (TID 41). 2956 bytes result sent to driver
2018-02-08 09:19:02,692 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 8.0 (TID 43, localhost, executor driver, partition 39, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,694 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 8.0 (TID 41) in 17 ms on localhost (executor driver) (13/100)
2018-02-08 09:19:02,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,695 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 8.0 (TID 43)
2018-02-08 09:19:02,700 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,700 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,701 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 8.0 (TID 42). 2999 bytes result sent to driver
2018-02-08 09:19:02,704 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 8.0 (TID 44, localhost, executor driver, partition 40, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,705 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 8.0 (TID 43). 2956 bytes result sent to driver
2018-02-08 09:19:02,705 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 8.0 (TID 42) in 21 ms on localhost (executor driver) (14/100)
2018-02-08 09:19:02,706 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 8.0 (TID 44)
2018-02-08 09:19:02,706 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 8.0 (TID 45, localhost, executor driver, partition 41, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,707 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 8.0 (TID 43) in 15 ms on localhost (executor driver) (15/100)
2018-02-08 09:19:02,707 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 8.0 (TID 45)
2018-02-08 09:19:02,710 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,710 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,716 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 8.0 (TID 44). 2999 bytes result sent to driver
2018-02-08 09:19:02,717 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 8.0 (TID 46, localhost, executor driver, partition 42, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,718 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 8.0 (TID 44) in 14 ms on localhost (executor driver) (16/100)
2018-02-08 09:19:02,719 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 8.0 (TID 46)
2018-02-08 09:19:02,726 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,726 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,731 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 8.0 (TID 46). 2999 bytes result sent to driver
2018-02-08 09:19:02,732 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 8.0 (TID 47, localhost, executor driver, partition 43, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,733 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 8.0 (TID 46) in 16 ms on localhost (executor driver) (17/100)
2018-02-08 09:19:02,733 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 8.0 (TID 47)
2018-02-08 09:19:02,737 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,738 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,744 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,744 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,745 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 8.0 (TID 45). 3085 bytes result sent to driver
2018-02-08 09:19:02,749 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 8.0 (TID 48, localhost, executor driver, partition 44, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,752 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 8.0 (TID 45) in 46 ms on localhost (executor driver) (18/100)
2018-02-08 09:19:02,753 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 8.0 (TID 47). 2956 bytes result sent to driver
2018-02-08 09:19:02,753 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 8.0 (TID 48)
2018-02-08 09:19:02,758 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 8.0 (TID 49, localhost, executor driver, partition 45, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,760 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,760 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,769 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 8.0 (TID 48). 2999 bytes result sent to driver
2018-02-08 09:19:02,769 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 8.0 (TID 47) in 37 ms on localhost (executor driver) (19/100)
2018-02-08 09:19:02,770 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 8.0 (TID 49)
2018-02-08 09:19:02,772 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 8.0 (TID 50, localhost, executor driver, partition 46, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,779 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,779 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,786 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 8.0 (TID 49). 2999 bytes result sent to driver
2018-02-08 09:19:02,788 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 8.0 (TID 48) in 42 ms on localhost (executor driver) (20/100)
2018-02-08 09:19:02,798 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 8.0 (TID 50)
2018-02-08 09:19:02,820 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,820 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,846 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 8.0 (TID 51, localhost, executor driver, partition 47, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,849 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 8.0 (TID 49) in 91 ms on localhost (executor driver) (21/100)
2018-02-08 09:19:02,850 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 8.0 (TID 51)
2018-02-08 09:19:02,851 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 8.0 (TID 50). 3042 bytes result sent to driver
2018-02-08 09:19:02,855 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 8.0 (TID 52, localhost, executor driver, partition 48, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,856 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_4_piece0 on 192.168.11.26:50888 in memory (size: 20.4 KB, free: 631.7 MB)
2018-02-08 09:19:02,858 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 8.0 (TID 52)
2018-02-08 09:19:02,860 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 8.0 (TID 50) in 88 ms on localhost (executor driver) (22/100)
2018-02-08 09:19:02,857 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,862 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 09:19:02,864 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,864 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,867 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 8.0 (TID 51). 3042 bytes result sent to driver
2018-02-08 09:19:02,868 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 8.0 (TID 53, localhost, executor driver, partition 49, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,869 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 8.0 (TID 52). 2999 bytes result sent to driver
2018-02-08 09:19:02,870 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 8.0 (TID 54, localhost, executor driver, partition 50, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,871 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 8.0 (TID 53)
2018-02-08 09:19:02,872 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 8.0 (TID 52) in 17 ms on localhost (executor driver) (23/100)
2018-02-08 09:19:02,873 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 8.0 (TID 51) in 27 ms on localhost (executor driver) (24/100)
2018-02-08 09:19:02,874 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 8.0 (TID 54)
2018-02-08 09:19:02,874 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,879 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 09:19:02,885 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 8.0 (TID 53). 2956 bytes result sent to driver
2018-02-08 09:19:02,885 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_5_piece0 on 192.168.11.26:50888 in memory (size: 20.4 KB, free: 631.7 MB)
2018-02-08 09:19:02,886 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,886 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,890 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 8.0 (TID 55, localhost, executor driver, partition 51, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,890 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 8.0 (TID 53) in 22 ms on localhost (executor driver) (25/100)
2018-02-08 09:19:02,891 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 8.0 (TID 54). 2956 bytes result sent to driver
2018-02-08 09:19:02,892 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 8.0 (TID 55)
2018-02-08 09:19:02,895 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,896 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,898 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 8.0 (TID 56, localhost, executor driver, partition 52, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,899 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 8.0 (TID 54) in 29 ms on localhost (executor driver) (26/100)
2018-02-08 09:19:02,901 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 8.0 (TID 55). 2999 bytes result sent to driver
2018-02-08 09:19:02,901 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 8.0 (TID 56)
2018-02-08 09:19:02,903 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 8.0 (TID 57, localhost, executor driver, partition 53, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,904 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.11.26:50888 in memory (size: 29.2 KB, free: 631.8 MB)
2018-02-08 09:19:02,905 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 8.0 (TID 55) in 18 ms on localhost (executor driver) (27/100)
2018-02-08 09:19:02,905 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 8.0 (TID 57)
2018-02-08 09:19:02,906 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,906 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,912 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 8.0 (TID 56). 2956 bytes result sent to driver
2018-02-08 09:19:02,912 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 8.0 (TID 58, localhost, executor driver, partition 54, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,913 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 8.0 (TID 56) in 17 ms on localhost (executor driver) (28/100)
2018-02-08 09:19:02,913 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 8.0 (TID 58)
2018-02-08 09:19:02,913 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_3_piece0 on 192.168.11.26:50888 in memory (size: 20.5 KB, free: 631.8 MB)
2018-02-08 09:19:02,915 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,915 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,919 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 8.0 (TID 58). 2956 bytes result sent to driver
2018-02-08 09:19:02,920 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 8.0 (TID 59, localhost, executor driver, partition 55, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,920 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 8.0 (TID 58) in 8 ms on localhost (executor driver) (29/100)
2018-02-08 09:19:02,920 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 8.0 (TID 59)
2018-02-08 09:19:02,924 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,924 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:02,929 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 8.0 (TID 59). 2999 bytes result sent to driver
2018-02-08 09:19:02,932 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 8.0 (TID 60, localhost, executor driver, partition 56, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,933 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 8.0 (TID 59) in 13 ms on localhost (executor driver) (30/100)
2018-02-08 09:19:02,934 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 8.0 (TID 60)
2018-02-08 09:19:02,939 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,939 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,943 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 8.0 (TID 60). 2999 bytes result sent to driver
2018-02-08 09:19:02,944 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 8.0 (TID 61, localhost, executor driver, partition 57, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,946 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 8.0 (TID 60) in 17 ms on localhost (executor driver) (31/100)
2018-02-08 09:19:02,950 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,950 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,960 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 8.0 (TID 57). 2956 bytes result sent to driver
2018-02-08 09:19:02,962 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 8.0 (TID 62, localhost, executor driver, partition 58, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,962 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 8.0 (TID 57) in 59 ms on localhost (executor driver) (32/100)
2018-02-08 09:19:02,963 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 8.0 (TID 62)
2018-02-08 09:19:02,962 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 8.0 (TID 61)
2018-02-08 09:19:02,967 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,967 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:02,977 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 8.0 (TID 62). 2956 bytes result sent to driver
2018-02-08 09:19:02,977 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 8.0 (TID 63, localhost, executor driver, partition 59, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:02,978 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 8.0 (TID 62) in 17 ms on localhost (executor driver) (33/100)
2018-02-08 09:19:02,978 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 8.0 (TID 63)
2018-02-08 09:19:02,979 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,982 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:02,982 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,010 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 31 ms
2018-02-08 09:19:03,012 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 8.0 (TID 63). 2956 bytes result sent to driver
2018-02-08 09:19:03,013 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 8.0 (TID 61). 2956 bytes result sent to driver
2018-02-08 09:19:03,014 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 8.0 (TID 64, localhost, executor driver, partition 61, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,015 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 8.0 (TID 65, localhost, executor driver, partition 62, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,016 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 8.0 (TID 63) in 38 ms on localhost (executor driver) (34/100)
2018-02-08 09:19:03,016 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 8.0 (TID 61) in 72 ms on localhost (executor driver) (35/100)
2018-02-08 09:19:03,016 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 8.0 (TID 64)
2018-02-08 09:19:03,022 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 8.0 (TID 65)
2018-02-08 09:19:03,023 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,023 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,025 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,025 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,030 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 8.0 (TID 65). 2956 bytes result sent to driver
2018-02-08 09:19:03,034 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 8.0 (TID 66, localhost, executor driver, partition 63, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,035 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 8.0 (TID 64). 2956 bytes result sent to driver
2018-02-08 09:19:03,038 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 8.0 (TID 67, localhost, executor driver, partition 64, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,038 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 8.0 (TID 65) in 23 ms on localhost (executor driver) (36/100)
2018-02-08 09:19:03,038 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 8.0 (TID 67)
2018-02-08 09:19:03,038 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 8.0 (TID 66)
2018-02-08 09:19:03,041 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,041 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,042 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 8.0 (TID 64) in 29 ms on localhost (executor driver) (37/100)
2018-02-08 09:19:03,045 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 8.0 (TID 67). 2956 bytes result sent to driver
2018-02-08 09:19:03,046 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 8.0 (TID 68, localhost, executor driver, partition 65, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,047 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 8.0 (TID 67) in 10 ms on localhost (executor driver) (38/100)
2018-02-08 09:19:03,047 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 8.0 (TID 68)
2018-02-08 09:19:03,053 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,053 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,057 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 8.0 (TID 68). 2956 bytes result sent to driver
2018-02-08 09:19:03,058 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 8.0 (TID 69, localhost, executor driver, partition 66, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,058 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 8.0 (TID 68) in 12 ms on localhost (executor driver) (39/100)
2018-02-08 09:19:03,058 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 8.0 (TID 69)
2018-02-08 09:19:03,060 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,060 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,061 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,065 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 8.0 (TID 66). 2956 bytes result sent to driver
2018-02-08 09:19:03,066 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 09:19:03,066 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 8.0 (TID 70, localhost, executor driver, partition 67, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,066 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 8.0 (TID 66) in 32 ms on localhost (executor driver) (40/100)
2018-02-08 09:19:03,066 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 8.0 (TID 70)
2018-02-08 09:19:03,072 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,072 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,076 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 8.0 (TID 70). 2999 bytes result sent to driver
2018-02-08 09:19:03,076 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 8.0 (TID 69). 2956 bytes result sent to driver
2018-02-08 09:19:03,077 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 8.0 (TID 71, localhost, executor driver, partition 68, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,077 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 8.0 (TID 72, localhost, executor driver, partition 69, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,077 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 8.0 (TID 70) in 11 ms on localhost (executor driver) (41/100)
2018-02-08 09:19:03,078 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 8.0 (TID 69) in 20 ms on localhost (executor driver) (42/100)
2018-02-08 09:19:03,078 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 8.0 (TID 71)
2018-02-08 09:19:03,079 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 8.0 (TID 72)
2018-02-08 09:19:03,081 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,082 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,082 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,082 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,086 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 8.0 (TID 72). 2999 bytes result sent to driver
2018-02-08 09:19:03,086 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 8.0 (TID 71). 2999 bytes result sent to driver
2018-02-08 09:19:03,087 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 8.0 (TID 73, localhost, executor driver, partition 70, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,087 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 8.0 (TID 74, localhost, executor driver, partition 71, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,087 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 8.0 (TID 71) in 10 ms on localhost (executor driver) (43/100)
2018-02-08 09:19:03,087 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 8.0 (TID 73)
2018-02-08 09:19:03,088 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 8.0 (TID 72) in 11 ms on localhost (executor driver) (44/100)
2018-02-08 09:19:03,088 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 8.0 (TID 74)
2018-02-08 09:19:03,090 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,090 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,093 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,093 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,094 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 8.0 (TID 73). 2956 bytes result sent to driver
2018-02-08 09:19:03,094 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 8.0 (TID 75, localhost, executor driver, partition 72, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,096 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 8.0 (TID 73) in 10 ms on localhost (executor driver) (45/100)
2018-02-08 09:19:03,096 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 8.0 (TID 75)
2018-02-08 09:19:03,097 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 8.0 (TID 74). 2956 bytes result sent to driver
2018-02-08 09:19:03,102 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 8.0 (TID 76, localhost, executor driver, partition 73, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,102 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,102 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,103 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 8.0 (TID 74) in 16 ms on localhost (executor driver) (46/100)
2018-02-08 09:19:03,104 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 8.0 (TID 76)
2018-02-08 09:19:03,106 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 8.0 (TID 75). 2956 bytes result sent to driver
2018-02-08 09:19:03,111 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 8.0 (TID 77, localhost, executor driver, partition 74, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,111 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,111 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,113 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 8.0 (TID 75) in 19 ms on localhost (executor driver) (47/100)
2018-02-08 09:19:03,114 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 8.0 (TID 77)
2018-02-08 09:19:03,118 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,118 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,122 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 8.0 (TID 77). 2956 bytes result sent to driver
2018-02-08 09:19:03,122 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 8.0 (TID 76). 2956 bytes result sent to driver
2018-02-08 09:19:03,122 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 8.0 (TID 78, localhost, executor driver, partition 75, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,123 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 8.0 (TID 79, localhost, executor driver, partition 76, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,123 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 8.0 (TID 78)
2018-02-08 09:19:03,123 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 8.0 (TID 76) in 23 ms on localhost (executor driver) (48/100)
2018-02-08 09:19:03,124 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 8.0 (TID 77) in 14 ms on localhost (executor driver) (49/100)
2018-02-08 09:19:03,126 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 8.0 (TID 79)
2018-02-08 09:19:03,127 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,127 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,132 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 8.0 (TID 78). 2999 bytes result sent to driver
2018-02-08 09:19:03,134 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 8.0 (TID 80, localhost, executor driver, partition 77, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,134 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 8.0 (TID 78) in 12 ms on localhost (executor driver) (50/100)
2018-02-08 09:19:03,134 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 8.0 (TID 80)
2018-02-08 09:19:03,137 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,138 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,144 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 8.0 (TID 80). 2956 bytes result sent to driver
2018-02-08 09:19:03,145 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 8.0 (TID 81, localhost, executor driver, partition 78, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,146 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 8.0 (TID 80) in 13 ms on localhost (executor driver) (51/100)
2018-02-08 09:19:03,146 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 8.0 (TID 81)
2018-02-08 09:19:03,152 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,153 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,158 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 8.0 (TID 81). 2956 bytes result sent to driver
2018-02-08 09:19:03,159 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 8.0 (TID 82, localhost, executor driver, partition 79, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,161 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 8.0 (TID 81) in 16 ms on localhost (executor driver) (52/100)
2018-02-08 09:19:03,162 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 8.0 (TID 82)
2018-02-08 09:19:03,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,177 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 8.0 (TID 82). 2956 bytes result sent to driver
2018-02-08 09:19:03,178 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 8.0 (TID 83, localhost, executor driver, partition 80, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,178 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 8.0 (TID 82) in 19 ms on localhost (executor driver) (53/100)
2018-02-08 09:19:03,178 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 8.0 (TID 83)
2018-02-08 09:19:03,182 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,183 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,189 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 8.0 (TID 79). 2999 bytes result sent to driver
2018-02-08 09:19:03,189 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 8.0 (TID 84, localhost, executor driver, partition 81, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,190 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 8.0 (TID 79) in 67 ms on localhost (executor driver) (54/100)
2018-02-08 09:19:03,190 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 8.0 (TID 84)
2018-02-08 09:19:03,193 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,193 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,202 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 8.0 (TID 84). 2999 bytes result sent to driver
2018-02-08 09:19:03,202 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 8.0 (TID 85, localhost, executor driver, partition 82, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,203 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 8.0 (TID 85)
2018-02-08 09:19:03,203 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 8.0 (TID 84) in 14 ms on localhost (executor driver) (55/100)
2018-02-08 09:19:03,206 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,206 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,213 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 8.0 (TID 85). 3042 bytes result sent to driver
2018-02-08 09:19:03,214 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 8.0 (TID 86, localhost, executor driver, partition 83, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,215 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 8.0 (TID 85) in 12 ms on localhost (executor driver) (56/100)
2018-02-08 09:19:03,215 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 8.0 (TID 86)
2018-02-08 09:19:03,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,218 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,223 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 8.0 (TID 86). 2956 bytes result sent to driver
2018-02-08 09:19:03,224 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 8.0 (TID 87, localhost, executor driver, partition 84, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,225 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 8.0 (TID 86) in 11 ms on localhost (executor driver) (57/100)
2018-02-08 09:19:03,225 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 8.0 (TID 87)
2018-02-08 09:19:03,229 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,229 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,235 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,235 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,237 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 8.0 (TID 87). 2956 bytes result sent to driver
2018-02-08 09:19:03,237 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 8.0 (TID 88, localhost, executor driver, partition 85, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,237 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 8.0 (TID 87) in 14 ms on localhost (executor driver) (58/100)
2018-02-08 09:19:03,237 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 8.0 (TID 88)
2018-02-08 09:19:03,240 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,240 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,246 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 8.0 (TID 88). 2999 bytes result sent to driver
2018-02-08 09:19:03,247 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 8.0 (TID 89, localhost, executor driver, partition 86, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,247 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 8.0 (TID 88) in 10 ms on localhost (executor driver) (59/100)
2018-02-08 09:19:03,248 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 8.0 (TID 89)
2018-02-08 09:19:03,251 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,252 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,253 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 8.0 (TID 83). 2956 bytes result sent to driver
2018-02-08 09:19:03,253 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 8.0 (TID 90, localhost, executor driver, partition 87, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,254 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 8.0 (TID 83) in 77 ms on localhost (executor driver) (60/100)
2018-02-08 09:19:03,254 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 8.0 (TID 90)
2018-02-08 09:19:03,255 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 8.0 (TID 89). 2999 bytes result sent to driver
2018-02-08 09:19:03,256 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 8.0 (TID 91, localhost, executor driver, partition 88, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,257 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 8.0 (TID 89) in 10 ms on localhost (executor driver) (61/100)
2018-02-08 09:19:03,258 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 8.0 (TID 91)
2018-02-08 09:19:03,258 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,261 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:19:03,265 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 8.0 (TID 90). 2999 bytes result sent to driver
2018-02-08 09:19:03,266 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 8.0 (TID 92, localhost, executor driver, partition 89, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,267 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 8.0 (TID 90) in 13 ms on localhost (executor driver) (62/100)
2018-02-08 09:19:03,267 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 8.0 (TID 92)
2018-02-08 09:19:03,267 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,267 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,272 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 8.0 (TID 91). 2999 bytes result sent to driver
2018-02-08 09:19:03,273 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,273 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,275 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 8.0 (TID 93, localhost, executor driver, partition 90, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,278 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 8.0 (TID 91) in 23 ms on localhost (executor driver) (63/100)
2018-02-08 09:19:03,278 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 8.0 (TID 93)
2018-02-08 09:19:03,278 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 8.0 (TID 92). 2956 bytes result sent to driver
2018-02-08 09:19:03,280 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 8.0 (TID 94, localhost, executor driver, partition 91, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,281 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,281 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,282 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 8.0 (TID 94)
2018-02-08 09:19:03,284 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 8.0 (TID 93). 2956 bytes result sent to driver
2018-02-08 09:19:03,281 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 8.0 (TID 92) in 15 ms on localhost (executor driver) (64/100)
2018-02-08 09:19:03,286 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 8.0 (TID 95, localhost, executor driver, partition 92, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,287 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,287 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,288 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 8.0 (TID 95)
2018-02-08 09:19:03,292 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 8.0 (TID 94). 2999 bytes result sent to driver
2018-02-08 09:19:03,293 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,293 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,287 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 8.0 (TID 93) in 13 ms on localhost (executor driver) (65/100)
2018-02-08 09:19:03,295 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 8.0 (TID 96, localhost, executor driver, partition 94, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,296 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 8.0 (TID 95). 2956 bytes result sent to driver
2018-02-08 09:19:03,297 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 8.0 (TID 97, localhost, executor driver, partition 95, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,298 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 8.0 (TID 94) in 18 ms on localhost (executor driver) (66/100)
2018-02-08 09:19:03,298 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 8.0 (TID 95) in 12 ms on localhost (executor driver) (67/100)
2018-02-08 09:19:03,299 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 8.0 (TID 96)
2018-02-08 09:19:03,299 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 8.0 (TID 97)
2018-02-08 09:19:03,304 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,304 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,309 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 8.0 (TID 97). 2956 bytes result sent to driver
2018-02-08 09:19:03,310 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 8.0 (TID 98, localhost, executor driver, partition 96, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,310 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 8.0 (TID 97) in 13 ms on localhost (executor driver) (68/100)
2018-02-08 09:19:03,310 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 8.0 (TID 98)
2018-02-08 09:19:03,313 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,314 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,319 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,319 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,321 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 8.0 (TID 98). 2956 bytes result sent to driver
2018-02-08 09:19:03,322 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 8.0 (TID 99, localhost, executor driver, partition 97, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,322 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 8.0 (TID 99)
2018-02-08 09:19:03,322 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 8.0 (TID 98) in 13 ms on localhost (executor driver) (69/100)
2018-02-08 09:19:03,324 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 8.0 (TID 96). 2999 bytes result sent to driver
2018-02-08 09:19:03,325 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 8.0 (TID 100, localhost, executor driver, partition 98, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,328 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,328 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,331 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 8.0 (TID 96) in 36 ms on localhost (executor driver) (70/100)
2018-02-08 09:19:03,333 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 8.0 (TID 99). 2956 bytes result sent to driver
2018-02-08 09:19:03,331 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 8.0 (TID 100)
2018-02-08 09:19:03,334 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 8.0 (TID 101, localhost, executor driver, partition 99, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,335 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 8.0 (TID 99) in 14 ms on localhost (executor driver) (71/100)
2018-02-08 09:19:03,335 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 8.0 (TID 101)
2018-02-08 09:19:03,336 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,336 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,338 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,338 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,342 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 8.0 (TID 101). 2956 bytes result sent to driver
2018-02-08 09:19:03,343 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 8.0 (TID 100). 2956 bytes result sent to driver
2018-02-08 09:19:03,344 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 8.0 (TID 102, localhost, executor driver, partition 100, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,344 INFO[org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 8.0 (TID 102)
2018-02-08 09:19:03,345 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 8.0 (TID 103, localhost, executor driver, partition 101, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,345 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 8.0 (TID 101) in 11 ms on localhost (executor driver) (72/100)
2018-02-08 09:19:03,346 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 8.0 (TID 100) in 21 ms on localhost (executor driver) (73/100)
2018-02-08 09:19:03,346 INFO[org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 8.0 (TID 103)
2018-02-08 09:19:03,347 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,347 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,349 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,350 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,351 INFO[org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 8.0 (TID 102). 2999 bytes result sent to driver
2018-02-08 09:19:03,354 INFO[org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 8.0 (TID 103). 2999 bytes result sent to driver
2018-02-08 09:19:03,354 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 8.0 (TID 104, localhost, executor driver, partition 102, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,355 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 8.0 (TID 105, localhost, executor driver, partition 103, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,357 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 8.0 (TID 102) in 14 ms on localhost (executor driver) (74/100)
2018-02-08 09:19:03,358 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 8.0 (TID 103) in 14 ms on localhost (executor driver) (75/100)
2018-02-08 09:19:03,358 INFO[org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 8.0 (TID 104)
2018-02-08 09:19:03,358 INFO[org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 8.0 (TID 105)
2018-02-08 09:19:03,365 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,366 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,371 INFO[org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 8.0 (TID 104). 2999 bytes result sent to driver
2018-02-08 09:19:03,372 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 8.0 (TID 106, localhost, executor driver, partition 104, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,373 INFO[org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 8.0 (TID 106)
2018-02-08 09:19:03,373 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 8.0 (TID 104) in 19 ms on localhost (executor driver) (76/100)
2018-02-08 09:19:03,377 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,377 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,383 INFO[org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 8.0 (TID 106). 2999 bytes result sent to driver
2018-02-08 09:19:03,384 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,384 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,384 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 8.0 (TID 107, localhost, executor driver, partition 105, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,384 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 8.0 (TID 106) in 12 ms on localhost (executor driver) (77/100)
2018-02-08 09:19:03,385 INFO[org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 8.0 (TID 107)
2018-02-08 09:19:03,393 INFO[org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 8.0 (TID 105). 2956 bytes result sent to driver
2018-02-08 09:19:03,394 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 8.0 (TID 108, localhost, executor driver, partition 106, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 8.0 (TID 105) in 42 ms on localhost (executor driver) (78/100)
2018-02-08 09:19:03,397 INFO[org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 8.0 (TID 108)
2018-02-08 09:19:03,397 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,398 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,404 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,405 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,406 INFO[org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 8.0 (TID 107). 2999 bytes result sent to driver
2018-02-08 09:19:03,408 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 8.0 (TID 109, localhost, executor driver, partition 107, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,409 INFO[org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 8.0 (TID 108). 2956 bytes result sent to driver
2018-02-08 09:19:03,409 INFO[org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 8.0 (TID 109)
2018-02-08 09:19:03,409 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 8.0 (TID 107) in 25 ms on localhost (executor driver) (79/100)
2018-02-08 09:19:03,409 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 8.0 (TID 110, localhost, executor driver, partition 108, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,410 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 8.0 (TID 108) in 16 ms on localhost (executor driver) (80/100)
2018-02-08 09:19:03,410 INFO[org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 8.0 (TID 110)
2018-02-08 09:19:03,416 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,416 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,417 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,417 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,423 INFO[org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 8.0 (TID 109). 2999 bytes result sent to driver
2018-02-08 09:19:03,426 INFO[org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 8.0 (TID 110). 2999 bytes result sent to driver
2018-02-08 09:19:03,428 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 8.0 (TID 111, localhost, executor driver, partition 109, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,428 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 8.0 (TID 112, localhost, executor driver, partition 110, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,428 INFO[org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 8.0 (TID 111)
2018-02-08 09:19:03,430 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 8.0 (TID 110) in 21 ms on localhost (executor driver) (81/100)
2018-02-08 09:19:03,430 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 8.0 (TID 109) in 23 ms on localhost (executor driver) (82/100)
2018-02-08 09:19:03,430 INFO[org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 8.0 (TID 112)
2018-02-08 09:19:03,431 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,431 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,434 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,434 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,435 INFO[org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 8.0 (TID 111). 2956 bytes result sent to driver
2018-02-08 09:19:03,435 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 8.0 (TID 113, localhost, executor driver, partition 111, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,442 INFO[org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 8.0 (TID 112). 2999 bytes result sent to driver
2018-02-08 09:19:03,445 INFO[org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 8.0 (TID 113)
2018-02-08 09:19:03,445 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 8.0 (TID 114, localhost, executor driver, partition 112, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,446 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 8.0 (TID 111) in 19 ms on localhost (executor driver) (83/100)
2018-02-08 09:19:03,447 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,447 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,455 INFO[org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 8.0 (TID 114)
2018-02-08 09:19:03,457 INFO[org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 8.0 (TID 113). 2956 bytes result sent to driver
2018-02-08 09:19:03,455 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 8.0 (TID 112) in 27 ms on localhost (executor driver) (84/100)
2018-02-08 09:19:03,458 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 8.0 (TID 115, localhost, executor driver, partition 113, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,458 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,459 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,459 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 8.0 (TID 113) in 24 ms on localhost (executor driver) (85/100)
2018-02-08 09:19:03,462 INFO[org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 8.0 (TID 114). 2999 bytes result sent to driver
2018-02-08 09:19:03,463 INFO[org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 8.0 (TID 115)
2018-02-08 09:19:03,466 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 8.0 (TID 116, localhost, executor driver, partition 114, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,467 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,467 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,471 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 8.0 (TID 114) in 26 ms on localhost (executor driver) (86/100)
2018-02-08 09:19:03,475 INFO[org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 8.0 (TID 116)
2018-02-08 09:19:03,475 INFO[org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 8.0 (TID 115). 2956 bytes result sent to driver
2018-02-08 09:19:03,476 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 8.0 (TID 117, localhost, executor driver, partition 115, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,477 INFO[org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 8.0 (TID 117)
2018-02-08 09:19:03,477 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 8.0 (TID 115) in 19 ms on localhost (executor driver) (87/100)
2018-02-08 09:19:03,481 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,481 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,488 INFO[org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 8.0 (TID 116). 2956 bytes result sent to driver
2018-02-08 09:19:03,488 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 8.0 (TID 118, localhost, executor driver, partition 116, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,489 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 8.0 (TID 116) in 23 ms on localhost (executor driver) (88/100)
2018-02-08 09:19:03,489 INFO[org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 8.0 (TID 118)
2018-02-08 09:19:03,490 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,491 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,492 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,492 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,499 INFO[org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 8.0 (TID 118). 2956 bytes result sent to driver
2018-02-08 09:19:03,502 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 8.0 (TID 119, localhost, executor driver, partition 117, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,502 INFO[org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 8.0 (TID 119)
2018-02-08 09:19:03,503 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 8.0 (TID 118) in 14 ms on localhost (executor driver) (89/100)
2018-02-08 09:19:03,505 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,506 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,510 INFO[org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 8.0 (TID 119). 2999 bytes result sent to driver
2018-02-08 09:19:03,511 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 8.0 (TID 120, localhost, executor driver, partition 118, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,511 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 8.0 (TID 119) in 9 ms on localhost (executor driver) (90/100)
2018-02-08 09:19:03,512 INFO[org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 8.0 (TID 120)
2018-02-08 09:19:03,515 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,516 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,519 INFO[org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 8.0 (TID 120). 2956 bytes result sent to driver
2018-02-08 09:19:03,521 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 8.0 (TID 121, localhost, executor driver, partition 119, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,522 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 8.0 (TID 120) in 11 ms on localhost (executor driver) (91/100)
2018-02-08 09:19:03,523 INFO[org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 8.0 (TID 121)
2018-02-08 09:19:03,526 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,527 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,533 INFO[org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 8.0 (TID 121). 2956 bytes result sent to driver
2018-02-08 09:19:03,534 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 8.0 (TID 122, localhost, executor driver, partition 120, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,535 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 8.0 (TID 121) in 14 ms on localhost (executor driver) (92/100)
2018-02-08 09:19:03,536 INFO[org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 8.0 (TID 122)
2018-02-08 09:19:03,544 INFO[org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 8.0 (TID 117). 2999 bytes result sent to driver
2018-02-08 09:19:03,545 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 8.0 (TID 123, localhost, executor driver, partition 121, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,545 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 8.0 (TID 117) in 69 ms on localhost (executor driver) (93/100)
2018-02-08 09:19:03,545 INFO[org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 8.0 (TID 123)
2018-02-08 09:19:03,549 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,550 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,553 INFO[org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 8.0 (TID 123). 3042 bytes result sent to driver
2018-02-08 09:19:03,553 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,553 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,553 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 8.0 (TID 124, localhost, executor driver, partition 122, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,555 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 8.0 (TID 123) in 10 ms on localhost (executor driver) (94/100)
2018-02-08 09:19:03,557 INFO[org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 8.0 (TID 124)
2018-02-08 09:19:03,560 INFO[org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 8.0 (TID 122). 2956 bytes result sent to driver
2018-02-08 09:19:03,561 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 8.0 (TID 125, localhost, executor driver, partition 123, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,562 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 8.0 (TID 122) in 28 ms on localhost (executor driver) (95/100)
2018-02-08 09:19:03,562 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,562 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,563 INFO[org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 8.0 (TID 125)
2018-02-08 09:19:03,577 INFO[org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 8.0 (TID 124). 2956 bytes result sent to driver
2018-02-08 09:19:03,578 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 8.0 (TID 126, localhost, executor driver, partition 124, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,578 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 8.0 (TID 124) in 25 ms on localhost (executor driver) (96/100)
2018-02-08 09:19:03,579 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,579 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,582 INFO[org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 8.0 (TID 126)
2018-02-08 09:19:03,586 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,587 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,599 INFO[org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 8.0 (TID 125). 2999 bytes result sent to driver
2018-02-08 09:19:03,600 INFO[org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 8.0 (TID 126). 2999 bytes result sent to driver
2018-02-08 09:19:03,600 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 8.0 (TID 127, localhost, executor driver, partition 60, ANY, 4726 bytes)
2018-02-08 09:19:03,602 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 8.0 (TID 128, localhost, executor driver, partition 93, ANY, 4726 bytes)
2018-02-08 09:19:03,603 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 8.0 (TID 125) in 42 ms on localhost (executor driver) (97/100)
2018-02-08 09:19:03,603 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 8.0 (TID 126) in 26 ms on localhost (executor driver) (98/100)
2018-02-08 09:19:03,604 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 8.0 (TID 127)
2018-02-08 09:19:03,605 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 8.0 (TID 128)
2018-02-08 09:19:03,606 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,606 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,607 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,610 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:19:03,618 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 8.0 (TID 128). 3017 bytes result sent to driver
2018-02-08 09:19:03,618 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 8.0 (TID 128) in 16 ms on localhost (executor driver) (99/100)
2018-02-08 09:19:03,622 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 8.0 (TID 127). 2978 bytes result sent to driver
2018-02-08 09:19:03,623 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 8.0 (TID 127) in 23 ms on localhost (executor driver) (100/100)
2018-02-08 09:19:03,623 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 09:19:03,623 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 8 (show at MachineLeaningSelector.java:195) finished in 1.069 s
2018-02-08 09:19:03,624 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: show at MachineLeaningSelector.java:195, took 1.123080 s
2018-02-08 09:19:03,629 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:195
2018-02-08 09:19:03,630 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (show at MachineLeaningSelector.java:195) with 75 output partitions
2018-02-08 09:19:03,630 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 10 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:03,631 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 9)
2018-02-08 09:19:03,631 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:03,631 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 10 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:03,636 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 60.5 KB, free 615.7 MB)
2018-02-08 09:19:03,638 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 20.5 KB, free 615.6 MB)
2018-02-08 09:19:03,638 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:50888 (size: 20.5 KB, free: 631.8 MB)
2018-02-08 09:19:03,639 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:03,640 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 75 missing tasks from ResultStage 10 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139))
2018-02-08 09:19:03,640 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 75 tasks
2018-02-08 09:19:03,640 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 129, localhost, executor driver, partition 125, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,641 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 10.0 (TID 130, localhost, executor driver, partition 126, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,641 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 129)
2018-02-08 09:19:03,641 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 10.0 (TID 130)
2018-02-08 09:19:03,643 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,645 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:19:03,649 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,649 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,651 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 129). 2999 bytes result sent to driver
2018-02-08 09:19:03,652 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 10.0 (TID 130). 2956 bytes result sent to driver
2018-02-08 09:19:03,652 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 10.0 (TID 131, localhost, executor driver, partition 127, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,653 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 10.0 (TID 132, localhost, executor driver, partition 128, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,653 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 10.0 (TID 131)
2018-02-08 09:19:03,653 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 10.0 (TID 130) in 12 ms on localhost (executor driver) (1/75)
2018-02-08 09:19:03,654 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 129) in 14 ms on localhost (executor driver) (2/75)
2018-02-08 09:19:03,654 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 10.0 (TID 132)
2018-02-08 09:19:03,656 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,656 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,660 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 10.0 (TID 132). 2956 bytes result sent to driver
2018-02-08 09:19:03,662 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 10.0 (TID 133, localhost, executor driver, partition 129, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,662 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 10.0 (TID 132) in 10 ms on localhost (executor driver) (3/75)
2018-02-08 09:19:03,662 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 10.0 (TID 133)
2018-02-08 09:19:03,663 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,663 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,665 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,665 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,666 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 10.0 (TID 131). 2956 bytes result sent to driver
2018-02-08 09:19:03,667 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 10.0 (TID 133). 2956 bytes result sent to driver
2018-02-08 09:19:03,667 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 10.0 (TID 134, localhost, executor driver, partition 130, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,668 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 10.0 (TID 135, localhost, executor driver, partition 131, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,668 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 10.0 (TID 134)
2018-02-08 09:19:03,668 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 10.0 (TID 135)
2018-02-08 09:19:03,668 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 10.0 (TID 133) in 7 ms on localhost (executor driver) (4/75)
2018-02-08 09:19:03,670 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 10.0 (TID 131) in 17 ms on localhost (executor driver) (5/75)
2018-02-08 09:19:03,671 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,671 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,671 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,671 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,674 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 10.0 (TID 135). 2956 bytes result sent to driver
2018-02-08 09:19:03,674 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 10.0 (TID 134). 2956 bytes result sent to driver
2018-02-08 09:19:03,675 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 10.0 (TID 136, localhost, executor driver, partition 132, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,676 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 10.0 (TID 135) in 7 ms on localhost (executor driver) (6/75)
2018-02-08 09:19:03,676 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 10.0 (TID 136)
2018-02-08 09:19:03,676 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 10.0 (TID 134) in 9 ms on localhost (executor driver) (7/75)
2018-02-08 09:19:03,677 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 10.0 (TID 137, localhost, executor driver, partition 133, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,678 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 10.0 (TID 137)
2018-02-08 09:19:03,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,689 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 10.0 (TID 137). 2956 bytes result sent to driver
2018-02-08 09:19:03,689 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 10.0 (TID 136). 2999 bytes result sent to driver
2018-02-08 09:19:03,690 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 10.0 (TID 138, localhost, executor driver, partition 134, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,690 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 10.0 (TID 139, localhost, executor driver, partition 135, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,691 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 10.0 (TID 138)
2018-02-08 09:19:03,691 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 10.0 (TID 139)
2018-02-08 09:19:03,691 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 10.0 (TID 137) in 15 ms on localhost (executor driver) (8/75)
2018-02-08 09:19:03,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,694 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 10.0 (TID 136) in 19 ms on localhost (executor driver) (9/75)
2018-02-08 09:19:03,698 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 10.0 (TID 138). 2999 bytes result sent to driver
2018-02-08 09:19:03,698 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 10.0 (TID 140, localhost, executor driver, partition 136, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,698 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 10.0 (TID 138) in 8 ms on localhost (executor driver) (10/75)
2018-02-08 09:19:03,699 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 10.0 (TID 140)
2018-02-08 09:19:03,699 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,699 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,701 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,701 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,703 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 10.0 (TID 139). 2999 bytes result sent to driver
2018-02-08 09:19:03,703 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 10.0 (TID 141, localhost, executor driver, partition 137, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,703 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 10.0 (TID 140). 2956 bytes result sent to driver
2018-02-08 09:19:03,704 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 10.0 (TID 139) in 13 ms on localhost (executor driver) (11/75)
2018-02-08 09:19:03,704 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 10.0 (TID 141)
2018-02-08 09:19:03,704 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 10.0 (TID 142, localhost, executor driver, partition 138, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,705 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 10.0 (TID 140) in 7 ms on localhost (executor driver) (12/75)
2018-02-08 09:19:03,705 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 10.0 (TID 142)
2018-02-08 09:19:03,706 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,706 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,707 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,707 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,710 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 10.0 (TID 141). 3042 bytes result sent to driver
2018-02-08 09:19:03,711 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 10.0 (TID 143, localhost, executor driver, partition 139, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,711 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 10.0 (TID 141) in 8 ms on localhost (executor driver) (13/75)
2018-02-08 09:19:03,712 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 10.0 (TID 143)
2018-02-08 09:19:03,714 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,714 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,716 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 10.0 (TID 142). 2999 bytes result sent to driver
2018-02-08 09:19:03,716 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 10.0 (TID 144, localhost, executor driver, partition 140, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,717 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 10.0 (TID 142) in 13 ms on localhost (executor driver) (14/75)
2018-02-08 09:19:03,717 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 10.0 (TID 144)
2018-02-08 09:19:03,718 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 10.0 (TID 143). 2956 bytes result sent to driver
2018-02-08 09:19:03,718 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 10.0 (TID 145, localhost, executor driver, partition 141, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,719 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 10.0 (TID 143) in 9 ms on localhost (executor driver) (15/75)
2018-02-08 09:19:03,720 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 10.0 (TID 145)
2018-02-08 09:19:03,720 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,720 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,722 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,722 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,723 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 10.0 (TID 144). 2999 bytes result sent to driver
2018-02-08 09:19:03,724 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 10.0 (TID 146, localhost, executor driver, partition 142, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,727 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 10.0 (TID 145). 2999 bytes result sent to driver
2018-02-08 09:19:03,727 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 10.0 (TID 144) in 11 ms on localhost (executor driver) (16/75)
2018-02-08 09:19:03,727 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 10.0 (TID 146)
2018-02-08 09:19:03,727 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 10.0 (TID 147, localhost, executor driver, partition 143, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,728 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 10.0 (TID 145) in 10 ms on localhost (executor driver) (17/75)
2018-02-08 09:19:03,728 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 10.0 (TID 147)
2018-02-08 09:19:03,730 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,731 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,730 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,731 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,733 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 10.0 (TID 146). 2956 bytes result sent to driver
2018-02-08 09:19:03,734 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 10.0 (TID 147). 2956 bytes result sent to driver
2018-02-08 09:19:03,734 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 10.0 (TID 148, localhost, executor driver, partition 144, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,734 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 10.0 (TID 148)
2018-02-08 09:19:03,734 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 10.0 (TID 149, localhost, executor driver, partition 145, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,735 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 10.0 (TID 146) in 11 ms on localhost (executor driver) (18/75)
2018-02-08 09:19:03,736 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 10.0 (TID 149)
2018-02-08 09:19:03,737 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,737 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,738 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,738 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,740 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 10.0 (TID 148). 2999 bytes result sent to driver
2018-02-08 09:19:03,741 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 10.0 (TID 147) in 14 ms on localhost (executor driver) (19/75)
2018-02-08 09:19:03,741 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 10.0 (TID 149). 2999 bytes result sent to driver
2018-02-08 09:19:03,741 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 10.0 (TID 150, localhost, executor driver, partition 146, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,742 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 10.0 (TID 151, localhost, executor driver, partition 147, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,742 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 10.0 (TID 149) in 8 ms on localhost (executor driver) (20/75)
2018-02-08 09:19:03,742 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 10.0 (TID 150)
2018-02-08 09:19:03,742 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 10.0 (TID 148) in 8 ms on localhost (executor driver) (21/75)
2018-02-08 09:19:03,742 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 10.0 (TID 151)
2018-02-08 09:19:03,745 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,745 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,746 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,746 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,748 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 10.0 (TID 151). 2956 bytes result sent to driver
2018-02-08 09:19:03,749 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 10.0 (TID 152, localhost, executor driver, partition 148, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,750 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 10.0 (TID 151) in 8 ms on localhost (executor driver) (22/75)
2018-02-08 09:19:03,750 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 10.0 (TID 152)
2018-02-08 09:19:03,753 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,753 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,754 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 10.0 (TID 150). 2956 bytes result sent to driver
2018-02-08 09:19:03,755 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 10.0 (TID 153, localhost, executor driver, partition 149, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,755 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 10.0 (TID 150) in 14 ms on localhost (executor driver) (23/75)
2018-02-08 09:19:03,756 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 10.0 (TID 152). 2999 bytes result sent to driver
2018-02-08 09:19:03,757 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 10.0 (TID 153)
2018-02-08 09:19:03,757 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 10.0 (TID 154, localhost, executor driver, partition 150, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,757 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 10.0 (TID 152) in 8 ms on localhost (executor driver) (24/75)
2018-02-08 09:19:03,758 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 10.0 (TID 154)
2018-02-08 09:19:03,759 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,759 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,761 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,761 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,763 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 10.0 (TID 154). 2956 bytes result sent to driver
2018-02-08 09:19:03,765 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 10.0 (TID 155, localhost, executor driver, partition 151, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,766 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 10.0 (TID 154) in 9 ms on localhost (executor driver) (25/75)
2018-02-08 09:19:03,766 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 10.0 (TID 155)
2018-02-08 09:19:03,767 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 10.0 (TID 153). 2956 bytes result sent to driver
2018-02-08 09:19:03,768 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 10.0 (TID 156, localhost, executor driver, partition 152, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,769 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 10.0 (TID 153) in 13 ms on localhost (executor driver) (26/75)
2018-02-08 09:19:03,769 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 10.0 (TID 156)
2018-02-08 09:19:03,769 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,769 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,772 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,772 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,775 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 10.0 (TID 155). 2999 bytes result sent to driver
2018-02-08 09:19:03,775 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 10.0 (TID 157, localhost, executor driver, partition 153, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,775 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 10.0 (TID 156). 2956 bytes result sent to driver
2018-02-08 09:19:03,776 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 10.0 (TID 158, localhost, executor driver, partition 154, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,776 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 10.0 (TID 157)
2018-02-08 09:19:03,777 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 10.0 (TID 156) in 10 ms on localhost (executor driver) (27/75)
2018-02-08 09:19:03,777 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 10.0 (TID 155) in 12 ms on localhost (executor driver) (28/75)
2018-02-08 09:19:03,777 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 10.0 (TID 158)
2018-02-08 09:19:03,779 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,779 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,784 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 10.0 (TID 158). 2956 bytes result sent to driver
2018-02-08 09:19:03,785 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 10.0 (TID 159, localhost, executor driver, partition 155, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,786 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 10.0 (TID 158) in 10 ms on localhost (executor driver) (29/75)
2018-02-08 09:19:03,787 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 10.0 (TID 159)
2018-02-08 09:19:03,792 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,793 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,813 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 10.0 (TID 159). 2956 bytes result sent to driver
2018-02-08 09:19:03,814 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 10.0 (TID 160, localhost, executor driver, partition 156, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,814 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 10.0 (TID 159) in 29 ms on localhost (executor driver) (30/75)
2018-02-08 09:19:03,814 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 10.0 (TID 160)
2018-02-08 09:19:03,817 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,817 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,817 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,817 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,823 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 10.0 (TID 160). 2999 bytes result sent to driver
2018-02-08 09:19:03,825 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 10.0 (TID 161, localhost, executor driver, partition 157, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,825 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 10.0 (TID 160) in 11 ms on localhost (executor driver) (31/75)
2018-02-08 09:19:03,826 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 10.0 (TID 161)
2018-02-08 09:19:03,825 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 10.0 (TID 157). 2999 bytes result sent to driver
2018-02-08 09:19:03,827 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 10.0 (TID 162, localhost, executor driver, partition 158, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,827 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 10.0 (TID 157) in 52 ms on localhost (executor driver) (32/75)
2018-02-08 09:19:03,828 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 10.0 (TID 162)
2018-02-08 09:19:03,831 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,831 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,831 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,831 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,834 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 10.0 (TID 161). 2999 bytes result sent to driver
2018-02-08 09:19:03,834 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 10.0 (TID 162). 2999 bytes result sent to driver
2018-02-08 09:19:03,834 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 10.0 (TID 163, localhost, executor driver, partition 159, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,835 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 10.0 (TID 164, localhost, executor driver, partition 160, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,835 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 10.0 (TID 163)
2018-02-08 09:19:03,835 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 10.0 (TID 164)
2018-02-08 09:19:03,835 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 10.0 (TID 161) in 11 ms on localhost (executor driver) (33/75)
2018-02-08 09:19:03,837 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 10.0 (TID 162) in 10 ms on localhost (executor driver) (34/75)
2018-02-08 09:19:03,839 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,839 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,840 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,840 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,842 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 10.0 (TID 163). 2956 bytes result sent to driver
2018-02-08 09:19:03,843 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 10.0 (TID 164). 2956 bytes result sent to driver
2018-02-08 09:19:03,843 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 10.0 (TID 165, localhost, executor driver, partition 161, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,844 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 10.0 (TID 166, localhost, executor driver, partition 162, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,845 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 10.0 (TID 163) in 11 ms on localhost (executor driver) (35/75)
2018-02-08 09:19:03,845 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 10.0 (TID 166)
2018-02-08 09:19:03,846 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 10.0 (TID 164) in 11 ms on localhost (executor driver) (36/75)
2018-02-08 09:19:03,845 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 10.0 (TID 165)
2018-02-08 09:19:03,848 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,848 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,849 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,850 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,854 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 10.0 (TID 166). 2999 bytes result sent to driver
2018-02-08 09:19:03,855 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 10.0 (TID 167, localhost, executor driver, partition 163, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,856 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 10.0 (TID 165). 2999 bytes result sent to driver
2018-02-08 09:19:03,857 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 10.0 (TID 168, localhost, executor driver, partition 164, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,857 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 10.0 (TID 167)
2018-02-08 09:19:03,857 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 10.0 (TID 168)
2018-02-08 09:19:03,857 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 10.0 (TID 165) in 14 ms on localhost (executor driver) (37/75)
2018-02-08 09:19:03,859 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,860 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,860 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 10.0 (TID 166) in 16 ms on localhost (executor driver) (38/75)
2018-02-08 09:19:03,859 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,861 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:19:03,862 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 10.0 (TID 167). 2956 bytes result sent to driver
2018-02-08 09:19:03,864 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 10.0 (TID 168). 2999 bytes result sent to driver
2018-02-08 09:19:03,865 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 10.0 (TID 169, localhost, executor driver, partition 165, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,866 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 10.0 (TID 170, localhost, executor driver, partition 166, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,866 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 10.0 (TID 169)
2018-02-08 09:19:03,867 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 10.0 (TID 170)
2018-02-08 09:19:03,869 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,869 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,870 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,885 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 10.0 (TID 169). 2999 bytes result sent to driver
2018-02-08 09:19:03,885 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 15 ms
2018-02-08 09:19:03,866 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 10.0 (TID 167) in 11 ms on localhost (executor driver) (39/75)
2018-02-08 09:19:03,889 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 10.0 (TID 170). 2956 bytes result sent to driver
2018-02-08 09:19:03,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 10.0 (TID 171, localhost, executor driver, partition 167, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,890 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 10.0 (TID 172, localhost, executor driver, partition 168, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,890 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 10.0 (TID 168) in 33 ms on localhost (executor driver) (40/75)
2018-02-08 09:19:03,891 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 10.0 (TID 169) in 26 ms on localhost (executor driver) (41/75)
2018-02-08 09:19:03,891 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 10.0 (TID 172)
2018-02-08 09:19:03,891 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 10.0 (TID 170) in 25 ms on localhost (executor driver) (42/75)
2018-02-08 09:19:03,892 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 10.0 (TID 171)
2018-02-08 09:19:03,894 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,894 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,897 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,897 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,898 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 10.0 (TID 172). 2999 bytes result sent to driver
2018-02-08 09:19:03,898 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 10.0 (TID 173, localhost, executor driver, partition 169, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,899 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 10.0 (TID 172) in 10 ms on localhost (executor driver) (43/75)
2018-02-08 09:19:03,899 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 10.0 (TID 173)
2018-02-08 09:19:03,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,903 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 10.0 (TID 171). 2956 bytes result sent to driver
2018-02-08 09:19:03,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,903 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 10.0 (TID 174, localhost, executor driver, partition 170, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,904 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 10.0 (TID 171) in 15 ms on localhost (executor driver) (44/75)
2018-02-08 09:19:03,904 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 10.0 (TID 174)
2018-02-08 09:19:03,906 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 10.0 (TID 173). 2956 bytes result sent to driver
2018-02-08 09:19:03,906 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,907 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,907 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 10.0 (TID 175, localhost, executor driver, partition 171, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,908 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 10.0 (TID 175)
2018-02-08 09:19:03,908 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 10.0 (TID 173) in 10 ms on localhost (executor driver) (45/75)
2018-02-08 09:19:03,909 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 10.0 (TID 174). 2956 bytes result sent to driver
2018-02-08 09:19:03,910 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,910 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,910 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 10.0 (TID 176, localhost, executor driver, partition 172, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,911 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 10.0 (TID 174) in 8 ms on localhost (executor driver) (46/75)
2018-02-08 09:19:03,911 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 10.0 (TID 176)
2018-02-08 09:19:03,913 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 10.0 (TID 175). 2999 bytes result sent to driver
2018-02-08 09:19:03,914 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,914 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 10.0 (TID 177, localhost, executor driver, partition 173, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,914 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,914 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 10.0 (TID 175) in 7 ms on localhost (executor driver) (47/75)
2018-02-08 09:19:03,914 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 10.0 (TID 177)
2018-02-08 09:19:03,919 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 10.0 (TID 176). 2956 bytes result sent to driver
2018-02-08 09:19:03,920 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,920 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,920 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 10.0 (TID 178, localhost, executor driver, partition 174, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,920 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 10.0 (TID 176) in 10 ms on localhost (executor driver) (48/75)
2018-02-08 09:19:03,920 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 10.0 (TID 178)
2018-02-08 09:19:03,922 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 10.0 (TID 177). 2956 bytes result sent to driver
2018-02-08 09:19:03,923 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 10.0 (TID 179, localhost, executor driver, partition 175, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,923 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,923 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,923 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 10.0 (TID 179)
2018-02-08 09:19:03,923 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 10.0 (TID 177) in 10 ms on localhost (executor driver) (49/75)
2018-02-08 09:19:03,925 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 10.0 (TID 178). 2956 bytes result sent to driver
2018-02-08 09:19:03,927 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,927 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,930 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 10.0 (TID 179). 2956 bytes result sent to driver
2018-02-08 09:19:03,931 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 10.0 (TID 180, localhost, executor driver, partition 176, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,931 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 10.0 (TID 178) in 11 ms on localhost (executor driver) (50/75)
2018-02-08 09:19:03,931 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 10.0 (TID 180)
2018-02-08 09:19:03,932 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 10.0 (TID 179) in 10 ms on localhost (executor driver) (51/75)
2018-02-08 09:19:03,933 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 10.0 (TID 181, localhost, executor driver, partition 177, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,935 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 10.0 (TID 181)
2018-02-08 09:19:03,935 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,935 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,937 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,937 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,940 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 10.0 (TID 181). 2956 bytes result sent to driver
2018-02-08 09:19:03,940 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 10.0 (TID 180). 2956 bytes result sent to driver
2018-02-08 09:19:03,940 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 10.0 (TID 182, localhost, executor driver, partition 178, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,941 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 10.0 (TID 183, localhost, executor driver, partition 179, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,941 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 10.0 (TID 181) in 8 ms on localhost (executor driver) (52/75)
2018-02-08 09:19:03,941 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 10.0 (TID 183)
2018-02-08 09:19:03,941 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 10.0 (TID 180) in 10 ms on localhost (executor driver) (53/75)
2018-02-08 09:19:03,941 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 10.0 (TID 182)
2018-02-08 09:19:03,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,947 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 10.0 (TID 183). 2999 bytes result sent to driver
2018-02-08 09:19:03,949 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 10.0 (TID 184, localhost, executor driver, partition 180, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,950 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 10.0 (TID 183) in 9 ms on localhost (executor driver) (54/75)
2018-02-08 09:19:03,950 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 10.0 (TID 184)
2018-02-08 09:19:03,953 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,953 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,954 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 10.0 (TID 182). 2956 bytes result sent to driver
2018-02-08 09:19:03,955 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 10.0 (TID 185, localhost, executor driver, partition 181, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,955 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 10.0 (TID 182) in 15 ms on localhost (executor driver) (55/75)
2018-02-08 09:19:03,955 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 10.0 (TID 185)
2018-02-08 09:19:03,955 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 10.0 (TID 184). 2956 bytes result sent to driver
2018-02-08 09:19:03,956 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 10.0 (TID 186, localhost, executor driver, partition 182, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,957 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 10.0 (TID 184) in 8 ms on localhost (executor driver) (56/75)
2018-02-08 09:19:03,959 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 10.0 (TID 186)
2018-02-08 09:19:03,959 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,959 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,962 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,962 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,962 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 10.0 (TID 185). 2999 bytes result sent to driver
2018-02-08 09:19:03,966 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 10.0 (TID 186). 2956 bytes result sent to driver
2018-02-08 09:19:03,967 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 10.0 (TID 187, localhost, executor driver, partition 183, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,967 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 10.0 (TID 188, localhost, executor driver, partition 184, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,968 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 10.0 (TID 185) in 13 ms on localhost (executor driver) (57/75)
2018-02-08 09:19:03,969 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 10.0 (TID 186) in 13 ms on localhost (executor driver) (58/75)
2018-02-08 09:19:03,970 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 10.0 (TID 187)
2018-02-08 09:19:03,974 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 10.0 (TID 188)
2018-02-08 09:19:03,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,981 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 10.0 (TID 187). 2999 bytes result sent to driver
2018-02-08 09:19:03,983 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 10.0 (TID 189, localhost, executor driver, partition 185, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,984 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 10.0 (TID 187) in 18 ms on localhost (executor driver) (59/75)
2018-02-08 09:19:03,984 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,984 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,984 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 10.0 (TID 189)
2018-02-08 09:19:03,987 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 10.0 (TID 188). 2956 bytes result sent to driver
2018-02-08 09:19:03,987 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 10.0 (TID 190, localhost, executor driver, partition 186, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,987 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,988 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:03,988 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 10.0 (TID 190)
2018-02-08 09:19:03,987 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 10.0 (TID 188) in 20 ms on localhost (executor driver) (60/75)
2018-02-08 09:19:03,991 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,991 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:03,991 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 10.0 (TID 189). 2999 bytes result sent to driver
2018-02-08 09:19:03,993 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 10.0 (TID 191, localhost, executor driver, partition 187, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,993 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 10.0 (TID 189) in 10 ms on localhost (executor driver) (61/75)
2018-02-08 09:19:03,994 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 10.0 (TID 191)
2018-02-08 09:19:03,994 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 10.0 (TID 190). 2999 bytes result sent to driver
2018-02-08 09:19:03,995 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 10.0 (TID 192, localhost, executor driver, partition 188, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:03,997 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:03,997 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:04,001 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 10.0 (TID 192)
2018-02-08 09:19:04,007 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 10.0 (TID 191). 2956 bytes result sent to driver
2018-02-08 09:19:04,008 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,008 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:04,014 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 10.0 (TID 192). 2999 bytes result sent to driver
2018-02-08 09:19:04,016 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 10.0 (TID 190) in 28 ms on localhost (executor driver) (62/75)
2018-02-08 09:19:04,016 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 10.0 (TID 193, localhost, executor driver, partition 189, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:04,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 10.0 (TID 194, localhost, executor driver, partition 190, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:04,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 10.0 (TID 191) in 24 ms on localhost (executor driver) (63/75)
2018-02-08 09:19:04,018 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 10.0 (TID 192) in 23 ms on localhost (executor driver) (64/75)
2018-02-08 09:19:04,021 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 10.0 (TID 193)
2018-02-08 09:19:04,023 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 10.0 (TID 194)
2018-02-08 09:19:04,027 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,027 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:04,033 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 10.0 (TID 193). 2956 bytes result sent to driver
2018-02-08 09:19:04,038 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 10.0 (TID 195, localhost, executor driver, partition 191, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:04,038 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,038 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:04,038 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 10.0 (TID 195)
2018-02-08 09:19:04,038 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 10.0 (TID 193) in 22 ms on localhost (executor driver) (65/75)
2018-02-08 09:19:04,048 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 10.0 (TID 194). 2956 bytes result sent to driver
2018-02-08 09:19:04,049 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 10.0 (TID 196, localhost, executor driver, partition 192, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:04,050 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 10.0 (TID 194) in 33 ms on localhost (executor driver) (66/75)
2018-02-08 09:19:04,050 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 10.0 (TID 196)
2018-02-08 09:19:04,054 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,054 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:04,062 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 10.0 (TID 196). 2956 bytes result sent to driver
2018-02-08 09:19:04,063 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 10.0 (TID 197, localhost, executor driver, partition 193, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:04,063 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 10.0 (TID 196) in 14 ms on localhost (executor driver) (67/75)
2018-02-08 09:19:04,063 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 10.0 (TID 197)
2018-02-08 09:19:04,065 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,066 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,066 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:04,066 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:04,071 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 10.0 (TID 197). 2999 bytes result sent to driver
2018-02-08 09:19:04,074 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 10.0 (TID 198, localhost, executor driver, partition 194, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:04,074 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 10.0 (TID 195). 2999 bytes result sent to driver
2018-02-08 09:19:04,075 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 10.0 (TID 198)
2018-02-08 09:19:04,075 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 10.0 (TID 197) in 12 ms on localhost (executor driver) (68/75)
2018-02-08 09:19:04,079 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 10.0 (TID 199, localhost, executor driver, partition 195, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:04,080 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,080 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:04,085 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 10.0 (TID 198). 2999 bytes result sent to driver
2018-02-08 09:19:04,086 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 10.0 (TID 195) in 49 ms on localhost (executor driver) (69/75)
2018-02-08 09:19:04,086 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 10.0 (TID 199)
2018-02-08 09:19:04,086 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 10.0 (TID 200, localhost, executor driver, partition 196, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:04,088 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 10.0 (TID 198) in 14 ms on localhost (executor driver) (70/75)
2018-02-08 09:19:04,088 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 10.0 (TID 200)
2018-02-08 09:19:04,089 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,089 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:04,090 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,090 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:04,096 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 10.0 (TID 199). 2956 bytes result sent to driver
2018-02-08 09:19:04,102 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 10.0 (TID 200). 2999 bytes result sent to driver
2018-02-08 09:19:04,103 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 10.0 (TID 201, localhost, executor driver, partition 197, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:04,103 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 10.0 (TID 202, localhost, executor driver, partition 199, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:04,104 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 10.0 (TID 199) in 25 ms on localhost (executor driver) (71/75)
2018-02-08 09:19:04,104 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 10.0 (TID 200) in 18 ms on localhost (executor driver) (72/75)
2018-02-08 09:19:04,104 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 10.0 (TID 201)
2018-02-08 09:19:04,111 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,111 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:04,111 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 10.0 (TID 202)
2018-02-08 09:19:04,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:04,121 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 10.0 (TID 201). 2956 bytes result sent to driver
2018-02-08 09:19:04,121 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 10.0 (TID 202). 2956 bytes result sent to driver
2018-02-08 09:19:04,121 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 10.0 (TID 203, localhost, executor driver, partition 198, ANY, 4726 bytes)
2018-02-08 09:19:04,122 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 10.0 (TID 203)
2018-02-08 09:19:04,122 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 10.0 (TID 201) in 19 ms on localhost (executor driver) (73/75)
2018-02-08 09:19:04,123 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 10.0 (TID 202) in 20 ms on localhost (executor driver) (74/75)
2018-02-08 09:19:04,126 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:19:04,126 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:04,130 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 10.0 (TID 203). 3014 bytes result sent to driver
2018-02-08 09:19:04,131 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 10.0 (TID 203) in 10 ms on localhost (executor driver) (75/75)
2018-02-08 09:19:04,131 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 09:19:04,131 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 10 (show at MachineLeaningSelector.java:195) finished in 0.491 s
2018-02-08 09:19:04,132 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: show at MachineLeaningSelector.java:195, took 0.503008 s
2018-02-08 09:19:04,148 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 5.740481 ms
2018-02-08 09:19:04,248 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 44.800654 ms
2018-02-08 09:19:04,329 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 63.04546 ms
2018-02-08 09:19:04,342 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.682884 ms
2018-02-08 09:19:04,384 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:198
2018-02-08 09:19:04,385 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (show at MachineLeaningSelector.java:198) with 2 output partitions
2018-02-08 09:19:04,385 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 11 (show at MachineLeaningSelector.java:198)
2018-02-08 09:19:04,385 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:19:04,385 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:04,385 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 11 (MapPartitionsRDD[17] at show at MachineLeaningSelector.java:198), which has no missing parents
2018-02-08 09:19:04,389 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 27.5 KB, free 615.6 MB)
2018-02-08 09:19:04,391 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 615.6 MB)
2018-02-08 09:19:04,392 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:50888 (size: 9.4 KB, free: 631.7 MB)
2018-02-08 09:19:04,392 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:04,392 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[17] at show at MachineLeaningSelector.java:198) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:19:04,393 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 2 tasks
2018-02-08 09:19:04,393 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 5123 bytes)
2018-02-08 09:19:04,393 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 11.0 (TID 205, localhost, executor driver, partition 1, PROCESS_LOCAL, 5276 bytes)
2018-02-08 09:19:04,394 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 11.0 (TID 205)
2018-02-08 09:19:04,394 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 204)
2018-02-08 09:19:04,412 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 204). 3161 bytes result sent to driver
2018-02-08 09:19:04,413 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 204) in 20 ms on localhost (executor driver) (1/2)
2018-02-08 09:19:04,420 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 11.0 (TID 205). 2493 bytes result sent to driver
2018-02-08 09:19:04,421 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 11.0 (TID 205) in 28 ms on localhost (executor driver) (2/2)
2018-02-08 09:19:04,421 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 09:19:04,421 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 11 (show at MachineLeaningSelector.java:198) finished in 0.028 s
2018-02-08 09:19:04,421 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: show at MachineLeaningSelector.java:198, took 0.036115 s
2018-02-08 09:19:04,438 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.508164 ms
2018-02-08 09:19:04,451 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 219
2018-02-08 09:19:04,453 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.11.26:50888 in memory (size: 9.4 KB, free: 631.8 MB)
2018-02-08 09:19:04,454 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:50888 in memory (size: 20.4 KB, free: 631.8 MB)
2018-02-08 09:19:04,454 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 218
2018-02-08 09:19:04,455 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:50888 in memory (size: 20.5 KB, free: 631.8 MB)
2018-02-08 09:19:04,455 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 220
2018-02-08 09:19:04,456 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:19:04,461 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@42f3156d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:19:04,465 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:19:04,474 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:19:04,584 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:19:04,585 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:19:04,586 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:19:04,588 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:19:04,593 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:19:04,593 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:19:04,594 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-70abfe1b-656b-4658-8f78-917a08609bb1
2018-02-08 09:19:21,315 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:19:21,804 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:19:21,825 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:19:21,827 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:19:21,827 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:19:21,828 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:19:21,829 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:19:22,191 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 50928.
2018-02-08 09:19:22,213 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:19:22,260 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:19:22,263 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:19:22,263 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:19:22,271 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-02aaf472-a581-4a8a-9b17-27c8fa5023b8
2018-02-08 09:19:22,295 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:19:22,349 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:19:22,426 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2683ms
2018-02-08 09:19:22,505 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:19:22,520 INFO[org.spark_project.jetty.server.Server:403] - Started @2778ms
2018-02-08 09:19:22,542 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@3660b7af{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:19:22,542 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:19:22,565 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@18245eb0{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,566 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4052274f{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,567 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,568 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,569 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,569 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,571 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,573 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,574 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,575 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,575 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,576 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,576 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,577 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,578 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,578 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,579 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,580 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,580 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,581 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,589 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/static,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,591 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@743cb8e0{/,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,594 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/api,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,596 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@fd0e5b6{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,597 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:19:22,599 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:19:22,682 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:19:22,710 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50941.
2018-02-08 09:19:22,711 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:50941
2018-02-08 09:19:22,712 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:19:22,718 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 50941, None)
2018-02-08 09:19:22,723 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:50941 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 50941, None)
2018-02-08 09:19:22,731 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 50941, None)
2018-02-08 09:19:22,733 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 50941, None)
2018-02-08 09:19:22,936 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@632aa1a3{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:23,034 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:19:23,035 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:19:23,043 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410e94e{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:19:23,043 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1bdbf9be{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:23,044 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b69d40d{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:19:23,045 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@15f193b8{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:19:23,048 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4aa3d36{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:19:24,166 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:19:26,082 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 212.534148 ms
2018-02-08 09:19:26,104 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.616643 ms
2018-02-08 09:19:26,219 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 27.254729 ms
2018-02-08 09:19:26,251 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 25.556488 ms
2018-02-08 09:19:27,153 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 0
2018-02-08 09:19:27,153 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 1
2018-02-08 09:19:27,153 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 2
2018-02-08 09:19:27,292 INFO[org.apache.spark.sql.execution.aggregate.HashAggregateExec:54] - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
2018-02-08 09:19:27,441 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 122.900839 ms
2018-02-08 09:19:27,489 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 152.268528 ms
2018-02-08 09:19:27,491 INFO[org.apache.spark.sql.execution.aggregate.HashAggregateExec:54] - spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
2018-02-08 09:19:27,641 INFO[org.apache.spark.SparkContext:54] - Starting job: run at ThreadPoolExecutor.java:1142
2018-02-08 09:19:27,661 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (run at ThreadPoolExecutor.java:1142) with 2 output partitions
2018-02-08 09:19:27,662 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (run at ThreadPoolExecutor.java:1142)
2018-02-08 09:19:27,662 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:19:27,663 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:27,668 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[4] at run at ThreadPoolExecutor.java:1142), which has no missing parents
2018-02-08 09:19:27,765 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 31.4 KB, free 631.8 MB)
2018-02-08 09:19:27,795 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.1 KB, free 631.8 MB)
2018-02-08 09:19:27,798 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:50941 (size: 9.1 KB, free: 631.8 MB)
2018-02-08 09:19:27,800 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:27,810 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at run at ThreadPoolExecutor.java:1142) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:19:27,811 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 09:19:27,842 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5510 bytes)
2018-02-08 09:19:27,843 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 6050 bytes)
2018-02-08 09:19:27,850 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 09:19:27,850 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:19:27,962 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 29.206729 ms
2018-02-08 09:19:27,988 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1506 bytes result sent to driver
2018-02-08 09:19:27,988 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1711 bytes result sent to driver
2018-02-08 09:19:27,994 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 150 ms on localhost (executor driver) (1/2)
2018-02-08 09:19:27,995 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 162 ms on localhost (executor driver) (2/2)
2018-02-08 09:19:27,997 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:19:28,002 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (run at ThreadPoolExecutor.java:1142) finished in 0.175 s
2018-02-08 09:19:28,007 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: run at ThreadPoolExecutor.java:1142, took 0.365626 s
2018-02-08 09:19:28,034 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.071684 ms
2018-02-08 09:19:28,045 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 16.0 MB, free 615.8 MB)
2018-02-08 09:19:28,054 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1160.0 B, free 615.8 MB)
2018-02-08 09:19:28,055 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:50941 (size: 1160.0 B, free: 631.8 MB)
2018-02-08 09:19:28,056 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from run at ThreadPoolExecutor.java:1142
2018-02-08 09:19:28,246 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 155.89317 ms
2018-02-08 09:19:28,374 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:50941 in memory (size: 9.1 KB, free: 631.8 MB)
2018-02-08 09:19:28,389 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:195
2018-02-08 09:19:28,392 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 9 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:28,393 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (show at MachineLeaningSelector.java:195) with 1 output partitions
2018-02-08 09:19:28,393 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:28,393 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 1)
2018-02-08 09:19:28,393 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 1)
2018-02-08 09:19:28,394 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[9] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:28,400 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 100.1 KB, free 615.7 MB)
2018-02-08 09:19:28,403 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.2 KB, free 615.7 MB)
2018-02-08 09:19:28,405 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:50941 (size: 29.2 KB, free: 631.8 MB)
2018-02-08 09:19:28,406 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:28,408 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[9] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:19:28,408 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 09:19:28,410 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5499 bytes)
2018-02-08 09:19:28,411 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 6039 bytes)
2018-02-08 09:19:28,412 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 09:19:28,412 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 3)
2018-02-08 09:19:28,474 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 31.13473 ms
2018-02-08 09:19:28,504 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.901123 ms
2018-02-08 09:19:28,568 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 56.571858 ms
2018-02-08 09:19:28,673 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 2755 bytes result sent to driver
2018-02-08 09:19:28,681 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 272 ms on localhost (executor driver) (1/2)
2018-02-08 09:19:28,685 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 3). 2669 bytes result sent to driver
2018-02-08 09:19:28,690 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 3) in 280 ms on localhost (executor driver) (2/2)
2018-02-08 09:19:28,691 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 09:19:28,691 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (show at MachineLeaningSelector.java:195) finished in 0.282 s
2018-02-08 09:19:28,693 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 09:19:28,694 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 09:19:28,694 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 2)
2018-02-08 09:19:28,694 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 09:19:28,698 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:28,702 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 60.5 KB, free 615.6 MB)
2018-02-08 09:19:28,704 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 20.5 KB, free 615.6 MB)
2018-02-08 09:19:28,704 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:50941 (size: 20.5 KB, free: 631.8 MB)
2018-02-08 09:19:28,707 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:28,708 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:19:28,708 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 09:19:28,710 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,710 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 4)
2018-02-08 09:19:28,728 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,730 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
2018-02-08 09:19:28,742 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 4). 2999 bytes result sent to driver
2018-02-08 09:19:28,744 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 4) in 34 ms on localhost (executor driver) (1/1)
2018-02-08 09:19:28,744 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 09:19:28,744 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (show at MachineLeaningSelector.java:195) finished in 0.035 s
2018-02-08 09:19:28,745 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: show at MachineLeaningSelector.java:195, took 0.355681 s
2018-02-08 09:19:28,750 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:195
2018-02-08 09:19:28,756 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 174 bytes
2018-02-08 09:19:28,758 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (show at MachineLeaningSelector.java:195) with 4 output partitions
2018-02-08 09:19:28,758 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:28,758 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 3)
2018-02-08 09:19:28,758 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:28,759 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:28,767 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 60.5 KB, free 615.5 MB)
2018-02-08 09:19:28,771 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.4 KB, free 615.5 MB)
2018-02-08 09:19:28,772 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:50941 (size: 20.4 KB, free: 631.7 MB)
2018-02-08 09:19:28,772 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:28,773 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2018-02-08 09:19:28,774 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 4 tasks
2018-02-08 09:19:28,775 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,776 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 4.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,776 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 09:19:28,776 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 4.0 (TID 6)
2018-02-08 09:19:28,781 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,781 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:28,782 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,783 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:28,792 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 2999 bytes result sent to driver
2018-02-08 09:19:28,793 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 4.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,794 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 19 ms on localhost (executor driver) (1/4)
2018-02-08 09:19:28,795 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 4.0 (TID 6). 2999 bytes result sent to driver
2018-02-08 09:19:28,795 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 4.0 (TID 7)
2018-02-08 09:19:28,796 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 4.0 (TID 8, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,797 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 4.0 (TID 8)
2018-02-08 09:19:28,800 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,801 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:28,802 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,802 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:28,807 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 4.0 (TID 6) in 32 ms on localhost (executor driver) (2/4)
2018-02-08 09:19:28,810 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 4.0 (TID 7). 2999 bytes result sent to driver
2018-02-08 09:19:28,811 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 4.0 (TID 8). 2999 bytes result sent to driver
2018-02-08 09:19:28,812 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 4.0 (TID 7) in 19 ms on localhost (executor driver) (3/4)
2018-02-08 09:19:28,813 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 4.0 (TID 8) in 17 ms on localhost (executor driver) (4/4)
2018-02-08 09:19:28,813 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 09:19:28,814 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (show at MachineLeaningSelector.java:195) finished in 0.038 s
2018-02-08 09:19:28,815 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: show at MachineLeaningSelector.java:195, took 0.063999 s
2018-02-08 09:19:28,818 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:195
2018-02-08 09:19:28,820 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at MachineLeaningSelector.java:195) with 20 output partitions
2018-02-08 09:19:28,820 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:28,820 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 5)
2018-02-08 09:19:28,820 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:28,820 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:28,830 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 60.5 KB, free 615.5 MB)
2018-02-08 09:19:28,831 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 20.4 KB, free 615.4 MB)
2018-02-08 09:19:28,832 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:50941 (size: 20.4 KB, free: 631.7 MB)
2018-02-08 09:19:28,832 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:28,834 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 20 missing tasks from ResultStage 6 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19))
2018-02-08 09:19:28,834 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 20 tasks
2018-02-08 09:19:28,838 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 9, localhost, executor driver, partition 5, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,839 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 6.0 (TID 10, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,839 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 9)
2018-02-08 09:19:28,839 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 6.0 (TID 10)
2018-02-08 09:19:28,844 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,844 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:28,845 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,845 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:28,853 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 6.0 (TID 10). 3042 bytes result sent to driver
2018-02-08 09:19:28,853 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 9). 2999 bytes result sent to driver
2018-02-08 09:19:28,854 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 6.0 (TID 11, localhost, executor driver, partition 7, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,855 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 6.0 (TID 11)
2018-02-08 09:19:28,856 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 6.0 (TID 12, localhost, executor driver, partition 8, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,857 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 6.0 (TID 10) in 19 ms on localhost (executor driver) (1/20)
2018-02-08 09:19:28,857 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 6.0 (TID 12)
2018-02-08 09:19:28,860 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,860 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:28,864 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 6.0 (TID 11). 2956 bytes result sent to driver
2018-02-08 09:19:28,865 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,865 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:28,866 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 9) in 28 ms on localhost (executor driver) (2/20)
2018-02-08 09:19:28,870 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 6.0 (TID 13, localhost, executor driver, partition 9, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,874 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 6.0 (TID 12). 3042 bytes result sent to driver
2018-02-08 09:19:28,875 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 6.0 (TID 14, localhost, executor driver, partition 10, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,875 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 6.0 (TID 11) in 21 ms on localhost (executor driver) (3/20)
2018-02-08 09:19:28,876 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 6.0 (TID 12) in 21 ms on localhost (executor driver) (4/20)
2018-02-08 09:19:28,876 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 6.0 (TID 13)
2018-02-08 09:19:28,877 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 6.0 (TID 14)
2018-02-08 09:19:28,880 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,882 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:19:28,883 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,883 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:28,887 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 6.0 (TID 14). 2956 bytes result sent to driver
2018-02-08 09:19:28,891 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 6.0 (TID 13). 2999 bytes result sent to driver
2018-02-08 09:19:28,891 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 6.0 (TID 15, localhost, executor driver, partition 11, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,892 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 6.0 (TID 16, localhost, executor driver, partition 12, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,893 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 6.0 (TID 15)
2018-02-08 09:19:28,894 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 6.0 (TID 16)
2018-02-08 09:19:28,893 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 6.0 (TID 14) in 19 ms on localhost (executor driver) (5/20)
2018-02-08 09:19:28,909 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 6.0 (TID 13) in 39 ms on localhost (executor driver) (6/20)
2018-02-08 09:19:28,912 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,912 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:28,919 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 6.0 (TID 16). 2999 bytes result sent to driver
2018-02-08 09:19:28,920 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 6.0 (TID 17, localhost, executor driver, partition 14, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,922 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 6.0 (TID 16) in 30 ms on localhost (executor driver) (7/20)
2018-02-08 09:19:28,924 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,925 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:19:28,926 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 6.0 (TID 17)
2018-02-08 09:19:28,935 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 6.0 (TID 15). 2999 bytes result sent to driver
2018-02-08 09:19:28,936 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 6.0 (TID 18, localhost, executor driver, partition 15, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,938 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 6.0 (TID 15) in 47 ms on localhost (executor driver) (8/20)
2018-02-08 09:19:28,938 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,939 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:28,939 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 6.0 (TID 18)
2018-02-08 09:19:28,948 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 6.0 (TID 17). 2999 bytes result sent to driver
2018-02-08 09:19:28,949 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 6.0 (TID 19, localhost, executor driver, partition 16, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,950 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 6.0 (TID 17) in 30 ms on localhost (executor driver) (9/20)
2018-02-08 09:19:28,950 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 6.0 (TID 19)
2018-02-08 09:19:28,952 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,952 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:28,963 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 6.0 (TID 18). 2956 bytes result sent to driver
2018-02-08 09:19:28,965 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 6.0 (TID 20, localhost, executor driver, partition 17, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,970 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,970 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:28,971 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 6.0 (TID 18) in 35 ms on localhost (executor driver) (10/20)
2018-02-08 09:19:28,974 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 6.0 (TID 20)
2018-02-08 09:19:28,982 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 6.0 (TID 19). 2956 bytes result sent to driver
2018-02-08 09:19:28,987 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:28,988 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:28,996 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 6.0 (TID 21, localhost, executor driver, partition 18, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:28,999 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 6.0 (TID 20). 2999 bytes result sent to driver
2018-02-08 09:19:29,000 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 6.0 (TID 22, localhost, executor driver, partition 19, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,000 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 6.0 (TID 21)
2018-02-08 09:19:29,005 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 6.0 (TID 19) in 56 ms on localhost (executor driver) (11/20)
2018-02-08 09:19:29,006 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 6.0 (TID 22)
2018-02-08 09:19:29,011 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,011 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 6.0 (TID 20) in 46 ms on localhost (executor driver) (12/20)
2018-02-08 09:19:29,011 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,016 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 6.0 (TID 22). 2956 bytes result sent to driver
2018-02-08 09:19:29,018 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 6.0 (TID 23, localhost, executor driver, partition 20, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,018 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 6.0 (TID 22) in 18 ms on localhost (executor driver) (13/20)
2018-02-08 09:19:29,022 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,022 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,022 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 6.0 (TID 23)
2018-02-08 09:19:29,029 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,029 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,033 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 6.0 (TID 23). 2956 bytes result sent to driver
2018-02-08 09:19:29,034 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 6.0 (TID 24, localhost, executor driver, partition 21, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,034 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 6.0 (TID 23) in 17 ms on localhost (executor driver) (14/20)
2018-02-08 09:19:29,035 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 6.0 (TID 24)
2018-02-08 09:19:29,039 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,040 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,043 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 6.0 (TID 21). 2999 bytes result sent to driver
2018-02-08 09:19:29,044 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 6.0 (TID 25, localhost, executor driver, partition 22, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,045 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 6.0 (TID 24). 2956 bytes result sent to driver
2018-02-08 09:19:29,045 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 6.0 (TID 21) in 49 ms on localhost (executor driver) (15/20)
2018-02-08 09:19:29,045 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 6.0 (TID 25)
2018-02-08 09:19:29,047 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 6.0 (TID 26, localhost, executor driver, partition 23, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,048 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 6.0 (TID 24) in 14 ms on localhost (executor driver) (16/20)
2018-02-08 09:19:29,049 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 6.0 (TID 26)
2018-02-08 09:19:29,052 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,052 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,057 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 6.0 (TID 25). 2999 bytes result sent to driver
2018-02-08 09:19:29,058 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,058 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,061 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 6.0 (TID 27, localhost, executor driver, partition 24, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,065 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 6.0 (TID 25) in 20 ms on localhost (executor driver) (17/20)
2018-02-08 09:19:29,065 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 6.0 (TID 26). 2999 bytes result sent to driver
2018-02-08 09:19:29,067 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 6.0 (TID 27)
2018-02-08 09:19:29,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 6.0 (TID 28, localhost, executor driver, partition 13, ANY, 4726 bytes)
2018-02-08 09:19:29,073 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 6.0 (TID 26) in 26 ms on localhost (executor driver) (18/20)
2018-02-08 09:19:29,074 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,074 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,075 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 6.0 (TID 28)
2018-02-08 09:19:29,078 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 6.0 (TID 27). 2956 bytes result sent to driver
2018-02-08 09:19:29,080 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 6.0 (TID 27) in 19 ms on localhost (executor driver) (19/20)
2018-02-08 09:19:29,081 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,081 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,102 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 6.0 (TID 28). 3017 bytes result sent to driver
2018-02-08 09:19:29,103 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 6.0 (TID 28) in 33 ms on localhost (executor driver) (20/20)
2018-02-08 09:19:29,103 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 09:19:29,104 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (show at MachineLeaningSelector.java:195) finished in 0.266 s
2018-02-08 09:19:29,104 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at MachineLeaningSelector.java:195, took 0.286010 s
2018-02-08 09:19:29,108 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:195
2018-02-08 09:19:29,112 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (show at MachineLeaningSelector.java:195) with 100 output partitions
2018-02-08 09:19:29,112 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 8 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:29,112 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 7)
2018-02-08 09:19:29,113 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:29,114 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 8 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:29,135 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 60.5 KB, free 615.4 MB)
2018-02-08 09:19:29,142 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.5 KB, free 615.4 MB)
2018-02-08 09:19:29,143 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:50941 (size: 20.5 KB, free: 631.7 MB)
2018-02-08 09:19:29,144 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:29,147 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 100 missing tasks from ResultStage 8 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39))
2018-02-08 09:19:29,147 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 100 tasks
2018-02-08 09:19:29,150 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 29, localhost, executor driver, partition 25, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,150 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 8.0 (TID 30, localhost, executor driver, partition 26, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,151 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 29)
2018-02-08 09:19:29,160 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 8.0 (TID 30)
2018-02-08 09:19:29,164 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,164 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,169 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 29). 3042 bytes result sent to driver
2018-02-08 09:19:29,172 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 8.0 (TID 31, localhost, executor driver, partition 27, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,172 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 8.0 (TID 30). 2999 bytes result sent to driver
2018-02-08 09:19:29,173 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 29) in 24 ms on localhost (executor driver) (1/100)
2018-02-08 09:19:29,174 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 8.0 (TID 31)
2018-02-08 09:19:29,175 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 8.0 (TID 32, localhost, executor driver, partition 28, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 8.0 (TID 30) in 27 ms on localhost (executor driver) (2/100)
2018-02-08 09:19:29,177 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 8.0 (TID 32)
2018-02-08 09:19:29,181 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,181 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,182 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:19:29,188 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 8.0 (TID 31). 2999 bytes result sent to driver
2018-02-08 09:19:29,190 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 8.0 (TID 33, localhost, executor driver, partition 29, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,191 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 8.0 (TID 31) in 19 ms on localhost (executor driver) (3/100)
2018-02-08 09:19:29,191 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 8.0 (TID 33)
2018-02-08 09:19:29,191 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 8.0 (TID 32). 2956 bytes result sent to driver
2018-02-08 09:19:29,193 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 8.0 (TID 34, localhost, executor driver, partition 30, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,194 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 8.0 (TID 32) in 19 ms on localhost (executor driver) (4/100)
2018-02-08 09:19:29,194 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 8.0 (TID 34)
2018-02-08 09:19:29,196 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,197 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,199 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,200 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,207 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 8.0 (TID 33). 2999 bytes result sent to driver
2018-02-08 09:19:29,208 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 8.0 (TID 35, localhost, executor driver, partition 31, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,209 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 8.0 (TID 33) in 19 ms on localhost (executor driver) (5/100)
2018-02-08 09:19:29,209 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 8.0 (TID 35)
2018-02-08 09:19:29,210 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 8.0 (TID 34). 2999 bytes result sent to driver
2018-02-08 09:19:29,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 8.0 (TID 36, localhost, executor driver, partition 32, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,214 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 8.0 (TID 36)
2018-02-08 09:19:29,214 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 8.0 (TID 34) in 21 ms on localhost (executor driver) (6/100)
2018-02-08 09:19:29,220 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,220 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,222 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,222 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,225 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 8.0 (TID 36). 2956 bytes result sent to driver
2018-02-08 09:19:29,227 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 8.0 (TID 37, localhost, executor driver, partition 33, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,228 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 8.0 (TID 35). 2999 bytes result sent to driver
2018-02-08 09:19:29,229 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 8.0 (TID 36) in 16 ms on localhost (executor driver) (7/100)
2018-02-08 09:19:29,229 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 8.0 (TID 37)
2018-02-08 09:19:29,229 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 8.0 (TID 38, localhost, executor driver, partition 34, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,231 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 8.0 (TID 35) in 23 ms on localhost (executor driver) (8/100)
2018-02-08 09:19:29,232 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 8.0 (TID 38)
2018-02-08 09:19:29,234 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,234 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,235 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,236 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,240 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 8.0 (TID 37). 2999 bytes result sent to driver
2018-02-08 09:19:29,242 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 8.0 (TID 39, localhost, executor driver, partition 35, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,243 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 8.0 (TID 37) in 16 ms on localhost (executor driver) (9/100)
2018-02-08 09:19:29,244 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 8.0 (TID 39)
2018-02-08 09:19:29,243 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 8.0 (TID 38). 2956 bytes result sent to driver
2018-02-08 09:19:29,245 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 8.0 (TID 40, localhost, executor driver, partition 36, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,248 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 8.0 (TID 38) in 19 ms on localhost (executor driver) (10/100)
2018-02-08 09:19:29,249 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 8.0 (TID 40)
2018-02-08 09:19:29,249 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,251 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:19:29,255 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,255 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,255 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 8.0 (TID 39). 2999 bytes result sent to driver
2018-02-08 09:19:29,257 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 8.0 (TID 41, localhost, executor driver, partition 37, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,259 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 8.0 (TID 39) in 18 ms on localhost (executor driver) (11/100)
2018-02-08 09:19:29,260 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 8.0 (TID 41)
2018-02-08 09:19:29,262 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 8.0 (TID 40). 2999 bytes result sent to driver
2018-02-08 09:19:29,264 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 8.0 (TID 42, localhost, executor driver, partition 38, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,265 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,265 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,265 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 8.0 (TID 40) in 20 ms on localhost (executor driver) (12/100)
2018-02-08 09:19:29,265 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 8.0 (TID 42)
2018-02-08 09:19:29,270 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 8.0 (TID 41). 2999 bytes result sent to driver
2018-02-08 09:19:29,271 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 8.0 (TID 43, localhost, executor driver, partition 39, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,272 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 8.0 (TID 41) in 16 ms on localhost (executor driver) (13/100)
2018-02-08 09:19:29,274 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,274 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,276 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 8.0 (TID 43)
2018-02-08 09:19:29,283 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 8.0 (TID 42). 2956 bytes result sent to driver
2018-02-08 09:19:29,284 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 8.0 (TID 44, localhost, executor driver, partition 40, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,284 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 8.0 (TID 42) in 22 ms on localhost (executor driver) (14/100)
2018-02-08 09:19:29,284 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 8.0 (TID 44)
2018-02-08 09:19:29,294 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,295 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,305 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 8.0 (TID 44). 2999 bytes result sent to driver
2018-02-08 09:19:29,306 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 8.0 (TID 45, localhost, executor driver, partition 41, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,307 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 8.0 (TID 44) in 24 ms on localhost (executor driver) (15/100)
2018-02-08 09:19:29,308 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 8.0 (TID 45)
2018-02-08 09:19:29,315 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,315 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,317 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,317 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,322 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 8.0 (TID 45). 2999 bytes result sent to driver
2018-02-08 09:19:29,333 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 8.0 (TID 46, localhost, executor driver, partition 42, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,334 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 8.0 (TID 45) in 28 ms on localhost (executor driver) (16/100)
2018-02-08 09:19:29,334 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 8.0 (TID 46)
2018-02-08 09:19:29,338 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,339 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,346 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 8.0 (TID 46). 2956 bytes result sent to driver
2018-02-08 09:19:29,349 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 8.0 (TID 47, localhost, executor driver, partition 43, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,349 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 8.0 (TID 46) in 16 ms on localhost (executor driver) (17/100)
2018-02-08 09:19:29,350 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 8.0 (TID 47)
2018-02-08 09:19:29,357 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,358 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,361 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 8.0 (TID 43). 2999 bytes result sent to driver
2018-02-08 09:19:29,366 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 8.0 (TID 47). 2956 bytes result sent to driver
2018-02-08 09:19:29,367 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 8.0 (TID 48, localhost, executor driver, partition 44, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,369 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 8.0 (TID 48)
2018-02-08 09:19:29,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 8.0 (TID 47) in 21 ms on localhost (executor driver) (18/100)
2018-02-08 09:19:29,372 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 8.0 (TID 49, localhost, executor driver, partition 45, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,373 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 8.0 (TID 43) in 102 ms on localhost (executor driver) (19/100)
2018-02-08 09:19:29,373 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 8.0 (TID 49)
2018-02-08 09:19:29,374 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,374 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,384 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,384 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,390 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 8.0 (TID 49). 2956 bytes result sent to driver
2018-02-08 09:19:29,384 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 8.0 (TID 48). 2956 bytes result sent to driver
2018-02-08 09:19:29,391 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 8.0 (TID 50, localhost, executor driver, partition 46, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 8.0 (TID 51, localhost, executor driver, partition 47, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,398 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 8.0 (TID 48) in 31 ms on localhost (executor driver) (20/100)
2018-02-08 09:19:29,397 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 8.0 (TID 50)
2018-02-08 09:19:29,399 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 8.0 (TID 49) in 27 ms on localhost (executor driver) (21/100)
2018-02-08 09:19:29,399 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 8.0 (TID 51)
2018-02-08 09:19:29,420 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,420 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 09:19:29,421 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,422 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,427 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 8.0 (TID 51). 2999 bytes result sent to driver
2018-02-08 09:19:29,429 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 8.0 (TID 52, localhost, executor driver, partition 48, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,429 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 8.0 (TID 51) in 38 ms on localhost (executor driver) (22/100)
2018-02-08 09:19:29,430 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 8.0 (TID 52)
2018-02-08 09:19:29,430 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_5_piece0 on 192.168.11.26:50941 in memory (size: 20.4 KB, free: 631.7 MB)
2018-02-08 09:19:29,434 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_4_piece0 on 192.168.11.26:50941 in memory (size: 20.4 KB, free: 631.7 MB)
2018-02-08 09:19:29,434 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,434 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,436 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.11.26:50941 in memory (size: 29.2 KB, free: 631.8 MB)
2018-02-08 09:19:29,454 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 8.0 (TID 52). 2956 bytes result sent to driver
2018-02-08 09:19:29,455 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 8.0 (TID 53, localhost, executor driver, partition 49, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,457 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 8.0 (TID 53)
2018-02-08 09:19:29,457 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 8.0 (TID 52) in 28 ms on localhost (executor driver) (23/100)
2018-02-08 09:19:29,460 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_3_piece0 on 192.168.11.26:50941 in memory (size: 20.5 KB, free: 631.8 MB)
2018-02-08 09:19:29,463 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 8.0 (TID 50). 3042 bytes result sent to driver
2018-02-08 09:19:29,464 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 8.0 (TID 54, localhost, executor driver, partition 50, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,464 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 8.0 (TID 50) in 73 ms on localhost (executor driver) (24/100)
2018-02-08 09:19:29,464 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 8.0 (TID 54)
2018-02-08 09:19:29,468 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,469 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,473 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 8.0 (TID 54). 2956 bytes result sent to driver
2018-02-08 09:19:29,475 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,475 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,475 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 8.0 (TID 55, localhost, executor driver, partition 51, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,476 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 8.0 (TID 54) in 12 ms on localhost (executor driver) (25/100)
2018-02-08 09:19:29,477 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 8.0 (TID 55)
2018-02-08 09:19:29,481 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 8.0 (TID 53). 3042 bytes result sent to driver
2018-02-08 09:19:29,482 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 8.0 (TID 56, localhost, executor driver, partition 52, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,482 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 8.0 (TID 53) in 27 ms on localhost (executor driver) (26/100)
2018-02-08 09:19:29,483 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,483 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,483 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 8.0 (TID 56)
2018-02-08 09:19:29,488 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 8.0 (TID 55). 2956 bytes result sent to driver
2018-02-08 09:19:29,489 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,489 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,489 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 8.0 (TID 57, localhost, executor driver, partition 53, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,492 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 8.0 (TID 55) in 17 ms on localhost (executor driver) (27/100)
2018-02-08 09:19:29,493 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 8.0 (TID 56). 2999 bytes result sent to driver
2018-02-08 09:19:29,493 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 8.0 (TID 57)
2018-02-08 09:19:29,498 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,498 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,502 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 8.0 (TID 57). 2956 bytes result sent to driver
2018-02-08 09:19:29,503 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 8.0 (TID 58, localhost, executor driver, partition 54, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,504 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 8.0 (TID 59, localhost, executor driver, partition 55, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,505 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 8.0 (TID 56) in 24 ms on localhost (executor driver) (28/100)
2018-02-08 09:19:29,507 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 8.0 (TID 57) in 18 ms on localhost (executor driver) (29/100)
2018-02-08 09:19:29,509 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 8.0 (TID 58)
2018-02-08 09:19:29,514 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,514 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,519 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 8.0 (TID 58). 2956 bytes result sent to driver
2018-02-08 09:19:29,519 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 8.0 (TID 59)
2018-02-08 09:19:29,525 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,526 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,538 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 8.0 (TID 59). 2999 bytes result sent to driver
2018-02-08 09:19:29,540 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 8.0 (TID 60, localhost, executor driver, partition 56, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,541 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 8.0 (TID 61, localhost, executor driver, partition 57, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,541 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 8.0 (TID 58) in 39 ms on localhost (executor driver) (30/100)
2018-02-08 09:19:29,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 8.0 (TID 59) in 38 ms on localhost (executor driver) (31/100)
2018-02-08 09:19:29,545 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 8.0 (TID 60)
2018-02-08 09:19:29,546 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 8.0 (TID 61)
2018-02-08 09:19:29,550 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,550 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,550 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,550 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,559 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 8.0 (TID 61). 2999 bytes result sent to driver
2018-02-08 09:19:29,560 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 8.0 (TID 60). 2956 bytes result sent to driver
2018-02-08 09:19:29,561 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 8.0 (TID 62, localhost, executor driver, partition 58, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,561 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 8.0 (TID 63, localhost, executor driver, partition 59, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,562 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 8.0 (TID 60) in 24 ms on localhost (executor driver) (32/100)
2018-02-08 09:19:29,561 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 8.0 (TID 62)
2018-02-08 09:19:29,562 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 8.0 (TID 63)
2018-02-08 09:19:29,567 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 8.0 (TID 61) in 27 ms on localhost (executor driver) (33/100)
2018-02-08 09:19:29,572 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,573 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,577 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 8.0 (TID 63). 2956 bytes result sent to driver
2018-02-08 09:19:29,578 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 8.0 (TID 64, localhost, executor driver, partition 61, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,580 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 8.0 (TID 63) in 19 ms on localhost (executor driver) (34/100)
2018-02-08 09:19:29,580 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 8.0 (TID 64)
2018-02-08 09:19:29,586 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,586 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,594 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 8.0 (TID 64). 2999 bytes result sent to driver
2018-02-08 09:19:29,595 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 8.0 (TID 65, localhost, executor driver, partition 62, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,596 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 8.0 (TID 64) in 18 ms on localhost (executor driver) (35/100)
2018-02-08 09:19:29,596 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 8.0 (TID 65)
2018-02-08 09:19:29,605 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,605 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,610 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,610 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,617 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 8.0 (TID 62). 2999 bytes result sent to driver
2018-02-08 09:19:29,618 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 8.0 (TID 66, localhost, executor driver, partition 63, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,618 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 8.0 (TID 62) in 58 ms on localhost (executor driver) (36/100)
2018-02-08 09:19:29,620 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 8.0 (TID 66)
2018-02-08 09:19:29,621 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 8.0 (TID 65). 2956 bytes result sent to driver
2018-02-08 09:19:29,623 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 8.0 (TID 67, localhost, executor driver, partition 64, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,627 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,627 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,630 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 8.0 (TID 65) in 35 ms on localhost (executor driver) (37/100)
2018-02-08 09:19:29,641 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 8.0 (TID 66). 2999 bytes result sent to driver
2018-02-08 09:19:29,641 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 8.0 (TID 67)
2018-02-08 09:19:29,646 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,647 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,649 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 8.0 (TID 68, localhost, executor driver, partition 65, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,652 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 8.0 (TID 66) in 35 ms on localhost (executor driver) (38/100)
2018-02-08 09:19:29,654 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 8.0 (TID 68)
2018-02-08 09:19:29,653 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 8.0 (TID 67). 2999 bytes result sent to driver
2018-02-08 09:19:29,655 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 8.0 (TID 69, localhost, executor driver, partition 66, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,655 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 8.0 (TID 67) in 32 ms on localhost (executor driver) (39/100)
2018-02-08 09:19:29,656 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 8.0 (TID 69)
2018-02-08 09:19:29,659 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,659 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,660 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,660 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,664 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 8.0 (TID 69). 2999 bytes result sent to driver
2018-02-08 09:19:29,665 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 8.0 (TID 68). 2956 bytes result sent to driver
2018-02-08 09:19:29,665 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 8.0 (TID 70, localhost, executor driver, partition 67, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,666 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 8.0 (TID 71, localhost, executor driver, partition 68, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,668 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 8.0 (TID 69) in 13 ms on localhost (executor driver) (40/100)
2018-02-08 09:19:29,668 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 8.0 (TID 71)
2018-02-08 09:19:29,669 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 8.0 (TID 68) in 20 ms on localhost (executor driver) (41/100)
2018-02-08 09:19:29,670 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 8.0 (TID 70)
2018-02-08 09:19:29,671 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,672 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,675 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,675 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 8.0 (TID 71). 2956 bytes result sent to driver
2018-02-08 09:19:29,675 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,676 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 8.0 (TID 72, localhost, executor driver, partition 69, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,677 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 8.0 (TID 71) in 12 ms on localhost (executor driver) (42/100)
2018-02-08 09:19:29,678 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 8.0 (TID 72)
2018-02-08 09:19:29,680 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 8.0 (TID 70). 2956 bytes result sent to driver
2018-02-08 09:19:29,681 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 8.0 (TID 73, localhost, executor driver, partition 70, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,682 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 8.0 (TID 73)
2018-02-08 09:19:29,682 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 8.0 (TID 70) in 17 ms on localhost (executor driver) (43/100)
2018-02-08 09:19:29,687 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,688 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,691 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 8.0 (TID 73). 2956 bytes result sent to driver
2018-02-08 09:19:29,692 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 8.0 (TID 74, localhost, executor driver, partition 71, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,692 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 8.0 (TID 73) in 12 ms on localhost (executor driver) (44/100)
2018-02-08 09:19:29,692 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 8.0 (TID 74)
2018-02-08 09:19:29,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,697 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,697 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,702 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 8.0 (TID 74). 2956 bytes result sent to driver
2018-02-08 09:19:29,702 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 8.0 (TID 75, localhost, executor driver, partition 72, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,703 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 8.0 (TID 75)
2018-02-08 09:19:29,703 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 8.0 (TID 74) in 11 ms on localhost (executor driver) (45/100)
2018-02-08 09:19:29,705 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 8.0 (TID 72). 2956 bytes result sent to driver
2018-02-08 09:19:29,706 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 8.0 (TID 76, localhost, executor driver, partition 73, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,706 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 8.0 (TID 72) in 30 ms on localhost (executor driver) (46/100)
2018-02-08 09:19:29,707 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,707 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,709 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 8.0 (TID 76)
2018-02-08 09:19:29,711 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 8.0 (TID 75). 2999 bytes result sent to driver
2018-02-08 09:19:29,713 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 8.0 (TID 77, localhost, executor driver, partition 74, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,714 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 8.0 (TID 75) in 12 ms on localhost (executor driver) (47/100)
2018-02-08 09:19:29,716 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,717 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,720 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 8.0 (TID 76). 2956 bytes result sent to driver
2018-02-08 09:19:29,721 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 8.0 (TID 78, localhost, executor driver, partition 75, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,721 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 8.0 (TID 76) in 16 ms on localhost (executor driver) (48/100)
2018-02-08 09:19:29,722 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 8.0 (TID 78)
2018-02-08 09:19:29,722 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 8.0 (TID 77)
2018-02-08 09:19:29,725 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,725 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,729 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,729 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,730 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 8.0 (TID 78). 2999 bytes result sent to driver
2018-02-08 09:19:29,730 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 8.0 (TID 79, localhost, executor driver, partition 76, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,731 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 8.0 (TID 78) in 10 ms on localhost (executor driver) (49/100)
2018-02-08 09:19:29,731 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 8.0 (TID 79)
2018-02-08 09:19:29,735 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,735 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,736 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 8.0 (TID 77). 2999 bytes result sent to driver
2018-02-08 09:19:29,737 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 8.0 (TID 80, localhost, executor driver, partition 77, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,738 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 8.0 (TID 77) in 26 ms on localhost (executor driver) (50/100)
2018-02-08 09:19:29,739 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 8.0 (TID 80)
2018-02-08 09:19:29,739 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 8.0 (TID 79). 2999 bytes result sent to driver
2018-02-08 09:19:29,740 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 8.0 (TID 81, localhost, executor driver, partition 78, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,744 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,744 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,750 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 8.0 (TID 79) in 20 ms on localhost (executor driver) (51/100)
2018-02-08 09:19:29,751 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 8.0 (TID 81)
2018-02-08 09:19:29,752 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 8.0 (TID 80). 2956 bytes result sent to driver
2018-02-08 09:19:29,755 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,756 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 8.0 (TID 82, localhost, executor driver, partition 79, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,769 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 8.0 (TID 80) in 32 ms on localhost (executor driver) (52/100)
2018-02-08 09:19:29,769 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 8.0 (TID 82)
2018-02-08 09:19:29,772 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 8.0 (TID 81). 2999 bytes result sent to driver
2018-02-08 09:19:29,774 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 8.0 (TID 83, localhost, executor driver, partition 80, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,775 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,776 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,778 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 8.0 (TID 81) in 38 ms on localhost (executor driver) (53/100)
2018-02-08 09:19:29,780 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 8.0 (TID 83)
2018-02-08 09:19:29,782 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 8.0 (TID 82). 2999 bytes result sent to driver
2018-02-08 09:19:29,783 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 8.0 (TID 84, localhost, executor driver, partition 81, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,785 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 8.0 (TID 82) in 24 ms on localhost (executor driver) (54/100)
2018-02-08 09:19:29,790 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,791 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,797 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 8.0 (TID 84)
2018-02-08 09:19:29,802 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,802 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,804 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 8.0 (TID 83). 2999 bytes result sent to driver
2018-02-08 09:19:29,805 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 8.0 (TID 85, localhost, executor driver, partition 82, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,806 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 8.0 (TID 83) in 33 ms on localhost (executor driver) (55/100)
2018-02-08 09:19:29,807 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 8.0 (TID 85)
2018-02-08 09:19:29,807 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 8.0 (TID 84). 2999 bytes result sent to driver
2018-02-08 09:19:29,809 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 8.0 (TID 86, localhost, executor driver, partition 83, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,809 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 8.0 (TID 84) in 27 ms on localhost (executor driver) (56/100)
2018-02-08 09:19:29,815 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,816 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,816 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 8.0 (TID 86)
2018-02-08 09:19:29,820 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 8.0 (TID 85). 2999 bytes result sent to driver
2018-02-08 09:19:29,821 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 8.0 (TID 87, localhost, executor driver, partition 84, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,821 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 8.0 (TID 87)
2018-02-08 09:19:29,822 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 8.0 (TID 85) in 17 ms on localhost (executor driver) (57/100)
2018-02-08 09:19:29,830 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,830 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,835 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,837 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:19:29,844 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 8.0 (TID 86). 2999 bytes result sent to driver
2018-02-08 09:19:29,845 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 8.0 (TID 88, localhost, executor driver, partition 85, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,845 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 8.0 (TID 86) in 36 ms on localhost (executor driver) (58/100)
2018-02-08 09:19:29,845 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 8.0 (TID 88)
2018-02-08 09:19:29,850 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,850 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,853 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 8.0 (TID 87). 2999 bytes result sent to driver
2018-02-08 09:19:29,854 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 8.0 (TID 89, localhost, executor driver, partition 86, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,855 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 8.0 (TID 88). 2956 bytes result sent to driver
2018-02-08 09:19:29,855 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 8.0 (TID 87) in 34 ms on localhost (executor driver) (59/100)
2018-02-08 09:19:29,856 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 8.0 (TID 89)
2018-02-08 09:19:29,857 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 8.0 (TID 90, localhost, executor driver, partition 87, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,857 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 8.0 (TID 88) in 12 ms on localhost (executor driver) (60/100)
2018-02-08 09:19:29,861 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 8.0 (TID 90)
2018-02-08 09:19:29,862 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,862 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,865 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,865 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,865 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 8.0 (TID 89). 2999 bytes result sent to driver
2018-02-08 09:19:29,867 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 8.0 (TID 91, localhost, executor driver, partition 88, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,867 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 8.0 (TID 89) in 13 ms on localhost (executor driver) (61/100)
2018-02-08 09:19:29,868 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 8.0 (TID 91)
2018-02-08 09:19:29,870 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 8.0 (TID 90). 2999 bytes result sent to driver
2018-02-08 09:19:29,870 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 8.0 (TID 92, localhost, executor driver, partition 89, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,871 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 8.0 (TID 90) in 14 ms on localhost (executor driver) (62/100)
2018-02-08 09:19:29,872 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 8.0 (TID 92)
2018-02-08 09:19:29,871 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,872 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,877 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 8.0 (TID 91). 2956 bytes result sent to driver
2018-02-08 09:19:29,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 8.0 (TID 93, localhost, executor driver, partition 90, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,878 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,878 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 8.0 (TID 91) in 12 ms on localhost (executor driver) (63/100)
2018-02-08 09:19:29,879 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 8.0 (TID 93)
2018-02-08 09:19:29,882 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 8.0 (TID 92). 2999 bytes result sent to driver
2018-02-08 09:19:29,883 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 8.0 (TID 94, localhost, executor driver, partition 91, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,884 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 8.0 (TID 92) in 14 ms on localhost (executor driver) (64/100)
2018-02-08 09:19:29,884 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,884 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,888 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 8.0 (TID 94)
2018-02-08 09:19:29,891 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 8.0 (TID 93). 2956 bytes result sent to driver
2018-02-08 09:19:29,892 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 8.0 (TID 95, localhost, executor driver, partition 92, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,893 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 8.0 (TID 93) in 16 ms on localhost (executor driver) (65/100)
2018-02-08 09:19:29,893 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 8.0 (TID 95)
2018-02-08 09:19:29,896 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,896 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,896 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,897 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,901 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 8.0 (TID 94). 2956 bytes result sent to driver
2018-02-08 09:19:29,904 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 8.0 (TID 95). 2999 bytes result sent to driver
2018-02-08 09:19:29,905 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 8.0 (TID 96, localhost, executor driver, partition 94, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,907 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 8.0 (TID 97, localhost, executor driver, partition 95, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,909 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 8.0 (TID 94) in 26 ms on localhost (executor driver) (66/100)
2018-02-08 09:19:29,910 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 8.0 (TID 95) in 18 ms on localhost (executor driver) (67/100)
2018-02-08 09:19:29,914 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 8.0 (TID 96)
2018-02-08 09:19:29,914 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 8.0 (TID 97)
2018-02-08 09:19:29,917 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,918 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,922 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 8.0 (TID 96). 2956 bytes result sent to driver
2018-02-08 09:19:29,923 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,923 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,923 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 8.0 (TID 98, localhost, executor driver, partition 96, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,924 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 8.0 (TID 96) in 22 ms on localhost (executor driver) (68/100)
2018-02-08 09:19:29,925 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 8.0 (TID 98)
2018-02-08 09:19:29,927 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 8.0 (TID 97). 2999 bytes result sent to driver
2018-02-08 09:19:29,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 8.0 (TID 99, localhost, executor driver, partition 97, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 8.0 (TID 97) in 23 ms on localhost (executor driver) (69/100)
2018-02-08 09:19:29,928 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,929 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,929 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 8.0 (TID 99)
2018-02-08 09:19:29,934 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 8.0 (TID 98). 2956 bytes result sent to driver
2018-02-08 09:19:29,934 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 8.0 (TID 100, localhost, executor driver, partition 98, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,935 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,935 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,936 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 8.0 (TID 98) in 13 ms on localhost (executor driver) (70/100)
2018-02-08 09:19:29,937 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 8.0 (TID 100)
2018-02-08 09:19:29,941 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 8.0 (TID 99). 2956 bytes result sent to driver
2018-02-08 09:19:29,943 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 8.0 (TID 101, localhost, executor driver, partition 99, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,943 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 8.0 (TID 99) in 16 ms on localhost (executor driver) (71/100)
2018-02-08 09:19:29,943 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 8.0 (TID 101)
2018-02-08 09:19:29,947 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,947 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,963 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 8.0 (TID 101). 2956 bytes result sent to driver
2018-02-08 09:19:29,965 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 8.0 (TID 102, localhost, executor driver, partition 100, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,966 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 8.0 (TID 101) in 24 ms on localhost (executor driver) (72/100)
2018-02-08 09:19:29,966 INFO[org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 8.0 (TID 102)
2018-02-08 09:19:29,971 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,972 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:29,973 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,973 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 31 ms
2018-02-08 09:19:29,978 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 8.0 (TID 100). 2999 bytes result sent to driver
2018-02-08 09:19:29,978 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 8.0 (TID 103, localhost, executor driver, partition 101, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,979 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 8.0 (TID 100) in 45 ms on localhost (executor driver) (73/100)
2018-02-08 09:19:29,979 INFO[org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 8.0 (TID 103)
2018-02-08 09:19:29,984 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:29,984 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:29,992 INFO[org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 8.0 (TID 103). 2999 bytes result sent to driver
2018-02-08 09:19:29,992 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 8.0 (TID 104, localhost, executor driver, partition 102, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:29,994 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 8.0 (TID 103) in 16 ms on localhost (executor driver) (74/100)
2018-02-08 09:19:30,000 INFO[org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 8.0 (TID 104)
2018-02-08 09:19:30,006 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,006 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:19:30,011 INFO[org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 8.0 (TID 104). 2999 bytes result sent to driver
2018-02-08 09:19:30,011 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 8.0 (TID 105, localhost, executor driver, partition 103, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,012 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 8.0 (TID 104) in 20 ms on localhost (executor driver) (75/100)
2018-02-08 09:19:30,012 INFO[org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 8.0 (TID 105)
2018-02-08 09:19:30,015 INFO[org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 8.0 (TID 102). 2956 bytes result sent to driver
2018-02-08 09:19:30,015 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,015 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,020 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 8.0 (TID 106, localhost, executor driver, partition 104, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,022 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 8.0 (TID 102) in 57 ms on localhost (executor driver) (76/100)
2018-02-08 09:19:30,022 INFO[org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 8.0 (TID 105). 2956 bytes result sent to driver
2018-02-08 09:19:30,023 INFO[org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 8.0 (TID 106)
2018-02-08 09:19:30,027 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 8.0 (TID 107, localhost, executor driver, partition 105, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,028 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,028 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,036 INFO[org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 8.0 (TID 106). 2956 bytes result sent to driver
2018-02-08 09:19:30,038 INFO[org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 8.0 (TID 107)
2018-02-08 09:19:30,029 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 8.0 (TID 105) in 18 ms on localhost (executor driver) (77/100)
2018-02-08 09:19:30,043 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 8.0 (TID 108, localhost, executor driver, partition 106, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,045 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 8.0 (TID 106) in 25 ms on localhost (executor driver) (78/100)
2018-02-08 09:19:30,045 INFO[org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 8.0 (TID 108)
2018-02-08 09:19:30,049 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,049 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,049 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,052 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:19:30,055 INFO[org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 8.0 (TID 108). 2999 bytes result sent to driver
2018-02-08 09:19:30,055 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 8.0 (TID 109, localhost, executor driver, partition 107, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,057 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 8.0 (TID 108) in 17 ms on localhost (executor driver) (79/100)
2018-02-08 09:19:30,057 INFO[org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 8.0 (TID 109)
2018-02-08 09:19:30,061 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,061 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,062 INFO[org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 8.0 (TID 107). 2956 bytes result sent to driver
2018-02-08 09:19:30,064 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 8.0 (TID 110, localhost, executor driver, partition 108, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,064 INFO[org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 8.0 (TID 109). 2956 bytes result sent to driver
2018-02-08 09:19:30,065 INFO[org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 8.0 (TID 110)
2018-02-08 09:19:30,065 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 8.0 (TID 107) in 38 ms on localhost (executor driver) (80/100)
2018-02-08 09:19:30,065 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 8.0 (TID 111, localhost, executor driver, partition 109, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,069 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 8.0 (TID 109) in 14 ms on localhost (executor driver) (81/100)
2018-02-08 09:19:30,070 INFO[org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 8.0 (TID 111)
2018-02-08 09:19:30,071 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,071 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,074 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,074 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,076 INFO[org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 8.0 (TID 110). 2999 bytes result sent to driver
2018-02-08 09:19:30,077 INFO[org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 8.0 (TID 111). 2956 bytes result sent to driver
2018-02-08 09:19:30,078 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 8.0 (TID 112, localhost, executor driver, partition 110, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,079 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 8.0 (TID 113, localhost, executor driver, partition 111, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,079 INFO[org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 8.0 (TID 112)
2018-02-08 09:19:30,080 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 8.0 (TID 110) in 15 ms on localhost (executor driver) (82/100)
2018-02-08 09:19:30,080 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 8.0 (TID 111) in 15 ms on localhost (executor driver) (83/100)
2018-02-08 09:19:30,080 INFO[org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 8.0 (TID 113)
2018-02-08 09:19:30,084 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,084 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,088 INFO[org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 8.0 (TID 113). 2999 bytes result sent to driver
2018-02-08 09:19:30,090 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 8.0 (TID 114, localhost, executor driver, partition 112, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,091 INFO[org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 8.0 (TID 114)
2018-02-08 09:19:30,091 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 8.0 (TID 113) in 12 ms on localhost (executor driver) (84/100)
2018-02-08 09:19:30,094 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,094 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,100 INFO[org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 8.0 (TID 114). 2956 bytes result sent to driver
2018-02-08 09:19:30,100 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 8.0 (TID 115, localhost, executor driver, partition 113, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,101 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 8.0 (TID 114) in 11 ms on localhost (executor driver) (85/100)
2018-02-08 09:19:30,101 INFO[org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 8.0 (TID 115)
2018-02-08 09:19:30,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,107 INFO[org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 8.0 (TID 115). 2956 bytes result sent to driver
2018-02-08 09:19:30,108 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 8.0 (TID 116, localhost, executor driver, partition 114, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,108 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 8.0 (TID 115) in 8 ms on localhost (executor driver) (86/100)
2018-02-08 09:19:30,108 INFO[org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 8.0 (TID 112). 2999 bytes result sent to driver
2018-02-08 09:19:30,108 INFO[org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 8.0 (TID 116)
2018-02-08 09:19:30,109 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 8.0 (TID 117, localhost, executor driver, partition 115, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,109 INFO[org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 8.0 (TID 117)
2018-02-08 09:19:30,110 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 8.0 (TID 112) in 32 ms on localhost (executor driver) (87/100)
2018-02-08 09:19:30,113 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,113 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,116 INFO[org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 8.0 (TID 117). 2999 bytes result sent to driver
2018-02-08 09:19:30,117 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 8.0 (TID 118, localhost, executor driver, partition 116, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,118 INFO[org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 8.0 (TID 118)
2018-02-08 09:19:30,118 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 8.0 (TID 117) in 9 ms on localhost (executor driver) (88/100)
2018-02-08 09:19:30,121 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,122 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,122 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,124 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:19:30,127 INFO[org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 8.0 (TID 118). 2956 bytes result sent to driver
2018-02-08 09:19:30,128 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 8.0 (TID 119, localhost, executor driver, partition 117, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,128 INFO[org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 8.0 (TID 116). 2956 bytes result sent to driver
2018-02-08 09:19:30,129 INFO[org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 8.0 (TID 119)
2018-02-08 09:19:30,129 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 8.0 (TID 118) in 12 ms on localhost (executor driver) (89/100)
2018-02-08 09:19:30,131 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 8.0 (TID 120, localhost, executor driver, partition 118, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,132 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 8.0 (TID 116) in 24 ms on localhost (executor driver) (90/100)
2018-02-08 09:19:30,133 INFO[org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 8.0 (TID 120)
2018-02-08 09:19:30,133 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,135 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:19:30,136 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,137 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,138 INFO[org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 8.0 (TID 119). 2956 bytes result sent to driver
2018-02-08 09:19:30,139 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 8.0 (TID 121, localhost, executor driver, partition 119, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,139 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 8.0 (TID 119) in 11 ms on localhost (executor driver) (91/100)
2018-02-08 09:19:30,141 INFO[org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 8.0 (TID 120). 2956 bytes result sent to driver
2018-02-08 09:19:30,141 INFO[org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 8.0 (TID 121)
2018-02-08 09:19:30,142 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 8.0 (TID 122, localhost, executor driver, partition 120, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,143 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 8.0 (TID 120) in 12 ms on localhost (executor driver) (92/100)
2018-02-08 09:19:30,144 INFO[org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 8.0 (TID 122)
2018-02-08 09:19:30,144 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,145 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,148 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,148 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,149 INFO[org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 8.0 (TID 121). 2956 bytes result sent to driver
2018-02-08 09:19:30,149 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 8.0 (TID 123, localhost, executor driver, partition 121, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,150 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 8.0 (TID 121) in 12 ms on localhost (executor driver) (93/100)
2018-02-08 09:19:30,154 INFO[org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 8.0 (TID 122). 2999 bytes result sent to driver
2018-02-08 09:19:30,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 8.0 (TID 124, localhost, executor driver, partition 122, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,155 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 8.0 (TID 122) in 13 ms on localhost (executor driver) (94/100)
2018-02-08 09:19:30,155 INFO[org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 8.0 (TID 124)
2018-02-08 09:19:30,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,188 INFO[org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 8.0 (TID 124). 2999 bytes result sent to driver
2018-02-08 09:19:30,190 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 8.0 (TID 125, localhost, executor driver, partition 123, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,199 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 8.0 (TID 124) in 45 ms on localhost (executor driver) (95/100)
2018-02-08 09:19:30,202 INFO[org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 8.0 (TID 125)
2018-02-08 09:19:30,221 INFO[org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 8.0 (TID 123)
2018-02-08 09:19:30,226 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,226 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,230 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,232 INFO[org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 8.0 (TID 125). 2956 bytes result sent to driver
2018-02-08 09:19:30,232 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:19:30,232 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 8.0 (TID 126, localhost, executor driver, partition 124, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,233 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 8.0 (TID 125) in 44 ms on localhost (executor driver) (96/100)
2018-02-08 09:19:30,234 INFO[org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 8.0 (TID 126)
2018-02-08 09:19:30,236 INFO[org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 8.0 (TID 123). 2956 bytes result sent to driver
2018-02-08 09:19:30,240 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,240 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,254 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 8.0 (TID 127, localhost, executor driver, partition 60, ANY, 4726 bytes)
2018-02-08 09:19:30,256 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 8.0 (TID 123) in 107 ms on localhost (executor driver) (97/100)
2018-02-08 09:19:30,261 INFO[org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 8.0 (TID 126). 3042 bytes result sent to driver
2018-02-08 09:19:30,262 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 8.0 (TID 127)
2018-02-08 09:19:30,266 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,266 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,272 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 8.0 (TID 127). 3021 bytes result sent to driver
2018-02-08 09:19:30,273 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 8.0 (TID 128, localhost, executor driver, partition 93, ANY, 4726 bytes)
2018-02-08 09:19:30,276 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 8.0 (TID 128)
2018-02-08 09:19:30,285 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,285 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,295 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 8.0 (TID 128). 3017 bytes result sent to driver
2018-02-08 09:19:30,296 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 8.0 (TID 126) in 63 ms on localhost (executor driver) (98/100)
2018-02-08 09:19:30,298 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 8.0 (TID 127) in 56 ms on localhost (executor driver) (99/100)
2018-02-08 09:19:30,302 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 8.0 (TID 128) in 29 ms on localhost (executor driver) (100/100)
2018-02-08 09:19:30,303 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 09:19:30,304 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 8 (show at MachineLeaningSelector.java:195) finished in 1.155 s
2018-02-08 09:19:30,305 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: show at MachineLeaningSelector.java:195, took 1.195994 s
2018-02-08 09:19:30,310 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:195
2018-02-08 09:19:30,405 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (show at MachineLeaningSelector.java:195) with 75 output partitions
2018-02-08 09:19:30,405 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 10 (show at MachineLeaningSelector.java:195)
2018-02-08 09:19:30,405 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 9)
2018-02-08 09:19:30,405 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:30,406 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 10 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195), which has no missing parents
2018-02-08 09:19:30,422 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 60.5 KB, free 615.7 MB)
2018-02-08 09:19:30,424 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 20.5 KB, free 615.6 MB)
2018-02-08 09:19:30,431 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:50941 (size: 20.5 KB, free: 631.8 MB)
2018-02-08 09:19:30,432 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:30,433 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 75 missing tasks from ResultStage 10 (MapPartitionsRDD[12] at show at MachineLeaningSelector.java:195) (first 15 tasks are for partitions Vector(125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139))
2018-02-08 09:19:30,433 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 75 tasks
2018-02-08 09:19:30,434 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 129, localhost, executor driver, partition 125, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,437 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 10.0 (TID 130, localhost, executor driver, partition 126, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,437 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 129)
2018-02-08 09:19:30,437 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 10.0 (TID 130)
2018-02-08 09:19:30,448 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,448 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,450 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,450 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,454 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 10.0 (TID 130). 2956 bytes result sent to driver
2018-02-08 09:19:30,454 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 10.0 (TID 131, localhost, executor driver, partition 127, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,459 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 129). 2999 bytes result sent to driver
2018-02-08 09:19:30,460 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 10.0 (TID 132, localhost, executor driver, partition 128, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,460 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 10.0 (TID 130) in 26 ms on localhost (executor driver) (1/75)
2018-02-08 09:19:30,461 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 129) in 27 ms on localhost (executor driver) (2/75)
2018-02-08 09:19:30,462 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 10.0 (TID 131)
2018-02-08 09:19:30,470 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,471 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:19:30,477 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 10.0 (TID 131). 2999 bytes result sent to driver
2018-02-08 09:19:30,478 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 10.0 (TID 133, localhost, executor driver, partition 129, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,478 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 10.0 (TID 132)
2018-02-08 09:19:30,482 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,482 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,485 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 10.0 (TID 132). 2956 bytes result sent to driver
2018-02-08 09:19:30,486 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 10.0 (TID 131) in 32 ms on localhost (executor driver) (3/75)
2018-02-08 09:19:30,489 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 10.0 (TID 134, localhost, executor driver, partition 130, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,489 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 10.0 (TID 133)
2018-02-08 09:19:30,492 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,492 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,540 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 10.0 (TID 133). 2999 bytes result sent to driver
2018-02-08 09:19:30,540 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 10.0 (TID 132) in 80 ms on localhost (executor driver) (4/75)
2018-02-08 09:19:30,541 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 10.0 (TID 134)
2018-02-08 09:19:30,541 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 10.0 (TID 135, localhost, executor driver, partition 131, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,541 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 10.0 (TID 133) in 64 ms on localhost (executor driver) (5/75)
2018-02-08 09:19:30,542 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 10.0 (TID 135)
2018-02-08 09:19:30,544 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,545 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,546 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,546 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,551 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 10.0 (TID 135). 2999 bytes result sent to driver
2018-02-08 09:19:30,552 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 10.0 (TID 134). 2999 bytes result sent to driver
2018-02-08 09:19:30,553 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 10.0 (TID 136, localhost, executor driver, partition 132, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,553 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 10.0 (TID 136)
2018-02-08 09:19:30,553 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 10.0 (TID 137, localhost, executor driver, partition 133, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,554 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 10.0 (TID 134) in 67 ms on localhost (executor driver) (6/75)
2018-02-08 09:19:30,554 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 10.0 (TID 137)
2018-02-08 09:19:30,556 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,556 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,557 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 10.0 (TID 135) in 16 ms on localhost (executor driver) (7/75)
2018-02-08 09:19:30,560 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 10.0 (TID 136). 2956 bytes result sent to driver
2018-02-08 09:19:30,561 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 10.0 (TID 138, localhost, executor driver, partition 134, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,562 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 10.0 (TID 136) in 9 ms on localhost (executor driver) (8/75)
2018-02-08 09:19:30,562 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 10.0 (TID 138)
2018-02-08 09:19:30,565 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,565 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,580 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,581 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,585 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 10.0 (TID 137). 2999 bytes result sent to driver
2018-02-08 09:19:30,586 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 10.0 (TID 139, localhost, executor driver, partition 135, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,588 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 10.0 (TID 137) in 35 ms on localhost (executor driver) (9/75)
2018-02-08 09:19:30,589 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 10.0 (TID 139)
2018-02-08 09:19:30,602 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,608 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 16 ms
2018-02-08 09:19:30,615 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 10.0 (TID 139). 2956 bytes result sent to driver
2018-02-08 09:19:30,624 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 10.0 (TID 140, localhost, executor driver, partition 136, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,625 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 10.0 (TID 139) in 39 ms on localhost (executor driver) (10/75)
2018-02-08 09:19:30,626 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 10.0 (TID 140)
2018-02-08 09:19:30,649 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,649 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
2018-02-08 09:19:30,661 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 10.0 (TID 140). 2956 bytes result sent to driver
2018-02-08 09:19:30,662 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 10.0 (TID 141, localhost, executor driver, partition 137, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,662 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 10.0 (TID 140) in 38 ms on localhost (executor driver) (11/75)
2018-02-08 09:19:30,663 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 10.0 (TID 141)
2018-02-08 09:19:30,669 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,669 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,674 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 10.0 (TID 141). 2956 bytes result sent to driver
2018-02-08 09:19:30,674 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 10.0 (TID 142, localhost, executor driver, partition 138, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,682 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 10.0 (TID 141) in 20 ms on localhost (executor driver) (12/75)
2018-02-08 09:19:30,682 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 10.0 (TID 142)
2018-02-08 09:19:30,685 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,689 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 10.0 (TID 142). 2956 bytes result sent to driver
2018-02-08 09:19:30,696 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 10.0 (TID 143, localhost, executor driver, partition 139, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,697 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 10.0 (TID 142) in 23 ms on localhost (executor driver) (13/75)
2018-02-08 09:19:30,697 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 10.0 (TID 143)
2018-02-08 09:19:30,700 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,700 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,706 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 10.0 (TID 138). 2999 bytes result sent to driver
2018-02-08 09:19:30,706 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 10.0 (TID 144, localhost, executor driver, partition 140, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,709 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 10.0 (TID 138) in 148 ms on localhost (executor driver) (14/75)
2018-02-08 09:19:30,709 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 10.0 (TID 144)
2018-02-08 09:19:30,712 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,713 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,716 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 10.0 (TID 144). 2956 bytes result sent to driver
2018-02-08 09:19:30,717 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 10.0 (TID 145, localhost, executor driver, partition 141, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,717 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 10.0 (TID 144) in 11 ms on localhost (executor driver) (15/75)
2018-02-08 09:19:30,718 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 10.0 (TID 145)
2018-02-08 09:19:30,721 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,721 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,726 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 10.0 (TID 145). 2999 bytes result sent to driver
2018-02-08 09:19:30,727 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 10.0 (TID 146, localhost, executor driver, partition 142, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,728 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 10.0 (TID 145) in 12 ms on localhost (executor driver) (16/75)
2018-02-08 09:19:30,728 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 10.0 (TID 146)
2018-02-08 09:19:30,731 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,733 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 09:19:30,736 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 10.0 (TID 146). 2956 bytes result sent to driver
2018-02-08 09:19:30,736 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 10.0 (TID 147, localhost, executor driver, partition 143, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,738 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 10.0 (TID 146) in 11 ms on localhost (executor driver) (17/75)
2018-02-08 09:19:30,738 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 10.0 (TID 147)
2018-02-08 09:19:30,742 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,742 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,746 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 10.0 (TID 147). 2999 bytes result sent to driver
2018-02-08 09:19:30,747 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 10.0 (TID 148, localhost, executor driver, partition 144, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,747 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 10.0 (TID 147) in 11 ms on localhost (executor driver) (18/75)
2018-02-08 09:19:30,748 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 10.0 (TID 148)
2018-02-08 09:19:30,759 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 10.0 (TID 143). 2956 bytes result sent to driver
2018-02-08 09:19:30,759 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 10.0 (TID 149, localhost, executor driver, partition 145, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,760 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 10.0 (TID 143) in 65 ms on localhost (executor driver) (19/75)
2018-02-08 09:19:30,760 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 10.0 (TID 149)
2018-02-08 09:19:30,763 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,764 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,766 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 10.0 (TID 149). 2956 bytes result sent to driver
2018-02-08 09:19:30,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 10.0 (TID 150, localhost, executor driver, partition 146, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 10.0 (TID 149) in 8 ms on localhost (executor driver) (20/75)
2018-02-08 09:19:30,768 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 10.0 (TID 150)
2018-02-08 09:19:30,774 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,774 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,778 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 10.0 (TID 150). 2999 bytes result sent to driver
2018-02-08 09:19:30,780 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 10.0 (TID 151, localhost, executor driver, partition 147, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,780 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 10.0 (TID 150) in 14 ms on localhost (executor driver) (21/75)
2018-02-08 09:19:30,780 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 10.0 (TID 151)
2018-02-08 09:19:30,785 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,785 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,790 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 10.0 (TID 151). 2999 bytes result sent to driver
2018-02-08 09:19:30,790 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 10.0 (TID 152, localhost, executor driver, partition 148, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,790 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 10.0 (TID 152)
2018-02-08 09:19:30,791 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 10.0 (TID 151) in 11 ms on localhost (executor driver) (22/75)
2018-02-08 09:19:30,792 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,793 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,793 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,793 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,797 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 10.0 (TID 152). 2956 bytes result sent to driver
2018-02-08 09:19:30,798 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 10.0 (TID 153, localhost, executor driver, partition 149, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,798 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 10.0 (TID 153)
2018-02-08 09:19:30,798 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 10.0 (TID 152) in 8 ms on localhost (executor driver) (23/75)
2018-02-08 09:19:30,800 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 10.0 (TID 148). 2956 bytes result sent to driver
2018-02-08 09:19:30,800 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 10.0 (TID 154, localhost, executor driver, partition 150, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,801 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 10.0 (TID 148) in 54 ms on localhost (executor driver) (24/75)
2018-02-08 09:19:30,801 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,801 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,801 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 10.0 (TID 154)
2018-02-08 09:19:30,806 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,806 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,808 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 10.0 (TID 153). 2999 bytes result sent to driver
2018-02-08 09:19:30,809 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 10.0 (TID 155, localhost, executor driver, partition 151, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,809 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 10.0 (TID 154). 2956 bytes result sent to driver
2018-02-08 09:19:30,809 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 10.0 (TID 153) in 12 ms on localhost (executor driver) (25/75)
2018-02-08 09:19:30,810 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 10.0 (TID 156, localhost, executor driver, partition 152, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,810 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 10.0 (TID 154) in 10 ms on localhost (executor driver) (26/75)
2018-02-08 09:19:30,810 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 10.0 (TID 156)
2018-02-08 09:19:30,813 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,813 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,816 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 10.0 (TID 156). 2956 bytes result sent to driver
2018-02-08 09:19:30,818 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 10.0 (TID 157, localhost, executor driver, partition 153, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,818 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 10.0 (TID 156) in 8 ms on localhost (executor driver) (27/75)
2018-02-08 09:19:30,820 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 10.0 (TID 157)
2018-02-08 09:19:30,824 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,824 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,829 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 10.0 (TID 157). 2956 bytes result sent to driver
2018-02-08 09:19:30,830 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 10.0 (TID 158, localhost, executor driver, partition 154, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,830 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 10.0 (TID 158)
2018-02-08 09:19:30,830 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 10.0 (TID 157) in 12 ms on localhost (executor driver) (28/75)
2018-02-08 09:19:30,831 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 10.0 (TID 155)
2018-02-08 09:19:30,833 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,833 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,833 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,834 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,844 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 10.0 (TID 158). 2999 bytes result sent to driver
2018-02-08 09:19:30,845 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 10.0 (TID 159, localhost, executor driver, partition 155, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,846 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 10.0 (TID 158) in 17 ms on localhost (executor driver) (29/75)
2018-02-08 09:19:30,846 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 10.0 (TID 159)
2018-02-08 09:19:30,854 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,854 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,857 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 10.0 (TID 159). 2999 bytes result sent to driver
2018-02-08 09:19:30,858 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 10.0 (TID 155). 2999 bytes result sent to driver
2018-02-08 09:19:30,871 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 10.0 (TID 160, localhost, executor driver, partition 156, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,872 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 10.0 (TID 160)
2018-02-08 09:19:30,872 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 10.0 (TID 161, localhost, executor driver, partition 157, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,872 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 10.0 (TID 155) in 63 ms on localhost (executor driver) (30/75)
2018-02-08 09:19:30,872 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 10.0 (TID 161)
2018-02-08 09:19:30,876 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,876 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 10.0 (TID 159) in 33 ms on localhost (executor driver) (31/75)
2018-02-08 09:19:30,881 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 10.0 (TID 160). 2999 bytes result sent to driver
2018-02-08 09:19:30,882 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 10.0 (TID 162, localhost, executor driver, partition 158, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,883 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,883 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,889 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 10.0 (TID 161). 2956 bytes result sent to driver
2018-02-08 09:19:30,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 10.0 (TID 160) in 18 ms on localhost (executor driver) (32/75)
2018-02-08 09:19:30,890 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 10.0 (TID 162)
2018-02-08 09:19:30,892 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 10.0 (TID 163, localhost, executor driver, partition 159, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,892 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 10.0 (TID 161) in 20 ms on localhost (executor driver) (33/75)
2018-02-08 09:19:30,893 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 10.0 (TID 163)
2018-02-08 09:19:30,893 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,894 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,896 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,897 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,904 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 10.0 (TID 163). 2999 bytes result sent to driver
2018-02-08 09:19:30,905 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 10.0 (TID 162). 2999 bytes result sent to driver
2018-02-08 09:19:30,905 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 10.0 (TID 164, localhost, executor driver, partition 160, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,906 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 10.0 (TID 164)
2018-02-08 09:19:30,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 10.0 (TID 165, localhost, executor driver, partition 161, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 10.0 (TID 162) in 24 ms on localhost (executor driver) (34/75)
2018-02-08 09:19:30,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 10.0 (TID 163) in 15 ms on localhost (executor driver) (35/75)
2018-02-08 09:19:30,907 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 10.0 (TID 165)
2018-02-08 09:19:30,908 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,909 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,909 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,909 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,913 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 10.0 (TID 164). 2999 bytes result sent to driver
2018-02-08 09:19:30,918 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 10.0 (TID 166, localhost, executor driver, partition 162, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,919 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 10.0 (TID 165). 2999 bytes result sent to driver
2018-02-08 09:19:30,919 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 10.0 (TID 166)
2018-02-08 09:19:30,919 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 10.0 (TID 164) in 14 ms on localhost (executor driver) (36/75)
2018-02-08 09:19:30,920 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 10.0 (TID 167, localhost, executor driver, partition 163, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,920 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 10.0 (TID 165) in 14 ms on localhost (executor driver) (37/75)
2018-02-08 09:19:30,921 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 10.0 (TID 167)
2018-02-08 09:19:30,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,923 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,923 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,929 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 10.0 (TID 167). 2999 bytes result sent to driver
2018-02-08 09:19:30,930 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 10.0 (TID 168, localhost, executor driver, partition 164, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,930 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 10.0 (TID 166). 2956 bytes result sent to driver
2018-02-08 09:19:30,930 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 10.0 (TID 167) in 10 ms on localhost (executor driver) (38/75)
2018-02-08 09:19:30,930 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 10.0 (TID 168)
2018-02-08 09:19:30,934 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 10.0 (TID 169, localhost, executor driver, partition 165, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,934 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 10.0 (TID 166) in 16 ms on localhost (executor driver) (39/75)
2018-02-08 09:19:30,935 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 10.0 (TID 169)
2018-02-08 09:19:30,936 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,936 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,938 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,938 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,940 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 10.0 (TID 168). 2956 bytes result sent to driver
2018-02-08 09:19:30,941 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 10.0 (TID 170, localhost, executor driver, partition 166, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,942 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 10.0 (TID 168) in 13 ms on localhost (executor driver) (40/75)
2018-02-08 09:19:30,943 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 10.0 (TID 170)
2018-02-08 09:19:30,943 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 10.0 (TID 169). 2999 bytes result sent to driver
2018-02-08 09:19:30,945 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 10.0 (TID 171, localhost, executor driver, partition 167, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,946 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 10.0 (TID 169) in 12 ms on localhost (executor driver) (41/75)
2018-02-08 09:19:30,946 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,946 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,949 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 10.0 (TID 171)
2018-02-08 09:19:30,950 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 10.0 (TID 170). 2956 bytes result sent to driver
2018-02-08 09:19:30,951 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 10.0 (TID 172, localhost, executor driver, partition 168, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,951 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 10.0 (TID 170) in 10 ms on localhost (executor driver) (42/75)
2018-02-08 09:19:30,951 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 10.0 (TID 172)
2018-02-08 09:19:30,954 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,954 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,954 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,957 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 10.0 (TID 172). 2999 bytes result sent to driver
2018-02-08 09:19:30,957 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 10.0 (TID 171). 2999 bytes result sent to driver
2018-02-08 09:19:30,958 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 10.0 (TID 173, localhost, executor driver, partition 169, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,959 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 10.0 (TID 174, localhost, executor driver, partition 170, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,959 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 10.0 (TID 173)
2018-02-08 09:19:30,959 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 10.0 (TID 171) in 14 ms on localhost (executor driver) (43/75)
2018-02-08 09:19:30,959 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 10.0 (TID 172) in 9 ms on localhost (executor driver) (44/75)
2018-02-08 09:19:30,960 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 10.0 (TID 174)
2018-02-08 09:19:30,962 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,962 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,965 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,965 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 09:19:30,966 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 10.0 (TID 173). 2956 bytes result sent to driver
2018-02-08 09:19:30,967 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 10.0 (TID 175, localhost, executor driver, partition 171, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,968 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 10.0 (TID 173) in 10 ms on localhost (executor driver) (45/75)
2018-02-08 09:19:30,968 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 10.0 (TID 175)
2018-02-08 09:19:30,968 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 10.0 (TID 174). 2956 bytes result sent to driver
2018-02-08 09:19:30,969 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 10.0 (TID 176, localhost, executor driver, partition 172, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,970 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 10.0 (TID 174) in 12 ms on localhost (executor driver) (46/75)
2018-02-08 09:19:30,970 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 10.0 (TID 176)
2018-02-08 09:19:30,971 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,971 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,973 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,973 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,974 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 10.0 (TID 175). 2999 bytes result sent to driver
2018-02-08 09:19:30,975 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 10.0 (TID 177, localhost, executor driver, partition 173, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,975 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 10.0 (TID 175) in 9 ms on localhost (executor driver) (47/75)
2018-02-08 09:19:30,975 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 10.0 (TID 176). 2999 bytes result sent to driver
2018-02-08 09:19:30,975 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 10.0 (TID 177)
2018-02-08 09:19:30,976 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 10.0 (TID 178, localhost, executor driver, partition 174, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,976 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 10.0 (TID 176) in 7 ms on localhost (executor driver) (48/75)
2018-02-08 09:19:30,977 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 10.0 (TID 178)
2018-02-08 09:19:30,979 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,979 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,980 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,980 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,982 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 10.0 (TID 177). 2956 bytes result sent to driver
2018-02-08 09:19:30,982 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 10.0 (TID 179, localhost, executor driver, partition 175, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,983 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 10.0 (TID 177) in 8 ms on localhost (executor driver) (49/75)
2018-02-08 09:19:30,983 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 10.0 (TID 179)
2018-02-08 09:19:30,985 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,986 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:30,988 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 10.0 (TID 179). 2956 bytes result sent to driver
2018-02-08 09:19:30,989 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 10.0 (TID 180, localhost, executor driver, partition 176, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,988 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 10.0 (TID 178). 2956 bytes result sent to driver
2018-02-08 09:19:30,989 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 10.0 (TID 180)
2018-02-08 09:19:30,989 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 10.0 (TID 179) in 7 ms on localhost (executor driver) (50/75)
2018-02-08 09:19:30,991 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 10.0 (TID 181, localhost, executor driver, partition 177, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,991 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 10.0 (TID 178) in 15 ms on localhost (executor driver) (51/75)
2018-02-08 09:19:30,992 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 10.0 (TID 181)
2018-02-08 09:19:30,992 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,992 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,994 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:30,994 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:30,996 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 10.0 (TID 180). 2956 bytes result sent to driver
2018-02-08 09:19:30,998 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 10.0 (TID 182, localhost, executor driver, partition 178, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:30,998 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 10.0 (TID 181). 2956 bytes result sent to driver
2018-02-08 09:19:30,999 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 10.0 (TID 182)
2018-02-08 09:19:30,999 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 10.0 (TID 180) in 10 ms on localhost (executor driver) (52/75)
2018-02-08 09:19:31,000 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 10.0 (TID 183, localhost, executor driver, partition 179, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,000 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 10.0 (TID 181) in 9 ms on localhost (executor driver) (53/75)
2018-02-08 09:19:31,000 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 10.0 (TID 183)
2018-02-08 09:19:31,002 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,002 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:31,004 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,005 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:31,006 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 10.0 (TID 182). 2999 bytes result sent to driver
2018-02-08 09:19:31,006 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 10.0 (TID 184, localhost, executor driver, partition 180, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,007 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 10.0 (TID 182) in 10 ms on localhost (executor driver) (54/75)
2018-02-08 09:19:31,008 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 10.0 (TID 184)
2018-02-08 09:19:31,009 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 10.0 (TID 183). 2999 bytes result sent to driver
2018-02-08 09:19:31,009 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 10.0 (TID 185, localhost, executor driver, partition 181, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,010 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 10.0 (TID 183) in 10 ms on localhost (executor driver) (55/75)
2018-02-08 09:19:31,010 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 10.0 (TID 185)
2018-02-08 09:19:31,012 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,012 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:31,013 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,014 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:31,015 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 10.0 (TID 184). 2956 bytes result sent to driver
2018-02-08 09:19:31,016 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 10.0 (TID 186, localhost, executor driver, partition 182, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 10.0 (TID 184) in 11 ms on localhost (executor driver) (56/75)
2018-02-08 09:19:31,018 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 10.0 (TID 185). 2956 bytes result sent to driver
2018-02-08 09:19:31,018 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 10.0 (TID 186)
2018-02-08 09:19:31,018 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 10.0 (TID 187, localhost, executor driver, partition 183, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,019 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 10.0 (TID 185) in 10 ms on localhost (executor driver) (57/75)
2018-02-08 09:19:31,019 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 10.0 (TID 187)
2018-02-08 09:19:31,021 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,021 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,022 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,022 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,024 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 10.0 (TID 186). 2999 bytes result sent to driver
2018-02-08 09:19:31,025 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 10.0 (TID 187). 2999 bytes result sent to driver
2018-02-08 09:19:31,028 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 10.0 (TID 188, localhost, executor driver, partition 184, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,029 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 10.0 (TID 189, localhost, executor driver, partition 185, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,030 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 10.0 (TID 186) in 14 ms on localhost (executor driver) (58/75)
2018-02-08 09:19:31,031 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 10.0 (TID 187) in 13 ms on localhost (executor driver) (59/75)
2018-02-08 09:19:31,039 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 10.0 (TID 188)
2018-02-08 09:19:31,041 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 10.0 (TID 189)
2018-02-08 09:19:31,043 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,043 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,046 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 10.0 (TID 188). 2956 bytes result sent to driver
2018-02-08 09:19:31,046 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 10.0 (TID 190, localhost, executor driver, partition 186, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,047 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 10.0 (TID 189). 2956 bytes result sent to driver
2018-02-08 09:19:31,047 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 10.0 (TID 188) in 19 ms on localhost (executor driver) (60/75)
2018-02-08 09:19:31,048 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 10.0 (TID 191, localhost, executor driver, partition 187, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,048 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 10.0 (TID 189) in 19 ms on localhost (executor driver) (61/75)
2018-02-08 09:19:31,048 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 10.0 (TID 190)
2018-02-08 09:19:31,052 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 10.0 (TID 191)
2018-02-08 09:19:31,057 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,057 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,058 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,058 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,063 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 10.0 (TID 191). 2956 bytes result sent to driver
2018-02-08 09:19:31,064 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 10.0 (TID 192, localhost, executor driver, partition 188, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,064 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 10.0 (TID 191) in 16 ms on localhost (executor driver) (62/75)
2018-02-08 09:19:31,065 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 10.0 (TID 192)
2018-02-08 09:19:31,074 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 10.0 (TID 190). 2999 bytes result sent to driver
2018-02-08 09:19:31,078 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 10.0 (TID 193, localhost, executor driver, partition 189, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,078 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 10.0 (TID 190) in 32 ms on localhost (executor driver) (63/75)
2018-02-08 09:19:31,079 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 10.0 (TID 193)
2018-02-08 09:19:31,083 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,083 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,083 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,084 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:31,087 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 10.0 (TID 193). 2999 bytes result sent to driver
2018-02-08 09:19:31,088 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 10.0 (TID 192). 2956 bytes result sent to driver
2018-02-08 09:19:31,088 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 10.0 (TID 194, localhost, executor driver, partition 190, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,088 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 10.0 (TID 195, localhost, executor driver, partition 191, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,090 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 10.0 (TID 193) in 13 ms on localhost (executor driver) (64/75)
2018-02-08 09:19:31,090 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 10.0 (TID 192) in 26 ms on localhost (executor driver) (65/75)
2018-02-08 09:19:31,093 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 10.0 (TID 194)
2018-02-08 09:19:31,095 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 10.0 (TID 195)
2018-02-08 09:19:31,097 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,097 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,100 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,101 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:31,101 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 10.0 (TID 194). 2999 bytes result sent to driver
2018-02-08 09:19:31,102 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 10.0 (TID 196, localhost, executor driver, partition 192, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,103 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 10.0 (TID 195). 2956 bytes result sent to driver
2018-02-08 09:19:31,104 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 10.0 (TID 197, localhost, executor driver, partition 193, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,104 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 10.0 (TID 196)
2018-02-08 09:19:31,104 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 10.0 (TID 195) in 16 ms on localhost (executor driver) (66/75)
2018-02-08 09:19:31,105 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 10.0 (TID 194) in 17 ms on localhost (executor driver) (67/75)
2018-02-08 09:19:31,105 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 10.0 (TID 197)
2018-02-08 09:19:31,108 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,108 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:31,111 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,111 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:31,112 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 10.0 (TID 196). 2956 bytes result sent to driver
2018-02-08 09:19:31,112 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 10.0 (TID 198, localhost, executor driver, partition 194, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,114 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 10.0 (TID 197). 2999 bytes result sent to driver
2018-02-08 09:19:31,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 10.0 (TID 199, localhost, executor driver, partition 195, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,114 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 10.0 (TID 198)
2018-02-08 09:19:31,115 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 10.0 (TID 199)
2018-02-08 09:19:31,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 10.0 (TID 196) in 12 ms on localhost (executor driver) (68/75)
2018-02-08 09:19:31,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,122 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 10.0 (TID 198). 2956 bytes result sent to driver
2018-02-08 09:19:31,125 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 10.0 (TID 199). 2956 bytes result sent to driver
2018-02-08 09:19:31,125 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 10.0 (TID 197) in 22 ms on localhost (executor driver) (69/75)
2018-02-08 09:19:31,126 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 10.0 (TID 200, localhost, executor driver, partition 196, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,128 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 10.0 (TID 200)
2018-02-08 09:19:31,131 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 10.0 (TID 201, localhost, executor driver, partition 197, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,134 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,134 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,137 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 10.0 (TID 198) in 25 ms on localhost (executor driver) (70/75)
2018-02-08 09:19:31,137 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 10.0 (TID 201)
2018-02-08 09:19:31,138 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 10.0 (TID 199) in 23 ms on localhost (executor driver) (71/75)
2018-02-08 09:19:31,140 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,141 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 09:19:31,144 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 10.0 (TID 201). 2956 bytes result sent to driver
2018-02-08 09:19:31,145 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 10.0 (TID 202, localhost, executor driver, partition 199, PROCESS_LOCAL, 4726 bytes)
2018-02-08 09:19:31,145 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 10.0 (TID 201) in 14 ms on localhost (executor driver) (72/75)
2018-02-08 09:19:31,145 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 10.0 (TID 202)
2018-02-08 09:19:31,149 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 10.0 (TID 200). 2999 bytes result sent to driver
2018-02-08 09:19:31,150 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 10.0 (TID 203, localhost, executor driver, partition 198, ANY, 4726 bytes)
2018-02-08 09:19:31,150 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 10.0 (TID 200) in 24 ms on localhost (executor driver) (73/75)
2018-02-08 09:19:31,150 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 10.0 (TID 203)
2018-02-08 09:19:31,153 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,153 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 09:19:31,158 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 10.0 (TID 203). 2971 bytes result sent to driver
2018-02-08 09:19:31,159 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 10.0 (TID 203) in 9 ms on localhost (executor driver) (74/75)
2018-02-08 09:19:31,159 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 2 blocks
2018-02-08 09:19:31,159 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 11 ms
2018-02-08 09:19:31,163 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 10.0 (TID 202). 2999 bytes result sent to driver
2018-02-08 09:19:31,166 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 10.0 (TID 202) in 22 ms on localhost (executor driver) (75/75)
2018-02-08 09:19:31,166 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 09:19:31,167 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 10 (show at MachineLeaningSelector.java:195) finished in 0.734 s
2018-02-08 09:19:31,172 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: show at MachineLeaningSelector.java:195, took 0.862314 s
2018-02-08 09:19:31,197 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.953602 ms
2018-02-08 09:19:31,343 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 22.716808 ms
2018-02-08 09:19:31,389 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 32.26049 ms
2018-02-08 09:19:31,401 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.496643 ms
2018-02-08 09:19:31,438 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningSelector.java:198
2018-02-08 09:19:31,439 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (show at MachineLeaningSelector.java:198) with 2 output partitions
2018-02-08 09:19:31,439 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 11 (show at MachineLeaningSelector.java:198)
2018-02-08 09:19:31,439 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:19:31,439 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:19:31,440 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 11 (MapPartitionsRDD[17] at show at MachineLeaningSelector.java:198), which has no missing parents
2018-02-08 09:19:31,445 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 27.5 KB, free 615.6 MB)
2018-02-08 09:19:31,448 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 615.6 MB)
2018-02-08 09:19:31,449 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:50941 (size: 9.4 KB, free: 631.7 MB)
2018-02-08 09:19:31,449 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:19:31,450 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 11 (MapPartitionsRDD[17] at show at MachineLeaningSelector.java:198) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:19:31,450 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 2 tasks
2018-02-08 09:19:31,450 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 204, localhost, executor driver, partition 0, PROCESS_LOCAL, 5123 bytes)
2018-02-08 09:19:31,451 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 11.0 (TID 205, localhost, executor driver, partition 1, PROCESS_LOCAL, 5276 bytes)
2018-02-08 09:19:31,451 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 11.0 (TID 205)
2018-02-08 09:19:31,451 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 204)
2018-02-08 09:19:31,469 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 204). 3161 bytes result sent to driver
2018-02-08 09:19:31,510 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 11.0 (TID 205). 2450 bytes result sent to driver
2018-02-08 09:19:31,514 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 204) in 64 ms on localhost (executor driver) (1/2)
2018-02-08 09:19:31,515 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 11.0 (TID 205) in 65 ms on localhost (executor driver) (2/2)
2018-02-08 09:19:31,528 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 09:19:31,529 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:50941 in memory (size: 20.5 KB, free: 631.8 MB)
2018-02-08 09:19:31,532 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 11 (show at MachineLeaningSelector.java:198) finished in 0.080 s
2018-02-08 09:19:31,533 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: show at MachineLeaningSelector.java:198, took 0.094258 s
2018-02-08 09:19:31,535 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:50941 in memory (size: 20.5 KB, free: 631.8 MB)
2018-02-08 09:19:31,569 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 33.656011 ms
2018-02-08 09:19:31,577 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:19:31,582 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@3660b7af{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:19:31,584 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:19:31,598 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:19:31,680 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:19:31,681 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:19:31,682 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:19:31,687 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:19:31,689 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:19:31,690 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:19:31,690 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-5eccf6f1-fdb6-4952-a8bf-8d0affcef9ad
2018-02-08 09:39:52,802 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:39:53,267 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:39:53,286 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:39:53,287 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:39:53,287 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:39:53,288 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:39:53,288 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:39:53,656 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 51505.
2018-02-08 09:39:53,674 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:39:53,716 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:39:53,719 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:39:53,720 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:39:53,729 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-7cda5f88-d7b7-4fb3-a095-52a3f11525d1
2018-02-08 09:39:53,752 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:39:53,806 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:39:53,883 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2572ms
2018-02-08 09:39:53,946 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:39:53,958 INFO[org.spark_project.jetty.server.Server:403] - Started @2648ms
2018-02-08 09:39:53,978 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@866e093{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:39:53,978 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:39:54,000 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24fb6a80{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,001 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,002 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,003 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,003 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,004 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,004 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,006 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,007 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,008 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,008 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,011 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,012 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,013 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,013 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,014 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,015 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,016 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,017 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,018 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,025 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/static,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,026 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,028 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@649725e3{/api,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,028 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,029 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,031 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:39:54,107 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:39:54,134 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51518.
2018-02-08 09:39:54,135 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:51518
2018-02-08 09:39:54,138 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:39:54,141 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 51518, None)
2018-02-08 09:39:54,144 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:51518 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 51518, None)
2018-02-08 09:39:54,149 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 51518, None)
2018-02-08 09:39:54,151 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 51518, None)
2018-02-08 09:39:54,312 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3b582111{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,379 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:39:54,380 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:39:54,385 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,386 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410e94e{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,387 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@78d39a69{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,387 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b69d40d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:39:54,389 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@72889280{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:39:55,411 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:39:55,478 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:39:55,485 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@866e093{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:39:55,487 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:39:55,494 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:39:55,501 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:39:55,501 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:39:55,506 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:39:55,509 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:39:55,512 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:39:55,512 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:39:55,513 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-91d366c6-43cc-4bb9-a4dd-17c8cd35c8f9
2018-02-08 09:40:19,751 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:40:20,214 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:40:20,235 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:40:20,236 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:40:20,237 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:40:20,237 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:40:20,238 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:40:20,588 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 51543.
2018-02-08 09:40:20,606 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:40:20,652 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:40:20,655 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:40:20,655 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:40:20,663 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-9397a407-f40d-4d5e-9f8c-f11b0fb7fa8a
2018-02-08 09:40:20,685 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:40:20,735 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:40:20,821 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2422ms
2018-02-08 09:40:20,880 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:40:20,892 INFO[org.spark_project.jetty.server.Server:403] - Started @2495ms
2018-02-08 09:40:20,910 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@68bd5dc2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:40:20,911 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:40:20,931 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24fb6a80{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,932 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,933 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,934 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,934 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,935 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,936 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,937 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,938 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,939 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,939 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,940 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,941 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,942 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,944 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,947 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,948 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,950 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,952 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,953 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,961 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/static,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,962 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,963 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@649725e3{/api,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,963 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,964 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:40:20,966 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:40:21,043 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:40:21,065 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51557.
2018-02-08 09:40:21,066 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:51557
2018-02-08 09:40:21,068 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:40:21,070 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 51557, None)
2018-02-08 09:40:21,075 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:51557 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 51557, None)
2018-02-08 09:40:21,078 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 51557, None)
2018-02-08 09:40:21,079 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 51557, None)
2018-02-08 09:40:21,261 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3b582111{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:21,340 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:40:21,342 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:40:21,351 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410e94e{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:40:21,352 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1bdbf9be{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:21,353 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b69d40d{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:40:21,354 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@15f193b8{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:40:21,356 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4aa3d36{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:40:22,331 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:40:22,383 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:40:22,388 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@68bd5dc2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:40:22,389 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:40:22,396 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:40:22,403 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:40:22,403 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:40:22,408 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:40:22,410 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:40:22,413 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:40:22,413 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:40:22,414 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-0d278cd3-bddd-44c4-b3e8-a28818f4995f
2018-02-08 09:41:03,295 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:41:03,916 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:41:03,938 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:41:03,939 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:41:03,940 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:41:03,940 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:41:03,941 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:41:04,357 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 51585.
2018-02-08 09:41:04,411 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:41:04,428 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:41:04,430 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:41:04,431 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:41:04,439 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-35de1d25-94d6-4226-9681-f61bd4c2eee1
2018-02-08 09:41:04,460 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:41:04,515 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:41:04,594 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2859ms
2018-02-08 09:41:04,671 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:41:04,683 INFO[org.spark_project.jetty.server.Server:403] - Started @2950ms
2018-02-08 09:41:04,702 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@7b32f141{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:41:04,702 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:41:04,724 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24fb6a80{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,724 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,725 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,726 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,726 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,727 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,728 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,729 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,731 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,732 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,732 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,733 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,734 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,735 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,735 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,736 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,737 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,738 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,738 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,740 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,746 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/static,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,747 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,749 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@649725e3{/api,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,749 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,750 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:41:04,752 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:41:04,832 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:41:04,868 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51600.
2018-02-08 09:41:04,869 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:51600
2018-02-08 09:41:04,871 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:41:04,877 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 51600, None)
2018-02-08 09:41:04,884 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:51600 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 51600, None)
2018-02-08 09:41:04,890 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 51600, None)
2018-02-08 09:41:04,890 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 51600, None)
2018-02-08 09:41:05,199 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3b582111{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:05,300 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:41:05,303 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:41:05,310 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1bdbf9be{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:41:05,310 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1da6ee17{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:05,312 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@15f193b8{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:41:05,312 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@304a9d7b{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:05,321 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@347bdeef{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:41:06,584 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:41:07,006 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 09:41:07,071 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 09:41:07,074 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:51600 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 09:41:07,078 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 09:41:07,187 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 09:41:07,203 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 09:41:07,237 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 09:41:07,237 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 09:41:07,238 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:41:07,241 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:41:07,249 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 09:41:07,302 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 09:41:07,307 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 09:41:07,308 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:51600 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 09:41:07,309 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:41:07,323 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:41:07,324 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 09:41:07,362 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4894 bytes)
2018-02-08 09:41:07,364 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4894 bytes)
2018-02-08 09:41:07,373 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 09:41:07,373 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:41:07,432 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_libsvm_data.txt:0+52368
2018-02-08 09:41:07,433 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_libsvm_data.txt:52368+52368
2018-02-08 09:41:07,590 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
2018-02-08 09:41:07,590 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 910 bytes result sent to driver
2018-02-08 09:41:07,601 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 251 ms on localhost (executor driver) (1/2)
2018-02-08 09:41:07,603 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 240 ms on localhost (executor driver) (2/2)
2018-02-08 09:41:07,605 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:41:07,610 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.271 s
2018-02-08 09:41:07,616 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.412962 s
2018-02-08 09:41:08,378 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:51600 in memory (size: 27.3 KB, free: 631.8 MB)
2018-02-08 09:41:08,382 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:51600 in memory (size: 2.3 KB, free: 631.8 MB)
2018-02-08 09:41:09,185 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 09:41:09,188 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 09:41:09,191 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 09:41:09,199 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 09:41:09,512 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 186.74086 ms
2018-02-08 09:41:09,523 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 09:41:09,536 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 09:41:09,538 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:51600 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 09:41:09,539 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at LibSVMRelation.scala:153
2018-02-08 09:41:09,552 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 09:41:09,606 INFO[org.apache.spark.SparkContext:54] - Starting job: take at VectorIndexer.scala:119
2018-02-08 09:41:09,607 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (take at VectorIndexer.scala:119) with 1 output partitions
2018-02-08 09:41:09,607 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (take at VectorIndexer.scala:119)
2018-02-08 09:41:09,607 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:41:09,607 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:41:09,608 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[8] at take at VectorIndexer.scala:119), which has no missing parents
2018-02-08 09:41:09,630 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 7.2 KB, free 631.5 MB)
2018-02-08 09:41:09,633 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 631.4 MB)
2018-02-08 09:41:09,633 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:51600 (size: 4.0 KB, free: 631.8 MB)
2018-02-08 09:41:09,634 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:41:09,636 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at take at VectorIndexer.scala:119) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:41:09,636 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 09:41:09,643 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 09:41:09,644 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 09:41:09,656 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_libsvm_data.txt, range: 0-104736, partition values: [empty row]
2018-02-08 09:41:09,696 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 24.183368 ms
2018-02-08 09:41:09,732 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 19.086406 ms
2018-02-08 09:41:09,804 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 40.638093 ms
2018-02-08 09:41:09,813 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 2518 bytes result sent to driver
2018-02-08 09:41:09,815 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 178 ms on localhost (executor driver) (1/1)
2018-02-08 09:41:09,815 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (take at VectorIndexer.scala:119) finished in 0.178 s
2018-02-08 09:41:09,817 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: take at VectorIndexer.scala:119, took 0.210391 s
2018-02-08 09:41:09,822 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 09:41:09,844 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.232324 ms
2018-02-08 09:41:09,875 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 09:41:09,875 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 09:41:09,876 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 09:41:09,876 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 09:41:09,884 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 322.9 KB, free 631.1 MB)
2018-02-08 09:41:09,899 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.1 MB)
2018-02-08 09:41:09,900 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:51600 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 09:41:09,901 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at LibSVMRelation.scala:153
2018-02-08 09:41:09,901 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 09:41:09,926 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at VectorIndexer.scala:128
2018-02-08 09:41:09,927 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (reduce at VectorIndexer.scala:128) with 1 output partitions
2018-02-08 09:41:09,927 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (reduce at VectorIndexer.scala:128)
2018-02-08 09:41:09,927 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:41:09,927 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:41:09,928 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[14] at mapPartitions at VectorIndexer.scala:124), which has no missing parents
2018-02-08 09:41:09,952 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 11.5 KB, free 631.1 MB)
2018-02-08 09:41:09,954 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KB, free 631.1 MB)
2018-02-08 09:41:09,956 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:51600 (size: 6.0 KB, free: 631.7 MB)
2018-02-08 09:41:09,957 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:41:09,958 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at mapPartitions at VectorIndexer.scala:124) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:41:09,958 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 09:41:09,959 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 09:41:09,960 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 09:41:09,969 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_libsvm_data.txt, range: 0-104736, partition values: [empty row]
2018-02-08 09:41:10,069 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 413672 bytes result sent to driver
2018-02-08 09:41:10,085 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 125 ms on localhost (executor driver) (1/1)
2018-02-08 09:41:10,086 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (reduce at VectorIndexer.scala:128) finished in 0.127 s
2018-02-08 09:41:10,088 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: reduce at VectorIndexer.scala:128, took 0.160960 s
2018-02-08 09:41:10,095 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 09:41:10,330 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 09:41:10,331 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 09:41:10,331 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 09:41:10,332 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 09:41:10,391 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 36.669452 ms
2018-02-08 09:41:10,396 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 322.9 KB, free 630.8 MB)
2018-02-08 09:41:10,410 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 27.6 KB, free 630.7 MB)
2018-02-08 09:41:10,412 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:51600 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 09:41:10,413 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at LibSVMRelation.scala:153
2018-02-08 09:41:10,413 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 09:41:10,446 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningTransformer.java:318
2018-02-08 09:41:10,447 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at MachineLeaningTransformer.java:318) with 1 output partitions
2018-02-08 09:41:10,447 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (show at MachineLeaningTransformer.java:318)
2018-02-08 09:41:10,447 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:41:10,447 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:41:10,448 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[17] at show at MachineLeaningTransformer.java:318), which has no missing parents
2018-02-08 09:41:10,456 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 81.1 KB, free 630.7 MB)
2018-02-08 09:41:10,462 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.0 KB, free 630.6 MB)
2018-02-08 09:41:10,464 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:51600 (size: 23.0 KB, free: 631.7 MB)
2018-02-08 09:41:10,465 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:41:10,466 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at show at MachineLeaningTransformer.java:318) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:41:10,466 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 09:41:10,467 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 09:41:10,467 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 09:41:10,482 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_libsvm_data.txt, range: 0-104736, partition values: [empty row]
2018-02-08 09:41:10,525 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 41.403533 ms
2018-02-08 09:41:10,566 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 17548 bytes result sent to driver
2018-02-08 09:41:10,567 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 101 ms on localhost (executor driver) (1/1)
2018-02-08 09:41:10,567 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 09:41:10,568 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (show at MachineLeaningTransformer.java:318) finished in 0.102 s
2018-02-08 09:41:10,568 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at MachineLeaningTransformer.java:318, took 0.122136 s
2018-02-08 09:41:10,597 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.136646 ms
2018-02-08 09:41:10,666 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:41:10,675 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@7b32f141{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:41:10,680 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:41:10,706 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:41:10,730 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:41:10,731 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:41:10,735 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:41:10,737 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:41:10,806 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:41:10,806 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:41:10,812 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-d208f794-8a0c-43db-927f-63940af5a6a3
2018-02-08 09:41:26,642 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 09:41:27,234 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 09:41:27,258 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 09:41:27,259 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 09:41:27,260 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 09:41:27,260 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 09:41:27,261 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 09:41:27,667 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 51626.
2018-02-08 09:41:27,714 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 09:41:27,731 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 09:41:27,734 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 09:41:27,734 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 09:41:27,743 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-596008d5-d886-441b-a771-3aa8f402712d
2018-02-08 09:41:27,768 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 09:41:27,817 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 09:41:27,899 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2692ms
2018-02-08 09:41:27,971 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 09:41:27,984 INFO[org.spark_project.jetty.server.Server:403] - Started @2778ms
2018-02-08 09:41:28,002 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@2c163e6f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:41:28,003 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 09:41:28,023 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24fb6a80{/jobs,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,023 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,024 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,025 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,025 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,026 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,026 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,027 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,028 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,028 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,029 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/storage,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,029 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,030 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,030 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,031 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/environment,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,031 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,032 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/executors,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,033 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,033 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,034 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,041 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/static,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,042 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,043 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@649725e3{/api,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,044 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@36b0fcd5{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,045 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@475835b1{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,047 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 09:41:28,118 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 09:41:28,141 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51639.
2018-02-08 09:41:28,142 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:51639
2018-02-08 09:41:28,143 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 09:41:28,145 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 51639, None)
2018-02-08 09:41:28,148 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:51639 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 51639, None)
2018-02-08 09:41:28,159 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 51639, None)
2018-02-08 09:41:28,160 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 51639, None)
2018-02-08 09:41:28,409 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3b582111{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,473 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 09:41:28,474 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 09:41:28,480 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1bdbf9be{/SQL,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,481 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1da6ee17{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,482 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@15f193b8{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,483 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@304a9d7b{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 09:41:28,485 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@347bdeef{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 09:41:29,444 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 09:41:29,835 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 09:41:29,904 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 09:41:29,907 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:51639 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 09:41:29,912 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 09:41:30,043 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 09:41:30,066 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 09:41:30,099 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 09:41:30,100 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 09:41:30,100 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:41:30,102 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:41:30,113 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 09:41:30,154 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 09:41:30,157 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 09:41:30,158 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:51639 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 09:41:30,159 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:41:30,172 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 09:41:30,173 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 09:41:30,208 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4894 bytes)
2018-02-08 09:41:30,211 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4894 bytes)
2018-02-08 09:41:30,227 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 09:41:30,227 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 09:41:30,310 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_libsvm_data.txt:52368+52368
2018-02-08 09:41:30,312 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_libsvm_data.txt:0+52368
2018-02-08 09:41:30,424 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
2018-02-08 09:41:30,424 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 996 bytes result sent to driver
2018-02-08 09:41:30,438 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 240 ms on localhost (executor driver) (1/2)
2018-02-08 09:41:30,439 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 229 ms on localhost (executor driver) (2/2)
2018-02-08 09:41:30,440 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 09:41:30,449 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.263 s
2018-02-08 09:41:30,456 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.389135 s
2018-02-08 09:41:31,204 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:51639 in memory (size: 2.3 KB, free: 631.8 MB)
2018-02-08 09:41:31,208 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:51639 in memory (size: 27.3 KB, free: 631.8 MB)
2018-02-08 09:41:32,168 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 09:41:32,170 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 09:41:32,172 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 09:41:32,180 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 09:41:32,497 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 194.412862 ms
2018-02-08 09:41:32,506 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 09:41:32,518 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.5 KB, free 631.5 MB)
2018-02-08 09:41:32,520 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:51639 (size: 27.5 KB, free: 631.8 MB)
2018-02-08 09:41:32,521 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at LibSVMRelation.scala:153
2018-02-08 09:41:32,531 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 09:41:32,578 INFO[org.apache.spark.SparkContext:54] - Starting job: take at VectorIndexer.scala:119
2018-02-08 09:41:32,579 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (take at VectorIndexer.scala:119) with 1 output partitions
2018-02-08 09:41:32,579 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (take at VectorIndexer.scala:119)
2018-02-08 09:41:32,579 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:41:32,580 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:41:32,581 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[8] at take at VectorIndexer.scala:119), which has no missing parents
2018-02-08 09:41:32,601 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 7.2 KB, free 631.5 MB)
2018-02-08 09:41:32,605 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 631.4 MB)
2018-02-08 09:41:32,606 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:51639 (size: 4.0 KB, free: 631.8 MB)
2018-02-08 09:41:32,606 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:41:32,607 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at take at VectorIndexer.scala:119) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:41:32,607 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 09:41:32,614 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 09:41:32,615 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 09:41:32,626 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_libsvm_data.txt, range: 0-104736, partition values: [empty row]
2018-02-08 09:41:32,667 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 27.105609 ms
2018-02-08 09:41:32,699 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 16.721286 ms
2018-02-08 09:41:32,786 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 59.642259 ms
2018-02-08 09:41:32,806 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 2475 bytes result sent to driver
2018-02-08 09:41:32,808 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 199 ms on localhost (executor driver) (1/1)
2018-02-08 09:41:32,808 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (take at VectorIndexer.scala:119) finished in 0.200 s
2018-02-08 09:41:32,809 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: take at VectorIndexer.scala:119, took 0.230827 s
2018-02-08 09:41:32,815 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 09:41:32,838 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.251204 ms
2018-02-08 09:41:32,865 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 09:41:32,865 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 09:41:32,865 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 09:41:32,866 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 09:41:32,873 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 322.9 KB, free 631.1 MB)
2018-02-08 09:41:32,887 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.5 KB, free 631.1 MB)
2018-02-08 09:41:32,889 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:51639 (size: 27.5 KB, free: 631.7 MB)
2018-02-08 09:41:32,889 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at LibSVMRelation.scala:153
2018-02-08 09:41:32,890 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 09:41:32,913 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at VectorIndexer.scala:128
2018-02-08 09:41:32,914 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (reduce at VectorIndexer.scala:128) with 1 output partitions
2018-02-08 09:41:32,915 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (reduce at VectorIndexer.scala:128)
2018-02-08 09:41:32,915 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:41:32,915 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:41:32,916 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[14] at mapPartitions at VectorIndexer.scala:124), which has no missing parents
2018-02-08 09:41:32,936 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 11.5 KB, free 631.1 MB)
2018-02-08 09:41:32,939 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KB, free 631.1 MB)
2018-02-08 09:41:32,941 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:51639 (size: 6.0 KB, free: 631.7 MB)
2018-02-08 09:41:32,941 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:41:32,942 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at mapPartitions at VectorIndexer.scala:124) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:41:32,942 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 09:41:32,943 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 09:41:32,943 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 09:41:32,951 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_libsvm_data.txt, range: 0-104736, partition values: [empty row]
2018-02-08 09:41:33,007 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 413672 bytes result sent to driver
2018-02-08 09:41:33,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 74 ms on localhost (executor driver) (1/1)
2018-02-08 09:41:33,018 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 09:41:33,018 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (reduce at VectorIndexer.scala:128) finished in 0.076 s
2018-02-08 09:41:33,019 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: reduce at VectorIndexer.scala:128, took 0.104292 s
2018-02-08 09:41:33,190 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 09:41:33,191 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 09:41:33,191 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 09:41:33,191 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 09:41:33,252 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 40.198413 ms
2018-02-08 09:41:33,256 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 322.9 KB, free 630.8 MB)
2018-02-08 09:41:33,274 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 27.5 KB, free 630.7 MB)
2018-02-08 09:41:33,276 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:51639 (size: 27.5 KB, free: 631.7 MB)
2018-02-08 09:41:33,279 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at LibSVMRelation.scala:153
2018-02-08 09:41:33,280 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 09:41:33,326 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningTransformer.java:318
2018-02-08 09:41:33,328 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (show at MachineLeaningTransformer.java:318) with 1 output partitions
2018-02-08 09:41:33,328 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (show at MachineLeaningTransformer.java:318)
2018-02-08 09:41:33,328 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 09:41:33,328 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 09:41:33,329 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[17] at show at MachineLeaningTransformer.java:318), which has no missing parents
2018-02-08 09:41:33,337 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 81.1 KB, free 630.7 MB)
2018-02-08 09:41:33,342 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.0 KB, free 630.6 MB)
2018-02-08 09:41:33,344 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:51639 (size: 23.0 KB, free: 631.7 MB)
2018-02-08 09:41:33,345 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 09:41:33,346 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at show at MachineLeaningTransformer.java:318) (first 15 tasks are for partitions Vector(0))
2018-02-08 09:41:33,346 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 09:41:33,346 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 09:41:33,347 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 09:41:33,362 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_libsvm_data.txt, range: 0-104736, partition values: [empty row]
2018-02-08 09:41:33,378 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.322245 ms
2018-02-08 09:41:33,396 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 17548 bytes result sent to driver
2018-02-08 09:41:33,414 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 68 ms on localhost (executor driver) (1/1)
2018-02-08 09:41:33,414 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 09:41:33,415 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (show at MachineLeaningTransformer.java:318) finished in 0.069 s
2018-02-08 09:41:33,416 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: show at MachineLeaningTransformer.java:318, took 0.089354 s
2018-02-08 09:41:33,423 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_3_piece0 on 192.168.11.26:51639 in memory (size: 4.0 KB, free: 631.7 MB)
2018-02-08 09:41:33,429 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 77
2018-02-08 09:41:33,430 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 81
2018-02-08 09:41:33,430 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 80
2018-02-08 09:41:33,430 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 78
2018-02-08 09:41:33,438 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_4_piece0 on 192.168.11.26:51639 in memory (size: 27.5 KB, free: 631.7 MB)
2018-02-08 09:41:33,440 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.042886 ms
2018-02-08 09:41:33,443 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_5_piece0 on 192.168.11.26:51639 in memory (size: 6.0 KB, free: 631.7 MB)
2018-02-08 09:41:33,449 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 79
2018-02-08 09:41:33,483 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 09:41:33,493 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@2c163e6f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 09:41:33,496 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 09:41:33,508 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 09:41:33,531 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 09:41:33,531 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 09:41:33,534 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 09:41:33,536 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 09:41:33,539 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 09:41:33,540 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 09:41:33,540 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-6718d2b5-746c-4df1-85af-b2e97a953a6f
2018-02-08 11:19:12,527 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 11:19:13,424 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 11:19:13,458 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 11:19:13,459 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 11:19:13,460 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 11:19:13,460 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 11:19:13,461 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 11:19:13,881 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 55902.
2018-02-08 11:19:13,904 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 11:19:13,953 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 11:19:13,957 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 11:19:13,958 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 11:19:13,970 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-678cc4bc-b8a2-42c2-ad64-58e1746e5be3
2018-02-08 11:19:14,001 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 11:19:14,058 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 11:19:14,165 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @3188ms
2018-02-08 11:19:14,245 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 11:19:14,260 INFO[org.spark_project.jetty.server.Server:403] - Started @3284ms
2018-02-08 11:19:14,285 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@2c104774{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 11:19:14,285 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 11:19:14,329 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3276732{/jobs,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,329 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@34a75079{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,330 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@107ed6fc{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,331 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2e029d61{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,332 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4052274f{/stages,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,333 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,334 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,335 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,336 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,337 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,338 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/storage,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,339 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,340 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,341 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,342 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/environment,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,343 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,343 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/executors,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,344 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,345 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,345 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,355 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/static,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,355 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1536602f{/,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,357 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a1edad4{/api,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,357 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c7a975a{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,358 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@757d6814{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,361 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 11:19:14,467 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 11:19:14,500 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55916.
2018-02-08 11:19:14,502 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:55916
2018-02-08 11:19:14,503 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 11:19:14,507 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 55916, None)
2018-02-08 11:19:14,512 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:55916 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 55916, None)
2018-02-08 11:19:14,517 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 55916, None)
2018-02-08 11:19:14,518 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 55916, None)
2018-02-08 11:19:14,726 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6650813a{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,850 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 11:19:14,851 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 11:19:14,862 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3af9aa66{/SQL,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,863 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@91c4a3f{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,864 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64d43929{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,865 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 11:19:14,867 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1da6ee17{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 11:19:16,387 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 11:19:16,763 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 11:19:16,841 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 11:19:16,844 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:55916 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 11:19:16,850 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 11:19:17,017 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 11:19:17,034 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 11:19:17,060 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 11:19:17,061 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 11:19:17,061 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 11:19:17,066 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 11:19:17,074 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 11:19:17,161 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.0 KB, free 631.5 MB)
2018-02-08 11:19:17,166 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 631.5 MB)
2018-02-08 11:19:17,168 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:55916 (size: 2.2 KB, free: 631.8 MB)
2018-02-08 11:19:17,169 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 11:19:17,190 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 11:19:17,191 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 11:19:17,274 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:19:17,279 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:19:17,288 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 11:19:17,288 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 11:19:17,428 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt:289+289
2018-02-08 11:19:17,428 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt:0+289
2018-02-08 11:19:17,474 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_4_1 stored as values in memory (estimated size 1120.0 B, free 631.5 MB)
2018-02-08 11:19:17,474 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_4_0 stored as values in memory (estimated size 1560.0 B, free 631.5 MB)
2018-02-08 11:19:17,477 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_4_1 in memory on 192.168.11.26:55916 (size: 1120.0 B, free: 631.8 MB)
2018-02-08 11:19:17,478 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_4_0 in memory on 192.168.11.26:55916 (size: 1560.0 B, free: 631.8 MB)
2018-02-08 11:19:17,520 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1564 bytes result sent to driver
2018-02-08 11:19:17,520 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1607 bytes result sent to driver
2018-02-08 11:19:17,532 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 290 ms on localhost (executor driver) (1/2)
2018-02-08 11:19:17,534 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 254 ms on localhost (executor driver) (2/2)
2018-02-08 11:19:17,535 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 11:19:17,541 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.325 s
2018-02-08 11:19:17,548 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.513347 s
2018-02-08 11:19:17,575 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at MachineLeaning.java:32
2018-02-08 11:19:17,577 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (collect at MachineLeaning.java:32) with 2 output partitions
2018-02-08 11:19:17,577 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (collect at MachineLeaning.java:32)
2018-02-08 11:19:17,577 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 11:19:17,580 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 11:19:17,581 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[6] at map at MLUtils.scala:84), which has no missing parents
2018-02-08 11:19:17,584 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 11:19:17,588 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.4 MB)
2018-02-08 11:19:17,590 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:55916 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 11:19:17,591 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 11:19:17,592 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at map at MLUtils.scala:84) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 11:19:17,593 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 11:19:17,598 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:19:17,598 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:19:17,598 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 3)
2018-02-08 11:19:17,598 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 11:19:17,607 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_4_0 locally
2018-02-08 11:19:17,608 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_4_1 locally
2018-02-08 11:19:17,643 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:55916 in memory (size: 2.2 KB, free: 631.8 MB)
2018-02-08 11:19:17,646 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 3). 1984 bytes result sent to driver
2018-02-08 11:19:17,646 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 2339 bytes result sent to driver
2018-02-08 11:19:17,648 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 3) in 50 ms on localhost (executor driver) (1/2)
2018-02-08 11:19:17,649 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 53 ms on localhost (executor driver) (2/2)
2018-02-08 11:19:17,649 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 11:19:17,650 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (collect at MachineLeaning.java:32) finished in 0.053 s
2018-02-08 11:19:17,650 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: collect at MachineLeaning.java:32, took 0.074356 s
2018-02-08 11:19:17,656 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 11:19:17,661 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@2c104774{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 11:19:17,663 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 11:19:17,672 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 11:19:17,684 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 11:19:17,684 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 11:19:17,686 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 11:19:17,688 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 11:19:17,697 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 11:19:17,698 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 11:19:17,699 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-f28961c7-c5fa-45d7-84cb-0e485ce3fd72
2018-02-08 11:20:32,352 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 11:20:33,108 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 11:20:33,131 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 11:20:33,132 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 11:20:33,133 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 11:20:33,133 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 11:20:33,134 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 11:20:33,655 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 56008.
2018-02-08 11:20:33,675 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 11:20:33,727 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 11:20:33,731 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 11:20:33,731 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 11:20:33,740 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-76053923-881f-4e31-9ee7-40c64c5a7f92
2018-02-08 11:20:33,763 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 11:20:33,835 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 11:20:33,915 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @3343ms
2018-02-08 11:20:34,007 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 11:20:34,020 INFO[org.spark_project.jetty.server.Server:403] - Started @3449ms
2018-02-08 11:20:34,037 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@55fc9508{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 11:20:34,038 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 11:20:34,058 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@f74e835{/jobs,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,058 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a3591c5{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,059 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@346a361{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,060 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@186978a6{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,060 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@482d776b{/stages,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,061 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,063 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,066 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,067 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,067 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,068 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/storage,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,069 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,069 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,070 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,070 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/environment,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,071 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,072 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/executors,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,072 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,073 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,074 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,081 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/static,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,082 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@25ddbbbb{/,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,083 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4ebea12c{/api,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,084 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@743cb8e0{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,084 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c1b9e4b{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,086 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 11:20:34,156 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 11:20:34,180 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56022.
2018-02-08 11:20:34,181 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:56022
2018-02-08 11:20:34,182 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 11:20:34,184 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 56022, None)
2018-02-08 11:20:34,186 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:56022 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 56022, None)
2018-02-08 11:20:34,189 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 56022, None)
2018-02-08 11:20:34,190 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 56022, None)
2018-02-08 11:20:34,383 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@38d5b107{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,450 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 11:20:34,451 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 11:20:34,459 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62d0ac62{/SQL,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,460 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6826c41e{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,460 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41c89d2f{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,461 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d691f3d{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 11:20:34,462 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b69d40d{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 11:20:35,630 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 11:20:35,927 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 11:20:35,995 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 11:20:35,998 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:56022 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 11:20:36,002 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 11:20:36,110 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 11:20:36,124 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 11:20:36,142 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 11:20:36,142 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 11:20:36,143 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 11:20:36,159 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 11:20:36,165 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 11:20:36,240 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.0 KB, free 631.5 MB)
2018-02-08 11:20:36,244 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 631.5 MB)
2018-02-08 11:20:36,245 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:56022 (size: 2.2 KB, free: 631.8 MB)
2018-02-08 11:20:36,246 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 11:20:36,264 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 11:20:36,266 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 11:20:36,318 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:20:36,330 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:20:36,337 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 11:20:36,337 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 11:20:36,424 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt:289+289
2018-02-08 11:20:36,424 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt:0+289
2018-02-08 11:20:36,463 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_4_1 stored as values in memory (estimated size 1120.0 B, free 631.5 MB)
2018-02-08 11:20:36,463 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_4_0 stored as values in memory (estimated size 1560.0 B, free 631.5 MB)
2018-02-08 11:20:36,463 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_4_1 in memory on 192.168.11.26:56022 (size: 1120.0 B, free: 631.8 MB)
2018-02-08 11:20:36,464 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_4_0 in memory on 192.168.11.26:56022 (size: 1560.0 B, free: 631.8 MB)
2018-02-08 11:20:36,485 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1607 bytes result sent to driver
2018-02-08 11:20:36,485 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1607 bytes result sent to driver
2018-02-08 11:20:36,493 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 172 ms on localhost (executor driver) (1/2)
2018-02-08 11:20:36,494 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 195 ms on localhost (executor driver) (2/2)
2018-02-08 11:20:36,495 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 11:20:36,498 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.217 s
2018-02-08 11:20:36,503 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.378454 s
2018-02-08 11:20:36,521 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at MachineLeaning.java:33
2018-02-08 11:20:36,522 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (collect at MachineLeaning.java:33) with 2 output partitions
2018-02-08 11:20:36,522 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (collect at MachineLeaning.java:33)
2018-02-08 11:20:36,522 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 11:20:36,524 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 11:20:36,524 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[6] at map at MLUtils.scala:84), which has no missing parents
2018-02-08 11:20:36,527 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 11:20:36,530 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.4 MB)
2018-02-08 11:20:36,532 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:56022 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 11:20:36,533 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 11:20:36,534 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at map at MLUtils.scala:84) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 11:20:36,535 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 11:20:36,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:20:36,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:20:36,543 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 11:20:36,543 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 3)
2018-02-08 11:20:36,548 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_4_1 locally
2018-02-08 11:20:36,549 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_4_0 locally
2018-02-08 11:20:36,562 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 3). 1941 bytes result sent to driver
2018-02-08 11:20:36,562 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 2253 bytes result sent to driver
2018-02-08 11:20:36,564 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 3) in 21 ms on localhost (executor driver) (1/2)
2018-02-08 11:20:36,564 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 24 ms on localhost (executor driver) (2/2)
2018-02-08 11:20:36,564 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 11:20:36,565 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (collect at MachineLeaning.java:33) finished in 0.025 s
2018-02-08 11:20:36,565 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: collect at MachineLeaning.java:33, took 0.044163 s
2018-02-08 11:20:36,642 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 11:20:36,647 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@55fc9508{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 11:20:36,651 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 11:20:36,661 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 11:20:36,675 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 11:20:36,675 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 11:20:36,681 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 11:20:36,685 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 11:20:36,688 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 11:20:36,688 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 11:20:36,689 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-cdad8ba9-916a-4890-8b55-4557aae6acd8
2018-02-08 11:23:04,315 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 11:23:04,905 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 11:23:04,932 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 11:23:04,933 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 11:23:04,934 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 11:23:04,935 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 11:23:04,936 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 11:23:05,313 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 56178.
2018-02-08 11:23:05,333 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 11:23:05,381 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 11:23:05,384 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 11:23:05,384 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 11:23:05,393 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-63ca8767-1d9b-4e8f-8f21-cc0da7a2a152
2018-02-08 11:23:05,415 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 11:23:05,469 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 11:23:05,548 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2744ms
2018-02-08 11:23:05,619 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 11:23:05,633 INFO[org.spark_project.jetty.server.Server:403] - Started @2829ms
2018-02-08 11:23:05,653 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@2c104774{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 11:23:05,653 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 11:23:05,675 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3276732{/jobs,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,676 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@34a75079{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,677 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@107ed6fc{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,678 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2e029d61{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,679 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4052274f{/stages,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,679 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,680 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,682 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,683 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,683 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,684 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/storage,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,684 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,685 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,686 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,687 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/environment,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,688 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,688 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/executors,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,689 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,690 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,692 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,699 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/static,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,700 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1536602f{/,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,701 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a1edad4{/api,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,701 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c7a975a{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,702 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@757d6814{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 11:23:05,704 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 11:23:05,783 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 11:23:05,808 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56191.
2018-02-08 11:23:05,808 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:56191
2018-02-08 11:23:05,811 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 11:23:05,813 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 56191, None)
2018-02-08 11:23:05,816 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:56191 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 56191, None)
2018-02-08 11:23:05,819 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 56191, None)
2018-02-08 11:23:05,820 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 56191, None)
2018-02-08 11:23:06,037 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6650813a{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:06,120 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 11:23:06,120 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 11:23:06,126 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@150d80c4{/SQL,null,AVAILABLE,@Spark}
2018-02-08 11:23:06,127 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3003697{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:06,128 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410e94e{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 11:23:06,130 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1bdbf9be{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 11:23:06,132 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@71154f21{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 11:23:07,520 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 11:23:07,985 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 11:23:08,095 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 11:23:08,100 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:56191 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 11:23:08,107 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 11:23:08,315 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 11:23:08,335 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 11:23:08,375 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 11:23:08,375 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 11:23:08,377 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 11:23:08,383 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 11:23:08,394 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 11:23:08,473 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.0 KB, free 631.5 MB)
2018-02-08 11:23:08,478 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.2 KB, free 631.5 MB)
2018-02-08 11:23:08,479 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:56191 (size: 2.2 KB, free: 631.8 MB)
2018-02-08 11:23:08,479 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 11:23:08,496 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 11:23:08,497 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 11:23:08,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:23:08,559 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:23:08,572 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 11:23:08,572 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 11:23:08,665 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt:0+289
2018-02-08 11:23:08,665 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt:289+289
2018-02-08 11:23:08,712 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_4_0 stored as values in memory (estimated size 1560.0 B, free 631.5 MB)
2018-02-08 11:23:08,713 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_4_1 stored as values in memory (estimated size 1120.0 B, free 631.5 MB)
2018-02-08 11:23:08,714 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_4_0 in memory on 192.168.11.26:56191 (size: 1560.0 B, free: 631.8 MB)
2018-02-08 11:23:08,714 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_4_1 in memory on 192.168.11.26:56191 (size: 1120.0 B, free: 631.8 MB)
2018-02-08 11:23:08,741 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1607 bytes result sent to driver
2018-02-08 11:23:08,741 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1607 bytes result sent to driver
2018-02-08 11:23:08,750 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 216 ms on localhost (executor driver) (1/2)
2018-02-08 11:23:08,752 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 193 ms on localhost (executor driver) (2/2)
2018-02-08 11:23:08,753 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 11:23:08,758 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.241 s
2018-02-08 11:23:08,770 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.434397 s
2018-02-08 11:23:08,806 INFO[org.apache.spark.SparkContext:54] - Starting job: hasNext at MachineLeaning.java:36
2018-02-08 11:23:08,808 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (hasNext at MachineLeaning.java:36) with 1 output partitions
2018-02-08 11:23:08,808 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (hasNext at MachineLeaning.java:36)
2018-02-08 11:23:08,808 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 11:23:08,816 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 11:23:08,817 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[6] at map at MLUtils.scala:84), which has no missing parents
2018-02-08 11:23:08,820 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 4.2 KB, free 631.5 MB)
2018-02-08 11:23:08,826 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.4 MB)
2018-02-08 11:23:08,829 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:56191 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 11:23:08,831 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 11:23:08,836 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at map at MLUtils.scala:84) (first 15 tasks are for partitions Vector(0))
2018-02-08 11:23:08,836 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 11:23:08,844 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:23:08,845 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 11:23:08,850 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_4_0 locally
2018-02-08 11:23:08,876 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 2296 bytes result sent to driver
2018-02-08 11:23:08,896 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 54 ms on localhost (executor driver) (1/1)
2018-02-08 11:23:08,896 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 11:23:08,897 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (hasNext at MachineLeaning.java:36) finished in 0.055 s
2018-02-08 11:23:08,899 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: hasNext at MachineLeaning.java:36, took 0.091303 s
2018-02-08 11:23:08,919 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:56191 in memory (size: 2.2 KB, free: 631.8 MB)
2018-02-08 11:23:08,993 INFO[org.apache.spark.SparkContext:54] - Starting job: hasNext at MachineLeaning.java:36
2018-02-08 11:23:08,994 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (hasNext at MachineLeaning.java:36) with 1 output partitions
2018-02-08 11:23:08,994 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (hasNext at MachineLeaning.java:36)
2018-02-08 11:23:08,994 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 11:23:08,995 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 11:23:08,997 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[6] at map at MLUtils.scala:84), which has no missing parents
2018-02-08 11:23:09,003 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 4.2 KB, free 631.5 MB)
2018-02-08 11:23:09,006 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.4 MB)
2018-02-08 11:23:09,007 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:56191 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 11:23:09,008 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 11:23:09,009 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at map at MLUtils.scala:84) (first 15 tasks are for partitions Vector(1))
2018-02-08 11:23:09,009 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 11:23:09,012 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 4898 bytes)
2018-02-08 11:23:09,012 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 11:23:09,019 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_4_1 locally
2018-02-08 11:23:09,021 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 1855 bytes result sent to driver
2018-02-08 11:23:09,023 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 12 ms on localhost (executor driver) (1/1)
2018-02-08 11:23:09,024 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 11:23:09,024 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (hasNext at MachineLeaning.java:36) finished in 0.014 s
2018-02-08 11:23:09,025 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: hasNext at MachineLeaning.java:36, took 0.031376 s
2018-02-08 11:23:09,031 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 11:23:09,041 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@2c104774{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 11:23:09,043 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 11:23:09,057 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 11:23:09,074 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 11:23:09,074 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 11:23:09,076 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 11:23:09,081 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 11:23:09,085 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 11:23:09,086 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 11:23:09,087 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-40608a73-34c4-4701-a748-7475338d3bab
2018-02-08 12:28:20,120 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 12:28:20,828 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 12:28:20,863 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 12:28:20,864 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 12:28:20,865 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 12:28:20,865 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 12:28:20,866 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 12:28:21,284 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 58972.
2018-02-08 12:28:21,309 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 12:28:21,364 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 12:28:21,368 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 12:28:21,369 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 12:28:21,381 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-7c59c63f-5145-498e-8f12-7b2fb52a56e1
2018-02-08 12:28:21,411 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 12:28:21,468 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 12:28:21,585 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @3015ms
2018-02-08 12:28:21,667 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 12:28:21,681 INFO[org.spark_project.jetty.server.Server:403] - Started @3112ms
2018-02-08 12:28:21,705 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@2c7d121c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 12:28:21,705 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 12:28:21,734 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@18f20260{/jobs,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,735 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,735 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,736 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,737 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/stages,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,737 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,738 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,739 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,740 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,740 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,741 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/storage,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,741 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,742 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4648ce9{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,743 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@61526469{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,743 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76ba13c{/environment,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,744 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7c351808{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,744 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@42b64ab8{/executors,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,745 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a39fe6a{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,745 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@319988b0{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,746 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68759011{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,755 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@305f031{/static,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,756 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4c168660{/,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,757 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@fd0e5b6{/api,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,757 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5241cf67{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,758 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@77192705{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 12:28:21,760 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 12:28:21,861 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 12:28:21,895 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58985.
2018-02-08 12:28:21,896 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:58985
2018-02-08 12:28:21,898 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 12:28:21,901 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 58985, None)
2018-02-08 12:28:21,905 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:58985 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 58985, None)
2018-02-08 12:28:21,911 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 58985, None)
2018-02-08 12:28:21,912 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 58985, None)
2018-02-08 12:28:22,134 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@76b0ae1b{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:22,231 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 12:28:22,232 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 12:28:22,242 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1bdbf9be{/SQL,null,AVAILABLE,@Spark}
2018-02-08 12:28:22,242 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1da6ee17{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:22,243 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@15f193b8{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 12:28:22,244 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@304a9d7b{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 12:28:22,246 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@347bdeef{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 12:28:23,463 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 12:28:26,005 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 202.203905 ms
2018-02-08 12:28:26,195 INFO[org.apache.spark.SparkContext:54] - Starting job: first at RowMatrix.scala:61
2018-02-08 12:28:26,225 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (first at RowMatrix.scala:61) with 1 output partitions
2018-02-08 12:28:26,226 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (first at RowMatrix.scala:61)
2018-02-08 12:28:26,226 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 12:28:26,228 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 12:28:26,236 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[4] at map at Correlation.scala:70), which has no missing parents
2018-02-08 12:28:26,492 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 8.1 KB, free 631.8 MB)
2018-02-08 12:28:26,532 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 631.8 MB)
2018-02-08 12:28:26,536 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:58985 (size: 4.2 KB, free: 631.8 MB)
2018-02-08 12:28:26,538 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 12:28:26,554 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at Correlation.scala:70) (first 15 tasks are for partitions Vector(0))
2018-02-08 12:28:26,555 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
2018-02-08 12:28:26,600 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5220 bytes)
2018-02-08 12:28:26,609 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 12:28:26,697 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.917124 ms
2018-02-08 12:28:26,731 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1202 bytes result sent to driver
2018-02-08 12:28:26,740 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 152 ms on localhost (executor driver) (1/1)
2018-02-08 12:28:26,743 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 12:28:26,746 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (first at RowMatrix.scala:61) finished in 0.173 s
2018-02-08 12:28:26,755 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: first at RowMatrix.scala:61, took 0.559888 s
2018-02-08 12:28:26,784 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at RowMatrix.scala:419
2018-02-08 12:28:26,785 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (treeAggregate at RowMatrix.scala:419) with 2 output partitions
2018-02-08 12:28:26,785 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (treeAggregate at RowMatrix.scala:419)
2018-02-08 12:28:26,785 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 12:28:26,787 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 12:28:26,788 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:419), which has no missing parents
2018-02-08 12:28:26,793 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 9.0 KB, free 631.8 MB)
2018-02-08 12:28:26,795 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 631.8 MB)
2018-02-08 12:28:26,798 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:58985 (size: 4.6 KB, free: 631.8 MB)
2018-02-08 12:28:26,799 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 12:28:26,800 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:419) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 12:28:26,800 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 12:28:26,803 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5220 bytes)
2018-02-08 12:28:26,803 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 5220 bytes)
2018-02-08 12:28:26,804 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
2018-02-08 12:28:26,804 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 2)
2018-02-08 12:28:26,825 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 2). 1657 bytes result sent to driver
2018-02-08 12:28:26,825 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1657 bytes result sent to driver
2018-02-08 12:28:26,827 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 2) in 24 ms on localhost (executor driver) (1/2)
2018-02-08 12:28:26,828 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 27 ms on localhost (executor driver) (2/2)
2018-02-08 12:28:26,829 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 12:28:26,829 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (treeAggregate at RowMatrix.scala:419) finished in 0.028 s
2018-02-08 12:28:26,831 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: treeAggregate at RowMatrix.scala:419, took 0.047089 s
2018-02-08 12:28:27,424 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at RowMatrix.scala:122
2018-02-08 12:28:27,427 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (treeAggregate at RowMatrix.scala:122) with 2 output partitions
2018-02-08 12:28:27,427 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (treeAggregate at RowMatrix.scala:122)
2018-02-08 12:28:27,427 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 12:28:27,427 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 12:28:27,428 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:122), which has no missing parents
2018-02-08 12:28:27,431 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 631.8 MB)
2018-02-08 12:28:27,434 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 631.8 MB)
2018-02-08 12:28:27,436 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:58985 (size: 4.5 KB, free: 631.8 MB)
2018-02-08 12:28:27,437 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 12:28:27,437 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:122) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 12:28:27,438 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 2 tasks
2018-02-08 12:28:27,439 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5220 bytes)
2018-02-08 12:28:27,439 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 5220 bytes)
2018-02-08 12:28:27,440 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 12:28:27,440 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 4)
2018-02-08 12:28:27,457 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 12:28:27,458 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 12:28:27,463 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 1180 bytes result sent to driver
2018-02-08 12:28:27,463 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 4). 1137 bytes result sent to driver
2018-02-08 12:28:27,464 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 4) in 25 ms on localhost (executor driver) (1/2)
2018-02-08 12:28:27,464 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 26 ms on localhost (executor driver) (2/2)
2018-02-08 12:28:27,464 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 12:28:27,465 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (treeAggregate at RowMatrix.scala:122) finished in 0.027 s
2018-02-08 12:28:27,465 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: treeAggregate at RowMatrix.scala:122, took 0.040597 s
2018-02-08 12:28:27,851 WARN[org.apache.spark.mllib.stat.correlation.PearsonCorrelation:66] - Pearson correlation matrix contains NaN values.
2018-02-08 12:28:27,920 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 21.985607 ms
2018-02-08 12:28:27,932 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.468802 ms
2018-02-08 12:28:27,945 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 12:28:27,951 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@2c7d121c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 12:28:27,952 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 12:28:27,962 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 12:28:27,975 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 12:28:27,975 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 12:28:27,980 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 12:28:27,982 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 12:28:27,985 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 12:28:27,986 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 12:28:27,987 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-a3ab72e6-47ad-4a0f-bce6-98a12b220ecb
2018-02-08 15:08:05,639 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:08:06,398 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:08:06,436 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:08:06,436 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:08:06,437 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:08:06,438 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:08:06,438 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:08:06,831 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 61968.
2018-02-08 15:08:06,854 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:08:06,901 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:08:06,905 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:08:06,906 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:08:06,917 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-22d3ccff-30d2-4760-a56c-551d39a158b0
2018-02-08 15:08:06,947 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:08:07,004 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:08:07,105 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2861ms
2018-02-08 15:08:07,182 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:08:07,196 INFO[org.spark_project.jetty.server.Server:403] - Started @2953ms
2018-02-08 15:08:07,218 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@52845b96{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:08:07,219 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:08:07,249 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1c9f0a20{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,249 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,250 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,251 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a3591c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,251 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@346a361{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,252 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1643d68f{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,253 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2e029d61{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,254 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,255 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,255 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,256 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,256 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,257 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,257 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,258 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,259 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,260 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,260 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,261 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,261 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,270 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/static,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,271 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@592e843a{/,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,272 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@423e4cbb{/api,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,272 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a1edad4{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,273 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@44c79f32{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,275 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:08:07,380 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:08:07,410 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61981.
2018-02-08 15:08:07,412 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:61981
2018-02-08 15:08:07,414 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:08:07,421 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 61981, None)
2018-02-08 15:08:07,428 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:61981 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 61981, None)
2018-02-08 15:08:07,432 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 61981, None)
2018-02-08 15:08:07,433 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 61981, None)
2018-02-08 15:08:07,636 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4a67318f{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,744 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:08:07,746 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:08:07,757 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@408613cc{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,757 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@11ce2e22{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,758 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@771158fb{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,759 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62d0ac62{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:08:07,762 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:08:09,058 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:08:09,551 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 15:08:09,630 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 15:08:09,633 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:61981 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:08:09,638 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 15:08:09,755 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 15:08:09,772 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 15:08:09,801 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 15:08:09,802 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 15:08:09,802 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:08:09,805 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:08:09,812 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 15:08:09,872 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 15:08:09,878 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 15:08:09,880 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:61981 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:08:09,881 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:09,900 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 15:08:09,901 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 15:08:09,945 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:08:09,948 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:08:09,957 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 15:08:09,957 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:08:10,069 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:60+60
2018-02-08 15:08:10,069 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:0+60
2018-02-08 15:08:10,143 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 910 bytes result sent to driver
2018-02-08 15:08:10,143 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
2018-02-08 15:08:10,149 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 201 ms on localhost (executor driver) (1/2)
2018-02-08 15:08:10,150 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 219 ms on localhost (executor driver) (2/2)
2018-02-08 15:08:10,151 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:08:10,155 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.237 s
2018-02-08 15:08:10,160 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.388352 s
2018-02-08 15:08:11,120 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:61981 in memory (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:08:11,124 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:61981 in memory (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:08:11,854 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:08:11,858 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:08:11,862 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:08:11,871 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:08:12,226 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 208.621827 ms
2018-02-08 15:08:12,237 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:08:12,251 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:08:12,253 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:61981 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:08:12,255 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:08:12,265 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:08:12,383 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:08:12,383 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:08:12,384 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:08:12,384 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:08:12,391 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 322.9 KB, free 631.1 MB)
2018-02-08 15:08:12,404 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.1 MB)
2018-02-08 15:08:12,405 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:61981 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:08:12,406 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:08:12,406 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:08:12,424 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_932cd6708ee7-1619282322-1: training: numPartitions=1 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
2018-02-08 15:08:12,453 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_932cd6708ee7-1619282322-1: {"k":2,"seed":1}
2018-02-08 15:08:12,493 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at KMeans.scala:353
2018-02-08 15:08:12,494 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (takeSample at KMeans.scala:353) with 1 output partitions
2018-02-08 15:08:12,494 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (takeSample at KMeans.scala:353)
2018-02-08 15:08:12,494 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:08:12,497 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:08:12,498 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[17] at map at KMeans.scala:224), which has no missing parents
2018-02-08 15:08:12,562 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 11.9 KB, free 631.1 MB)
2018-02-08 15:08:12,565 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.2 KB, free 631.1 MB)
2018-02-08 15:08:12,566 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:61981 (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:08:12,567 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:12,568 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[17] at map at KMeans.scala:224) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:12,568 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 15:08:12,574 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5605 bytes)
2018-02-08 15:08:12,574 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 15:08:12,617 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.720644 ms
2018-02-08 15:08:12,624 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:08:12,666 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 29.32801 ms
2018-02-08 15:08:12,710 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 19.466567 ms
2018-02-08 15:08:12,767 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 36.603852 ms
2018-02-08 15:08:12,781 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_14_0 stored as values in memory (estimated size 576.0 B, free 631.1 MB)
2018-02-08 15:08:12,783 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_14_0 in memory on 192.168.11.26:61981 (size: 576.0 B, free: 631.7 MB)
2018-02-08 15:08:12,787 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:08:12,791 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_15_0 stored as values in memory (estimated size 64.0 B, free 631.1 MB)
2018-02-08 15:08:12,791 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_15_0 in memory on 192.168.11.26:61981 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:08:12,795 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 2160 bytes result sent to driver
2018-02-08 15:08:12,798 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 229 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:12,799 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (takeSample at KMeans.scala:353) finished in 0.231 s
2018-02-08 15:08:12,800 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: takeSample at KMeans.scala:353, took 0.307368 s
2018-02-08 15:08:12,802 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 15:08:12,827 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at KMeans.scala:353
2018-02-08 15:08:12,828 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (takeSample at KMeans.scala:353) with 1 output partitions
2018-02-08 15:08:12,829 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (takeSample at KMeans.scala:353)
2018-02-08 15:08:12,829 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:08:12,834 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:08:12,834 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (PartitionwiseSampledRDD[19] at takeSample at KMeans.scala:353), which has no missing parents
2018-02-08 15:08:12,838 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 12.6 KB, free 631.1 MB)
2018-02-08 15:08:12,841 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.6 KB, free 631.1 MB)
2018-02-08 15:08:12,843 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:61981 (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:08:12,844 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:12,845 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (PartitionwiseSampledRDD[19] at takeSample at KMeans.scala:353) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:12,845 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 15:08:12,851 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5714 bytes)
2018-02-08 15:08:12,852 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 15:08:12,858 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:08:12,859 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:08:12,864 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 2104 bytes result sent to driver
2018-02-08 15:08:12,866 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 17 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:12,866 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 15:08:12,867 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (takeSample at KMeans.scala:353) finished in 0.019 s
2018-02-08 15:08:12,867 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: takeSample at KMeans.scala:353, took 0.040309 s
2018-02-08 15:08:12,871 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 144.0 B, free 631.1 MB)
2018-02-08 15:08:12,876 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 339.0 B, free 631.1 MB)
2018-02-08 15:08:12,878 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:61981 (size: 339.0 B, free: 631.7 MB)
2018-02-08 15:08:12,878 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at KMeans.scala:367
2018-02-08 15:08:12,894 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeans.scala:373
2018-02-08 15:08:12,895 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (sum at KMeans.scala:373) with 1 output partitions
2018-02-08 15:08:12,895 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (sum at KMeans.scala:373)
2018-02-08 15:08:12,895 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:08:12,897 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:08:12,898 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[21] at map at KMeans.scala:370), which has no missing parents
2018-02-08 15:08:12,903 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 631.1 MB)
2018-02-08 15:08:12,906 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 631.1 MB)
2018-02-08 15:08:12,908 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:61981 (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:08:12,908 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:12,909 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[21] at map at KMeans.scala:370) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:12,909 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 15:08:12,911 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5637 bytes)
2018-02-08 15:08:12,911 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 15:08:12,918 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:08:12,919 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:08:12,919 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:08:12,919 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:08:12,928 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_0 stored as values in memory (estimated size 64.0 B, free 631.1 MB)
2018-02-08 15:08:12,930 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_0 in memory on 192.168.11.26:61981 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:08:12,931 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 2115 bytes result sent to driver
2018-02-08 15:08:12,932 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 22 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:12,932 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 15:08:12,935 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (sum at KMeans.scala:373) finished in 0.024 s
2018-02-08 15:08:12,936 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: sum at KMeans.scala:373, took 0.041560 s
2018-02-08 15:08:12,939 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 18 from persistence list
2018-02-08 15:08:12,942 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 18
2018-02-08 15:08:12,968 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at KMeans.scala:381
2018-02-08 15:08:12,969 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (collect at KMeans.scala:381) with 1 output partitions
2018-02-08 15:08:12,970 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (collect at KMeans.scala:381)
2018-02-08 15:08:12,970 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:08:12,971 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:08:12,971 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[23] at mapPartitionsWithIndex at KMeans.scala:378), which has no missing parents
2018-02-08 15:08:12,976 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 13.3 KB, free 631.0 MB)
2018-02-08 15:08:12,978 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.9 KB, free 631.0 MB)
2018-02-08 15:08:12,982 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:61981 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:08:12,982 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:12,983 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at mapPartitionsWithIndex at KMeans.scala:378) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:12,983 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
2018-02-08 15:08:12,984 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5669 bytes)
2018-02-08 15:08:12,986 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 15:08:12,994 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:08:12,995 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:08:12,995 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:08:12,999 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 1778 bytes result sent to driver
2018-02-08 15:08:13,001 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 17 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:13,001 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 15:08:13,002 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (collect at KMeans.scala:381) finished in 0.018 s
2018-02-08 15:08:13,003 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: collect at KMeans.scala:381, took 0.034035 s
2018-02-08 15:08:13,006 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:08:13,009 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 413.0 B, free 631.0 MB)
2018-02-08 15:08:13,011 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.11.26:61981 (size: 413.0 B, free: 631.7 MB)
2018-02-08 15:08:13,011 INFO[org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at KMeans.scala:367
2018-02-08 15:08:13,023 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeans.scala:373
2018-02-08 15:08:13,024 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (sum at KMeans.scala:373) with 1 output partitions
2018-02-08 15:08:13,024 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (sum at KMeans.scala:373)
2018-02-08 15:08:13,024 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:08:13,026 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:08:13,026 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[25] at map at KMeans.scala:370), which has no missing parents
2018-02-08 15:08:13,029 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 12.9 KB, free 631.0 MB)
2018-02-08 15:08:13,032 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.7 KB, free 631.0 MB)
2018-02-08 15:08:13,033 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.11.26:61981 (size: 6.7 KB, free: 631.7 MB)
2018-02-08 15:08:13,034 INFO[org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:13,035 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at map at KMeans.scala:370) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:13,035 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
2018-02-08 15:08:13,037 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5669 bytes)
2018-02-08 15:08:13,037 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 6)
2018-02-08 15:08:13,040 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:08:13,040 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:08:13,040 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:08:13,042 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_25_0 stored as values in memory (estimated size 64.0 B, free 631.0 MB)
2018-02-08 15:08:13,043 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_25_0 in memory on 192.168.11.26:61981 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:08:13,046 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 6). 2029 bytes result sent to driver
2018-02-08 15:08:13,048 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 6) in 10 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:13,048 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 15:08:13,048 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (sum at KMeans.scala:373) finished in 0.012 s
2018-02-08 15:08:13,049 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: sum at KMeans.scala:373, took 0.025505 s
2018-02-08 15:08:13,050 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 21 from persistence list
2018-02-08 15:08:13,051 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 21
2018-02-08 15:08:13,072 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at KMeans.scala:381
2018-02-08 15:08:13,074 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (collect at KMeans.scala:381) with 1 output partitions
2018-02-08 15:08:13,075 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (collect at KMeans.scala:381)
2018-02-08 15:08:13,075 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:08:13,079 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:08:13,081 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[27] at mapPartitionsWithIndex at KMeans.scala:378), which has no missing parents
2018-02-08 15:08:13,085 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 13.5 KB, free 631.0 MB)
2018-02-08 15:08:13,089 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.9 KB, free 631.0 MB)
2018-02-08 15:08:13,092 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.11.26:61981 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:08:13,094 INFO[org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:13,096 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at mapPartitionsWithIndex at KMeans.scala:378) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:13,096 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
2018-02-08 15:08:13,097 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5701 bytes)
2018-02-08 15:08:13,098 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 7)
2018-02-08 15:08:13,101 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:08:13,101 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:08:13,101 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_25_0 locally
2018-02-08 15:08:13,102 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 7). 1654 bytes result sent to driver
2018-02-08 15:08:13,104 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 7) in 8 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:13,105 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 15:08:13,107 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (collect at KMeans.scala:381) finished in 0.010 s
2018-02-08 15:08:13,110 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: collect at KMeans.scala:381, took 0.037338 s
2018-02-08 15:08:13,111 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 25 from persistence list
2018-02-08 15:08:13,111 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 25
2018-02-08 15:08:13,114 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(6) (from destroy at KMeans.scala:388)
2018-02-08 15:08:13,115 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(9) (from destroy at KMeans.scala:388)
2018-02-08 15:08:13,119 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:61981 in memory (size: 339.0 B, free: 631.7 MB)
2018-02-08 15:08:13,120 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.11.26:61981 in memory (size: 413.0 B, free: 631.7 MB)
2018-02-08 15:08:13,126 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 488.0 B, free 631.0 MB)
2018-02-08 15:08:13,133 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 498.0 B, free 631.0 MB)
2018-02-08 15:08:13,135 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.11.26:61981 (size: 498.0 B, free: 631.7 MB)
2018-02-08 15:08:13,135 INFO[org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at KMeans.scala:398
2018-02-08 15:08:13,182 INFO[org.apache.spark.SparkContext:54] - Starting job: countByValue at KMeans.scala:399
2018-02-08 15:08:13,368 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 30 (countByValue at KMeans.scala:399)
2018-02-08 15:08:13,369 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (countByValue at KMeans.scala:399) with 1 output partitions
2018-02-08 15:08:13,369 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 8 (countByValue at KMeans.scala:399)
2018-02-08 15:08:13,369 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 7)
2018-02-08 15:08:13,369 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 7)
2018-02-08 15:08:13,371 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 7 (MapPartitionsRDD[30] at countByValue at KMeans.scala:399), which has no missing parents
2018-02-08 15:08:13,383 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 13.8 KB, free 631.0 MB)
2018-02-08 15:08:13,388 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 7.1 KB, free 631.0 MB)
2018-02-08 15:08:13,389 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.11.26:61981 (size: 7.1 KB, free: 631.7 MB)
2018-02-08 15:08:13,390 INFO[org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:13,393 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[30] at countByValue at KMeans.scala:399) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:13,393 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
2018-02-08 15:08:13,396 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:08:13,396 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 8)
2018-02-08 15:08:13,402 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:08:13,403 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:08:13,449 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.11.26:61981 in memory (size: 6.7 KB, free: 631.7 MB)
2018-02-08 15:08:13,458 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_4_piece0 on 192.168.11.26:61981 in memory (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:08:13,459 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.11.26:61981 in memory (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:08:13,461 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_5_piece0 on 192.168.11.26:61981 in memory (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:08:13,462 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.11.26:61981 in memory (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:08:13,464 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:61981 in memory (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:08:13,493 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 8). 1754 bytes result sent to driver
2018-02-08 15:08:13,496 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 8) in 102 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:13,496 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-02-08 15:08:13,498 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 7 (countByValue at KMeans.scala:399) finished in 0.104 s
2018-02-08 15:08:13,500 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:08:13,500 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:08:13,501 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 8)
2018-02-08 15:08:13,501 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:08:13,506 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 8 (ShuffledRDD[31] at countByValue at KMeans.scala:399), which has no missing parents
2018-02-08 15:08:13,509 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 3.2 KB, free 631.1 MB)
2018-02-08 15:08:13,512 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 1971.0 B, free 631.1 MB)
2018-02-08 15:08:13,513 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.11.26:61981 (size: 1971.0 B, free: 631.7 MB)
2018-02-08 15:08:13,513 INFO[org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:13,514 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 8 (ShuffledRDD[31] at countByValue at KMeans.scala:399) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:13,514 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 1 tasks
2018-02-08 15:08:13,520 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:08:13,521 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 9)
2018-02-08 15:08:13,538 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:08:13,539 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 15:08:13,569 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 9). 1337 bytes result sent to driver
2018-02-08 15:08:13,571 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 9) in 55 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:13,571 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 15:08:13,572 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 8 (countByValue at KMeans.scala:399) finished in 0.055 s
2018-02-08 15:08:13,572 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: countByValue at KMeans.scala:399, took 0.388907 s
2018-02-08 15:08:13,574 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(12) (from destroy at KMeans.scala:401)
2018-02-08 15:08:13,582 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_12_piece0 on 192.168.11.26:61981 in memory (size: 498.0 B, free: 631.7 MB)
2018-02-08 15:08:13,590 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 15:08:13,591 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 15:08:13,603 INFO[org.apache.spark.mllib.clustering.LocalKMeans:54] - Local KMeans++ converged in 2 iterations.
2018-02-08 15:08:13,604 INFO[org.apache.spark.mllib.clustering.KMeans:54] - Initialization with k-means|| took 1.126 seconds.
2018-02-08 15:08:13,608 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_932cd6708ee7-1619282322-1: {"numFeatures":3}
2018-02-08 15:08:13,611 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 208.0 B, free 631.1 MB)
2018-02-08 15:08:13,613 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 310.0 B, free 631.1 MB)
2018-02-08 15:08:13,614 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.11.26:61981 (size: 310.0 B, free: 631.7 MB)
2018-02-08 15:08:13,614 INFO[org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at KMeans.scala:273
2018-02-08 15:08:13,650 INFO[org.apache.spark.SparkContext:54] - Starting job: collectAsMap at KMeans.scala:295
2018-02-08 15:08:13,651 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 32 (mapPartitions at KMeans.scala:276)
2018-02-08 15:08:13,651 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (collectAsMap at KMeans.scala:295) with 1 output partitions
2018-02-08 15:08:13,651 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 10 (collectAsMap at KMeans.scala:295)
2018-02-08 15:08:13,651 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 9)
2018-02-08 15:08:13,652 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 9)
2018-02-08 15:08:13,656 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[32] at mapPartitions at KMeans.scala:276), which has no missing parents
2018-02-08 15:08:13,660 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16 stored as values in memory (estimated size 13.2 KB, free 631.1 MB)
2018-02-08 15:08:13,663 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 6.9 KB, free 631.1 MB)
2018-02-08 15:08:13,664 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_16_piece0 in memory on 192.168.11.26:61981 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:08:13,664 INFO[org.apache.spark.SparkContext:54] - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:13,665 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[32] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:13,666 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 1 tasks
2018-02-08 15:08:13,667 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:08:13,668 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 10)
2018-02-08 15:08:13,674 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:08:13,674 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:08:13,683 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 10). 1781 bytes result sent to driver
2018-02-08 15:08:13,683 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 10) in 16 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:13,684 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-02-08 15:08:13,684 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 9 (mapPartitions at KMeans.scala:276) finished in 0.017 s
2018-02-08 15:08:13,685 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:08:13,685 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:08:13,685 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 10)
2018-02-08 15:08:13,685 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:08:13,687 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 10 (ShuffledRDD[33] at reduceByKey at KMeans.scala:292), which has no missing parents
2018-02-08 15:08:13,688 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17 stored as values in memory (estimated size 2.8 KB, free 631.1 MB)
2018-02-08 15:08:13,690 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 1654.0 B, free 631.1 MB)
2018-02-08 15:08:13,691 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_17_piece0 in memory on 192.168.11.26:61981 (size: 1654.0 B, free: 631.7 MB)
2018-02-08 15:08:13,691 INFO[org.apache.spark.SparkContext:54] - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:13,692 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 10 (ShuffledRDD[33] at reduceByKey at KMeans.scala:292) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:13,692 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 1 tasks
2018-02-08 15:08:13,693 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 11, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:08:13,694 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 11)
2018-02-08 15:08:13,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:08:13,696 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:08:13,699 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 11). 1393 bytes result sent to driver
2018-02-08 15:08:13,700 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 11) in 6 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:13,700 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 15:08:13,700 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 10 (collectAsMap at KMeans.scala:295) finished in 0.008 s
2018-02-08 15:08:13,703 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: collectAsMap at KMeans.scala:295, took 0.051881 s
2018-02-08 15:08:13,706 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(15) (from destroy at KMeans.scala:297)
2018-02-08 15:08:13,708 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_15_piece0 on 192.168.11.26:61981 in memory (size: 310.0 B, free: 631.7 MB)
2018-02-08 15:08:13,710 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18 stored as values in memory (estimated size 208.0 B, free 631.1 MB)
2018-02-08 15:08:13,714 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 311.0 B, free 631.1 MB)
2018-02-08 15:08:13,715 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_18_piece0 in memory on 192.168.11.26:61981 (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:08:13,716 INFO[org.apache.spark.SparkContext:54] - Created broadcast 18 from broadcast at KMeans.scala:273
2018-02-08 15:08:13,732 INFO[org.apache.spark.SparkContext:54] - Starting job: collectAsMap at KMeans.scala:295
2018-02-08 15:08:13,735 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 34 (mapPartitions at KMeans.scala:276)
2018-02-08 15:08:13,736 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (collectAsMap at KMeans.scala:295) with 1 output partitions
2018-02-08 15:08:13,736 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 12 (collectAsMap at KMeans.scala:295)
2018-02-08 15:08:13,736 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 11)
2018-02-08 15:08:13,736 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 11)
2018-02-08 15:08:13,737 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 11 (MapPartitionsRDD[34] at mapPartitions at KMeans.scala:276), which has no missing parents
2018-02-08 15:08:13,739 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19 stored as values in memory (estimated size 13.2 KB, free 631.1 MB)
2018-02-08 15:08:13,742 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.9 KB, free 631.0 MB)
2018-02-08 15:08:13,744 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_19_piece0 in memory on 192.168.11.26:61981 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:08:13,744 INFO[org.apache.spark.SparkContext:54] - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:13,745 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[34] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:13,745 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 1 tasks
2018-02-08 15:08:13,746 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:08:13,747 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 12)
2018-02-08 15:08:13,750 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:08:13,751 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:08:13,762 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 12). 1781 bytes result sent to driver
2018-02-08 15:08:13,763 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 12) in 17 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:13,763 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 15:08:13,764 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 11 (mapPartitions at KMeans.scala:276) finished in 0.017 s
2018-02-08 15:08:13,764 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:08:13,764 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:08:13,764 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 12)
2018-02-08 15:08:13,764 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:08:13,764 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 12 (ShuffledRDD[35] at reduceByKey at KMeans.scala:292), which has no missing parents
2018-02-08 15:08:13,766 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20 stored as values in memory (estimated size 2.8 KB, free 631.0 MB)
2018-02-08 15:08:13,769 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 1659.0 B, free 631.0 MB)
2018-02-08 15:08:13,771 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_20_piece0 in memory on 192.168.11.26:61981 (size: 1659.0 B, free: 631.7 MB)
2018-02-08 15:08:13,772 INFO[org.apache.spark.SparkContext:54] - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:13,773 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 12 (ShuffledRDD[35] at reduceByKey at KMeans.scala:292) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:13,774 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 12.0 with 1 tasks
2018-02-08 15:08:13,774 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:08:13,775 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 12.0 (TID 13)
2018-02-08 15:08:13,777 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:08:13,778 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:08:13,780 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 12.0 (TID 13). 1393 bytes result sent to driver
2018-02-08 15:08:13,784 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 12.0 (TID 13) in 10 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:13,784 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2018-02-08 15:08:13,787 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 12 (collectAsMap at KMeans.scala:295) finished in 0.013 s
2018-02-08 15:08:13,790 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: collectAsMap at KMeans.scala:295, took 0.057254 s
2018-02-08 15:08:13,791 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(18) (from destroy at KMeans.scala:297)
2018-02-08 15:08:13,793 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_18_piece0 on 192.168.11.26:61981 in memory (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:08:13,793 INFO[org.apache.spark.mllib.clustering.KMeans:54] - Iterations took 0.188 seconds.
2018-02-08 15:08:13,795 INFO[org.apache.spark.mllib.clustering.KMeans:54] - KMeans converged in 2 iterations.
2018-02-08 15:08:13,795 INFO[org.apache.spark.mllib.clustering.KMeans:54] - The cost is 0.11999999999994547.
2018-02-08 15:08:13,801 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 15 from persistence list
2018-02-08 15:08:13,803 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 15
2018-02-08 15:08:14,106 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_932cd6708ee7-1619282322-1: training finished
2018-02-08 15:08:14,107 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 14 from persistence list
2018-02-08 15:08:14,107 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 14
2018-02-08 15:08:14,115 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:08:14,115 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:08:14,115 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:08:14,116 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:08:14,122 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21 stored as values in memory (estimated size 322.9 KB, free 630.7 MB)
2018-02-08 15:08:14,136 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 27.6 KB, free 630.7 MB)
2018-02-08 15:08:14,139 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_21_piece0 in memory on 192.168.11.26:61981 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:08:14,140 INFO[org.apache.spark.SparkContext:54] - Created broadcast 21 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:08:14,141 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:08:14,153 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22 stored as values in memory (estimated size 208.0 B, free 630.7 MB)
2018-02-08 15:08:14,154 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 311.0 B, free 630.7 MB)
2018-02-08 15:08:14,155 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_22_piece0 in memory on 192.168.11.26:61981 (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:08:14,155 INFO[org.apache.spark.SparkContext:54] - Created broadcast 22 from broadcast at KMeansModel.scala:87
2018-02-08 15:08:14,163 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeansModel.scala:88
2018-02-08 15:08:14,163 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 10 (sum at KMeansModel.scala:88) with 1 output partitions
2018-02-08 15:08:14,164 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 13 (sum at KMeansModel.scala:88)
2018-02-08 15:08:14,164 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:08:14,164 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:08:14,164 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 13 (MapPartitionsRDD[41] at map at KMeansModel.scala:88), which has no missing parents
2018-02-08 15:08:14,166 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23 stored as values in memory (estimated size 11.8 KB, free 630.7 MB)
2018-02-08 15:08:14,168 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.2 KB, free 630.7 MB)
2018-02-08 15:08:14,169 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_23_piece0 in memory on 192.168.11.26:61981 (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:08:14,170 INFO[org.apache.spark.SparkContext:54] - Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:08:14,170 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[41] at map at KMeansModel.scala:88) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:08:14,170 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 13.0 with 1 tasks
2018-02-08 15:08:14,171 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:08:14,171 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 13.0 (TID 14)
2018-02-08 15:08:14,176 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:08:14,185 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 13.0 (TID 14). 1348 bytes result sent to driver
2018-02-08 15:08:14,185 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 13.0 (TID 14) in 14 ms on localhost (executor driver) (1/1)
2018-02-08 15:08:14,185 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2018-02-08 15:08:14,186 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 13 (sum at KMeansModel.scala:88) finished in 0.015 s
2018-02-08 15:08:14,187 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 10 finished: sum at KMeansModel.scala:88, took 0.023581 s
2018-02-08 15:08:14,193 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:08:14,198 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@52845b96{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:08:14,200 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:08:14,208 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:08:14,259 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:08:14,259 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:08:14,261 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:08:14,263 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:08:14,266 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:08:14,266 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:08:14,267 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-4dc3cb9b-780d-4420-8a80-2d35caa4f016
2018-02-08 15:12:01,402 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:12:02,010 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:12:02,029 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:12:02,030 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:12:02,030 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:12:02,031 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:12:02,031 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:12:02,363 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62039.
2018-02-08 15:12:02,380 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:12:02,424 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:12:02,427 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:12:02,427 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:12:02,435 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-a45e3879-6361-4a97-a94d-7ea500e248e3
2018-02-08 15:12:02,455 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:12:02,503 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:12:02,570 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2661ms
2018-02-08 15:12:02,635 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:12:02,647 INFO[org.spark_project.jetty.server.Server:403] - Started @2739ms
2018-02-08 15:12:02,666 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@34a1d21f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:12:02,666 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:12:02,688 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1c9f0a20{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,689 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,689 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,690 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a3591c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,691 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@346a361{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,692 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1643d68f{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,693 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2e029d61{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,694 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,694 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,695 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,696 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,697 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,698 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,698 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,699 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,700 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,701 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,701 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,702 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,703 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,709 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/static,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,710 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@592e843a{/,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,711 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@423e4cbb{/api,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,712 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a1edad4{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,712 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@44c79f32{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:12:02,714 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:12:02,791 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:12:02,822 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62052.
2018-02-08 15:12:02,824 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62052
2018-02-08 15:12:02,826 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:12:02,828 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62052, None)
2018-02-08 15:12:02,837 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62052 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62052, None)
2018-02-08 15:12:02,847 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62052, None)
2018-02-08 15:12:02,851 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62052, None)
2018-02-08 15:12:03,062 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4a67318f{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:03,141 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:12:03,142 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:12:03,148 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@408613cc{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:12:03,149 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@11ce2e22{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:03,149 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@771158fb{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:12:03,150 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62d0ac62{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:12:03,152 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:12:04,205 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:12:04,617 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 15:12:04,676 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 15:12:04,678 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:62052 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:12:04,681 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 15:12:04,778 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 15:12:04,789 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 15:12:04,806 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 15:12:04,807 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 15:12:04,807 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:12:04,808 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:12:04,813 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 15:12:04,873 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 15:12:04,877 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 15:12:04,878 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:62052 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:12:04,879 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:04,894 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 15:12:04,894 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 15:12:04,936 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:12:04,938 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:12:04,947 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:12:04,947 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 15:12:05,015 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:0+60
2018-02-08 15:12:05,015 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:60+60
2018-02-08 15:12:05,056 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
2018-02-08 15:12:05,056 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 953 bytes result sent to driver
2018-02-08 15:12:05,063 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 125 ms on localhost (executor driver) (1/2)
2018-02-08 15:12:05,065 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 143 ms on localhost (executor driver) (2/2)
2018-02-08 15:12:05,066 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:12:05,086 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.176 s
2018-02-08 15:12:05,090 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.299216 s
2018-02-08 15:12:05,885 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:62052 in memory (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:12:05,887 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:62052 in memory (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:12:06,507 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:12:06,511 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:12:06,513 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:12:06,520 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:12:06,815 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 192.825022 ms
2018-02-08 15:12:06,825 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:12:06,840 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:12:06,842 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:62052 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:12:06,843 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:12:06,856 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:12:06,947 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:12:06,947 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:12:06,948 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:12:06,948 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:12:06,958 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 322.9 KB, free 631.1 MB)
2018-02-08 15:12:06,972 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.1 MB)
2018-02-08 15:12:06,973 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:62052 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:12:06,974 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:12:06,975 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:12:06,993 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_1a2f6e44eeae-1619282322-1: training: numPartitions=1 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
2018-02-08 15:12:07,013 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_1a2f6e44eeae-1619282322-1: {"k":3,"seed":1}
2018-02-08 15:12:07,043 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at KMeans.scala:353
2018-02-08 15:12:07,044 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (takeSample at KMeans.scala:353) with 1 output partitions
2018-02-08 15:12:07,045 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (takeSample at KMeans.scala:353)
2018-02-08 15:12:07,045 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:12:07,048 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:12:07,049 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[17] at map at KMeans.scala:224), which has no missing parents
2018-02-08 15:12:07,108 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 11.9 KB, free 631.1 MB)
2018-02-08 15:12:07,114 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.2 KB, free 631.1 MB)
2018-02-08 15:12:07,116 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:62052 (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:12:07,116 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:07,117 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[17] at map at KMeans.scala:224) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:12:07,117 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 15:12:07,122 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5605 bytes)
2018-02-08 15:12:07,124 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 15:12:07,165 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.758404 ms
2018-02-08 15:12:07,171 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:12:07,205 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.161926 ms
2018-02-08 15:12:07,241 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 21.453127 ms
2018-02-08 15:12:07,305 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 43.697294 ms
2018-02-08 15:12:07,321 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_14_0 stored as values in memory (estimated size 576.0 B, free 631.1 MB)
2018-02-08 15:12:07,328 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_14_0 in memory on 192.168.11.26:62052 (size: 576.0 B, free: 631.7 MB)
2018-02-08 15:12:07,332 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:12:07,339 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_15_0 stored as values in memory (estimated size 64.0 B, free 631.1 MB)
2018-02-08 15:12:07,340 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_15_0 in memory on 192.168.11.26:62052 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:12:07,343 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 2160 bytes result sent to driver
2018-02-08 15:12:07,345 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 227 ms on localhost (executor driver) (1/1)
2018-02-08 15:12:07,345 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 15:12:07,346 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (takeSample at KMeans.scala:353) finished in 0.228 s
2018-02-08 15:12:07,347 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: takeSample at KMeans.scala:353, took 0.303499 s
2018-02-08 15:12:07,368 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at KMeans.scala:353
2018-02-08 15:12:07,370 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (takeSample at KMeans.scala:353) with 1 output partitions
2018-02-08 15:12:07,370 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (takeSample at KMeans.scala:353)
2018-02-08 15:12:07,371 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:12:07,373 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:12:07,373 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (PartitionwiseSampledRDD[19] at takeSample at KMeans.scala:353), which has no missing parents
2018-02-08 15:12:07,377 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 12.6 KB, free 631.1 MB)
2018-02-08 15:12:07,381 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.6 KB, free 631.1 MB)
2018-02-08 15:12:07,385 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:62052 (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:12:07,386 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:07,386 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (PartitionwiseSampledRDD[19] at takeSample at KMeans.scala:353) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:12:07,387 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 15:12:07,392 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5714 bytes)
2018-02-08 15:12:07,392 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 15:12:07,399 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:12:07,399 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:12:07,402 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 2061 bytes result sent to driver
2018-02-08 15:12:07,403 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 13 ms on localhost (executor driver) (1/1)
2018-02-08 15:12:07,403 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 15:12:07,404 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (takeSample at KMeans.scala:353) finished in 0.014 s
2018-02-08 15:12:07,404 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: takeSample at KMeans.scala:353, took 0.035127 s
2018-02-08 15:12:07,407 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 144.0 B, free 631.1 MB)
2018-02-08 15:12:07,410 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 339.0 B, free 631.1 MB)
2018-02-08 15:12:07,411 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:62052 (size: 339.0 B, free: 631.7 MB)
2018-02-08 15:12:07,412 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at KMeans.scala:367
2018-02-08 15:12:07,425 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeans.scala:373
2018-02-08 15:12:07,426 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (sum at KMeans.scala:373) with 1 output partitions
2018-02-08 15:12:07,426 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (sum at KMeans.scala:373)
2018-02-08 15:12:07,426 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:12:07,427 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:12:07,427 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[21] at map at KMeans.scala:370), which has no missing parents
2018-02-08 15:12:07,430 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 12.7 KB, free 631.1 MB)
2018-02-08 15:12:07,432 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 631.1 MB)
2018-02-08 15:12:07,433 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:62052 (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:12:07,433 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:07,434 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[21] at map at KMeans.scala:370) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:12:07,434 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 15:12:07,435 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5637 bytes)
2018-02-08 15:12:07,435 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 15:12:07,440 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:12:07,440 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:12:07,440 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:12:07,441 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:12:07,449 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_0 stored as values in memory (estimated size 64.0 B, free 631.1 MB)
2018-02-08 15:12:07,451 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_0 in memory on 192.168.11.26:62052 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:12:07,453 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 2072 bytes result sent to driver
2018-02-08 15:12:07,454 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 19 ms on localhost (executor driver) (1/1)
2018-02-08 15:12:07,456 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 15:12:07,456 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (sum at KMeans.scala:373) finished in 0.021 s
2018-02-08 15:12:07,457 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: sum at KMeans.scala:373, took 0.031328 s
2018-02-08 15:12:07,459 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 18 from persistence list
2018-02-08 15:12:07,464 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 18
2018-02-08 15:12:07,488 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at KMeans.scala:381
2018-02-08 15:12:07,489 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (collect at KMeans.scala:381) with 1 output partitions
2018-02-08 15:12:07,489 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (collect at KMeans.scala:381)
2018-02-08 15:12:07,489 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:12:07,490 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:12:07,491 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[23] at mapPartitionsWithIndex at KMeans.scala:378), which has no missing parents
2018-02-08 15:12:07,497 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 13.3 KB, free 631.0 MB)
2018-02-08 15:12:07,501 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.9 KB, free 631.0 MB)
2018-02-08 15:12:07,502 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:62052 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:12:07,503 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:07,505 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at mapPartitionsWithIndex at KMeans.scala:378) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:12:07,505 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
2018-02-08 15:12:07,506 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5669 bytes)
2018-02-08 15:12:07,507 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 15:12:07,513 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:12:07,513 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:12:07,513 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:12:07,516 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 1778 bytes result sent to driver
2018-02-08 15:12:07,518 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 12 ms on localhost (executor driver) (1/1)
2018-02-08 15:12:07,519 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 15:12:07,520 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (collect at KMeans.scala:381) finished in 0.013 s
2018-02-08 15:12:07,520 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: collect at KMeans.scala:381, took 0.031741 s
2018-02-08 15:12:07,523 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:12:07,528 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 413.0 B, free 631.0 MB)
2018-02-08 15:12:07,530 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.11.26:62052 (size: 413.0 B, free: 631.7 MB)
2018-02-08 15:12:07,531 INFO[org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at KMeans.scala:367
2018-02-08 15:12:07,548 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeans.scala:373
2018-02-08 15:12:07,549 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (sum at KMeans.scala:373) with 1 output partitions
2018-02-08 15:12:07,549 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (sum at KMeans.scala:373)
2018-02-08 15:12:07,549 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:12:07,550 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:12:07,551 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[25] at map at KMeans.scala:370), which has no missing parents
2018-02-08 15:12:07,556 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 12.9 KB, free 631.0 MB)
2018-02-08 15:12:07,561 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.7 KB, free 631.0 MB)
2018-02-08 15:12:07,562 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.11.26:62052 (size: 6.7 KB, free: 631.7 MB)
2018-02-08 15:12:07,563 INFO[org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:07,564 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at map at KMeans.scala:370) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:12:07,564 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
2018-02-08 15:12:07,565 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5669 bytes)
2018-02-08 15:12:07,565 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 6)
2018-02-08 15:12:07,568 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:12:07,568 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:12:07,569 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:12:07,570 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_25_0 stored as values in memory (estimated size 64.0 B, free 631.0 MB)
2018-02-08 15:12:07,571 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_25_0 in memory on 192.168.11.26:62052 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:12:07,573 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 6). 2029 bytes result sent to driver
2018-02-08 15:12:07,575 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 6) in 10 ms on localhost (executor driver) (1/1)
2018-02-08 15:12:07,575 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 15:12:07,576 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (sum at KMeans.scala:373) finished in 0.012 s
2018-02-08 15:12:07,577 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: sum at KMeans.scala:373, took 0.028080 s
2018-02-08 15:12:07,579 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 21 from persistence list
2018-02-08 15:12:07,581 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 21
2018-02-08 15:12:07,599 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at KMeans.scala:381
2018-02-08 15:12:07,600 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (collect at KMeans.scala:381) with 1 output partitions
2018-02-08 15:12:07,600 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (collect at KMeans.scala:381)
2018-02-08 15:12:07,601 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:12:07,602 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:12:07,602 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[27] at mapPartitionsWithIndex at KMeans.scala:378), which has no missing parents
2018-02-08 15:12:07,605 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 13.5 KB, free 631.0 MB)
2018-02-08 15:12:07,611 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.9 KB, free 631.0 MB)
2018-02-08 15:12:07,613 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.11.26:62052 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:12:07,614 INFO[org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:07,614 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at mapPartitionsWithIndex at KMeans.scala:378) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:12:07,615 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
2018-02-08 15:12:07,615 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5701 bytes)
2018-02-08 15:12:07,616 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 7)
2018-02-08 15:12:07,618 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:12:07,619 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:12:07,619 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_25_0 locally
2018-02-08 15:12:07,620 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 7). 1734 bytes result sent to driver
2018-02-08 15:12:07,621 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 7) in 6 ms on localhost (executor driver) (1/1)
2018-02-08 15:12:07,621 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 15:12:07,621 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (collect at KMeans.scala:381) finished in 0.006 s
2018-02-08 15:12:07,622 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: collect at KMeans.scala:381, took 0.022425 s
2018-02-08 15:12:07,623 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 25 from persistence list
2018-02-08 15:12:07,624 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 25
2018-02-08 15:12:07,626 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(6) (from destroy at KMeans.scala:388)
2018-02-08 15:12:07,627 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(9) (from destroy at KMeans.scala:388)
2018-02-08 15:12:07,629 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:62052 in memory (size: 339.0 B, free: 631.7 MB)
2018-02-08 15:12:07,631 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.11.26:62052 in memory (size: 413.0 B, free: 631.7 MB)
2018-02-08 15:12:07,633 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 568.0 B, free 631.0 MB)
2018-02-08 15:12:07,636 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 524.0 B, free 631.0 MB)
2018-02-08 15:12:07,638 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.11.26:62052 (size: 524.0 B, free: 631.7 MB)
2018-02-08 15:12:07,638 INFO[org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at KMeans.scala:398
2018-02-08 15:12:07,674 INFO[org.apache.spark.SparkContext:54] - Starting job: countByValue at KMeans.scala:399
2018-02-08 15:12:07,809 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 30 (countByValue at KMeans.scala:399)
2018-02-08 15:12:07,810 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (countByValue at KMeans.scala:399) with 1 output partitions
2018-02-08 15:12:07,810 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 8 (countByValue at KMeans.scala:399)
2018-02-08 15:12:07,810 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 7)
2018-02-08 15:12:07,810 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 7)
2018-02-08 15:12:07,811 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 7 (MapPartitionsRDD[30] at countByValue at KMeans.scala:399), which has no missing parents
2018-02-08 15:12:07,819 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 13.8 KB, free 631.0 MB)
2018-02-08 15:12:07,841 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 7.1 KB, free 631.0 MB)
2018-02-08 15:12:07,841 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.11.26:62052 (size: 7.1 KB, free: 631.7 MB)
2018-02-08 15:12:07,842 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.11.26:62052 in memory (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:12:07,842 INFO[org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:07,846 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[30] at countByValue at KMeans.scala:399) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:12:07,846 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
2018-02-08 15:12:07,848 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_5_piece0 on 192.168.11.26:62052 in memory (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:12:07,848 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:12:07,849 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 8)
2018-02-08 15:12:07,849 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_4_piece0 on 192.168.11.26:62052 in memory (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:12:07,850 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:62052 in memory (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:12:07,852 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.11.26:62052 in memory (size: 6.7 KB, free: 631.7 MB)
2018-02-08 15:12:07,853 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:12:07,853 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:12:07,856 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.11.26:62052 in memory (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:12:07,914 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 8). 1711 bytes result sent to driver
2018-02-08 15:12:07,916 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 8) in 69 ms on localhost (executor driver) (1/1)
2018-02-08 15:12:07,916 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-02-08 15:12:07,917 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 7 (countByValue at KMeans.scala:399) finished in 0.070 s
2018-02-08 15:12:07,918 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:12:07,918 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:12:07,918 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 8)
2018-02-08 15:12:07,919 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:12:07,921 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 8 (ShuffledRDD[31] at countByValue at KMeans.scala:399), which has no missing parents
2018-02-08 15:12:07,929 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 3.2 KB, free 631.1 MB)
2018-02-08 15:12:07,933 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 1971.0 B, free 631.1 MB)
2018-02-08 15:12:07,934 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.11.26:62052 (size: 1971.0 B, free: 631.7 MB)
2018-02-08 15:12:07,935 INFO[org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:07,937 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 8 (ShuffledRDD[31] at countByValue at KMeans.scala:399) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:12:07,937 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 1 tasks
2018-02-08 15:12:07,943 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:12:07,944 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 9)
2018-02-08 15:12:07,956 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:12:07,958 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 15:12:07,995 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 9). 1306 bytes result sent to driver
2018-02-08 15:12:07,997 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 9) in 57 ms on localhost (executor driver) (1/1)
2018-02-08 15:12:07,997 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 15:12:08,000 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 8 (countByValue at KMeans.scala:399) finished in 0.060 s
2018-02-08 15:12:08,002 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: countByValue at KMeans.scala:399, took 0.327004 s
2018-02-08 15:12:08,005 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(12) (from destroy at KMeans.scala:401)
2018-02-08 15:12:08,008 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_12_piece0 on 192.168.11.26:62052 in memory (size: 524.0 B, free: 631.7 MB)
2018-02-08 15:12:08,013 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 15:12:08,013 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 15:12:08,020 INFO[org.apache.spark.mllib.clustering.LocalKMeans:54] - Local KMeans++ converged in 2 iterations.
2018-02-08 15:12:08,020 INFO[org.apache.spark.mllib.clustering.KMeans:54] - Initialization with k-means|| took 0.988 seconds.
2018-02-08 15:12:08,022 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_1a2f6e44eeae-1619282322-1: {"numFeatures":3}
2018-02-08 15:12:08,023 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 296.0 B, free 631.1 MB)
2018-02-08 15:12:08,025 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 328.0 B, free 631.1 MB)
2018-02-08 15:12:08,025 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.11.26:62052 (size: 328.0 B, free: 631.7 MB)
2018-02-08 15:12:08,026 INFO[org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at KMeans.scala:273
2018-02-08 15:12:08,046 INFO[org.apache.spark.SparkContext:54] - Starting job: collectAsMap at KMeans.scala:295
2018-02-08 15:12:08,047 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 32 (mapPartitions at KMeans.scala:276)
2018-02-08 15:12:08,047 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (collectAsMap at KMeans.scala:295) with 1 output partitions
2018-02-08 15:12:08,047 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 10 (collectAsMap at KMeans.scala:295)
2018-02-08 15:12:08,047 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 9)
2018-02-08 15:12:08,047 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 9)
2018-02-08 15:12:08,048 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[32] at mapPartitions at KMeans.scala:276), which has no missing parents
2018-02-08 15:12:08,052 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16 stored as values in memory (estimated size 13.2 KB, free 631.1 MB)
2018-02-08 15:12:08,054 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 6.9 KB, free 631.1 MB)
2018-02-08 15:12:08,055 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_16_piece0 in memory on 192.168.11.26:62052 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:12:08,055 INFO[org.apache.spark.SparkContext:54] - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:08,056 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[32] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:12:08,057 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 1 tasks
2018-02-08 15:12:08,058 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:12:08,058 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 10)
2018-02-08 15:12:08,062 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_14_0 locally
2018-02-08 15:12:08,062 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_15_0 locally
2018-02-08 15:12:08,072 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 10). 1781 bytes result sent to driver
2018-02-08 15:12:08,073 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 10) in 16 ms on localhost (executor driver) (1/1)
2018-02-08 15:12:08,073 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-02-08 15:12:08,074 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 9 (mapPartitions at KMeans.scala:276) finished in 0.017 s
2018-02-08 15:12:08,074 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:12:08,074 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:12:08,075 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 10)
2018-02-08 15:12:08,075 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:12:08,075 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 10 (ShuffledRDD[33] at reduceByKey at KMeans.scala:292), which has no missing parents
2018-02-08 15:12:08,077 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17 stored as values in memory (estimated size 2.8 KB, free 631.1 MB)
2018-02-08 15:12:08,081 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 1654.0 B, free 631.1 MB)
2018-02-08 15:12:08,082 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_17_piece0 in memory on 192.168.11.26:62052 (size: 1654.0 B, free: 631.7 MB)
2018-02-08 15:12:08,083 INFO[org.apache.spark.SparkContext:54] - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:08,084 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 10 (ShuffledRDD[33] at reduceByKey at KMeans.scala:292) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:12:08,084 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 1 tasks
2018-02-08 15:12:08,085 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 11, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:12:08,085 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 11)
2018-02-08 15:12:08,089 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:12:08,089 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:12:08,093 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 11). 1478 bytes result sent to driver
2018-02-08 15:12:08,094 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 11) in 10 ms on localhost (executor driver) (1/1)
2018-02-08 15:12:08,094 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 15:12:08,094 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 10 (collectAsMap at KMeans.scala:295) finished in 0.010 s
2018-02-08 15:12:08,095 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: collectAsMap at KMeans.scala:295, took 0.048621 s
2018-02-08 15:12:08,097 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(15) (from destroy at KMeans.scala:297)
2018-02-08 15:12:08,099 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_15_piece0 on 192.168.11.26:62052 in memory (size: 328.0 B, free: 631.7 MB)
2018-02-08 15:12:08,100 INFO[org.apache.spark.mllib.clustering.KMeans:54] - Iterations took 0.078 seconds.
2018-02-08 15:12:08,100 INFO[org.apache.spark.mllib.clustering.KMeans:54] - KMeans converged in 1 iterations.
2018-02-08 15:12:08,101 INFO[org.apache.spark.mllib.clustering.KMeans:54] - The cost is 0.07499999999994544.
2018-02-08 15:12:08,104 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 15 from persistence list
2018-02-08 15:12:08,105 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 15
2018-02-08 15:12:08,414 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_1a2f6e44eeae-1619282322-1: training finished
2018-02-08 15:12:08,415 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 14 from persistence list
2018-02-08 15:12:08,415 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 14
2018-02-08 15:12:08,426 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:12:08,427 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:12:08,427 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:12:08,427 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:12:08,433 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18 stored as values in memory (estimated size 322.9 KB, free 630.8 MB)
2018-02-08 15:12:08,449 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 27.6 KB, free 630.7 MB)
2018-02-08 15:12:08,449 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_18_piece0 in memory on 192.168.11.26:62052 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:12:08,450 INFO[org.apache.spark.SparkContext:54] - Created broadcast 18 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:12:08,451 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:12:08,463 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19 stored as values in memory (estimated size 296.0 B, free 630.7 MB)
2018-02-08 15:12:08,466 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 328.0 B, free 630.7 MB)
2018-02-08 15:12:08,468 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_19_piece0 in memory on 192.168.11.26:62052 (size: 328.0 B, free: 631.7 MB)
2018-02-08 15:12:08,468 INFO[org.apache.spark.SparkContext:54] - Created broadcast 19 from broadcast at KMeansModel.scala:87
2018-02-08 15:12:08,475 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeansModel.scala:88
2018-02-08 15:12:08,476 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (sum at KMeansModel.scala:88) with 1 output partitions
2018-02-08 15:12:08,476 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 11 (sum at KMeansModel.scala:88)
2018-02-08 15:12:08,476 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:12:08,476 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:12:08,477 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 11 (MapPartitionsRDD[39] at map at KMeansModel.scala:88), which has no missing parents
2018-02-08 15:12:08,479 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20 stored as values in memory (estimated size 11.8 KB, free 630.7 MB)
2018-02-08 15:12:08,482 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.2 KB, free 630.7 MB)
2018-02-08 15:12:08,483 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_20_piece0 in memory on 192.168.11.26:62052 (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:12:08,484 INFO[org.apache.spark.SparkContext:54] - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:12:08,485 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[39] at map at KMeansModel.scala:88) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:12:08,485 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 1 tasks
2018-02-08 15:12:08,487 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:12:08,487 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 12)
2018-02-08 15:12:08,491 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:12:08,499 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 12). 1391 bytes result sent to driver
2018-02-08 15:12:08,500 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 12) in 13 ms on localhost (executor driver) (1/1)
2018-02-08 15:12:08,500 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 15:12:08,501 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 11 (sum at KMeansModel.scala:88) finished in 0.014 s
2018-02-08 15:12:08,503 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: sum at KMeansModel.scala:88, took 0.025846 s
2018-02-08 15:12:08,509 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:12:08,513 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@34a1d21f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:12:08,515 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:12:08,523 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:12:08,565 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:12:08,566 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:12:08,567 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:12:08,569 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:12:08,571 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:12:08,572 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:12:08,572 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-5f3f57a7-3309-43b2-8551-decf25affca6
2018-02-08 15:20:36,740 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:20:37,387 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:20:37,409 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:20:37,410 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:20:37,412 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:20:37,414 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:20:37,415 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:20:37,766 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62155.
2018-02-08 15:20:37,782 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:20:37,829 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:20:37,832 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:20:37,833 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:20:37,841 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-cf12b9a3-f4fe-41a9-aa49-cd4be82b2f03
2018-02-08 15:20:37,864 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:20:37,948 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:20:38,022 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2673ms
2018-02-08 15:20:38,079 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:20:38,091 INFO[org.spark_project.jetty.server.Server:403] - Started @2743ms
2018-02-08 15:20:38,110 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@5d4ddf63{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:20:38,111 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:20:38,133 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2488b073{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,134 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,135 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,136 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@631e06ab{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,136 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@34a75079{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,137 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,138 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@186978a6{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,139 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,139 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,140 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,141 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,141 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,142 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,142 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,144 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,145 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,146 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,147 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,148 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,148 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,154 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/static,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,156 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@305f031{/,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,157 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d1f7216{/api,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,157 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4ebea12c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,158 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6256ac4f{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,160 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:20:38,236 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:20:38,260 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62168.
2018-02-08 15:20:38,261 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62168
2018-02-08 15:20:38,262 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:20:38,264 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62168, None)
2018-02-08 15:20:38,266 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62168 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62168, None)
2018-02-08 15:20:38,269 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62168, None)
2018-02-08 15:20:38,270 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62168, None)
2018-02-08 15:20:38,435 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5a6d5a8f{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,490 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:20:38,491 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:20:38,497 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63a5d002{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,498 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5aa6202e{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,500 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@150d80c4{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,501 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3003697{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:20:38,502 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d691f3d{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:20:39,421 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:20:39,760 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 15:20:39,814 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 15:20:39,817 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:62168 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:20:39,820 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 15:20:39,921 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 15:20:39,932 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 15:20:39,949 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 15:20:39,950 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 15:20:39,950 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:39,951 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:39,956 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 15:20:40,024 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 15:20:40,028 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 15:20:40,029 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:62168 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:20:40,031 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:40,044 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 15:20:40,045 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 15:20:40,083 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4898 bytes)
2018-02-08 15:20:40,085 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4898 bytes)
2018-02-08 15:20:40,093 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:20:40,093 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 15:20:40,149 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt:289+289
2018-02-08 15:20:40,152 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt:0+289
2018-02-08 15:20:40,195 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 867 bytes result sent to driver
2018-02-08 15:20:40,195 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 867 bytes result sent to driver
2018-02-08 15:20:40,202 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 116 ms on localhost (executor driver) (1/2)
2018-02-08 15:20:40,204 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 134 ms on localhost (executor driver) (2/2)
2018-02-08 15:20:40,207 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:20:40,214 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.155 s
2018-02-08 15:20:40,220 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.288074 s
2018-02-08 15:20:40,536 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:62168 in memory (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:20:41,626 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:62168 in memory (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:20:41,653 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:20:41,657 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:20:41,660 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:20:41,666 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:20:41,960 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 193.855742 ms
2018-02-08 15:20:41,973 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:20:41,988 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:20:41,990 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:62168 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:20:41,991 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:20:42,001 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:20:42,047 INFO[org.apache.spark.ml.util.Instrumentation:54] - LDA-lda_2f4d29e298c8-859725750-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
2018-02-08 15:20:42,069 INFO[org.apache.spark.ml.util.Instrumentation:54] - LDA-lda_2f4d29e298c8-859725750-1: {"k":10,"maxIter":10}
2018-02-08 15:20:42,182 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:20:42,182 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:20:42,183 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:20:42,183 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:20:42,246 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 29.919689 ms
2018-02-08 15:20:42,251 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 322.9 KB, free 631.1 MB)
2018-02-08 15:20:42,266 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.1 MB)
2018-02-08 15:20:42,267 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:62168 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:20:42,267 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:20:42,268 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:20:42,286 INFO[org.apache.spark.SparkContext:54] - Starting job: count at LDAOptimizer.scala:417
2018-02-08 15:20:42,287 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (count at LDAOptimizer.scala:417) with 1 output partitions
2018-02-08 15:20:42,287 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (count at LDAOptimizer.scala:417)
2018-02-08 15:20:42,287 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:42,288 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:42,288 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[14] at map at LDA.scala:943), which has no missing parents
2018-02-08 15:20:42,333 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 18.2 KB, free 631.1 MB)
2018-02-08 15:20:42,335 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.9 KB, free 631.1 MB)
2018-02-08 15:20:42,337 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:62168 (size: 7.9 KB, free: 631.7 MB)
2018-02-08 15:20:42,337 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:42,338 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[14] at map at LDA.scala:943) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:42,338 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 15:20:42,342 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5318 bytes)
2018-02-08 15:20:42,343 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 15:20:42,383 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.327044 ms
2018-02-08 15:20:42,391 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:42,418 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.760966 ms
2018-02-08 15:20:42,493 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 42.513294 ms
2018-02-08 15:20:42,512 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 1389 bytes result sent to driver
2018-02-08 15:20:42,513 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 174 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:42,513 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 15:20:42,514 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (count at LDAOptimizer.scala:417) finished in 0.175 s
2018-02-08 15:20:42,514 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: count at LDAOptimizer.scala:417, took 0.227830 s
2018-02-08 15:20:42,527 INFO[org.apache.spark.SparkContext:54] - Starting job: first at LDAOptimizer.scala:418
2018-02-08 15:20:42,528 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (first at LDAOptimizer.scala:418) with 1 output partitions
2018-02-08 15:20:42,528 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (first at LDAOptimizer.scala:418)
2018-02-08 15:20:42,528 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:42,528 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:42,528 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[14] at map at LDA.scala:943), which has no missing parents
2018-02-08 15:20:42,531 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 18.4 KB, free 631.1 MB)
2018-02-08 15:20:42,534 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.1 MB)
2018-02-08 15:20:42,536 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:62168 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:20:42,537 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:42,537 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at map at LDA.scala:943) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:42,537 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 15:20:42,538 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5318 bytes)
2018-02-08 15:20:42,538 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 15:20:42,544 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:42,555 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 1777 bytes result sent to driver
2018-02-08 15:20:42,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 18 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:42,557 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 15:20:42,557 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (first at LDAOptimizer.scala:418) finished in 0.019 s
2018-02-08 15:20:42,557 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: first at LDAOptimizer.scala:418, took 0.030378 s
2018-02-08 15:20:43,057 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_5_piece0 on 192.168.11.26:62168 in memory (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:20:43,058 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_4_piece0 on 192.168.11.26:62168 in memory (size: 7.9 KB, free: 631.7 MB)
2018-02-08 15:20:43,095 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at LDAOptimizer.scala:448
2018-02-08 15:20:43,096 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (isEmpty at LDAOptimizer.scala:448) with 1 output partitions
2018-02-08 15:20:43,096 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (isEmpty at LDAOptimizer.scala:448)
2018-02-08 15:20:43,096 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:43,096 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:43,097 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (PartitionwiseSampledRDD[15] at sample at LDAOptimizer.scala:446), which has no missing parents
2018-02-08 15:20:43,100 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 35.3 KB, free 631.1 MB)
2018-02-08 15:20:43,103 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.3 KB, free 631.1 MB)
2018-02-08 15:20:43,105 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:62168 (size: 14.3 KB, free: 631.7 MB)
2018-02-08 15:20:43,106 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:43,106 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (PartitionwiseSampledRDD[15] at sample at LDAOptimizer.scala:446) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:43,107 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 15:20:43,108 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:43,109 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 15:20:43,120 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:43,131 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 1347 bytes result sent to driver
2018-02-08 15:20:43,132 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 25 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:43,132 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 15:20:43,132 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (isEmpty at LDAOptimizer.scala:448) finished in 0.025 s
2018-02-08 15:20:43,133 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: isEmpty at LDAOptimizer.scala:448, took 0.037516 s
2018-02-08 15:20:43,139 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at LDAOptimizer.scala:448
2018-02-08 15:20:43,140 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (isEmpty at LDAOptimizer.scala:448) with 1 output partitions
2018-02-08 15:20:43,141 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (isEmpty at LDAOptimizer.scala:448)
2018-02-08 15:20:43,141 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:43,141 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:43,141 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (PartitionwiseSampledRDD[16] at sample at LDAOptimizer.scala:446), which has no missing parents
2018-02-08 15:20:43,144 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 35.3 KB, free 631.0 MB)
2018-02-08 15:20:43,147 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.3 KB, free 631.0 MB)
2018-02-08 15:20:43,148 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:62168 (size: 14.3 KB, free: 631.7 MB)
2018-02-08 15:20:43,149 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:43,149 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (PartitionwiseSampledRDD[16] at sample at LDAOptimizer.scala:446) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:43,149 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
2018-02-08 15:20:43,150 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:43,150 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 15:20:43,154 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:43,164 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 1347 bytes result sent to driver
2018-02-08 15:20:43,165 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 14 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:43,165 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 15:20:43,165 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (isEmpty at LDAOptimizer.scala:448) finished in 0.015 s
2018-02-08 15:20:43,165 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: isEmpty at LDAOptimizer.scala:448, took 0.026069 s
2018-02-08 15:20:43,172 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at LDAOptimizer.scala:448
2018-02-08 15:20:43,173 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (isEmpty at LDAOptimizer.scala:448) with 1 output partitions
2018-02-08 15:20:43,173 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (isEmpty at LDAOptimizer.scala:448)
2018-02-08 15:20:43,173 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:43,174 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:43,174 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (PartitionwiseSampledRDD[17] at sample at LDAOptimizer.scala:446), which has no missing parents
2018-02-08 15:20:43,176 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 35.3 KB, free 631.0 MB)
2018-02-08 15:20:43,179 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.3 KB, free 631.0 MB)
2018-02-08 15:20:43,180 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:62168 (size: 14.3 KB, free: 631.7 MB)
2018-02-08 15:20:43,181 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:43,181 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (PartitionwiseSampledRDD[17] at sample at LDAOptimizer.scala:446) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:43,181 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
2018-02-08 15:20:43,182 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:43,183 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 6)
2018-02-08 15:20:43,187 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:43,196 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 6). 1734 bytes result sent to driver
2018-02-08 15:20:43,197 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 6) in 15 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:43,197 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 15:20:43,198 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (isEmpty at LDAOptimizer.scala:448) finished in 0.016 s
2018-02-08 15:20:43,198 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: isEmpty at LDAOptimizer.scala:448, took 0.025338 s
2018-02-08 15:20:43,708 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 960.0 B, free 631.0 MB)
2018-02-08 15:20:43,725 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 1122.0 B, free 631.0 MB)
2018-02-08 15:20:43,727 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.11.26:62168 (size: 1122.0 B, free: 631.7 MB)
2018-02-08 15:20:43,727 INFO[org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at LDAOptimizer.scala:462
2018-02-08 15:20:43,759 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at LDAOptimizer.scala:479
2018-02-08 15:20:43,760 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (treeAggregate at LDAOptimizer.scala:479) with 1 output partitions
2018-02-08 15:20:43,760 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (treeAggregate at LDAOptimizer.scala:479)
2018-02-08 15:20:43,760 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:43,763 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:43,763 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[20] at treeAggregate at LDAOptimizer.scala:479), which has no missing parents
2018-02-08 15:20:43,766 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 37.6 KB, free 630.9 MB)
2018-02-08 15:20:43,769 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 15.0 KB, free 630.9 MB)
2018-02-08 15:20:43,771 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.11.26:62168 (size: 15.0 KB, free: 631.7 MB)
2018-02-08 15:20:43,771 INFO[org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:43,772 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[20] at treeAggregate at LDAOptimizer.scala:479) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:43,772 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
2018-02-08 15:20:43,773 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:43,773 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 7)
2018-02-08 15:20:43,783 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:43,825 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 15:20:43,825 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 15:20:43,867 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_18_0 stored as values in memory (estimated size 1152.0 B, free 630.9 MB)
2018-02-08 15:20:43,869 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_18_0 in memory on 192.168.11.26:62168 (size: 1152.0 B, free: 631.7 MB)
2018-02-08 15:20:43,876 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 7). 3168 bytes result sent to driver
2018-02-08 15:20:43,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 7) in 105 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:43,878 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 15:20:43,878 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (treeAggregate at LDAOptimizer.scala:479) finished in 0.106 s
2018-02-08 15:20:43,879 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: treeAggregate at LDAOptimizer.scala:479, took 0.118899 s
2018-02-08 15:20:43,899 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at LDAOptimizer.scala:482
2018-02-08 15:20:43,900 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (collect at LDAOptimizer.scala:482) with 1 output partitions
2018-02-08 15:20:43,901 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 7 (collect at LDAOptimizer.scala:482)
2018-02-08 15:20:43,901 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:43,903 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:43,903 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 7 (MapPartitionsRDD[22] at flatMap at LDAOptimizer.scala:482), which has no missing parents
2018-02-08 15:20:43,908 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 36.5 KB, free 630.9 MB)
2018-02-08 15:20:43,912 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.9 KB, free 630.9 MB)
2018-02-08 15:20:43,914 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.11.26:62168 (size: 14.9 KB, free: 631.7 MB)
2018-02-08 15:20:43,914 INFO[org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:43,915 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[22] at flatMap at LDAOptimizer.scala:482) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:43,915 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
2018-02-08 15:20:43,919 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:43,920 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 8)
2018-02-08 15:20:43,927 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:20:43,929 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 8). 1633 bytes result sent to driver
2018-02-08 15:20:43,930 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 8) in 12 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:43,931 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-02-08 15:20:43,931 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 7 (collect at LDAOptimizer.scala:482) finished in 0.013 s
2018-02-08 15:20:43,932 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: collect at LDAOptimizer.scala:482, took 0.032739 s
2018-02-08 15:20:43,947 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 18 from persistence list
2018-02-08 15:20:43,951 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 18
2018-02-08 15:20:43,965 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(9) (from destroy at LDAOptimizer.scala:484)
2018-02-08 15:20:43,970 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.11.26:62168 in memory (size: 1122.0 B, free: 631.7 MB)
2018-02-08 15:20:44,057 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at LDAOptimizer.scala:448
2018-02-08 15:20:44,058 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (isEmpty at LDAOptimizer.scala:448) with 1 output partitions
2018-02-08 15:20:44,058 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 8 (isEmpty at LDAOptimizer.scala:448)
2018-02-08 15:20:44,058 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,058 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,058 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 8 (PartitionwiseSampledRDD[23] at sample at LDAOptimizer.scala:446), which has no missing parents
2018-02-08 15:20:44,060 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 35.3 KB, free 630.8 MB)
2018-02-08 15:20:44,066 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.3 KB, free 630.8 MB)
2018-02-08 15:20:44,068 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.11.26:62168 (size: 14.3 KB, free: 631.7 MB)
2018-02-08 15:20:44,069 INFO[org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 8 (PartitionwiseSampledRDD[23] at sample at LDAOptimizer.scala:446) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,070 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 1 tasks
2018-02-08 15:20:44,071 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:44,072 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 9)
2018-02-08 15:20:44,076 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:44,085 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 9). 1347 bytes result sent to driver
2018-02-08 15:20:44,085 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 9) in 14 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,086 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,086 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 8 (isEmpty at LDAOptimizer.scala:448) finished in 0.016 s
2018-02-08 15:20:44,087 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: isEmpty at LDAOptimizer.scala:448, took 0.029213 s
2018-02-08 15:20:44,095 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at LDAOptimizer.scala:448
2018-02-08 15:20:44,096 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (isEmpty at LDAOptimizer.scala:448) with 1 output partitions
2018-02-08 15:20:44,097 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 9 (isEmpty at LDAOptimizer.scala:448)
2018-02-08 15:20:44,097 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,097 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,097 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 9 (PartitionwiseSampledRDD[24] at sample at LDAOptimizer.scala:446), which has no missing parents
2018-02-08 15:20:44,099 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 35.3 KB, free 630.8 MB)
2018-02-08 15:20:44,103 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 14.3 KB, free 630.8 MB)
2018-02-08 15:20:44,104 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.11.26:62168 (size: 14.3 KB, free: 631.6 MB)
2018-02-08 15:20:44,105 INFO[org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,106 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 9 (PartitionwiseSampledRDD[24] at sample at LDAOptimizer.scala:446) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,106 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 1 tasks
2018-02-08 15:20:44,107 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:44,107 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 10)
2018-02-08 15:20:44,113 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:44,124 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 10). 1722 bytes result sent to driver
2018-02-08 15:20:44,126 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 10) in 20 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,126 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,127 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 9 (isEmpty at LDAOptimizer.scala:448) finished in 0.020 s
2018-02-08 15:20:44,127 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: isEmpty at LDAOptimizer.scala:448, took 0.031562 s
2018-02-08 15:20:44,132 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 960.0 B, free 630.8 MB)
2018-02-08 15:20:44,136 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 1122.0 B, free 630.8 MB)
2018-02-08 15:20:44,137 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.11.26:62168 (size: 1122.0 B, free: 631.6 MB)
2018-02-08 15:20:44,137 INFO[org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at LDAOptimizer.scala:462
2018-02-08 15:20:44,160 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at LDAOptimizer.scala:479
2018-02-08 15:20:44,162 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 10 (treeAggregate at LDAOptimizer.scala:479) with 1 output partitions
2018-02-08 15:20:44,162 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 10 (treeAggregate at LDAOptimizer.scala:479)
2018-02-08 15:20:44,162 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,163 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,163 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 10 (MapPartitionsRDD[27] at treeAggregate at LDAOptimizer.scala:479), which has no missing parents
2018-02-08 15:20:44,166 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 37.6 KB, free 630.7 MB)
2018-02-08 15:20:44,168 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 15.1 KB, free 630.7 MB)
2018-02-08 15:20:44,169 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.11.26:62168 (size: 15.1 KB, free: 631.6 MB)
2018-02-08 15:20:44,169 INFO[org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,170 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[27] at treeAggregate at LDAOptimizer.scala:479) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,170 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 1 tasks
2018-02-08 15:20:44,173 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:44,175 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 11)
2018-02-08 15:20:44,183 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:44,208 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_25_0 stored as values in memory (estimated size 1152.0 B, free 630.7 MB)
2018-02-08 15:20:44,211 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_25_0 in memory on 192.168.11.26:62168 (size: 1152.0 B, free: 631.6 MB)
2018-02-08 15:20:44,216 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 11). 3211 bytes result sent to driver
2018-02-08 15:20:44,217 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 11) in 46 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,218 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,218 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 10 (treeAggregate at LDAOptimizer.scala:479) finished in 0.048 s
2018-02-08 15:20:44,219 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 10 finished: treeAggregate at LDAOptimizer.scala:479, took 0.058052 s
2018-02-08 15:20:44,239 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at LDAOptimizer.scala:482
2018-02-08 15:20:44,240 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 11 (collect at LDAOptimizer.scala:482) with 1 output partitions
2018-02-08 15:20:44,240 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 11 (collect at LDAOptimizer.scala:482)
2018-02-08 15:20:44,240 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,241 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,242 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 11 (MapPartitionsRDD[29] at flatMap at LDAOptimizer.scala:482), which has no missing parents
2018-02-08 15:20:44,244 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16 stored as values in memory (estimated size 36.5 KB, free 630.7 MB)
2018-02-08 15:20:44,252 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 15.0 KB, free 630.7 MB)
2018-02-08 15:20:44,253 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_16_piece0 in memory on 192.168.11.26:62168 (size: 15.0 KB, free: 631.6 MB)
2018-02-08 15:20:44,254 INFO[org.apache.spark.SparkContext:54] - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,255 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[29] at flatMap at LDAOptimizer.scala:482) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,255 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 1 tasks
2018-02-08 15:20:44,256 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:44,256 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 12)
2018-02-08 15:20:44,260 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_25_0 locally
2018-02-08 15:20:44,261 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 12). 1590 bytes result sent to driver
2018-02-08 15:20:44,263 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 12) in 8 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,264 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,264 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 11 (collect at LDAOptimizer.scala:482) finished in 0.009 s
2018-02-08 15:20:44,265 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 11 finished: collect at LDAOptimizer.scala:482, took 0.025336 s
2018-02-08 15:20:44,266 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 25 from persistence list
2018-02-08 15:20:44,266 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 25
2018-02-08 15:20:44,267 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(14) (from destroy at LDAOptimizer.scala:484)
2018-02-08 15:20:44,269 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_14_piece0 on 192.168.11.26:62168 in memory (size: 1122.0 B, free: 631.6 MB)
2018-02-08 15:20:44,277 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at LDAOptimizer.scala:448
2018-02-08 15:20:44,278 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 12 (isEmpty at LDAOptimizer.scala:448) with 1 output partitions
2018-02-08 15:20:44,278 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 12 (isEmpty at LDAOptimizer.scala:448)
2018-02-08 15:20:44,278 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,278 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,278 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 12 (PartitionwiseSampledRDD[30] at sample at LDAOptimizer.scala:446), which has no missing parents
2018-02-08 15:20:44,280 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17 stored as values in memory (estimated size 35.3 KB, free 630.6 MB)
2018-02-08 15:20:44,283 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 14.3 KB, free 630.6 MB)
2018-02-08 15:20:44,283 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_17_piece0 in memory on 192.168.11.26:62168 (size: 14.3 KB, free: 631.6 MB)
2018-02-08 15:20:44,284 INFO[org.apache.spark.SparkContext:54] - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,284 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 12 (PartitionwiseSampledRDD[30] at sample at LDAOptimizer.scala:446) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,284 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 12.0 with 1 tasks
2018-02-08 15:20:44,285 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:44,285 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 12.0 (TID 13)
2018-02-08 15:20:44,290 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:44,301 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 12.0 (TID 13). 1347 bytes result sent to driver
2018-02-08 15:20:44,302 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 12.0 (TID 13) in 16 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,302 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,303 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 12 (isEmpty at LDAOptimizer.scala:448) finished in 0.017 s
2018-02-08 15:20:44,303 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 12 finished: isEmpty at LDAOptimizer.scala:448, took 0.026159 s
2018-02-08 15:20:44,311 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at LDAOptimizer.scala:448
2018-02-08 15:20:44,311 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 13 (isEmpty at LDAOptimizer.scala:448) with 1 output partitions
2018-02-08 15:20:44,311 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 13 (isEmpty at LDAOptimizer.scala:448)
2018-02-08 15:20:44,312 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,312 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,312 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 13 (PartitionwiseSampledRDD[31] at sample at LDAOptimizer.scala:446), which has no missing parents
2018-02-08 15:20:44,323 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18 stored as values in memory (estimated size 35.3 KB, free 630.6 MB)
2018-02-08 15:20:44,328 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 14.3 KB, free 630.6 MB)
2018-02-08 15:20:44,330 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_18_piece0 in memory on 192.168.11.26:62168 (size: 14.3 KB, free: 631.6 MB)
2018-02-08 15:20:44,334 INFO[org.apache.spark.SparkContext:54] - Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,335 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 13 (PartitionwiseSampledRDD[31] at sample at LDAOptimizer.scala:446) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,335 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 13.0 with 1 tasks
2018-02-08 15:20:44,336 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:44,337 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 13.0 (TID 14)
2018-02-08 15:20:44,355 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:44,361 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_17_piece0 on 192.168.11.26:62168 in memory (size: 14.3 KB, free: 631.6 MB)
2018-02-08 15:20:44,367 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 13.0 (TID 14). 1390 bytes result sent to driver
2018-02-08 15:20:44,368 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 13.0 (TID 14) in 32 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,368 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,369 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 13 (isEmpty at LDAOptimizer.scala:448) finished in 0.033 s
2018-02-08 15:20:44,369 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:62168 in memory (size: 14.3 KB, free: 631.6 MB)
2018-02-08 15:20:44,369 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 13 finished: isEmpty at LDAOptimizer.scala:448, took 0.058640 s
2018-02-08 15:20:44,375 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.11.26:62168 in memory (size: 14.3 KB, free: 631.6 MB)
2018-02-08 15:20:44,377 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at LDAOptimizer.scala:448
2018-02-08 15:20:44,378 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 14 (isEmpty at LDAOptimizer.scala:448) with 1 output partitions
2018-02-08 15:20:44,378 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 14 (isEmpty at LDAOptimizer.scala:448)
2018-02-08 15:20:44,378 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,378 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,378 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 14 (PartitionwiseSampledRDD[32] at sample at LDAOptimizer.scala:446), which has no missing parents
2018-02-08 15:20:44,380 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19 stored as values in memory (estimated size 35.3 KB, free 630.7 MB)
2018-02-08 15:20:44,388 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 14.3 KB, free 630.7 MB)
2018-02-08 15:20:44,392 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_19_piece0 in memory on 192.168.11.26:62168 (size: 14.3 KB, free: 631.6 MB)
2018-02-08 15:20:44,394 INFO[org.apache.spark.SparkContext:54] - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,395 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 14 (PartitionwiseSampledRDD[32] at sample at LDAOptimizer.scala:446) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,395 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 14.0 with 1 tasks
2018-02-08 15:20:44,398 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:44,398 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 14.0 (TID 15)
2018-02-08 15:20:44,399 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.11.26:62168 in memory (size: 14.9 KB, free: 631.6 MB)
2018-02-08 15:20:44,403 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:44,424 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 14.0 (TID 15). 1347 bytes result sent to driver
2018-02-08 15:20:44,425 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 18
2018-02-08 15:20:44,426 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 14.0 (TID 15) in 29 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,430 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,431 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 14 (isEmpty at LDAOptimizer.scala:448) finished in 0.035 s
2018-02-08 15:20:44,432 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 14 finished: isEmpty at LDAOptimizer.scala:448, took 0.054867 s
2018-02-08 15:20:44,433 INFO[org.apache.spark.ContextCleaner:54] - Cleaned RDD 18
2018-02-08 15:20:44,445 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at LDAOptimizer.scala:448
2018-02-08 15:20:44,445 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_16_piece0 on 192.168.11.26:62168 in memory (size: 15.0 KB, free: 631.6 MB)
2018-02-08 15:20:44,446 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 15 (isEmpty at LDAOptimizer.scala:448) with 1 output partitions
2018-02-08 15:20:44,447 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 15 (isEmpty at LDAOptimizer.scala:448)
2018-02-08 15:20:44,447 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,447 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,447 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 15 (PartitionwiseSampledRDD[33] at sample at LDAOptimizer.scala:446), which has no missing parents
2018-02-08 15:20:44,449 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20 stored as values in memory (estimated size 35.3 KB, free 630.7 MB)
2018-02-08 15:20:44,454 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 14.3 KB, free 630.7 MB)
2018-02-08 15:20:44,457 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_20_piece0 in memory on 192.168.11.26:62168 (size: 14.3 KB, free: 631.6 MB)
2018-02-08 15:20:44,459 INFO[org.apache.spark.SparkContext:54] - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,460 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 25
2018-02-08 15:20:44,460 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 15 (PartitionwiseSampledRDD[33] at sample at LDAOptimizer.scala:446) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,460 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 15.0 with 1 tasks
2018-02-08 15:20:44,461 INFO[org.apache.spark.ContextCleaner:54] - Cleaned RDD 25
2018-02-08 15:20:44,461 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 15.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:44,462 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 15.0 (TID 16)
2018-02-08 15:20:44,464 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_15_piece0 on 192.168.11.26:62168 in memory (size: 15.1 KB, free: 631.6 MB)
2018-02-08 15:20:44,466 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:44,473 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_12_piece0 on 192.168.11.26:62168 in memory (size: 14.3 KB, free: 631.7 MB)
2018-02-08 15:20:44,478 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.11.26:62168 in memory (size: 15.0 KB, free: 631.7 MB)
2018-02-08 15:20:44,483 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 15.0 (TID 16). 1722 bytes result sent to driver
2018-02-08 15:20:44,487 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 15.0 (TID 16) in 26 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,488 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:62168 in memory (size: 14.3 KB, free: 631.7 MB)
2018-02-08 15:20:44,488 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,489 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 15 (isEmpty at LDAOptimizer.scala:448) finished in 0.027 s
2018-02-08 15:20:44,489 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 15 finished: isEmpty at LDAOptimizer.scala:448, took 0.044358 s
2018-02-08 15:20:44,491 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21 stored as values in memory (estimated size 960.0 B, free 630.9 MB)
2018-02-08 15:20:44,491 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_13_piece0 on 192.168.11.26:62168 in memory (size: 14.3 KB, free: 631.7 MB)
2018-02-08 15:20:44,493 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 1122.0 B, free 630.9 MB)
2018-02-08 15:20:44,495 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_21_piece0 in memory on 192.168.11.26:62168 (size: 1122.0 B, free: 631.7 MB)
2018-02-08 15:20:44,496 INFO[org.apache.spark.SparkContext:54] - Created broadcast 21 from broadcast at LDAOptimizer.scala:462
2018-02-08 15:20:44,514 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at LDAOptimizer.scala:479
2018-02-08 15:20:44,516 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 16 (treeAggregate at LDAOptimizer.scala:479) with 1 output partitions
2018-02-08 15:20:44,516 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 16 (treeAggregate at LDAOptimizer.scala:479)
2018-02-08 15:20:44,516 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,517 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,518 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 16 (MapPartitionsRDD[36] at treeAggregate at LDAOptimizer.scala:479), which has no missing parents
2018-02-08 15:20:44,520 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22 stored as values in memory (estimated size 37.6 KB, free 630.9 MB)
2018-02-08 15:20:44,523 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 15.1 KB, free 630.9 MB)
2018-02-08 15:20:44,524 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_22_piece0 in memory on 192.168.11.26:62168 (size: 15.1 KB, free: 631.7 MB)
2018-02-08 15:20:44,524 INFO[org.apache.spark.SparkContext:54] - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,525 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[36] at treeAggregate at LDAOptimizer.scala:479) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,525 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 16.0 with 1 tasks
2018-02-08 15:20:44,526 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:44,526 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 16.0 (TID 17)
2018-02-08 15:20:44,533 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:44,543 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_34_0 stored as values in memory (estimated size 1152.0 B, free 630.9 MB)
2018-02-08 15:20:44,545 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_34_0 in memory on 192.168.11.26:62168 (size: 1152.0 B, free: 631.7 MB)
2018-02-08 15:20:44,551 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 16.0 (TID 17). 3168 bytes result sent to driver
2018-02-08 15:20:44,552 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 16.0 (TID 17) in 26 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,552 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,553 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 16 (treeAggregate at LDAOptimizer.scala:479) finished in 0.027 s
2018-02-08 15:20:44,554 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 16 finished: treeAggregate at LDAOptimizer.scala:479, took 0.038779 s
2018-02-08 15:20:44,564 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at LDAOptimizer.scala:482
2018-02-08 15:20:44,565 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 17 (collect at LDAOptimizer.scala:482) with 1 output partitions
2018-02-08 15:20:44,565 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 17 (collect at LDAOptimizer.scala:482)
2018-02-08 15:20:44,565 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,566 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,566 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 17 (MapPartitionsRDD[38] at flatMap at LDAOptimizer.scala:482), which has no missing parents
2018-02-08 15:20:44,567 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23 stored as values in memory (estimated size 36.5 KB, free 630.9 MB)
2018-02-08 15:20:44,570 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 15.0 KB, free 630.9 MB)
2018-02-08 15:20:44,572 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_23_piece0 in memory on 192.168.11.26:62168 (size: 15.0 KB, free: 631.7 MB)
2018-02-08 15:20:44,572 INFO[org.apache.spark.SparkContext:54] - Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,573 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[38] at flatMap at LDAOptimizer.scala:482) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,574 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 17.0 with 1 tasks
2018-02-08 15:20:44,574 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:44,575 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 17.0 (TID 18)
2018-02-08 15:20:44,578 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_34_0 locally
2018-02-08 15:20:44,579 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 17.0 (TID 18). 1590 bytes result sent to driver
2018-02-08 15:20:44,579 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 17.0 (TID 18) in 5 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,580 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,580 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 17 (collect at LDAOptimizer.scala:482) finished in 0.006 s
2018-02-08 15:20:44,581 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 17 finished: collect at LDAOptimizer.scala:482, took 0.016120 s
2018-02-08 15:20:44,581 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 34 from persistence list
2018-02-08 15:20:44,583 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 34
2018-02-08 15:20:44,584 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(21) (from destroy at LDAOptimizer.scala:484)
2018-02-08 15:20:44,586 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_21_piece0 on 192.168.11.26:62168 in memory (size: 1122.0 B, free: 631.7 MB)
2018-02-08 15:20:44,591 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at LDAOptimizer.scala:448
2018-02-08 15:20:44,591 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 18 (isEmpty at LDAOptimizer.scala:448) with 1 output partitions
2018-02-08 15:20:44,592 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 18 (isEmpty at LDAOptimizer.scala:448)
2018-02-08 15:20:44,592 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,592 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,592 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 18 (PartitionwiseSampledRDD[39] at sample at LDAOptimizer.scala:446), which has no missing parents
2018-02-08 15:20:44,594 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24 stored as values in memory (estimated size 35.3 KB, free 630.8 MB)
2018-02-08 15:20:44,599 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 14.3 KB, free 630.8 MB)
2018-02-08 15:20:44,600 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_24_piece0 in memory on 192.168.11.26:62168 (size: 14.3 KB, free: 631.7 MB)
2018-02-08 15:20:44,600 INFO[org.apache.spark.SparkContext:54] - Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,601 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 18 (PartitionwiseSampledRDD[39] at sample at LDAOptimizer.scala:446) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,601 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 18.0 with 1 tasks
2018-02-08 15:20:44,602 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 18.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5427 bytes)
2018-02-08 15:20:44,602 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 18.0 (TID 19)
2018-02-08 15:20:44,606 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:44,616 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 18.0 (TID 19). 1347 bytes result sent to driver
2018-02-08 15:20:44,618 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 18.0 (TID 19) in 16 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,618 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,618 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 18 (isEmpty at LDAOptimizer.scala:448) finished in 0.017 s
2018-02-08 15:20:44,619 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 18 finished: isEmpty at LDAOptimizer.scala:448, took 0.027654 s
2018-02-08 15:20:44,631 INFO[org.apache.spark.ml.util.Instrumentation:54] - LDA-lda_2f4d29e298c8-859725750-1: {"numFeatures":11}
2018-02-08 15:20:44,634 INFO[org.apache.spark.ml.util.Instrumentation:54] - LDA-lda_2f4d29e298c8-859725750-1: training finished
2018-02-08 15:20:44,651 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:20:44,651 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:20:44,652 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:20:44,652 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:20:44,662 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25 stored as values in memory (estimated size 322.9 KB, free 630.5 MB)
2018-02-08 15:20:44,675 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 27.6 KB, free 630.5 MB)
2018-02-08 15:20:44,676 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_25_piece0 in memory on 192.168.11.26:62168 (size: 27.6 KB, free: 631.6 MB)
2018-02-08 15:20:44,676 INFO[org.apache.spark.SparkContext:54] - Created broadcast 25 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:20:44,677 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:20:44,686 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_26 stored as values in memory (estimated size 960.0 B, free 630.5 MB)
2018-02-08 15:20:44,690 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 1122.0 B, free 630.5 MB)
2018-02-08 15:20:44,690 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_26_piece0 in memory on 192.168.11.26:62168 (size: 1122.0 B, free: 631.6 MB)
2018-02-08 15:20:44,691 INFO[org.apache.spark.SparkContext:54] - Created broadcast 26 from broadcast at LDAModel.scala:300
2018-02-08 15:20:44,718 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at LDAModel.scala:322
2018-02-08 15:20:44,719 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 19 (sum at LDAModel.scala:322) with 1 output partitions
2018-02-08 15:20:44,720 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 19 (sum at LDAModel.scala:322)
2018-02-08 15:20:44,720 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,720 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,721 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 19 (MapPartitionsRDD[46] at map at LDAModel.scala:305), which has no missing parents
2018-02-08 15:20:44,722 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_27 stored as values in memory (estimated size 19.5 KB, free 630.5 MB)
2018-02-08 15:20:44,728 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.6 KB, free 630.4 MB)
2018-02-08 15:20:44,729 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_27_piece0 in memory on 192.168.11.26:62168 (size: 8.6 KB, free: 631.6 MB)
2018-02-08 15:20:44,730 INFO[org.apache.spark.SparkContext:54] - Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,731 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[46] at map at LDAModel.scala:305) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,731 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 19.0 with 1 tasks
2018-02-08 15:20:44,732 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 19.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 5318 bytes)
2018-02-08 15:20:44,732 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 19.0 (TID 20)
2018-02-08 15:20:44,736 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:44,820 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 19.0 (TID 20). 1477 bytes result sent to driver
2018-02-08 15:20:44,824 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 19.0 (TID 20) in 91 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,824 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,825 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 19 (sum at LDAModel.scala:322) finished in 0.094 s
2018-02-08 15:20:44,826 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 19 finished: sum at LDAModel.scala:322, took 0.107795 s
2018-02-08 15:20:44,849 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:20:44,850 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:20:44,850 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:20:44,850 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:20:44,859 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_28 stored as values in memory (estimated size 322.9 KB, free 630.1 MB)
2018-02-08 15:20:44,873 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 27.6 KB, free 630.1 MB)
2018-02-08 15:20:44,874 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_28_piece0 in memory on 192.168.11.26:62168 (size: 27.6 KB, free: 631.6 MB)
2018-02-08 15:20:44,874 INFO[org.apache.spark.SparkContext:54] - Created broadcast 28 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:20:44,875 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:20:44,891 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at LDAModel.scala:258
2018-02-08 15:20:44,892 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 20 (sum at LDAModel.scala:258) with 1 output partitions
2018-02-08 15:20:44,892 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 20 (sum at LDAModel.scala:258)
2018-02-08 15:20:44,892 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,892 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,893 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 20 (MapPartitionsRDD[52] at map at LDAModel.scala:257), which has no missing parents
2018-02-08 15:20:44,894 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_29 stored as values in memory (estimated size 18.8 KB, free 630.1 MB)
2018-02-08 15:20:44,897 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 8.2 KB, free 630.1 MB)
2018-02-08 15:20:44,898 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_29_piece0 in memory on 192.168.11.26:62168 (size: 8.2 KB, free: 631.6 MB)
2018-02-08 15:20:44,898 INFO[org.apache.spark.SparkContext:54] - Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,899 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[52] at map at LDAModel.scala:257) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,899 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 20.0 with 1 tasks
2018-02-08 15:20:44,899 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 20.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5318 bytes)
2018-02-08 15:20:44,900 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 20.0 (TID 21)
2018-02-08 15:20:44,904 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:44,914 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 20.0 (TID 21). 1391 bytes result sent to driver
2018-02-08 15:20:44,915 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 20.0 (TID 21) in 16 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:44,915 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2018-02-08 15:20:44,916 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 20 (sum at LDAModel.scala:258) finished in 0.017 s
2018-02-08 15:20:44,917 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 20 finished: sum at LDAModel.scala:258, took 0.024919 s
2018-02-08 15:20:44,918 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_30 stored as values in memory (estimated size 960.0 B, free 630.1 MB)
2018-02-08 15:20:44,920 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 1122.0 B, free 630.1 MB)
2018-02-08 15:20:44,923 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_30_piece0 in memory on 192.168.11.26:62168 (size: 1122.0 B, free: 631.6 MB)
2018-02-08 15:20:44,923 INFO[org.apache.spark.SparkContext:54] - Created broadcast 30 from broadcast at LDAModel.scala:300
2018-02-08 15:20:44,937 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at LDAModel.scala:322
2018-02-08 15:20:44,938 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 21 (sum at LDAModel.scala:322) with 1 output partitions
2018-02-08 15:20:44,939 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 21 (sum at LDAModel.scala:322)
2018-02-08 15:20:44,939 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:44,939 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:44,939 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 21 (MapPartitionsRDD[54] at map at LDAModel.scala:305), which has no missing parents
2018-02-08 15:20:44,942 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_31 stored as values in memory (estimated size 19.5 KB, free 630.1 MB)
2018-02-08 15:20:44,947 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 8.6 KB, free 630.1 MB)
2018-02-08 15:20:44,948 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_31_piece0 in memory on 192.168.11.26:62168 (size: 8.6 KB, free: 631.6 MB)
2018-02-08 15:20:44,949 INFO[org.apache.spark.SparkContext:54] - Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:44,952 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[54] at map at LDAModel.scala:305) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:44,952 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 21.0 with 1 tasks
2018-02-08 15:20:44,953 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 21.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 5318 bytes)
2018-02-08 15:20:44,954 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 21.0 (TID 22)
2018-02-08 15:20:44,960 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:45,004 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 21.0 (TID 22). 1434 bytes result sent to driver
2018-02-08 15:20:45,006 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 21.0 (TID 22) in 53 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:45,006 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2018-02-08 15:20:45,007 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 21 (sum at LDAModel.scala:322) finished in 0.054 s
2018-02-08 15:20:45,009 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 21 finished: sum at LDAModel.scala:322, took 0.071954 s
2018-02-08 15:20:45,424 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.542404 ms
2018-02-08 15:20:45,448 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.728326 ms
2018-02-08 15:20:45,467 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_32 stored as values in memory (estimated size 960.0 B, free 630.0 MB)
2018-02-08 15:20:45,469 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 1122.0 B, free 630.0 MB)
2018-02-08 15:20:45,469 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_32_piece0 in memory on 192.168.11.26:62168 (size: 1122.0 B, free: 631.6 MB)
2018-02-08 15:20:45,470 INFO[org.apache.spark.SparkContext:54] - Created broadcast 32 from broadcast at LDAModel.scala:375
2018-02-08 15:20:45,520 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:20:45,521 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:20:45,521 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:20:45,521 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:20:45,564 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 31.48609 ms
2018-02-08 15:20:45,568 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_33 stored as values in memory (estimated size 322.9 KB, free 629.7 MB)
2018-02-08 15:20:45,584 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 27.6 KB, free 629.7 MB)
2018-02-08 15:20:45,584 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_33_piece0 in memory on 192.168.11.26:62168 (size: 27.6 KB, free: 631.6 MB)
2018-02-08 15:20:45,585 INFO[org.apache.spark.SparkContext:54] - Created broadcast 33 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:20:45,587 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:20:45,612 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningClustering.java:58
2018-02-08 15:20:45,613 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 22 (show at MachineLeaningClustering.java:58) with 1 output partitions
2018-02-08 15:20:45,613 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 22 (show at MachineLeaningClustering.java:58)
2018-02-08 15:20:45,614 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:20:45,614 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:20:45,615 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 22 (MapPartitionsRDD[57] at show at MachineLeaningClustering.java:58), which has no missing parents
2018-02-08 15:20:45,619 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_34 stored as values in memory (estimated size 20.2 KB, free 629.7 MB)
2018-02-08 15:20:45,624 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 7.9 KB, free 629.7 MB)
2018-02-08 15:20:45,629 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_34_piece0 in memory on 192.168.11.26:62168 (size: 7.9 KB, free: 631.5 MB)
2018-02-08 15:20:45,630 INFO[org.apache.spark.SparkContext:54] - Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:20:45,631 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[57] at show at MachineLeaningClustering.java:58) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:20:45,631 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 22.0 with 1 tasks
2018-02-08 15:20:45,632 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 22.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5318 bytes)
2018-02-08 15:20:45,632 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 22.0 (TID 23)
2018-02-08 15:20:45,637 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_lda_libsvm_data.txt, range: 0-578, partition values: [empty row]
2018-02-08 15:20:45,669 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 22.0 (TID 23). 2896 bytes result sent to driver
2018-02-08 15:20:45,674 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 22.0 (TID 23) in 43 ms on localhost (executor driver) (1/1)
2018-02-08 15:20:45,674 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2018-02-08 15:20:45,675 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 22 (show at MachineLeaningClustering.java:58) finished in 0.043 s
2018-02-08 15:20:45,678 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 22 finished: show at MachineLeaningClustering.java:58, took 0.066038 s
2018-02-08 15:20:45,699 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.017603 ms
2018-02-08 15:20:45,710 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:20:45,715 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@5d4ddf63{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:20:45,717 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:20:45,726 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:20:45,802 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:20:45,803 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:20:45,804 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:20:45,806 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:20:45,809 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:20:45,810 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:20:45,812 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-762737d1-3d31-4d17-8d6c-6f2531e31ae3
2018-02-08 15:24:53,224 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:24:53,872 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:24:53,927 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:24:53,928 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:24:53,929 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:24:53,930 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:24:53,931 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:24:54,293 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62233.
2018-02-08 15:24:54,310 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:24:54,354 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:24:54,357 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:24:54,358 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:24:54,366 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-10c7840b-0340-44e1-bf37-2fa806f78174
2018-02-08 15:24:54,387 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:24:54,437 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:24:54,515 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @3067ms
2018-02-08 15:24:54,590 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:24:54,607 INFO[org.spark_project.jetty.server.Server:403] - Started @3160ms
2018-02-08 15:24:54,633 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@6b1b83d4{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:24:54,633 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:24:54,655 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2488b073{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,656 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,657 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,658 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@631e06ab{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,659 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@34a75079{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,660 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,662 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@186978a6{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,664 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,665 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,666 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,666 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,667 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,667 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,668 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,669 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,669 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,670 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,670 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,671 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,673 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,680 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/static,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,680 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@305f031{/,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,681 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d1f7216{/api,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,682 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4ebea12c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,682 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6256ac4f{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:24:54,684 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:24:54,782 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:24:54,813 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62246.
2018-02-08 15:24:54,822 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62246
2018-02-08 15:24:54,824 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:24:54,831 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62246, None)
2018-02-08 15:24:54,844 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62246 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62246, None)
2018-02-08 15:24:54,848 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62246, None)
2018-02-08 15:24:54,850 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62246, None)
2018-02-08 15:24:55,115 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5a6d5a8f{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:55,203 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:24:55,204 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:24:55,212 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@46b695ec{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:24:55,213 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@325f7fa9{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:55,214 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3af9aa66{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:24:55,215 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@91c4a3f{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:24:55,218 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d269ed7{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:24:56,417 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:24:56,870 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 15:24:56,934 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 15:24:56,936 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:62246 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:24:56,942 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 15:24:57,051 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 15:24:57,066 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 15:24:57,091 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 15:24:57,091 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 15:24:57,092 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:24:57,094 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:24:57,102 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 15:24:57,165 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 15:24:57,170 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 15:24:57,171 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:62246 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:24:57,172 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:24:57,187 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 15:24:57,187 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 15:24:57,220 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:24:57,222 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:24:57,230 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 15:24:57,230 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:24:57,288 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:60+60
2018-02-08 15:24:57,288 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:0+60
2018-02-08 15:24:57,345 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 867 bytes result sent to driver
2018-02-08 15:24:57,345 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
2018-02-08 15:24:57,353 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 128 ms on localhost (executor driver) (1/2)
2018-02-08 15:24:57,356 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 147 ms on localhost (executor driver) (2/2)
2018-02-08 15:24:57,357 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:24:57,361 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.161 s
2018-02-08 15:24:57,372 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.305742 s
2018-02-08 15:24:57,439 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:62246 in memory (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:24:57,443 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:62246 in memory (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:24:58,918 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:24:58,921 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:24:58,923 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:24:58,930 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:24:59,230 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 197.127743 ms
2018-02-08 15:24:59,242 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:24:59,258 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:24:59,260 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:62246 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:24:59,260 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:24:59,268 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:24:59,322 INFO[org.apache.spark.ml.util.Instrumentation:54] - BisectingKMeans-bisecting-kmeans_530ee1cc8d8a-828174704-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
2018-02-08 15:24:59,342 INFO[org.apache.spark.ml.util.Instrumentation:54] - BisectingKMeans-bisecting-kmeans_530ee1cc8d8a-828174704-1: {"k":2,"seed":1}
2018-02-08 15:24:59,346 WARN[org.apache.spark.mllib.clustering.BisectingKMeans:66] - The input RDD 10 is not directly cached, which may hurt performance if its parent RDDs are also not cached.
2018-02-08 15:24:59,398 INFO[org.apache.spark.SparkContext:54] - Starting job: first at BisectingKMeans.scala:148
2018-02-08 15:24:59,399 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (first at BisectingKMeans.scala:148) with 1 output partitions
2018-02-08 15:24:59,400 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (first at BisectingKMeans.scala:148)
2018-02-08 15:24:59,400 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:24:59,400 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:24:59,400 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[11] at map at BisectingKMeans.scala:148), which has no missing parents
2018-02-08 15:24:59,408 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 11.4 KB, free 631.4 MB)
2018-02-08 15:24:59,412 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.0 KB, free 631.4 MB)
2018-02-08 15:24:59,413 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:62246 (size: 6.0 KB, free: 631.8 MB)
2018-02-08 15:24:59,414 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:24:59,415 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at map at BisectingKMeans.scala:148) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:24:59,416 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 15:24:59,420 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:24:59,421 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 15:24:59,461 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.851525 ms
2018-02-08 15:24:59,469 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:24:59,507 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 22.891207 ms
2018-02-08 15:24:59,541 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.705926 ms
2018-02-08 15:24:59,592 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 34.280651 ms
2018-02-08 15:24:59,604 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 1338 bytes result sent to driver
2018-02-08 15:24:59,606 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 189 ms on localhost (executor driver) (1/1)
2018-02-08 15:24:59,606 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 15:24:59,606 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (first at BisectingKMeans.scala:148) finished in 0.190 s
2018-02-08 15:24:59,607 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: first at BisectingKMeans.scala:148, took 0.209062 s
2018-02-08 15:24:59,610 INFO[org.apache.spark.mllib.clustering.BisectingKMeans:54] - Feature dimension: 3.
2018-02-08 15:24:59,679 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:24:59,685 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 15 (map at BisectingKMeans.scala:153)
2018-02-08 15:24:59,686 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:24:59,686 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (collect at BisectingKMeans.scala:266)
2018-02-08 15:24:59,686 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 2)
2018-02-08 15:24:59,686 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 2)
2018-02-08 15:24:59,689 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 2 (MapPartitionsRDD[15] at map at BisectingKMeans.scala:153), which has no missing parents
2018-02-08 15:24:59,696 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 14.9 KB, free 631.4 MB)
2018-02-08 15:24:59,699 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.4 KB, free 631.4 MB)
2018-02-08 15:24:59,701 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:62246 (size: 7.4 KB, free: 631.8 MB)
2018-02-08 15:24:59,701 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:24:59,703 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[15] at map at BisectingKMeans.scala:153) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:24:59,703 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 15:24:59,708 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:24:59,709 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 15:24:59,722 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:24:59,739 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_12_0 stored as values in memory (estimated size 64.0 B, free 631.4 MB)
2018-02-08 15:24:59,740 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_12_0 in memory on 192.168.11.26:62246 (size: 64.0 B, free: 631.8 MB)
2018-02-08 15:24:59,754 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:24:59,795 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 2392 bytes result sent to driver
2018-02-08 15:24:59,797 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 93 ms on localhost (executor driver) (1/1)
2018-02-08 15:24:59,798 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 15:24:59,799 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 2 (map at BisectingKMeans.scala:153) finished in 0.094 s
2018-02-08 15:24:59,799 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:24:59,799 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:24:59,800 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 3)
2018-02-08 15:24:59,800 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:24:59,803 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (MapPartitionsRDD[17] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:24:59,808 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 15.9 KB, free 631.4 MB)
2018-02-08 15:24:59,810 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.7 KB, free 631.4 MB)
2018-02-08 15:24:59,811 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:62246 (size: 7.7 KB, free: 631.8 MB)
2018-02-08 15:24:59,812 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:24:59,813 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:24:59,813 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 15:24:59,816 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:24:59,816 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 15:24:59,831 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:24:59,833 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 15:24:59,852 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 15:24:59,853 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 15:24:59,858 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 2216 bytes result sent to driver
2018-02-08 15:24:59,859 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 44 ms on localhost (executor driver) (1/1)
2018-02-08 15:24:59,859 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 15:24:59,860 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (collect at BisectingKMeans.scala:266) finished in 0.045 s
2018-02-08 15:24:59,860 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: collect at BisectingKMeans.scala:266, took 0.180426 s
2018-02-08 15:24:59,863 INFO[org.apache.spark.mllib.clustering.BisectingKMeans:54] - Number of points: 6.
2018-02-08 15:24:59,864 INFO[org.apache.spark.mllib.clustering.BisectingKMeans:54] - Initial cost: 364.61999999999995.
2018-02-08 15:24:59,865 INFO[org.apache.spark.mllib.clustering.BisectingKMeans:54] - The minimum number of points of a divisible cluster is 1.
2018-02-08 15:24:59,866 INFO[org.apache.spark.mllib.clustering.BisectingKMeans:54] - Dividing 1 clusters on level 1.
2018-02-08 15:24:59,904 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:24:59,906 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 19 (filter at BisectingKMeans.scala:194)
2018-02-08 15:24:59,906 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:24:59,907 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (collect at BisectingKMeans.scala:266)
2018-02-08 15:24:59,907 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 4)
2018-02-08 15:24:59,907 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 4)
2018-02-08 15:24:59,908 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 4 (MapPartitionsRDD[19] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:24:59,910 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 16.2 KB, free 631.4 MB)
2018-02-08 15:24:59,912 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.4 MB)
2018-02-08 15:24:59,916 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:24:59,917 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:24:59,917 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[19] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:24:59,918 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
2018-02-08 15:24:59,920 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:24:59,921 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 15:24:59,926 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:24:59,927 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:24:59,950 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 1668 bytes result sent to driver
2018-02-08 15:24:59,951 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 32 ms on localhost (executor driver) (1/1)
2018-02-08 15:24:59,951 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 15:24:59,953 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 4 (filter at BisectingKMeans.scala:194) finished in 0.033 s
2018-02-08 15:24:59,953 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:24:59,953 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:24:59,953 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 5)
2018-02-08 15:24:59,953 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:24:59,954 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[21] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:24:59,957 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 17.3 KB, free 631.4 MB)
2018-02-08 15:24:59,960 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.3 MB)
2018-02-08 15:24:59,961 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:24:59,964 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:24:59,965 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:24:59,965 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
2018-02-08 15:24:59,966 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:24:59,967 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 6)
2018-02-08 15:24:59,972 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:24:59,972 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:24:59,975 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 6). 2312 bytes result sent to driver
2018-02-08 15:24:59,977 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 6) in 11 ms on localhost (executor driver) (1/1)
2018-02-08 15:24:59,977 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 15:24:59,979 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (collect at BisectingKMeans.scala:266) finished in 0.012 s
2018-02-08 15:24:59,981 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: collect at BisectingKMeans.scala:266, took 0.075714 s
2018-02-08 15:25:00,022 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:00,024 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 23 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:00,025 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:00,025 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 7 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:00,025 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 6)
2018-02-08 15:25:00,025 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 6)
2018-02-08 15:25:00,027 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:00,030 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 16.2 KB, free 631.3 MB)
2018-02-08 15:25:00,034 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.3 MB)
2018-02-08 15:25:00,036 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,036 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,037 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,037 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
2018-02-08 15:25:00,038 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:00,038 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 7)
2018-02-08 15:25:00,045 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:00,045 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:00,066 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 7). 1668 bytes result sent to driver
2018-02-08 15:25:00,068 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 7) in 30 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,068 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,069 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 6 (filter at BisectingKMeans.scala:194) finished in 0.032 s
2018-02-08 15:25:00,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:00,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:00,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 7)
2018-02-08 15:25:00,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:00,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 7 (MapPartitionsRDD[25] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:00,074 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 17.3 KB, free 631.3 MB)
2018-02-08 15:25:00,077 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.3 MB)
2018-02-08 15:25:00,079 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,080 INFO[org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,081 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[25] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,081 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
2018-02-08 15:25:00,082 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:00,085 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 8)
2018-02-08 15:25:00,090 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:00,091 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:25:00,093 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 8). 2312 bytes result sent to driver
2018-02-08 15:25:00,094 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 8) in 12 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,095 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,095 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 7 (collect at BisectingKMeans.scala:266) finished in 0.013 s
2018-02-08 15:25:00,097 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: collect at BisectingKMeans.scala:266, took 0.074056 s
2018-02-08 15:25:00,134 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:00,136 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 27 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:00,140 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:00,140 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 9 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:00,140 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 8)
2018-02-08 15:25:00,140 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 8)
2018-02-08 15:25:00,142 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 8 (MapPartitionsRDD[27] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:00,146 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 16.2 KB, free 631.3 MB)
2018-02-08 15:25:00,157 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.3 MB)
2018-02-08 15:25:00,162 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,165 INFO[org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,166 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[27] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,166 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 1 tasks
2018-02-08 15:25:00,167 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:00,168 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 9)
2018-02-08 15:25:00,179 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:00,180 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:00,212 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 9). 1668 bytes result sent to driver
2018-02-08 15:25:00,221 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 9) in 53 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,221 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,222 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 8 (filter at BisectingKMeans.scala:194) finished in 0.055 s
2018-02-08 15:25:00,223 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:00,223 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:00,223 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 9)
2018-02-08 15:25:00,223 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:00,223 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 9 (MapPartitionsRDD[29] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:00,227 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 17.3 KB, free 631.3 MB)
2018-02-08 15:25:00,231 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.2 MB)
2018-02-08 15:25:00,236 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,236 INFO[org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,237 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[29] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,237 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 1 tasks
2018-02-08 15:25:00,238 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:00,239 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 10)
2018-02-08 15:25:00,243 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:00,243 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:00,245 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 10). 2269 bytes result sent to driver
2018-02-08 15:25:00,246 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 10) in 8 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,246 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,247 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 9 (collect at BisectingKMeans.scala:266) finished in 0.008 s
2018-02-08 15:25:00,247 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: collect at BisectingKMeans.scala:266, took 0.113431 s
2018-02-08 15:25:00,280 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:00,304 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 31 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:00,305 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:00,305 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 11 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:00,305 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 10)
2018-02-08 15:25:00,306 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 10)
2018-02-08 15:25:00,309 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 10 (MapPartitionsRDD[31] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:00,316 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 16.2 KB, free 631.2 MB)
2018-02-08 15:25:00,324 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 2
2018-02-08 15:25:00,325 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.2 MB)
2018-02-08 15:25:00,329 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,333 INFO[org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,334 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[31] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,334 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 1 tasks
2018-02-08 15:25:00,334 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,335 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:00,336 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 11)
2018-02-08 15:25:00,339 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,341 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,341 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:00,342 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:00,359 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 11). 1668 bytes result sent to driver
2018-02-08 15:25:00,361 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,365 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 11) in 30 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,365 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,367 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 10 (filter at BisectingKMeans.scala:194) finished in 0.033 s
2018-02-08 15:25:00,367 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:00,367 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:00,367 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 11)
2018-02-08 15:25:00,367 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:00,371 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 11 (MapPartitionsRDD[33] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:00,374 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_3_piece0 on 192.168.11.26:62246 in memory (size: 6.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,374 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 17.3 KB, free 631.3 MB)
2018-02-08 15:25:00,379 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.3 MB)
2018-02-08 15:25:00,382 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,383 INFO[org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,383 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[33] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,384 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 1 tasks
2018-02-08 15:25:00,386 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 12, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:00,386 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 12)
2018-02-08 15:25:00,387 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_5_piece0 on 192.168.11.26:62246 in memory (size: 7.7 KB, free: 631.7 MB)
2018-02-08 15:25:00,389 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 0
2018-02-08 15:25:00,390 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:00,390 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:00,395 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 12). 2312 bytes result sent to driver
2018-02-08 15:25:00,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 12) in 12 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,398 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,398 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,399 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 11 (collect at BisectingKMeans.scala:266) finished in 0.015 s
2018-02-08 15:25:00,400 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: collect at BisectingKMeans.scala:266, took 0.097568 s
2018-02-08 15:25:00,405 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_4_piece0 on 192.168.11.26:62246 in memory (size: 7.4 KB, free: 631.7 MB)
2018-02-08 15:25:00,409 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 1
2018-02-08 15:25:00,418 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.8 MB)
2018-02-08 15:25:00,425 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 3
2018-02-08 15:25:00,434 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:00,435 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 35 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:00,435 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:00,435 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 13 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:00,435 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 12)
2018-02-08 15:25:00,435 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 12)
2018-02-08 15:25:00,439 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 12 (MapPartitionsRDD[35] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:00,442 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 16.2 KB, free 631.4 MB)
2018-02-08 15:25:00,445 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.4 MB)
2018-02-08 15:25:00,446 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,447 INFO[org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,447 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[35] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,447 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 12.0 with 1 tasks
2018-02-08 15:25:00,449 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:00,450 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 12.0 (TID 13)
2018-02-08 15:25:00,457 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:00,459 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:00,484 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 12.0 (TID 13). 1711 bytes result sent to driver
2018-02-08 15:25:00,486 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 12.0 (TID 13) in 37 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,487 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,487 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 12 (filter at BisectingKMeans.scala:194) finished in 0.039 s
2018-02-08 15:25:00,488 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:00,488 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:00,488 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 13)
2018-02-08 15:25:00,489 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:00,493 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 13 (MapPartitionsRDD[37] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:00,496 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 17.3 KB, free 631.4 MB)
2018-02-08 15:25:00,499 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.4 MB)
2018-02-08 15:25:00,502 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,503 INFO[org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,504 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[37] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,504 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 13.0 with 1 tasks
2018-02-08 15:25:00,509 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:00,509 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 13.0 (TID 14)
2018-02-08 15:25:00,515 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:00,515 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:00,520 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 13.0 (TID 14). 2312 bytes result sent to driver
2018-02-08 15:25:00,521 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 13.0 (TID 14) in 13 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,522 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,527 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 13 (collect at BisectingKMeans.scala:266) finished in 0.020 s
2018-02-08 15:25:00,533 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: collect at BisectingKMeans.scala:266, took 0.095262 s
2018-02-08 15:25:00,573 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:00,574 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 39 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:00,575 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:00,575 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 15 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:00,575 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 14)
2018-02-08 15:25:00,575 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 14)
2018-02-08 15:25:00,577 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 14 (MapPartitionsRDD[39] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:00,579 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16 stored as values in memory (estimated size 16.2 KB, free 631.3 MB)
2018-02-08 15:25:00,585 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.3 MB)
2018-02-08 15:25:00,586 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_16_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,587 INFO[org.apache.spark.SparkContext:54] - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,588 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[39] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,588 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 14.0 with 1 tasks
2018-02-08 15:25:00,589 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:00,589 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 14.0 (TID 15)
2018-02-08 15:25:00,595 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:00,596 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:00,613 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 14.0 (TID 15). 1668 bytes result sent to driver
2018-02-08 15:25:00,614 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 14.0 (TID 15) in 25 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,615 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,615 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 14 (filter at BisectingKMeans.scala:194) finished in 0.027 s
2018-02-08 15:25:00,615 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:00,616 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:00,616 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 15)
2018-02-08 15:25:00,616 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:00,616 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 15 (MapPartitionsRDD[41] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:00,618 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17 stored as values in memory (estimated size 17.3 KB, free 631.3 MB)
2018-02-08 15:25:00,620 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.3 MB)
2018-02-08 15:25:00,621 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_17_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,621 INFO[org.apache.spark.SparkContext:54] - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,622 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[41] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,622 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 15.0 with 1 tasks
2018-02-08 15:25:00,623 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 15.0 (TID 16, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:00,623 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 15.0 (TID 16)
2018-02-08 15:25:00,628 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:00,628 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:00,630 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 15.0 (TID 16). 2269 bytes result sent to driver
2018-02-08 15:25:00,631 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 15.0 (TID 16) in 8 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,633 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,633 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 15 (collect at BisectingKMeans.scala:266) finished in 0.011 s
2018-02-08 15:25:00,636 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: collect at BisectingKMeans.scala:266, took 0.062362 s
2018-02-08 15:25:00,663 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:00,664 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 43 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:00,665 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:00,665 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 17 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:00,665 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 16)
2018-02-08 15:25:00,665 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 16)
2018-02-08 15:25:00,666 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 16 (MapPartitionsRDD[43] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:00,675 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18 stored as values in memory (estimated size 16.2 KB, free 631.3 MB)
2018-02-08 15:25:00,680 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.3 MB)
2018-02-08 15:25:00,682 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_18_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,683 INFO[org.apache.spark.SparkContext:54] - Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,683 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[43] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,684 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 16.0 with 1 tasks
2018-02-08 15:25:00,685 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 16.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:00,685 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 16.0 (TID 17)
2018-02-08 15:25:00,694 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:00,695 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:00,719 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 16.0 (TID 17). 1668 bytes result sent to driver
2018-02-08 15:25:00,724 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 16.0 (TID 17) in 40 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,724 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,725 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 16 (filter at BisectingKMeans.scala:194) finished in 0.041 s
2018-02-08 15:25:00,725 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:00,725 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:00,725 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 17)
2018-02-08 15:25:00,725 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:00,726 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 17 (MapPartitionsRDD[45] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:00,732 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19 stored as values in memory (estimated size 17.3 KB, free 631.3 MB)
2018-02-08 15:25:00,738 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.3 MB)
2018-02-08 15:25:00,741 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_19_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,744 INFO[org.apache.spark.SparkContext:54] - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,745 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[45] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,745 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 17.0 with 1 tasks
2018-02-08 15:25:00,748 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 17.0 (TID 18, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:00,748 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 17.0 (TID 18)
2018-02-08 15:25:00,755 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:00,755 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:25:00,757 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 17.0 (TID 18). 2312 bytes result sent to driver
2018-02-08 15:25:00,758 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 17.0 (TID 18) in 11 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,758 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,759 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 17 (collect at BisectingKMeans.scala:266) finished in 0.013 s
2018-02-08 15:25:00,761 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: collect at BisectingKMeans.scala:266, took 0.096823 s
2018-02-08 15:25:00,798 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:00,799 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 47 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:00,799 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 10 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:00,799 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 19 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:00,799 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 18)
2018-02-08 15:25:00,800 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 18)
2018-02-08 15:25:00,800 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[47] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:00,802 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20 stored as values in memory (estimated size 16.2 KB, free 631.2 MB)
2018-02-08 15:25:00,805 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.2 MB)
2018-02-08 15:25:00,806 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_20_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,806 INFO[org.apache.spark.SparkContext:54] - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,807 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[47] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,807 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 18.0 with 1 tasks
2018-02-08 15:25:00,809 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 18.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:00,810 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 18.0 (TID 19)
2018-02-08 15:25:00,815 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:00,815 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:00,828 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 18.0 (TID 19). 1668 bytes result sent to driver
2018-02-08 15:25:00,829 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 18.0 (TID 19) in 20 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,829 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,830 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 18 (filter at BisectingKMeans.scala:194) finished in 0.020 s
2018-02-08 15:25:00,830 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:00,830 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:00,830 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 19)
2018-02-08 15:25:00,830 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:00,831 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 19 (MapPartitionsRDD[49] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:00,832 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21 stored as values in memory (estimated size 17.3 KB, free 631.2 MB)
2018-02-08 15:25:00,834 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.2 MB)
2018-02-08 15:25:00,836 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_21_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,836 INFO[org.apache.spark.SparkContext:54] - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,837 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[49] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,837 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 19.0 with 1 tasks
2018-02-08 15:25:00,838 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 19.0 (TID 20, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:00,838 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 19.0 (TID 20)
2018-02-08 15:25:00,841 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:00,841 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:00,844 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 19.0 (TID 20). 2312 bytes result sent to driver
2018-02-08 15:25:00,844 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 19.0 (TID 20) in 7 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,844 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,845 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 19 (collect at BisectingKMeans.scala:266) finished in 0.008 s
2018-02-08 15:25:00,846 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 10 finished: collect at BisectingKMeans.scala:266, took 0.047337 s
2018-02-08 15:25:00,867 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:00,868 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 51 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:00,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 11 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:00,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 21 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:00,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 20)
2018-02-08 15:25:00,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 20)
2018-02-08 15:25:00,870 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[51] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:00,872 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22 stored as values in memory (estimated size 16.2 KB, free 631.2 MB)
2018-02-08 15:25:00,877 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.2 MB)
2018-02-08 15:25:00,877 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_22_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,878 INFO[org.apache.spark.SparkContext:54] - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,878 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[51] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,878 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 20.0 with 1 tasks
2018-02-08 15:25:00,879 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 20.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:00,879 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 20.0 (TID 21)
2018-02-08 15:25:00,883 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:00,883 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:00,897 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 20.0 (TID 21). 1668 bytes result sent to driver
2018-02-08 15:25:00,898 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 20.0 (TID 21) in 19 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,898 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,899 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 20 (filter at BisectingKMeans.scala:194) finished in 0.020 s
2018-02-08 15:25:00,899 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:00,899 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:00,899 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 21)
2018-02-08 15:25:00,899 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:00,900 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 21 (MapPartitionsRDD[53] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:00,901 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23 stored as values in memory (estimated size 17.3 KB, free 631.2 MB)
2018-02-08 15:25:00,903 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.2 MB)
2018-02-08 15:25:00,904 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_23_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,905 INFO[org.apache.spark.SparkContext:54] - Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,905 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[53] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,905 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 21.0 with 1 tasks
2018-02-08 15:25:00,907 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 21.0 (TID 22, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:00,908 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 21.0 (TID 22)
2018-02-08 15:25:00,911 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:00,911 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:00,913 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 21.0 (TID 22). 2269 bytes result sent to driver
2018-02-08 15:25:00,913 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 21.0 (TID 22) in 7 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,913 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,914 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 21 (collect at BisectingKMeans.scala:266) finished in 0.008 s
2018-02-08 15:25:00,915 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 11 finished: collect at BisectingKMeans.scala:266, took 0.046220 s
2018-02-08 15:25:00,937 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:00,939 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 55 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:00,939 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 12 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:00,939 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 23 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:00,939 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 22)
2018-02-08 15:25:00,940 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 22)
2018-02-08 15:25:00,942 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 22 (MapPartitionsRDD[55] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:00,944 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24 stored as values in memory (estimated size 16.2 KB, free 631.1 MB)
2018-02-08 15:25:00,947 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.1 MB)
2018-02-08 15:25:00,948 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_24_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:00,948 INFO[org.apache.spark.SparkContext:54] - Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,949 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[55] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,949 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 22.0 with 1 tasks
2018-02-08 15:25:00,950 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 22.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:00,950 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 22.0 (TID 23)
2018-02-08 15:25:00,954 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:00,955 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:00,972 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 22.0 (TID 23). 1711 bytes result sent to driver
2018-02-08 15:25:00,974 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 22.0 (TID 23) in 24 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:00,974 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2018-02-08 15:25:00,974 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 22 (filter at BisectingKMeans.scala:194) finished in 0.024 s
2018-02-08 15:25:00,975 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:00,975 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:00,975 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 23)
2018-02-08 15:25:00,975 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:00,975 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 23 (MapPartitionsRDD[57] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:00,977 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25 stored as values in memory (estimated size 17.3 KB, free 631.1 MB)
2018-02-08 15:25:00,979 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.1 MB)
2018-02-08 15:25:00,980 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_25_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:00,981 INFO[org.apache.spark.SparkContext:54] - Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:00,981 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[57] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:00,981 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 23.0 with 1 tasks
2018-02-08 15:25:00,982 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 23.0 (TID 24, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:00,982 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 23.0 (TID 24)
2018-02-08 15:25:00,988 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:00,988 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:00,991 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 23.0 (TID 24). 2312 bytes result sent to driver
2018-02-08 15:25:01,002 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 23.0 (TID 24) in 18 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,002 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,003 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 23 (collect at BisectingKMeans.scala:266) finished in 0.021 s
2018-02-08 15:25:01,004 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 12 finished: collect at BisectingKMeans.scala:266, took 0.066548 s
2018-02-08 15:25:01,034 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:01,037 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 59 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:01,038 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 13 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:01,038 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 25 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:01,038 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 24)
2018-02-08 15:25:01,038 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 24)
2018-02-08 15:25:01,039 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 24 (MapPartitionsRDD[59] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:01,041 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_26 stored as values in memory (estimated size 16.2 KB, free 631.1 MB)
2018-02-08 15:25:01,044 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.1 MB)
2018-02-08 15:25:01,046 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_26_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:01,046 INFO[org.apache.spark.SparkContext:54] - Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,048 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[59] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,048 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 24.0 with 1 tasks
2018-02-08 15:25:01,049 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 24.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:01,049 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 24.0 (TID 25)
2018-02-08 15:25:01,055 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:01,056 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:01,077 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 24.0 (TID 25). 1668 bytes result sent to driver
2018-02-08 15:25:01,078 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 24.0 (TID 25) in 30 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,078 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,078 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 24 (filter at BisectingKMeans.scala:194) finished in 0.030 s
2018-02-08 15:25:01,078 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:01,078 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:01,079 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 25)
2018-02-08 15:25:01,079 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:01,079 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 25 (MapPartitionsRDD[61] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:01,081 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_27 stored as values in memory (estimated size 17.3 KB, free 631.1 MB)
2018-02-08 15:25:01,087 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.1 MB)
2018-02-08 15:25:01,087 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_27_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,088 INFO[org.apache.spark.SparkContext:54] - Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,088 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[61] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,088 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 25.0 with 1 tasks
2018-02-08 15:25:01,089 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 25.0 (TID 26, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:01,089 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 25.0 (TID 26)
2018-02-08 15:25:01,092 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:01,093 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:25:01,098 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 25.0 (TID 26). 2312 bytes result sent to driver
2018-02-08 15:25:01,098 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 25.0 (TID 26) in 9 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,098 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,099 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 25 (collect at BisectingKMeans.scala:266) finished in 0.010 s
2018-02-08 15:25:01,101 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 13 finished: collect at BisectingKMeans.scala:266, took 0.066160 s
2018-02-08 15:25:01,123 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:01,124 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 63 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:01,124 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 14 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:01,124 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 27 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:01,124 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 26)
2018-02-08 15:25:01,124 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 26)
2018-02-08 15:25:01,126 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 26 (MapPartitionsRDD[63] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:01,128 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_28 stored as values in memory (estimated size 16.2 KB, free 631.1 MB)
2018-02-08 15:25:01,130 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.0 MB)
2018-02-08 15:25:01,132 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_28_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:01,132 INFO[org.apache.spark.SparkContext:54] - Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,133 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[63] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,133 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 26.0 with 1 tasks
2018-02-08 15:25:01,134 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 26.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:01,134 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 26.0 (TID 27)
2018-02-08 15:25:01,138 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:01,138 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:01,151 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 26.0 (TID 27). 1668 bytes result sent to driver
2018-02-08 15:25:01,152 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 26.0 (TID 27) in 19 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,152 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,152 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 26 (filter at BisectingKMeans.scala:194) finished in 0.019 s
2018-02-08 15:25:01,153 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:01,153 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:01,153 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 27)
2018-02-08 15:25:01,153 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:01,153 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 27 (MapPartitionsRDD[65] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:01,155 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_29 stored as values in memory (estimated size 17.3 KB, free 631.0 MB)
2018-02-08 15:25:01,158 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.0 MB)
2018-02-08 15:25:01,159 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_29_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,160 INFO[org.apache.spark.SparkContext:54] - Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,160 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[65] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,161 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 27.0 with 1 tasks
2018-02-08 15:25:01,161 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 27.0 (TID 28, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:01,162 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 27.0 (TID 28)
2018-02-08 15:25:01,166 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:01,166 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:01,168 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 27.0 (TID 28). 2269 bytes result sent to driver
2018-02-08 15:25:01,169 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 27.0 (TID 28) in 8 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,169 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,169 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 27 (collect at BisectingKMeans.scala:266) finished in 0.008 s
2018-02-08 15:25:01,169 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 14 finished: collect at BisectingKMeans.scala:266, took 0.046408 s
2018-02-08 15:25:01,203 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:01,208 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 67 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:01,209 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 15 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:01,209 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 29 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:01,209 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 28)
2018-02-08 15:25:01,210 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 28)
2018-02-08 15:25:01,219 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 28 (MapPartitionsRDD[67] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:01,222 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_30 stored as values in memory (estimated size 16.2 KB, free 631.0 MB)
2018-02-08 15:25:01,225 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_30_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.0 MB)
2018-02-08 15:25:01,229 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_30_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:01,230 INFO[org.apache.spark.SparkContext:54] - Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,231 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[67] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,232 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 28.0 with 1 tasks
2018-02-08 15:25:01,235 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 28.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:01,236 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 28.0 (TID 29)
2018-02-08 15:25:01,242 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:01,243 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:01,269 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 28.0 (TID 29). 1711 bytes result sent to driver
2018-02-08 15:25:01,272 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 28.0 (TID 29) in 39 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,272 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,273 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 28 (filter at BisectingKMeans.scala:194) finished in 0.041 s
2018-02-08 15:25:01,273 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:01,273 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:01,273 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 29)
2018-02-08 15:25:01,273 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:01,278 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 29 (MapPartitionsRDD[69] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:01,287 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_31 stored as values in memory (estimated size 17.3 KB, free 631.0 MB)
2018-02-08 15:25:01,309 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_31_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.0 MB)
2018-02-08 15:25:01,310 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_31_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,311 INFO[org.apache.spark.SparkContext:54] - Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,311 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[69] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,312 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 29.0 with 1 tasks
2018-02-08 15:25:01,324 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 29.0 (TID 30, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:01,328 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 29.0 (TID 30)
2018-02-08 15:25:01,337 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:01,337 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:01,345 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 29.0 (TID 30). 2312 bytes result sent to driver
2018-02-08 15:25:01,347 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 29.0 (TID 30) in 25 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,347 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,348 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 29 (collect at BisectingKMeans.scala:266) finished in 0.036 s
2018-02-08 15:25:01,350 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 15 finished: collect at BisectingKMeans.scala:266, took 0.147528 s
2018-02-08 15:25:01,379 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:01,379 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 71 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:01,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 16 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:01,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 31 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:01,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 30)
2018-02-08 15:25:01,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 30)
2018-02-08 15:25:01,381 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 30 (MapPartitionsRDD[71] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:01,383 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_32 stored as values in memory (estimated size 16.2 KB, free 631.0 MB)
2018-02-08 15:25:01,385 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_32_piece0 stored as bytes in memory (estimated size 8.0 KB, free 630.9 MB)
2018-02-08 15:25:01,386 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_32_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:01,387 INFO[org.apache.spark.SparkContext:54] - Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,387 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[71] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,387 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 30.0 with 1 tasks
2018-02-08 15:25:01,388 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 30.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:01,388 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 30.0 (TID 31)
2018-02-08 15:25:01,391 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:01,392 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:01,405 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 30.0 (TID 31). 1668 bytes result sent to driver
2018-02-08 15:25:01,407 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 30.0 (TID 31) in 19 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,407 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,409 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 30 (filter at BisectingKMeans.scala:194) finished in 0.021 s
2018-02-08 15:25:01,409 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:01,409 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:01,409 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 31)
2018-02-08 15:25:01,409 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:01,410 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 31 (MapPartitionsRDD[73] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:01,412 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_33 stored as values in memory (estimated size 17.3 KB, free 630.9 MB)
2018-02-08 15:25:01,414 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.3 KB, free 630.9 MB)
2018-02-08 15:25:01,414 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_33_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,415 INFO[org.apache.spark.SparkContext:54] - Created broadcast 33 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,415 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[73] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,415 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 31.0 with 1 tasks
2018-02-08 15:25:01,417 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 31.0 (TID 32, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:01,418 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 31.0 (TID 32)
2018-02-08 15:25:01,425 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:01,425 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:01,427 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 31.0 (TID 32). 2312 bytes result sent to driver
2018-02-08 15:25:01,428 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 31.0 (TID 32) in 11 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,428 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,429 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 31 (collect at BisectingKMeans.scala:266) finished in 0.014 s
2018-02-08 15:25:01,429 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 16 finished: collect at BisectingKMeans.scala:266, took 0.050291 s
2018-02-08 15:25:01,454 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:01,458 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 75 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:01,458 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 17 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:01,458 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 33 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:01,459 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 32)
2018-02-08 15:25:01,459 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 32)
2018-02-08 15:25:01,462 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 32 (MapPartitionsRDD[75] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:01,466 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_34 stored as values in memory (estimated size 16.2 KB, free 630.9 MB)
2018-02-08 15:25:01,469 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_34_piece0 stored as bytes in memory (estimated size 8.0 KB, free 630.9 MB)
2018-02-08 15:25:01,471 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_34_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:01,474 INFO[org.apache.spark.SparkContext:54] - Created broadcast 34 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,474 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[75] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,475 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 32.0 with 1 tasks
2018-02-08 15:25:01,476 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 32.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:01,477 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 32.0 (TID 33)
2018-02-08 15:25:01,482 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:01,486 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:01,525 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 32.0 (TID 33). 1668 bytes result sent to driver
2018-02-08 15:25:01,526 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 32.0 (TID 33) in 50 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,527 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,527 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 32 (filter at BisectingKMeans.scala:194) finished in 0.052 s
2018-02-08 15:25:01,528 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:01,528 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:01,528 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 33)
2018-02-08 15:25:01,528 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:01,528 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 33 (MapPartitionsRDD[77] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:01,534 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_35 stored as values in memory (estimated size 17.3 KB, free 630.9 MB)
2018-02-08 15:25:01,538 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_35_piece0 stored as bytes in memory (estimated size 8.3 KB, free 630.9 MB)
2018-02-08 15:25:01,539 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_35_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,539 INFO[org.apache.spark.SparkContext:54] - Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,540 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[77] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,540 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 33.0 with 1 tasks
2018-02-08 15:25:01,541 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 33.0 (TID 34, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:01,541 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 33.0 (TID 34)
2018-02-08 15:25:01,565 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:01,565 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:01,568 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 33.0 (TID 34). 2269 bytes result sent to driver
2018-02-08 15:25:01,570 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 33.0 (TID 34) in 30 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,570 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,570 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 33 (collect at BisectingKMeans.scala:266) finished in 0.030 s
2018-02-08 15:25:01,571 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 17 finished: collect at BisectingKMeans.scala:266, took 0.115979 s
2018-02-08 15:25:01,601 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:01,602 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 79 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:01,602 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 18 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:01,602 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 35 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:01,602 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 34)
2018-02-08 15:25:01,603 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 34)
2018-02-08 15:25:01,604 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 34 (MapPartitionsRDD[79] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:01,607 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_36 stored as values in memory (estimated size 16.2 KB, free 630.9 MB)
2018-02-08 15:25:01,611 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.0 KB, free 630.9 MB)
2018-02-08 15:25:01,612 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_36_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:01,612 INFO[org.apache.spark.SparkContext:54] - Created broadcast 36 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,613 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[79] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,613 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 34.0 with 1 tasks
2018-02-08 15:25:01,615 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 34.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:01,615 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 34.0 (TID 35)
2018-02-08 15:25:01,620 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:01,621 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:01,638 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 34.0 (TID 35). 1668 bytes result sent to driver
2018-02-08 15:25:01,639 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 34.0 (TID 35) in 25 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,639 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,639 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 34 (filter at BisectingKMeans.scala:194) finished in 0.026 s
2018-02-08 15:25:01,639 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:01,640 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:01,640 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 35)
2018-02-08 15:25:01,640 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:01,641 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 35 (MapPartitionsRDD[81] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:01,645 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_37 stored as values in memory (estimated size 17.3 KB, free 630.8 MB)
2018-02-08 15:25:01,647 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_37_piece0 stored as bytes in memory (estimated size 8.3 KB, free 630.8 MB)
2018-02-08 15:25:01,649 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_37_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,650 INFO[org.apache.spark.SparkContext:54] - Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,650 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[81] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,650 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 35.0 with 1 tasks
2018-02-08 15:25:01,651 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 35.0 (TID 36, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:01,651 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 35.0 (TID 36)
2018-02-08 15:25:01,654 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:01,654 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:01,657 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 35.0 (TID 36). 2312 bytes result sent to driver
2018-02-08 15:25:01,658 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 35.0 (TID 36) in 7 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,658 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,659 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 35 (collect at BisectingKMeans.scala:266) finished in 0.009 s
2018-02-08 15:25:01,659 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 18 finished: collect at BisectingKMeans.scala:266, took 0.057639 s
2018-02-08 15:25:01,685 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:01,689 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 83 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:01,689 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 19 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:01,689 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 37 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:01,689 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 36)
2018-02-08 15:25:01,690 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 36)
2018-02-08 15:25:01,694 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 36 (MapPartitionsRDD[83] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:01,696 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_38 stored as values in memory (estimated size 16.2 KB, free 630.8 MB)
2018-02-08 15:25:01,700 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_38_piece0 stored as bytes in memory (estimated size 8.0 KB, free 630.8 MB)
2018-02-08 15:25:01,701 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_38_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:01,701 INFO[org.apache.spark.SparkContext:54] - Created broadcast 38 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,702 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[83] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,702 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 36.0 with 1 tasks
2018-02-08 15:25:01,703 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 36.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:01,703 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 36.0 (TID 37)
2018-02-08 15:25:01,707 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:01,709 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:01,732 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 36.0 (TID 37). 1668 bytes result sent to driver
2018-02-08 15:25:01,734 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 36.0 (TID 37) in 32 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,734 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,735 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 36 (filter at BisectingKMeans.scala:194) finished in 0.032 s
2018-02-08 15:25:01,736 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:01,736 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:01,736 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 37)
2018-02-08 15:25:01,736 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:01,737 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 37 (MapPartitionsRDD[85] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:01,742 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_39 stored as values in memory (estimated size 17.3 KB, free 630.8 MB)
2018-02-08 15:25:01,745 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_39_piece0 stored as bytes in memory (estimated size 8.3 KB, free 630.8 MB)
2018-02-08 15:25:01,746 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_39_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,748 INFO[org.apache.spark.SparkContext:54] - Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,749 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[85] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,749 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 37.0 with 1 tasks
2018-02-08 15:25:01,753 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 37.0 (TID 38, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:01,753 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 37.0 (TID 38)
2018-02-08 15:25:01,760 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:01,761 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:25:01,764 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 37.0 (TID 38). 2269 bytes result sent to driver
2018-02-08 15:25:01,766 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 37.0 (TID 38) in 14 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,766 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,766 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 37 (collect at BisectingKMeans.scala:266) finished in 0.016 s
2018-02-08 15:25:01,767 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 19 finished: collect at BisectingKMeans.scala:266, took 0.081375 s
2018-02-08 15:25:01,803 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:01,804 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 87 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:01,804 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 20 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:01,804 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 39 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:01,804 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 38)
2018-02-08 15:25:01,804 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 38)
2018-02-08 15:25:01,805 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 38 (MapPartitionsRDD[87] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:01,809 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_40 stored as values in memory (estimated size 16.2 KB, free 630.8 MB)
2018-02-08 15:25:01,813 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_40_piece0 stored as bytes in memory (estimated size 8.0 KB, free 630.8 MB)
2018-02-08 15:25:01,814 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_40_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.5 MB)
2018-02-08 15:25:01,814 INFO[org.apache.spark.SparkContext:54] - Created broadcast 40 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,816 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[87] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,816 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 38.0 with 1 tasks
2018-02-08 15:25:01,817 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 38.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:01,817 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 38.0 (TID 39)
2018-02-08 15:25:01,821 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:01,822 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:01,840 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 38.0 (TID 39). 1668 bytes result sent to driver
2018-02-08 15:25:01,841 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 38.0 (TID 39) in 24 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,842 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,842 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 38 (filter at BisectingKMeans.scala:194) finished in 0.026 s
2018-02-08 15:25:01,842 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:01,842 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:01,842 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 39)
2018-02-08 15:25:01,842 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:01,843 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 39 (MapPartitionsRDD[89] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:01,844 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_41 stored as values in memory (estimated size 17.3 KB, free 630.7 MB)
2018-02-08 15:25:01,857 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_41_piece0 stored as bytes in memory (estimated size 8.3 KB, free 630.7 MB)
2018-02-08 15:25:01,857 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_41_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.5 MB)
2018-02-08 15:25:01,859 INFO[org.apache.spark.SparkContext:54] - Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,859 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[89] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,859 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 39.0 with 1 tasks
2018-02-08 15:25:01,860 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 39.0 (TID 40, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:01,860 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 13
2018-02-08 15:25:01,860 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 39.0 (TID 40)
2018-02-08 15:25:01,863 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:01,863 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:01,866 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 39.0 (TID 40). 2269 bytes result sent to driver
2018-02-08 15:25:01,868 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_20_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.5 MB)
2018-02-08 15:25:01,869 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 39.0 (TID 40) in 10 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,869 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,870 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 39 (collect at BisectingKMeans.scala:266) finished in 0.011 s
2018-02-08 15:25:01,871 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 20 finished: collect at BisectingKMeans.scala:266, took 0.067589 s
2018-02-08 15:25:01,875 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_24_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.5 MB)
2018-02-08 15:25:01,878 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 6
2018-02-08 15:25:01,886 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_39_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,904 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_21_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,911 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:01,912 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 91 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:01,913 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 21 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:01,913 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 41 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:01,913 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 40)
2018-02-08 15:25:01,913 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_25_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,913 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 40)
2018-02-08 15:25:01,914 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 40 (MapPartitionsRDD[91] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:01,917 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_42 stored as values in memory (estimated size 16.2 KB, free 630.8 MB)
2018-02-08 15:25:01,925 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_42_piece0 stored as bytes in memory (estimated size 8.0 KB, free 630.8 MB)
2018-02-08 15:25:01,917 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 12
2018-02-08 15:25:01,927 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_42_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:01,928 INFO[org.apache.spark.SparkContext:54] - Created broadcast 42 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,929 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[91] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,929 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 40.0 with 1 tasks
2018-02-08 15:25:01,930 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 40.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:01,931 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 11
2018-02-08 15:25:01,931 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 40.0 (TID 41)
2018-02-08 15:25:01,940 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:01,941 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:01,944 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_34_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:01,954 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 5
2018-02-08 15:25:01,955 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 4
2018-02-08 15:25:01,956 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 7
2018-02-08 15:25:01,960 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_30_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:01,963 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 40.0 (TID 41). 1625 bytes result sent to driver
2018-02-08 15:25:01,967 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 40.0 (TID 41) in 37 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:01,967 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2018-02-08 15:25:01,969 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_17_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,971 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 40 (filter at BisectingKMeans.scala:194) finished in 0.041 s
2018-02-08 15:25:01,971 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:01,971 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:01,971 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 41)
2018-02-08 15:25:01,971 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:01,972 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 41 (MapPartitionsRDD[93] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:01,974 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 16
2018-02-08 15:25:01,975 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_43 stored as values in memory (estimated size 17.3 KB, free 630.9 MB)
2018-02-08 15:25:01,979 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_43_piece0 stored as bytes in memory (estimated size 8.3 KB, free 630.9 MB)
2018-02-08 15:25:01,983 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_43_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,986 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_37_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:01,987 INFO[org.apache.spark.SparkContext:54] - Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:01,988 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[93] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:01,988 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 41.0 with 1 tasks
2018-02-08 15:25:01,989 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 41.0 (TID 42, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:01,990 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 41.0 (TID 42)
2018-02-08 15:25:01,991 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_12_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:01,999 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:01,999 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:02,004 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 41.0 (TID 42). 2312 bytes result sent to driver
2018-02-08 15:25:02,006 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 41.0 (TID 42) in 17 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:02,006 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2018-02-08 15:25:02,007 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 41 (collect at BisectingKMeans.scala:266) finished in 0.018 s
2018-02-08 15:25:02,008 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_28_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:02,009 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 21 finished: collect at BisectingKMeans.scala:266, took 0.097102 s
2018-02-08 15:25:02,011 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_29_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:02,016 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_32_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:02,018 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 17
2018-02-08 15:25:02,019 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_23_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:02,027 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_33_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.6 MB)
2018-02-08 15:25:02,034 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_14_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.6 MB)
2018-02-08 15:25:02,035 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 15
2018-02-08 15:25:02,042 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at BisectingKMeans.scala:266
2018-02-08 15:25:02,043 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_26_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:02,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 95 (filter at BisectingKMeans.scala:194)
2018-02-08 15:25:02,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 22 (collect at BisectingKMeans.scala:266) with 1 output partitions
2018-02-08 15:25:02,044 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 43 (collect at BisectingKMeans.scala:266)
2018-02-08 15:25:02,044 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 42)
2018-02-08 15:25:02,044 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 42)
2018-02-08 15:25:02,045 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 42 (MapPartitionsRDD[95] at filter at BisectingKMeans.scala:194), which has no missing parents
2018-02-08 15:25:02,045 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_36_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:02,046 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_44 stored as values in memory (estimated size 16.2 KB, free 631.1 MB)
2018-02-08 15:25:02,047 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_19_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:02,049 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_44_piece0 stored as bytes in memory (estimated size 8.0 KB, free 631.1 MB)
2018-02-08 15:25:02,049 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_44_piece0 in memory on 192.168.11.26:62246 (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:02,050 INFO[org.apache.spark.SparkContext:54] - Created broadcast 44 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:02,050 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[95] at filter at BisectingKMeans.scala:194) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:02,050 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 42.0 with 1 tasks
2018-02-08 15:25:02,051 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 8
2018-02-08 15:25:02,052 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 42.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:25:02,053 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 42.0 (TID 43)
2018-02-08 15:25:02,055 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_27_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:02,057 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_12_0 locally
2018-02-08 15:25:02,057 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:02,063 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_31_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:02,064 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_38_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:02,072 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_18_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:02,073 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 42.0 (TID 43). 1668 bytes result sent to driver
2018-02-08 15:25:02,076 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 42.0 (TID 43) in 25 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:02,076 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2018-02-08 15:25:02,077 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 14
2018-02-08 15:25:02,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 42 (filter at BisectingKMeans.scala:194) finished in 0.026 s
2018-02-08 15:25:02,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:25:02,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:25:02,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 43)
2018-02-08 15:25:02,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:25:02,078 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 43 (MapPartitionsRDD[97] at mapValues at BisectingKMeans.scala:265), which has no missing parents
2018-02-08 15:25:02,079 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_45 stored as values in memory (estimated size 17.3 KB, free 631.2 MB)
2018-02-08 15:25:02,082 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_45_piece0 stored as bytes in memory (estimated size 8.3 KB, free 631.2 MB)
2018-02-08 15:25:02,083 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_45_piece0 in memory on 192.168.11.26:62246 (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:02,083 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 9
2018-02-08 15:25:02,086 INFO[org.apache.spark.SparkContext:54] - Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:02,087 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[97] at mapValues at BisectingKMeans.scala:265) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:02,087 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 43.0 with 1 tasks
2018-02-08 15:25:02,088 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 43.0 (TID 44, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:25:02,088 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 10
2018-02-08 15:25:02,089 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 43.0 (TID 44)
2018-02-08 15:25:02,090 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_22_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:02,091 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_15_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:02,092 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:25:02,092 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:25:02,095 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 43.0 (TID 44). 2312 bytes result sent to driver
2018-02-08 15:25:02,096 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_13_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:02,098 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 43.0 (TID 44) in 11 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:02,099 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2018-02-08 15:25:02,100 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 43 (collect at BisectingKMeans.scala:266) finished in 0.013 s
2018-02-08 15:25:02,100 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 22 finished: collect at BisectingKMeans.scala:266, took 0.058112 s
2018-02-08 15:25:02,107 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_35_piece0 on 192.168.11.26:62246 in memory (size: 8.3 KB, free: 631.7 MB)
2018-02-08 15:25:02,111 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_16_piece0 on 192.168.11.26:62246 in memory (size: 8.0 KB, free: 631.7 MB)
2018-02-08 15:25:02,115 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 99 from persistence list
2018-02-08 15:25:02,120 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 99
2018-02-08 15:25:02,416 INFO[org.apache.spark.ml.util.Instrumentation:54] - BisectingKMeans-bisecting-kmeans_530ee1cc8d8a-828174704-1: training finished
2018-02-08 15:25:02,423 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:25:02,424 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:25:02,424 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:25:02,424 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:25:02,429 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_46 stored as values in memory (estimated size 322.9 KB, free 631.0 MB)
2018-02-08 15:25:02,446 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_46_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.0 MB)
2018-02-08 15:25:02,446 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_46_piece0 in memory on 192.168.11.26:62246 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:25:02,447 INFO[org.apache.spark.SparkContext:54] - Created broadcast 46 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:25:02,448 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:25:02,472 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at BisectingKMeansModel.scala:94
2018-02-08 15:25:02,476 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 23 (sum at BisectingKMeansModel.scala:94) with 1 output partitions
2018-02-08 15:25:02,476 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 44 (sum at BisectingKMeansModel.scala:94)
2018-02-08 15:25:02,476 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:25:02,476 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:25:02,477 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 44 (MapPartitionsRDD[107] at map at BisectingKMeansModel.scala:94), which has no missing parents
2018-02-08 15:25:02,479 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_47 stored as values in memory (estimated size 12.8 KB, free 631.0 MB)
2018-02-08 15:25:02,481 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_47_piece0 stored as bytes in memory (estimated size 6.7 KB, free 631.0 MB)
2018-02-08 15:25:02,481 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_47_piece0 in memory on 192.168.11.26:62246 (size: 6.7 KB, free: 631.7 MB)
2018-02-08 15:25:02,482 INFO[org.apache.spark.SparkContext:54] - Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:25:02,482 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[107] at map at BisectingKMeansModel.scala:94) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:25:02,482 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 44.0 with 1 tasks
2018-02-08 15:25:02,483 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 44.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:25:02,483 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 44.0 (TID 45)
2018-02-08 15:25:02,486 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:25:02,494 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 44.0 (TID 45). 1391 bytes result sent to driver
2018-02-08 15:25:02,495 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 44.0 (TID 45) in 13 ms on localhost (executor driver) (1/1)
2018-02-08 15:25:02,495 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2018-02-08 15:25:02,495 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 44 (sum at BisectingKMeansModel.scala:94) finished in 0.013 s
2018-02-08 15:25:02,495 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 23 finished: sum at BisectingKMeansModel.scala:94, took 0.023056 s
2018-02-08 15:25:02,503 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:25:02,508 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@6b1b83d4{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:25:02,510 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:25:02,519 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:25:02,609 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:25:02,609 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:25:02,610 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:25:02,612 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:25:02,614 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:25:02,615 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:25:02,615 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-d80c99bb-076a-49c5-8159-2c15afa4d395
2018-02-08 15:26:21,266 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:26:21,939 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:26:21,958 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:26:21,959 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:26:21,959 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:26:21,960 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:26:21,960 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:26:22,300 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62276.
2018-02-08 15:26:22,317 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:26:22,361 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:26:22,363 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:26:22,364 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:26:22,371 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-fab2d946-cafe-4e9d-a141-c659432c9c1e
2018-02-08 15:26:22,391 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:26:22,441 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:26:22,511 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2712ms
2018-02-08 15:26:22,573 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:26:22,585 INFO[org.spark_project.jetty.server.Server:403] - Started @2787ms
2018-02-08 15:26:22,603 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@34a1d21f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:26:22,603 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:26:22,626 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1c9f0a20{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,627 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,627 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,629 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a3591c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,629 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@346a361{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,630 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1643d68f{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,631 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2e029d61{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,632 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,632 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,635 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,635 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,636 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,637 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,638 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,639 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,640 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,641 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,642 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,642 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,643 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,649 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/static,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,650 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@592e843a{/,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,651 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@423e4cbb{/api,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,652 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a1edad4{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,652 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@44c79f32{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:26:22,654 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:26:22,743 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:26:22,771 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62289.
2018-02-08 15:26:22,772 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62289
2018-02-08 15:26:22,774 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:26:22,775 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62289, None)
2018-02-08 15:26:22,784 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62289 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62289, None)
2018-02-08 15:26:22,791 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62289, None)
2018-02-08 15:26:22,792 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62289, None)
2018-02-08 15:26:22,944 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4a67318f{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:23,008 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:26:23,009 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:26:23,015 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@11ce2e22{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:26:23,020 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@13cda7c9{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:23,021 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62d0ac62{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:26:23,022 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6826c41e{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:26:23,023 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410e94e{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:26:23,993 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:26:24,350 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 15:26:24,405 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 15:26:24,408 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:62289 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:26:24,412 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 15:26:24,512 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 15:26:24,524 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 15:26:24,541 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 15:26:24,542 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 15:26:24,542 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:26:24,544 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:26:24,549 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 15:26:24,595 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 15:26:24,599 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 15:26:24,600 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:62289 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:26:24,601 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:26:24,617 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 15:26:24,618 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 15:26:24,659 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:26:24,661 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:26:24,671 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:26:24,671 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 15:26:24,734 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:60+60
2018-02-08 15:26:24,735 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:0+60
2018-02-08 15:26:24,795 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 953 bytes result sent to driver
2018-02-08 15:26:24,795 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 953 bytes result sent to driver
2018-02-08 15:26:24,802 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 141 ms on localhost (executor driver) (1/2)
2018-02-08 15:26:24,804 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 160 ms on localhost (executor driver) (2/2)
2018-02-08 15:26:24,805 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:26:24,809 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.176 s
2018-02-08 15:26:24,814 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.289765 s
2018-02-08 15:26:25,610 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:62289 in memory (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:26:25,613 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:62289 in memory (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:26:26,238 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:26:26,241 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:26:26,243 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:26:26,249 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:26:26,570 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 210.362627 ms
2018-02-08 15:26:26,582 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:26:26,597 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:26:26,599 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:62289 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:26:26,600 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:26:26,611 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:26:26,730 INFO[org.apache.spark.SparkContext:54] - Starting job: first at GaussianMixture.scala:348
2018-02-08 15:26:26,731 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (first at GaussianMixture.scala:348) with 1 output partitions
2018-02-08 15:26:26,732 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (first at GaussianMixture.scala:348)
2018-02-08 15:26:26,732 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:26:26,734 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:26:26,735 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[10] at map at GaussianMixture.scala:343), which has no missing parents
2018-02-08 15:26:26,741 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 11.1 KB, free 631.4 MB)
2018-02-08 15:26:26,745 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KB, free 631.4 MB)
2018-02-08 15:26:26,746 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:62289 (size: 5.9 KB, free: 631.8 MB)
2018-02-08 15:26:26,746 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:26:26,747 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[10] at map at GaussianMixture.scala:343) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:26:26,747 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 15:26:26,752 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:26:26,752 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 15:26:26,798 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.466885 ms
2018-02-08 15:26:26,805 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:26:26,844 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 23.660808 ms
2018-02-08 15:26:26,882 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.808646 ms
2018-02-08 15:26:26,930 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 31.21985 ms
2018-02-08 15:26:26,943 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_10_0 stored as values in memory (estimated size 576.0 B, free 631.4 MB)
2018-02-08 15:26:26,943 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_10_0 in memory on 192.168.11.26:62289 (size: 576.0 B, free: 631.8 MB)
2018-02-08 15:26:26,958 INFO[org.apache.spark.executor.Executor:54] - 1 block locks were not released by TID = 2:
[rdd_10_0]
2018-02-08 15:26:26,961 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 2234 bytes result sent to driver
2018-02-08 15:26:26,963 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 215 ms on localhost (executor driver) (1/1)
2018-02-08 15:26:26,963 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 15:26:26,964 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (first at GaussianMixture.scala:348) finished in 0.216 s
2018-02-08 15:26:26,964 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: first at GaussianMixture.scala:348, took 0.234231 s
2018-02-08 15:26:26,971 INFO[org.apache.spark.ml.util.Instrumentation:54] - GaussianMixture-GaussianMixture_c536e82d8869-1980377966-1: training: numPartitions=1 storageLevel=StorageLevel(memory, deserialized, 1 replicas)
2018-02-08 15:26:26,993 INFO[org.apache.spark.ml.util.Instrumentation:54] - GaussianMixture-GaussianMixture_c536e82d8869-1980377966-1: {"k":2}
2018-02-08 15:26:26,994 INFO[org.apache.spark.ml.util.Instrumentation:54] - GaussianMixture-GaussianMixture_c536e82d8869-1980377966-1: {"numFeatures":3}
2018-02-08 15:26:27,007 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at GaussianMixture.scala:452
2018-02-08 15:26:27,010 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (takeSample at GaussianMixture.scala:452) with 1 output partitions
2018-02-08 15:26:27,010 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (takeSample at GaussianMixture.scala:452)
2018-02-08 15:26:27,010 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:26:27,012 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:26:27,012 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[10] at map at GaussianMixture.scala:343), which has no missing parents
2018-02-08 15:26:27,015 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 11.0 KB, free 631.4 MB)
2018-02-08 15:26:27,018 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.8 KB, free 631.4 MB)
2018-02-08 15:26:27,021 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:62289 (size: 5.8 KB, free: 631.8 MB)
2018-02-08 15:26:27,022 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:26:27,023 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at map at GaussianMixture.scala:343) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:26:27,023 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 15:26:27,027 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:26:27,028 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 15:26:27,036 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_10_0 locally
2018-02-08 15:26:27,039 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 1389 bytes result sent to driver
2018-02-08 15:26:27,042 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 15 ms on localhost (executor driver) (1/1)
2018-02-08 15:26:27,042 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 15:26:27,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (takeSample at GaussianMixture.scala:452) finished in 0.017 s
2018-02-08 15:26:27,044 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: takeSample at GaussianMixture.scala:452, took 0.036212 s
2018-02-08 15:26:27,133 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at GaussianMixture.scala:452
2018-02-08 15:26:27,135 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (takeSample at GaussianMixture.scala:452) with 1 output partitions
2018-02-08 15:26:27,135 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (takeSample at GaussianMixture.scala:452)
2018-02-08 15:26:27,135 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:26:27,135 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:26:27,136 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (PartitionwiseSampledRDD[11] at takeSample at GaussianMixture.scala:452), which has no missing parents
2018-02-08 15:26:27,139 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 28.1 KB, free 631.4 MB)
2018-02-08 15:26:27,143 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.0 KB, free 631.4 MB)
2018-02-08 15:26:27,145 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:62289 (size: 12.0 KB, free: 631.7 MB)
2018-02-08 15:26:27,145 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:26:27,146 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (PartitionwiseSampledRDD[11] at takeSample at GaussianMixture.scala:452) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:26:27,146 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 15:26:27,148 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5423 bytes)
2018-02-08 15:26:27,148 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 15:26:27,158 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_10_0 locally
2018-02-08 15:26:27,162 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 2015 bytes result sent to driver
2018-02-08 15:26:27,163 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 16 ms on localhost (executor driver) (1/1)
2018-02-08 15:26:27,163 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 15:26:27,164 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (takeSample at GaussianMixture.scala:452) finished in 0.016 s
2018-02-08 15:26:27,164 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: takeSample at GaussianMixture.scala:452, took 0.030613 s
2018-02-08 15:26:27,178 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 15:26:27,178 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 15:26:27,631 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_3_piece0 on 192.168.11.26:62289 in memory (size: 5.9 KB, free: 631.8 MB)
2018-02-08 15:26:27,634 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_4_piece0 on 192.168.11.26:62289 in memory (size: 5.8 KB, free: 631.8 MB)
2018-02-08 15:26:27,636 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_5_piece0 on 192.168.11.26:62289 in memory (size: 12.0 KB, free: 631.8 MB)
2018-02-08 15:26:28,045 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 56.0 B, free 631.5 MB)
2018-02-08 15:26:28,048 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 85.0 B, free 631.5 MB)
2018-02-08 15:26:28,049 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:62289 (size: 85.0 B, free: 631.8 MB)
2018-02-08 15:26:28,050 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at GaussianMixture.scala:369
2018-02-08 15:26:28,051 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 368.0 B, free 631.5 MB)
2018-02-08 15:26:28,054 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 325.0 B, free 631.5 MB)
2018-02-08 15:26:28,056 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:62289 (size: 325.0 B, free: 631.8 MB)
2018-02-08 15:26:28,056 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at GaussianMixture.scala:370
2018-02-08 15:26:28,072 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at GaussianMixture.scala:374
2018-02-08 15:26:28,072 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (treeAggregate at GaussianMixture.scala:374) with 1 output partitions
2018-02-08 15:26:28,073 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (treeAggregate at GaussianMixture.scala:374)
2018-02-08 15:26:28,073 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:26:28,073 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:26:28,073 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[12] at treeAggregate at GaussianMixture.scala:374), which has no missing parents
2018-02-08 15:26:28,075 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 12.2 KB, free 631.4 MB)
2018-02-08 15:26:28,079 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.4 KB, free 631.4 MB)
2018-02-08 15:26:28,081 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:62289 (size: 6.4 KB, free: 631.8 MB)
2018-02-08 15:26:28,082 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:26:28,083 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[12] at treeAggregate at GaussianMixture.scala:374) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:26:28,083 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
2018-02-08 15:26:28,084 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:26:28,085 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 15:26:28,087 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_10_0 locally
2018-02-08 15:26:28,119 WARN[com.github.fommil.netlib.LAPACK:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2018-02-08 15:26:28,119 WARN[com.github.fommil.netlib.LAPACK:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2018-02-08 15:26:28,200 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 3006 bytes result sent to driver
2018-02-08 15:26:28,202 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 118 ms on localhost (executor driver) (1/1)
2018-02-08 15:26:28,202 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 15:26:28,202 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (treeAggregate at GaussianMixture.scala:374) finished in 0.118 s
2018-02-08 15:26:28,203 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: treeAggregate at GaussianMixture.scala:374, took 0.130915 s
2018-02-08 15:26:28,204 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(6) (from destroy at GaussianMixture.scala:382)
2018-02-08 15:26:28,205 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(7) (from destroy at GaussianMixture.scala:383)
2018-02-08 15:26:28,205 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:62289 in memory (size: 85.0 B, free: 631.8 MB)
2018-02-08 15:26:28,206 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:62289 in memory (size: 325.0 B, free: 631.8 MB)
2018-02-08 15:26:28,208 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 56.0 B, free 631.4 MB)
2018-02-08 15:26:28,210 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 85.0 B, free 631.4 MB)
2018-02-08 15:26:28,211 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.11.26:62289 (size: 85.0 B, free: 631.8 MB)
2018-02-08 15:26:28,211 INFO[org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at GaussianMixture.scala:369
2018-02-08 15:26:28,212 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 368.0 B, free 631.4 MB)
2018-02-08 15:26:28,214 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 308.0 B, free 631.4 MB)
2018-02-08 15:26:28,215 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.11.26:62289 (size: 308.0 B, free: 631.8 MB)
2018-02-08 15:26:28,216 INFO[org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at GaussianMixture.scala:370
2018-02-08 15:26:28,224 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at GaussianMixture.scala:374
2018-02-08 15:26:28,224 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (treeAggregate at GaussianMixture.scala:374) with 1 output partitions
2018-02-08 15:26:28,225 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (treeAggregate at GaussianMixture.scala:374)
2018-02-08 15:26:28,225 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:26:28,225 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:26:28,225 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[13] at treeAggregate at GaussianMixture.scala:374), which has no missing parents
2018-02-08 15:26:28,227 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 12.2 KB, free 631.4 MB)
2018-02-08 15:26:28,230 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.4 KB, free 631.4 MB)
2018-02-08 15:26:28,231 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.11.26:62289 (size: 6.4 KB, free: 631.8 MB)
2018-02-08 15:26:28,232 INFO[org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:26:28,232 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at treeAggregate at GaussianMixture.scala:374) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:26:28,232 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
2018-02-08 15:26:28,233 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:26:28,234 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 6)
2018-02-08 15:26:28,236 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_10_0 locally
2018-02-08 15:26:28,246 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 6). 2963 bytes result sent to driver
2018-02-08 15:26:28,247 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 6) in 14 ms on localhost (executor driver) (1/1)
2018-02-08 15:26:28,247 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 15:26:28,248 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (treeAggregate at GaussianMixture.scala:374) finished in 0.015 s
2018-02-08 15:26:28,248 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: treeAggregate at GaussianMixture.scala:374, took 0.024188 s
2018-02-08 15:26:28,249 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(9) (from destroy at GaussianMixture.scala:382)
2018-02-08 15:26:28,250 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(10) (from destroy at GaussianMixture.scala:383)
2018-02-08 15:26:28,252 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.11.26:62289 in memory (size: 85.0 B, free: 631.8 MB)
2018-02-08 15:26:28,254 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 56.0 B, free 631.4 MB)
2018-02-08 15:26:28,261 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.11.26:62289 in memory (size: 308.0 B, free: 631.8 MB)
2018-02-08 15:26:28,262 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 85.0 B, free 631.4 MB)
2018-02-08 15:26:28,264 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.11.26:62289 (size: 85.0 B, free: 631.8 MB)
2018-02-08 15:26:28,265 INFO[org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at GaussianMixture.scala:369
2018-02-08 15:26:28,265 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 368.0 B, free 631.4 MB)
2018-02-08 15:26:28,268 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 308.0 B, free 631.4 MB)
2018-02-08 15:26:28,270 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.11.26:62289 (size: 308.0 B, free: 631.8 MB)
2018-02-08 15:26:28,271 INFO[org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at GaussianMixture.scala:370
2018-02-08 15:26:28,279 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at GaussianMixture.scala:374
2018-02-08 15:26:28,282 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (treeAggregate at GaussianMixture.scala:374) with 1 output partitions
2018-02-08 15:26:28,282 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (treeAggregate at GaussianMixture.scala:374)
2018-02-08 15:26:28,283 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:26:28,283 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:26:28,283 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[14] at treeAggregate at GaussianMixture.scala:374), which has no missing parents
2018-02-08 15:26:28,286 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 12.2 KB, free 631.4 MB)
2018-02-08 15:26:28,290 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.4 KB, free 631.4 MB)
2018-02-08 15:26:28,291 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.11.26:62289 (size: 6.4 KB, free: 631.8 MB)
2018-02-08 15:26:28,291 INFO[org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:26:28,292 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[14] at treeAggregate at GaussianMixture.scala:374) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:26:28,292 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
2018-02-08 15:26:28,292 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:26:28,293 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 7)
2018-02-08 15:26:28,297 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_10_0 locally
2018-02-08 15:26:28,300 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 7). 3049 bytes result sent to driver
2018-02-08 15:26:28,302 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 7) in 10 ms on localhost (executor driver) (1/1)
2018-02-08 15:26:28,302 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 15:26:28,303 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (treeAggregate at GaussianMixture.scala:374) finished in 0.011 s
2018-02-08 15:26:28,305 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: treeAggregate at GaussianMixture.scala:374, took 0.025185 s
2018-02-08 15:26:28,306 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(12) (from destroy at GaussianMixture.scala:382)
2018-02-08 15:26:28,308 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(13) (from destroy at GaussianMixture.scala:383)
2018-02-08 15:26:28,309 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_12_piece0 on 192.168.11.26:62289 in memory (size: 85.0 B, free: 631.8 MB)
2018-02-08 15:26:28,309 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 56.0 B, free 631.4 MB)
2018-02-08 15:26:28,310 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_13_piece0 on 192.168.11.26:62289 in memory (size: 308.0 B, free: 631.8 MB)
2018-02-08 15:26:28,312 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 85.0 B, free 631.4 MB)
2018-02-08 15:26:28,313 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.11.26:62289 (size: 85.0 B, free: 631.8 MB)
2018-02-08 15:26:28,314 INFO[org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at GaussianMixture.scala:369
2018-02-08 15:26:28,315 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16 stored as values in memory (estimated size 368.0 B, free 631.4 MB)
2018-02-08 15:26:28,321 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 308.0 B, free 631.4 MB)
2018-02-08 15:26:28,322 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_16_piece0 in memory on 192.168.11.26:62289 (size: 308.0 B, free: 631.8 MB)
2018-02-08 15:26:28,322 INFO[org.apache.spark.SparkContext:54] - Created broadcast 16 from broadcast at GaussianMixture.scala:370
2018-02-08 15:26:28,330 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at GaussianMixture.scala:374
2018-02-08 15:26:28,331 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (treeAggregate at GaussianMixture.scala:374) with 1 output partitions
2018-02-08 15:26:28,331 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 7 (treeAggregate at GaussianMixture.scala:374)
2018-02-08 15:26:28,331 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:26:28,332 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:26:28,332 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 7 (MapPartitionsRDD[15] at treeAggregate at GaussianMixture.scala:374), which has no missing parents
2018-02-08 15:26:28,336 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17 stored as values in memory (estimated size 12.2 KB, free 631.4 MB)
2018-02-08 15:26:28,338 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 6.4 KB, free 631.4 MB)
2018-02-08 15:26:28,338 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_17_piece0 in memory on 192.168.11.26:62289 (size: 6.4 KB, free: 631.7 MB)
2018-02-08 15:26:28,339 INFO[org.apache.spark.SparkContext:54] - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:26:28,340 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[15] at treeAggregate at GaussianMixture.scala:374) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:26:28,340 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
2018-02-08 15:26:28,341 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:26:28,342 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 8)
2018-02-08 15:26:28,346 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_10_0 locally
2018-02-08 15:26:28,349 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 8). 3006 bytes result sent to driver
2018-02-08 15:26:28,349 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 8) in 9 ms on localhost (executor driver) (1/1)
2018-02-08 15:26:28,350 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-02-08 15:26:28,352 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 7 (treeAggregate at GaussianMixture.scala:374) finished in 0.012 s
2018-02-08 15:26:28,355 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: treeAggregate at GaussianMixture.scala:374, took 0.023879 s
2018-02-08 15:26:28,357 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(15) (from destroy at GaussianMixture.scala:382)
2018-02-08 15:26:28,358 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(16) (from destroy at GaussianMixture.scala:383)
2018-02-08 15:26:28,359 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_15_piece0 on 192.168.11.26:62289 in memory (size: 85.0 B, free: 631.7 MB)
2018-02-08 15:26:28,360 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_16_piece0 on 192.168.11.26:62289 in memory (size: 308.0 B, free: 631.7 MB)
2018-02-08 15:26:28,361 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18 stored as values in memory (estimated size 56.0 B, free 631.4 MB)
2018-02-08 15:26:28,365 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 85.0 B, free 631.4 MB)
2018-02-08 15:26:28,366 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_18_piece0 in memory on 192.168.11.26:62289 (size: 85.0 B, free: 631.7 MB)
2018-02-08 15:26:28,368 INFO[org.apache.spark.SparkContext:54] - Created broadcast 18 from broadcast at GaussianMixture.scala:369
2018-02-08 15:26:28,370 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19 stored as values in memory (estimated size 368.0 B, free 631.4 MB)
2018-02-08 15:26:28,373 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 308.0 B, free 631.4 MB)
2018-02-08 15:26:28,375 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_19_piece0 in memory on 192.168.11.26:62289 (size: 308.0 B, free: 631.7 MB)
2018-02-08 15:26:28,376 INFO[org.apache.spark.SparkContext:54] - Created broadcast 19 from broadcast at GaussianMixture.scala:370
2018-02-08 15:26:28,386 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at GaussianMixture.scala:374
2018-02-08 15:26:28,387 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (treeAggregate at GaussianMixture.scala:374) with 1 output partitions
2018-02-08 15:26:28,387 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 8 (treeAggregate at GaussianMixture.scala:374)
2018-02-08 15:26:28,387 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:26:28,388 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:26:28,388 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 8 (MapPartitionsRDD[16] at treeAggregate at GaussianMixture.scala:374), which has no missing parents
2018-02-08 15:26:28,390 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20 stored as values in memory (estimated size 12.2 KB, free 631.4 MB)
2018-02-08 15:26:28,393 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.4 KB, free 631.4 MB)
2018-02-08 15:26:28,395 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_20_piece0 in memory on 192.168.11.26:62289 (size: 6.4 KB, free: 631.7 MB)
2018-02-08 15:26:28,396 INFO[org.apache.spark.SparkContext:54] - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:26:28,396 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[16] at treeAggregate at GaussianMixture.scala:374) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:26:28,396 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 1 tasks
2018-02-08 15:26:28,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:26:28,399 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 9)
2018-02-08 15:26:28,401 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_10_0 locally
2018-02-08 15:26:28,405 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 9). 2963 bytes result sent to driver
2018-02-08 15:26:28,407 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 9) in 10 ms on localhost (executor driver) (1/1)
2018-02-08 15:26:28,407 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 15:26:28,408 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 8 (treeAggregate at GaussianMixture.scala:374) finished in 0.010 s
2018-02-08 15:26:28,408 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: treeAggregate at GaussianMixture.scala:374, took 0.020615 s
2018-02-08 15:26:28,409 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(18) (from destroy at GaussianMixture.scala:382)
2018-02-08 15:26:28,410 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(19) (from destroy at GaussianMixture.scala:383)
2018-02-08 15:26:28,410 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_18_piece0 on 192.168.11.26:62289 in memory (size: 85.0 B, free: 631.7 MB)
2018-02-08 15:26:28,411 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21 stored as values in memory (estimated size 56.0 B, free 631.4 MB)
2018-02-08 15:26:28,414 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 85.0 B, free 631.4 MB)
2018-02-08 15:26:28,416 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_21_piece0 in memory on 192.168.11.26:62289 (size: 85.0 B, free: 631.7 MB)
2018-02-08 15:26:28,416 INFO[org.apache.spark.SparkContext:54] - Created broadcast 21 from broadcast at GaussianMixture.scala:369
2018-02-08 15:26:28,416 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_19_piece0 on 192.168.11.26:62289 in memory (size: 308.0 B, free: 631.7 MB)
2018-02-08 15:26:28,417 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22 stored as values in memory (estimated size 368.0 B, free 631.4 MB)
2018-02-08 15:26:28,420 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 306.0 B, free 631.4 MB)
2018-02-08 15:26:28,421 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_22_piece0 in memory on 192.168.11.26:62289 (size: 306.0 B, free: 631.7 MB)
2018-02-08 15:26:28,422 INFO[org.apache.spark.SparkContext:54] - Created broadcast 22 from broadcast at GaussianMixture.scala:370
2018-02-08 15:26:28,430 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at GaussianMixture.scala:374
2018-02-08 15:26:28,431 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (treeAggregate at GaussianMixture.scala:374) with 1 output partitions
2018-02-08 15:26:28,432 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 9 (treeAggregate at GaussianMixture.scala:374)
2018-02-08 15:26:28,432 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:26:28,432 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:26:28,432 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 9 (MapPartitionsRDD[17] at treeAggregate at GaussianMixture.scala:374), which has no missing parents
2018-02-08 15:26:28,434 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23 stored as values in memory (estimated size 12.2 KB, free 631.4 MB)
2018-02-08 15:26:28,436 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.4 KB, free 631.3 MB)
2018-02-08 15:26:28,437 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_23_piece0 in memory on 192.168.11.26:62289 (size: 6.4 KB, free: 631.7 MB)
2018-02-08 15:26:28,438 INFO[org.apache.spark.SparkContext:54] - Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:26:28,439 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[17] at treeAggregate at GaussianMixture.scala:374) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:26:28,439 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 1 tasks
2018-02-08 15:26:28,440 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:26:28,441 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 10)
2018-02-08 15:26:28,443 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_10_0 locally
2018-02-08 15:26:28,445 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 10). 2963 bytes result sent to driver
2018-02-08 15:26:28,446 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
2018-02-08 15:26:28,447 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-02-08 15:26:28,448 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 9 (treeAggregate at GaussianMixture.scala:374) finished in 0.007 s
2018-02-08 15:26:28,448 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: treeAggregate at GaussianMixture.scala:374, took 0.017661 s
2018-02-08 15:26:28,449 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(21) (from destroy at GaussianMixture.scala:382)
2018-02-08 15:26:28,449 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(22) (from destroy at GaussianMixture.scala:383)
2018-02-08 15:26:28,451 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_21_piece0 on 192.168.11.26:62289 in memory (size: 85.0 B, free: 631.7 MB)
2018-02-08 15:26:28,452 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_22_piece0 on 192.168.11.26:62289 in memory (size: 306.0 B, free: 631.7 MB)
2018-02-08 15:26:28,453 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24 stored as values in memory (estimated size 56.0 B, free 631.3 MB)
2018-02-08 15:26:28,455 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 85.0 B, free 631.3 MB)
2018-02-08 15:26:28,456 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_24_piece0 in memory on 192.168.11.26:62289 (size: 85.0 B, free: 631.7 MB)
2018-02-08 15:26:28,457 INFO[org.apache.spark.SparkContext:54] - Created broadcast 24 from broadcast at GaussianMixture.scala:369
2018-02-08 15:26:28,458 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25 stored as values in memory (estimated size 368.0 B, free 631.3 MB)
2018-02-08 15:26:28,461 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 306.0 B, free 631.3 MB)
2018-02-08 15:26:28,463 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_25_piece0 in memory on 192.168.11.26:62289 (size: 306.0 B, free: 631.7 MB)
2018-02-08 15:26:28,464 INFO[org.apache.spark.SparkContext:54] - Created broadcast 25 from broadcast at GaussianMixture.scala:370
2018-02-08 15:26:28,477 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at GaussianMixture.scala:374
2018-02-08 15:26:28,477 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 10 (treeAggregate at GaussianMixture.scala:374) with 1 output partitions
2018-02-08 15:26:28,478 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 10 (treeAggregate at GaussianMixture.scala:374)
2018-02-08 15:26:28,478 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:26:28,480 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:26:28,481 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 10 (MapPartitionsRDD[18] at treeAggregate at GaussianMixture.scala:374), which has no missing parents
2018-02-08 15:26:28,487 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_26 stored as values in memory (estimated size 12.2 KB, free 631.3 MB)
2018-02-08 15:26:28,489 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 6.4 KB, free 631.3 MB)
2018-02-08 15:26:28,489 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_26_piece0 in memory on 192.168.11.26:62289 (size: 6.4 KB, free: 631.7 MB)
2018-02-08 15:26:28,490 INFO[org.apache.spark.SparkContext:54] - Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:26:28,490 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[18] at treeAggregate at GaussianMixture.scala:374) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:26:28,491 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 1 tasks
2018-02-08 15:26:28,493 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:26:28,494 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 11)
2018-02-08 15:26:28,499 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_10_0 locally
2018-02-08 15:26:28,502 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 11). 3006 bytes result sent to driver
2018-02-08 15:26:28,503 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 11) in 11 ms on localhost (executor driver) (1/1)
2018-02-08 15:26:28,503 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 15:26:28,503 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 10 (treeAggregate at GaussianMixture.scala:374) finished in 0.011 s
2018-02-08 15:26:28,506 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 10 finished: treeAggregate at GaussianMixture.scala:374, took 0.028984 s
2018-02-08 15:26:28,507 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(24) (from destroy at GaussianMixture.scala:382)
2018-02-08 15:26:28,509 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(25) (from destroy at GaussianMixture.scala:383)
2018-02-08 15:26:28,509 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_24_piece0 on 192.168.11.26:62289 in memory (size: 85.0 B, free: 631.7 MB)
2018-02-08 15:26:28,510 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_25_piece0 on 192.168.11.26:62289 in memory (size: 306.0 B, free: 631.7 MB)
2018-02-08 15:26:28,907 INFO[org.apache.spark.ml.util.Instrumentation:54] - GaussianMixture-GaussianMixture_c536e82d8869-1980377966-1: training finished
2018-02-08 15:26:28,918 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:26:28,924 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@34a1d21f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:26:28,927 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:26:28,957 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:26:29,024 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:26:29,025 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:26:29,026 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:26:29,028 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:26:29,032 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:26:29,033 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:26:29,034 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-141166e7-e3ae-4892-bbbf-77e3f4470ef3
2018-02-08 15:38:08,603 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:38:09,181 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:38:09,199 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:38:09,199 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:38:09,200 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:38:09,200 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:38:09,201 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:38:09,528 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62399.
2018-02-08 15:38:09,545 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:38:09,589 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:38:09,592 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:38:09,593 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:38:09,600 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-2422e719-95fe-4e9b-b5d3-ef62495818e9
2018-02-08 15:38:09,621 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:38:09,671 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:38:09,743 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2430ms
2018-02-08 15:38:09,808 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:38:09,821 INFO[org.spark_project.jetty.server.Server:403] - Started @2509ms
2018-02-08 15:38:09,839 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@5293becd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:38:09,839 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:38:09,862 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@55787112{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,863 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,864 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d0b5baf{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,865 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@34a75079{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,866 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,867 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@186978a6{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,867 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@482d776b{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,869 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,869 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,870 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,870 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,871 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,872 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,873 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,874 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,875 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,876 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,877 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,878 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,878 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,884 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/static,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,885 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d1f7216{/,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,886 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6e16b8b5{/api,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,887 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6256ac4f{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,887 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7fcbe147{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:38:09,889 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:38:09,968 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:38:09,996 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62412.
2018-02-08 15:38:09,998 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62412
2018-02-08 15:38:09,999 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:38:10,005 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62412, None)
2018-02-08 15:38:10,009 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62412 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62412, None)
2018-02-08 15:38:10,014 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62412, None)
2018-02-08 15:38:10,015 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62412, None)
2018-02-08 15:38:10,173 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@315ba14a{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:10,241 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:38:10,242 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:38:10,249 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63a5d002{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:38:10,253 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5aa6202e{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:10,254 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@150d80c4{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:38:10,254 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3003697{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:38:10,256 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d691f3d{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:38:11,243 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:38:12,903 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:38:12,907 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@5293becd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:38:12,909 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:38:12,915 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:38:12,921 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:38:12,922 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:38:12,926 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:38:12,928 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:38:12,930 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:38:12,931 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:38:12,931 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-ae38f3ef-f1c9-4ea8-9ab8-d11cc4dd23fa
2018-02-08 15:39:06,050 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:39:06,540 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:39:06,559 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:39:06,560 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:39:06,560 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:39:06,561 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:39:06,561 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:39:06,882 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62442.
2018-02-08 15:39:06,899 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:39:06,939 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:39:06,942 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:39:06,942 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:39:06,950 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-70877fa9-bc12-4c88-a71c-2a244a25f80e
2018-02-08 15:39:06,970 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:39:07,021 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:39:07,090 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2439ms
2018-02-08 15:39:07,149 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:39:07,161 INFO[org.spark_project.jetty.server.Server:403] - Started @2512ms
2018-02-08 15:39:07,179 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@5d4ddf63{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:39:07,180 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:39:07,201 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@55787112{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,202 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,202 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d0b5baf{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,203 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@34a75079{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,204 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,204 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@186978a6{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,205 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@482d776b{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,206 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,207 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,209 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,210 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,211 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,211 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,212 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,212 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,213 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,214 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,214 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,215 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,215 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,222 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@ab7a938{/static,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,222 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d1f7216{/,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,224 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6e16b8b5{/api,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,225 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6256ac4f{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,225 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7fcbe147{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,227 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:39:07,296 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:39:07,334 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62455.
2018-02-08 15:39:07,335 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62455
2018-02-08 15:39:07,339 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:39:07,345 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62455, None)
2018-02-08 15:39:07,349 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62455 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62455, None)
2018-02-08 15:39:07,355 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62455, None)
2018-02-08 15:39:07,356 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62455, None)
2018-02-08 15:39:07,559 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@315ba14a{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,643 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:39:07,644 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:39:07,651 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5aa6202e{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,651 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@771158fb{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,652 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3003697{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,652 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d269ed7{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:39:07,654 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1e7f2e0f{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:39:08,709 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:39:10,431 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:39:10,434 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:39:10,436 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<value: string>
2018-02-08 15:39:10,445 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:39:10,884 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 165.376053 ms
2018-02-08 15:39:11,023 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:39:11,071 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:39:11,074 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:62455 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:39:11,076 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from show at MachineLeaningClustering.java:26
2018-02-08 15:39:11,085 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:39:11,185 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningClustering.java:26
2018-02-08 15:39:11,199 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (show at MachineLeaningClustering.java:26) with 1 output partitions
2018-02-08 15:39:11,200 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (show at MachineLeaningClustering.java:26)
2018-02-08 15:39:11,200 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:39:11,201 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:39:11,204 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[2] at show at MachineLeaningClustering.java:26), which has no missing parents
2018-02-08 15:39:11,245 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 6.7 KB, free 631.5 MB)
2018-02-08 15:39:11,248 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.6 KB, free 631.4 MB)
2018-02-08 15:39:11,249 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:62455 (size: 3.6 KB, free: 631.8 MB)
2018-02-08 15:39:11,250 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:39:11,260 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at show at MachineLeaningClustering.java:26) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:39:11,260 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
2018-02-08 15:39:11,297 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:39:11,306 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:39:11,372 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:39:11,399 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.362244 ms
2018-02-08 15:39:11,438 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1308 bytes result sent to driver
2018-02-08 15:39:11,444 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 160 ms on localhost (executor driver) (1/1)
2018-02-08 15:39:11,446 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:39:11,449 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (show at MachineLeaningClustering.java:26) finished in 0.175 s
2018-02-08 15:39:11,455 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: show at MachineLeaningClustering.java:26, took 0.268862 s
2018-02-08 15:39:11,479 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.039364 ms
2018-02-08 15:39:11,571 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:39:11,575 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@5d4ddf63{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:39:11,577 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:39:11,586 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:39:11,595 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:39:11,595 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:39:11,600 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:39:11,602 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:39:11,605 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:39:11,606 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:39:11,607 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-a398c07d-7bd5-4f1b-bef7-545e902d511d
2018-02-08 15:40:46,580 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:40:47,217 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:40:47,239 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:40:47,240 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:40:47,240 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:40:47,241 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:40:47,242 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:40:47,581 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62491.
2018-02-08 15:40:47,598 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:40:47,639 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:40:47,642 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:40:47,643 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:40:47,650 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-2d7b95a1-2466-404d-98aa-357539a294fd
2018-02-08 15:40:47,670 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:40:47,718 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:40:47,789 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2780ms
2018-02-08 15:40:47,879 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:40:47,894 INFO[org.spark_project.jetty.server.Server:403] - Started @2887ms
2018-02-08 15:40:47,918 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@53028cb5{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:40:47,919 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:40:47,948 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2488b073{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,949 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,950 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,951 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@631e06ab{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,952 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@34a75079{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,953 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,957 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@186978a6{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,959 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,960 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,961 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,964 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,965 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,966 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,967 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,967 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,969 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,970 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,970 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,971 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,972 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,978 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/static,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,979 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@305f031{/,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,980 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d1f7216{/api,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,981 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4ebea12c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,982 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6256ac4f{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:40:47,984 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:40:48,077 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:40:48,103 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62504.
2018-02-08 15:40:48,103 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62504
2018-02-08 15:40:48,105 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:40:48,111 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62504, None)
2018-02-08 15:40:48,114 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62504 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62504, None)
2018-02-08 15:40:48,117 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62504, None)
2018-02-08 15:40:48,118 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62504, None)
2018-02-08 15:40:48,281 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5a6d5a8f{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:48,424 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:40:48,425 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:40:48,432 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@46b695ec{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:40:48,433 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@325f7fa9{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:48,433 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3af9aa66{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:40:48,434 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@91c4a3f{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:40:48,436 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d269ed7{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:40:49,570 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:40:50,005 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 15:40:50,062 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 15:40:50,065 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:62504 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:40:50,069 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 15:40:50,166 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 15:40:50,178 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 15:40:50,196 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 15:40:50,196 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 15:40:50,196 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:40:50,198 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:40:50,203 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 15:40:50,271 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 15:40:50,276 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 15:40:50,277 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:62504 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:40:50,277 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:50,293 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 15:40:50,294 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 15:40:50,340 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:40:50,344 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:40:50,354 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 15:40:50,354 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:40:50,426 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:0+60
2018-02-08 15:40:50,426 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:60+60
2018-02-08 15:40:50,471 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 910 bytes result sent to driver
2018-02-08 15:40:50,471 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 910 bytes result sent to driver
2018-02-08 15:40:50,478 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 152 ms on localhost (executor driver) (1/2)
2018-02-08 15:40:50,479 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 136 ms on localhost (executor driver) (2/2)
2018-02-08 15:40:50,481 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:40:50,485 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.172 s
2018-02-08 15:40:50,504 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.326058 s
2018-02-08 15:40:51,308 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:62504 in memory (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:40:51,312 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:62504 in memory (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:40:51,827 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:40:51,830 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:40:51,832 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:40:51,840 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:40:52,183 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 219.78919 ms
2018-02-08 15:40:52,193 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:40:52,206 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:40:52,208 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:62504 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:40:52,209 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:40:52,217 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:40:52,261 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningClustering.java:25
2018-02-08 15:40:52,263 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (show at MachineLeaningClustering.java:25) with 1 output partitions
2018-02-08 15:40:52,263 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (show at MachineLeaningClustering.java:25)
2018-02-08 15:40:52,263 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:40:52,263 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:40:52,263 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[8] at show at MachineLeaningClustering.java:25), which has no missing parents
2018-02-08 15:40:52,283 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 7.2 KB, free 631.5 MB)
2018-02-08 15:40:52,285 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 631.4 MB)
2018-02-08 15:40:52,286 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:62504 (size: 4.0 KB, free: 631.8 MB)
2018-02-08 15:40:52,286 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:52,287 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at MachineLeaningClustering.java:25) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:52,287 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 15:40:52,293 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:40:52,294 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 15:40:52,305 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:40:52,347 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 27.431369 ms
2018-02-08 15:40:52,437 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 53.676178 ms
2018-02-08 15:40:52,447 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 1301 bytes result sent to driver
2018-02-08 15:40:52,450 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 162 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:52,450 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (show at MachineLeaningClustering.java:25) finished in 0.163 s
2018-02-08 15:40:52,451 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: show at MachineLeaningClustering.java:25, took 0.189389 s
2018-02-08 15:40:52,453 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 15:40:52,475 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.484804 ms
2018-02-08 15:40:52,535 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:40:52,535 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:40:52,535 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:40:52,536 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:40:52,544 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 322.9 KB, free 631.1 MB)
2018-02-08 15:40:52,557 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.1 MB)
2018-02-08 15:40:52,560 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:62504 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:40:52,560 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:40:52,561 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:40:52,615 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:40:52,615 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:40:52,615 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:40:52,615 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:40:52,621 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 322.9 KB, free 630.8 MB)
2018-02-08 15:40:52,635 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 27.6 KB, free 630.8 MB)
2018-02-08 15:40:52,637 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:62504 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:40:52,639 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:40:52,640 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:40:52,664 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_a75cebff25ba-2032752946-1: training: numPartitions=1 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
2018-02-08 15:40:52,690 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_a75cebff25ba-2032752946-1: {"k":2,"seed":1}
2018-02-08 15:40:52,720 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at KMeans.scala:353
2018-02-08 15:40:52,722 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (takeSample at KMeans.scala:353) with 1 output partitions
2018-02-08 15:40:52,722 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (takeSample at KMeans.scala:353)
2018-02-08 15:40:52,722 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:40:52,725 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:40:52,726 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[20] at map at KMeans.scala:224), which has no missing parents
2018-02-08 15:40:52,756 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 11.9 KB, free 630.8 MB)
2018-02-08 15:40:52,758 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.2 KB, free 630.7 MB)
2018-02-08 15:40:52,760 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:62504 (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:40:52,760 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:52,761 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[20] at map at KMeans.scala:224) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:52,761 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 15:40:52,763 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5605 bytes)
2018-02-08 15:40:52,764 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 15:40:52,781 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.217283 ms
2018-02-08 15:40:52,782 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:40:52,798 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.281924 ms
2018-02-08 15:40:52,815 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.900164 ms
2018-02-08 15:40:52,826 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_0 stored as values in memory (estimated size 576.0 B, free 630.7 MB)
2018-02-08 15:40:52,828 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_0 in memory on 192.168.11.26:62504 (size: 576.0 B, free: 631.7 MB)
2018-02-08 15:40:52,832 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:40:52,834 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_18_0 stored as values in memory (estimated size 64.0 B, free 630.7 MB)
2018-02-08 15:40:52,835 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_18_0 in memory on 192.168.11.26:62504 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:40:52,839 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 2117 bytes result sent to driver
2018-02-08 15:40:52,840 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 78 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:52,840 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 15:40:52,841 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (takeSample at KMeans.scala:353) finished in 0.080 s
2018-02-08 15:40:52,842 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: takeSample at KMeans.scala:353, took 0.121135 s
2018-02-08 15:40:52,868 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at KMeans.scala:353
2018-02-08 15:40:52,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (takeSample at KMeans.scala:353) with 1 output partitions
2018-02-08 15:40:52,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (takeSample at KMeans.scala:353)
2018-02-08 15:40:52,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:40:52,872 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:40:52,873 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (PartitionwiseSampledRDD[22] at takeSample at KMeans.scala:353), which has no missing parents
2018-02-08 15:40:52,877 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 12.6 KB, free 630.7 MB)
2018-02-08 15:40:52,882 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 630.7 MB)
2018-02-08 15:40:52,884 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:62504 (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:40:52,885 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:52,887 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (PartitionwiseSampledRDD[22] at takeSample at KMeans.scala:353) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:52,887 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 15:40:52,892 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5714 bytes)
2018-02-08 15:40:52,892 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 15:40:52,905 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:40:52,907 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:40:52,915 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 2104 bytes result sent to driver
2018-02-08 15:40:52,916 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 26 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:52,916 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 15:40:52,917 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (takeSample at KMeans.scala:353) finished in 0.027 s
2018-02-08 15:40:52,917 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: takeSample at KMeans.scala:353, took 0.048864 s
2018-02-08 15:40:52,923 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 144.0 B, free 630.7 MB)
2018-02-08 15:40:52,926 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 339.0 B, free 630.7 MB)
2018-02-08 15:40:52,930 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:62504 (size: 339.0 B, free: 631.7 MB)
2018-02-08 15:40:52,931 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at KMeans.scala:367
2018-02-08 15:40:52,958 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeans.scala:373
2018-02-08 15:40:52,964 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (sum at KMeans.scala:373) with 1 output partitions
2018-02-08 15:40:52,965 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (sum at KMeans.scala:373)
2018-02-08 15:40:52,965 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:40:52,966 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:40:52,966 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[24] at map at KMeans.scala:370), which has no missing parents
2018-02-08 15:40:52,970 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 12.7 KB, free 630.7 MB)
2018-02-08 15:40:52,975 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.6 KB, free 630.7 MB)
2018-02-08 15:40:52,979 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.11.26:62504 (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:40:52,980 INFO[org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:52,981 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at map at KMeans.scala:370) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:52,981 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
2018-02-08 15:40:52,982 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5637 bytes)
2018-02-08 15:40:52,983 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 15:40:52,996 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:40:52,997 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:40:52,997 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:40:52,997 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:40:53,008 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_24_0 stored as values in memory (estimated size 64.0 B, free 630.7 MB)
2018-02-08 15:40:53,010 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_24_0 in memory on 192.168.11.26:62504 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:40:53,011 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 2115 bytes result sent to driver
2018-02-08 15:40:53,012 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 30 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:53,012 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 15:40:53,013 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (sum at KMeans.scala:373) finished in 0.031 s
2018-02-08 15:40:53,014 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: sum at KMeans.scala:373, took 0.051703 s
2018-02-08 15:40:53,015 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 21 from persistence list
2018-02-08 15:40:53,019 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 21
2018-02-08 15:40:53,041 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at KMeans.scala:381
2018-02-08 15:40:53,042 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (collect at KMeans.scala:381) with 1 output partitions
2018-02-08 15:40:53,042 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (collect at KMeans.scala:381)
2018-02-08 15:40:53,042 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:40:53,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:40:53,044 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[26] at mapPartitionsWithIndex at KMeans.scala:378), which has no missing parents
2018-02-08 15:40:53,046 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 13.3 KB, free 630.7 MB)
2018-02-08 15:40:53,050 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.7 MB)
2018-02-08 15:40:53,052 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.11.26:62504 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:40:53,052 INFO[org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:53,053 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at mapPartitionsWithIndex at KMeans.scala:378) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:53,053 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
2018-02-08 15:40:53,054 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5669 bytes)
2018-02-08 15:40:53,056 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 6)
2018-02-08 15:40:53,059 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:40:53,059 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:40:53,059 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_24_0 locally
2018-02-08 15:40:53,060 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 6). 1778 bytes result sent to driver
2018-02-08 15:40:53,061 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 6) in 7 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:53,061 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 15:40:53,062 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (collect at KMeans.scala:381) finished in 0.007 s
2018-02-08 15:40:53,062 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: collect at KMeans.scala:381, took 0.020390 s
2018-02-08 15:40:53,065 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 320.0 B, free 630.7 MB)
2018-02-08 15:40:53,069 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 413.0 B, free 630.7 MB)
2018-02-08 15:40:53,071 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.11.26:62504 (size: 413.0 B, free: 631.7 MB)
2018-02-08 15:40:53,072 INFO[org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at KMeans.scala:367
2018-02-08 15:40:53,083 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeans.scala:373
2018-02-08 15:40:53,084 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (sum at KMeans.scala:373) with 1 output partitions
2018-02-08 15:40:53,084 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (sum at KMeans.scala:373)
2018-02-08 15:40:53,084 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:40:53,085 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:40:53,085 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[28] at map at KMeans.scala:370), which has no missing parents
2018-02-08 15:40:53,089 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 12.9 KB, free 630.7 MB)
2018-02-08 15:40:53,094 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.7 KB, free 630.7 MB)
2018-02-08 15:40:53,096 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.11.26:62504 (size: 6.7 KB, free: 631.7 MB)
2018-02-08 15:40:53,096 INFO[org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:53,097 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at map at KMeans.scala:370) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:53,097 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
2018-02-08 15:40:53,098 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5669 bytes)
2018-02-08 15:40:53,098 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 7)
2018-02-08 15:40:53,105 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:40:53,105 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:40:53,105 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_24_0 locally
2018-02-08 15:40:53,106 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_28_0 stored as values in memory (estimated size 64.0 B, free 630.7 MB)
2018-02-08 15:40:53,108 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_28_0 in memory on 192.168.11.26:62504 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:40:53,110 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 7). 2029 bytes result sent to driver
2018-02-08 15:40:53,111 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 7) in 14 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:53,111 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 15:40:53,112 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (sum at KMeans.scala:373) finished in 0.014 s
2018-02-08 15:40:53,113 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: sum at KMeans.scala:373, took 0.029874 s
2018-02-08 15:40:53,115 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 24 from persistence list
2018-02-08 15:40:53,117 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 24
2018-02-08 15:40:53,139 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at KMeans.scala:381
2018-02-08 15:40:53,141 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (collect at KMeans.scala:381) with 1 output partitions
2018-02-08 15:40:53,141 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 7 (collect at KMeans.scala:381)
2018-02-08 15:40:53,141 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:40:53,143 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:40:53,144 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 7 (MapPartitionsRDD[30] at mapPartitionsWithIndex at KMeans.scala:378), which has no missing parents
2018-02-08 15:40:53,146 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 13.5 KB, free 630.7 MB)
2018-02-08 15:40:53,149 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.6 MB)
2018-02-08 15:40:53,155 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.11.26:62504 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:40:53,157 INFO[org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:53,158 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[30] at mapPartitionsWithIndex at KMeans.scala:378) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:53,158 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
2018-02-08 15:40:53,160 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5701 bytes)
2018-02-08 15:40:53,160 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 8)
2018-02-08 15:40:53,166 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:40:53,166 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:40:53,166 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_28_0 locally
2018-02-08 15:40:53,171 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 8). 1697 bytes result sent to driver
2018-02-08 15:40:53,173 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 8) in 14 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:53,173 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-02-08 15:40:53,174 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 7 (collect at KMeans.scala:381) finished in 0.014 s
2018-02-08 15:40:53,177 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: collect at KMeans.scala:381, took 0.036800 s
2018-02-08 15:40:53,179 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 28 from persistence list
2018-02-08 15:40:53,181 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 28
2018-02-08 15:40:53,182 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(8) (from destroy at KMeans.scala:388)
2018-02-08 15:40:53,189 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(11) (from destroy at KMeans.scala:388)
2018-02-08 15:40:53,190 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.11.26:62504 in memory (size: 339.0 B, free: 631.7 MB)
2018-02-08 15:40:53,192 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.11.26:62504 in memory (size: 413.0 B, free: 631.7 MB)
2018-02-08 15:40:53,195 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 488.0 B, free 630.6 MB)
2018-02-08 15:40:53,199 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 498.0 B, free 630.6 MB)
2018-02-08 15:40:53,200 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.11.26:62504 (size: 498.0 B, free: 631.7 MB)
2018-02-08 15:40:53,201 INFO[org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at KMeans.scala:398
2018-02-08 15:40:53,254 INFO[org.apache.spark.SparkContext:54] - Starting job: countByValue at KMeans.scala:399
2018-02-08 15:40:53,301 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.11.26:62504 in memory (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:40:53,310 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_3_piece0 on 192.168.11.26:62504 in memory (size: 4.0 KB, free: 631.7 MB)
2018-02-08 15:40:53,335 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_12_piece0 on 192.168.11.26:62504 in memory (size: 6.7 KB, free: 631.7 MB)
2018-02-08 15:40:53,338 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_13_piece0 on 192.168.11.26:62504 in memory (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:40:53,340 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:62504 in memory (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:40:53,341 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.11.26:62504 in memory (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:40:53,342 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:62504 in memory (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:40:53,473 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 33 (countByValue at KMeans.scala:399)
2018-02-08 15:40:53,474 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (countByValue at KMeans.scala:399) with 1 output partitions
2018-02-08 15:40:53,474 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 9 (countByValue at KMeans.scala:399)
2018-02-08 15:40:53,474 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 8)
2018-02-08 15:40:53,474 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 8)
2018-02-08 15:40:53,477 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at countByValue at KMeans.scala:399), which has no missing parents
2018-02-08 15:40:53,484 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 13.8 KB, free 630.8 MB)
2018-02-08 15:40:53,488 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.1 KB, free 630.8 MB)
2018-02-08 15:40:53,489 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.11.26:62504 (size: 7.1 KB, free: 631.7 MB)
2018-02-08 15:40:53,490 INFO[org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:53,493 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at countByValue at KMeans.scala:399) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:53,493 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 1 tasks
2018-02-08 15:40:53,495 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:40:53,496 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 9)
2018-02-08 15:40:53,501 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:40:53,501 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:40:53,563 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 9). 1754 bytes result sent to driver
2018-02-08 15:40:53,566 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 9) in 72 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:53,566 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 15:40:53,569 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 8 (countByValue at KMeans.scala:399) finished in 0.074 s
2018-02-08 15:40:53,570 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:40:53,571 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:40:53,572 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 9)
2018-02-08 15:40:53,573 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:40:53,577 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 9 (ShuffledRDD[34] at countByValue at KMeans.scala:399), which has no missing parents
2018-02-08 15:40:53,581 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16 stored as values in memory (estimated size 3.2 KB, free 630.7 MB)
2018-02-08 15:40:53,586 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 1971.0 B, free 630.7 MB)
2018-02-08 15:40:53,587 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_16_piece0 in memory on 192.168.11.26:62504 (size: 1971.0 B, free: 631.7 MB)
2018-02-08 15:40:53,587 INFO[org.apache.spark.SparkContext:54] - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:53,588 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[34] at countByValue at KMeans.scala:399) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:53,588 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 1 tasks
2018-02-08 15:40:53,590 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:40:53,590 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 10)
2018-02-08 15:40:53,602 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:40:53,603 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 15:40:53,630 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 10). 1337 bytes result sent to driver
2018-02-08 15:40:53,630 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 10) in 41 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:53,631 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-02-08 15:40:53,631 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 9 (countByValue at KMeans.scala:399) finished in 0.042 s
2018-02-08 15:40:53,632 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: countByValue at KMeans.scala:399, took 0.378306 s
2018-02-08 15:40:53,633 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(14) (from destroy at KMeans.scala:401)
2018-02-08 15:40:53,636 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_14_piece0 on 192.168.11.26:62504 in memory (size: 498.0 B, free: 631.7 MB)
2018-02-08 15:40:53,640 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 15:40:53,640 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 15:40:53,646 INFO[org.apache.spark.mllib.clustering.LocalKMeans:54] - Local KMeans++ converged in 2 iterations.
2018-02-08 15:40:53,647 INFO[org.apache.spark.mllib.clustering.KMeans:54] - Initialization with k-means|| took 0.938 seconds.
2018-02-08 15:40:53,649 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_a75cebff25ba-2032752946-1: {"numFeatures":3}
2018-02-08 15:40:53,651 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17 stored as values in memory (estimated size 208.0 B, free 630.7 MB)
2018-02-08 15:40:53,654 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 310.0 B, free 630.7 MB)
2018-02-08 15:40:53,656 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_17_piece0 in memory on 192.168.11.26:62504 (size: 310.0 B, free: 631.7 MB)
2018-02-08 15:40:53,657 INFO[org.apache.spark.SparkContext:54] - Created broadcast 17 from broadcast at KMeans.scala:273
2018-02-08 15:40:53,687 INFO[org.apache.spark.SparkContext:54] - Starting job: collectAsMap at KMeans.scala:295
2018-02-08 15:40:53,688 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 35 (mapPartitions at KMeans.scala:276)
2018-02-08 15:40:53,688 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (collectAsMap at KMeans.scala:295) with 1 output partitions
2018-02-08 15:40:53,688 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 11 (collectAsMap at KMeans.scala:295)
2018-02-08 15:40:53,688 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 10)
2018-02-08 15:40:53,688 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 10)
2018-02-08 15:40:53,689 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 10 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:276), which has no missing parents
2018-02-08 15:40:53,692 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18 stored as values in memory (estimated size 13.2 KB, free 630.7 MB)
2018-02-08 15:40:53,694 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.7 MB)
2018-02-08 15:40:53,694 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_18_piece0 in memory on 192.168.11.26:62504 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:40:53,695 INFO[org.apache.spark.SparkContext:54] - Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:53,697 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:53,697 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 1 tasks
2018-02-08 15:40:53,699 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:40:53,699 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 11)
2018-02-08 15:40:53,703 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:40:53,704 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:40:53,713 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 11). 1781 bytes result sent to driver
2018-02-08 15:40:53,717 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 11) in 19 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:53,718 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 15:40:53,720 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 10 (mapPartitions at KMeans.scala:276) finished in 0.022 s
2018-02-08 15:40:53,721 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:40:53,721 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:40:53,721 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 11)
2018-02-08 15:40:53,721 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:40:53,721 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 11 (ShuffledRDD[36] at reduceByKey at KMeans.scala:292), which has no missing parents
2018-02-08 15:40:53,723 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19 stored as values in memory (estimated size 2.8 KB, free 630.7 MB)
2018-02-08 15:40:53,726 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 1654.0 B, free 630.7 MB)
2018-02-08 15:40:53,729 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_19_piece0 in memory on 192.168.11.26:62504 (size: 1654.0 B, free: 631.7 MB)
2018-02-08 15:40:53,730 INFO[org.apache.spark.SparkContext:54] - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:53,730 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 11 (ShuffledRDD[36] at reduceByKey at KMeans.scala:292) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:53,730 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 1 tasks
2018-02-08 15:40:53,731 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 12, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:40:53,732 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 12)
2018-02-08 15:40:53,735 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:40:53,735 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:40:53,739 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 12). 1436 bytes result sent to driver
2018-02-08 15:40:53,741 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 12) in 10 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:53,742 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 15:40:53,742 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 11 (collectAsMap at KMeans.scala:295) finished in 0.011 s
2018-02-08 15:40:53,743 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: collectAsMap at KMeans.scala:295, took 0.055658 s
2018-02-08 15:40:53,746 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(17) (from destroy at KMeans.scala:297)
2018-02-08 15:40:53,747 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_17_piece0 on 192.168.11.26:62504 in memory (size: 310.0 B, free: 631.7 MB)
2018-02-08 15:40:53,748 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20 stored as values in memory (estimated size 208.0 B, free 630.7 MB)
2018-02-08 15:40:53,751 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 311.0 B, free 630.7 MB)
2018-02-08 15:40:53,754 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_20_piece0 in memory on 192.168.11.26:62504 (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:40:53,755 INFO[org.apache.spark.SparkContext:54] - Created broadcast 20 from broadcast at KMeans.scala:273
2018-02-08 15:40:53,771 INFO[org.apache.spark.SparkContext:54] - Starting job: collectAsMap at KMeans.scala:295
2018-02-08 15:40:53,772 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 37 (mapPartitions at KMeans.scala:276)
2018-02-08 15:40:53,772 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 10 (collectAsMap at KMeans.scala:295) with 1 output partitions
2018-02-08 15:40:53,772 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 13 (collectAsMap at KMeans.scala:295)
2018-02-08 15:40:53,772 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 12)
2018-02-08 15:40:53,772 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 12)
2018-02-08 15:40:53,774 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 12 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:276), which has no missing parents
2018-02-08 15:40:53,776 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21 stored as values in memory (estimated size 13.2 KB, free 630.7 MB)
2018-02-08 15:40:53,778 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.7 MB)
2018-02-08 15:40:53,780 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_21_piece0 in memory on 192.168.11.26:62504 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:40:53,781 INFO[org.apache.spark.SparkContext:54] - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:53,783 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:53,783 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 12.0 with 1 tasks
2018-02-08 15:40:53,783 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:40:53,784 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 12.0 (TID 13)
2018-02-08 15:40:53,787 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:40:53,787 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:40:53,794 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 12.0 (TID 13). 1738 bytes result sent to driver
2018-02-08 15:40:53,795 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 12.0 (TID 13) in 12 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:53,795 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2018-02-08 15:40:53,795 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 12 (mapPartitions at KMeans.scala:276) finished in 0.012 s
2018-02-08 15:40:53,795 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:40:53,795 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:40:53,796 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 13)
2018-02-08 15:40:53,796 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:40:53,796 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 13 (ShuffledRDD[38] at reduceByKey at KMeans.scala:292), which has no missing parents
2018-02-08 15:40:53,798 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22 stored as values in memory (estimated size 2.8 KB, free 630.7 MB)
2018-02-08 15:40:53,801 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 1659.0 B, free 630.7 MB)
2018-02-08 15:40:53,801 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_22_piece0 in memory on 192.168.11.26:62504 (size: 1659.0 B, free: 631.7 MB)
2018-02-08 15:40:53,801 INFO[org.apache.spark.SparkContext:54] - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:53,802 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 13 (ShuffledRDD[38] at reduceByKey at KMeans.scala:292) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:53,802 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 13.0 with 1 tasks
2018-02-08 15:40:53,803 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:40:53,803 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 13.0 (TID 14)
2018-02-08 15:40:53,805 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:40:53,805 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:40:53,807 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 13.0 (TID 14). 1350 bytes result sent to driver
2018-02-08 15:40:53,808 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 13.0 (TID 14) in 6 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:53,808 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2018-02-08 15:40:53,809 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 13 (collectAsMap at KMeans.scala:295) finished in 0.007 s
2018-02-08 15:40:53,809 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 10 finished: collectAsMap at KMeans.scala:295, took 0.038293 s
2018-02-08 15:40:53,810 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(20) (from destroy at KMeans.scala:297)
2018-02-08 15:40:53,811 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_20_piece0 on 192.168.11.26:62504 in memory (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:40:53,811 INFO[org.apache.spark.mllib.clustering.KMeans:54] - Iterations took 0.164 seconds.
2018-02-08 15:40:53,813 INFO[org.apache.spark.mllib.clustering.KMeans:54] - KMeans converged in 2 iterations.
2018-02-08 15:40:53,814 INFO[org.apache.spark.mllib.clustering.KMeans:54] - The cost is 0.11999999999994547.
2018-02-08 15:40:53,815 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 18 from persistence list
2018-02-08 15:40:53,816 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 18
2018-02-08 15:40:54,099 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_a75cebff25ba-2032752946-1: training finished
2018-02-08 15:40:54,099 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 17 from persistence list
2018-02-08 15:40:54,100 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 17
2018-02-08 15:40:54,107 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:40:54,107 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:40:54,108 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:40:54,108 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:40:54,115 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23 stored as values in memory (estimated size 322.9 KB, free 630.4 MB)
2018-02-08 15:40:54,127 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 27.6 KB, free 630.4 MB)
2018-02-08 15:40:54,128 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_23_piece0 in memory on 192.168.11.26:62504 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:40:54,129 INFO[org.apache.spark.SparkContext:54] - Created broadcast 23 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:40:54,130 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:40:54,139 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24 stored as values in memory (estimated size 208.0 B, free 630.4 MB)
2018-02-08 15:40:54,141 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 311.0 B, free 630.4 MB)
2018-02-08 15:40:54,142 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_24_piece0 in memory on 192.168.11.26:62504 (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:40:54,142 INFO[org.apache.spark.SparkContext:54] - Created broadcast 24 from broadcast at KMeansModel.scala:87
2018-02-08 15:40:54,148 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeansModel.scala:88
2018-02-08 15:40:54,149 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 11 (sum at KMeansModel.scala:88) with 1 output partitions
2018-02-08 15:40:54,149 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 14 (sum at KMeansModel.scala:88)
2018-02-08 15:40:54,149 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:40:54,149 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:40:54,150 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 14 (MapPartitionsRDD[44] at map at KMeansModel.scala:88), which has no missing parents
2018-02-08 15:40:54,151 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25 stored as values in memory (estimated size 11.8 KB, free 630.3 MB)
2018-02-08 15:40:54,153 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.2 KB, free 630.3 MB)
2018-02-08 15:40:54,154 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_25_piece0 in memory on 192.168.11.26:62504 (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:40:54,154 INFO[org.apache.spark.SparkContext:54] - Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:40:54,155 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[44] at map at KMeansModel.scala:88) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:40:54,155 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 14.0 with 1 tasks
2018-02-08 15:40:54,156 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:40:54,156 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 14.0 (TID 15)
2018-02-08 15:40:54,160 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:40:54,169 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 14.0 (TID 15). 1348 bytes result sent to driver
2018-02-08 15:40:54,170 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 14.0 (TID 15) in 14 ms on localhost (executor driver) (1/1)
2018-02-08 15:40:54,171 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-02-08 15:40:54,171 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 14 (sum at KMeansModel.scala:88) finished in 0.015 s
2018-02-08 15:40:54,171 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 11 finished: sum at KMeansModel.scala:88, took 0.023383 s
2018-02-08 15:40:54,178 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:40:54,183 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@53028cb5{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:40:54,186 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:40:54,195 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:40:54,283 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:40:54,283 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:40:54,285 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:40:54,287 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:40:54,292 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:40:54,294 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:40:54,295 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-9afed25d-a83b-4923-a47f-02d14ebcdcd3
2018-02-08 15:46:59,791 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:47:00,315 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:47:00,334 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:47:00,335 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:47:00,336 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:47:00,337 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:47:00,337 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:47:00,660 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62585.
2018-02-08 15:47:00,676 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:47:00,719 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:47:00,722 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:47:00,722 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:47:00,730 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-cabf4ba1-b76d-495a-8fb5-c83508653cb1
2018-02-08 15:47:00,750 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:47:00,795 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:47:00,864 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2706ms
2018-02-08 15:47:00,925 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:47:00,937 INFO[org.spark_project.jetty.server.Server:403] - Started @2780ms
2018-02-08 15:47:00,954 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@5e6e1c10{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:47:00,955 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:47:00,976 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2488b073{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,977 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,977 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,978 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@631e06ab{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,979 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@34a75079{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,979 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,981 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@186978a6{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,982 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,982 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,983 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,984 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,985 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,986 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,987 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,989 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,990 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,991 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,993 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,994 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:47:00,995 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:01,001 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/static,null,AVAILABLE,@Spark}
2018-02-08 15:47:01,002 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@305f031{/,null,AVAILABLE,@Spark}
2018-02-08 15:47:01,003 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d1f7216{/api,null,AVAILABLE,@Spark}
2018-02-08 15:47:01,003 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4ebea12c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:47:01,004 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6256ac4f{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:47:01,005 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:47:01,072 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:47:01,095 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62598.
2018-02-08 15:47:01,096 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62598
2018-02-08 15:47:01,098 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:47:01,099 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62598, None)
2018-02-08 15:47:01,102 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62598 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62598, None)
2018-02-08 15:47:01,104 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62598, None)
2018-02-08 15:47:01,106 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62598, None)
2018-02-08 15:47:01,281 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5a6d5a8f{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:01,352 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:47:01,353 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:47:01,359 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@325f7fa9{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:47:01,363 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63a5d002{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:01,364 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@91c4a3f{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:47:01,365 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@150d80c4{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:47:01,367 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41c89d2f{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:47:02,304 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:47:02,667 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 15:47:02,723 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 15:47:02,725 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:62598 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:47:02,730 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 15:47:02,835 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 15:47:02,847 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 15:47:02,865 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 15:47:02,866 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 15:47:02,866 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:47:02,868 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:47:02,873 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 15:47:02,943 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 15:47:02,949 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 15:47:02,952 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:62598 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:47:02,953 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:02,968 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 15:47:02,969 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 15:47:03,007 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:47:03,009 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:47:03,019 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:47:03,019 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 15:47:03,082 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:60+60
2018-02-08 15:47:03,085 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:0+60
2018-02-08 15:47:03,142 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 910 bytes result sent to driver
2018-02-08 15:47:03,142 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 910 bytes result sent to driver
2018-02-08 15:47:03,175 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 179 ms on localhost (executor driver) (1/2)
2018-02-08 15:47:03,176 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 167 ms on localhost (executor driver) (2/2)
2018-02-08 15:47:03,177 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:47:03,181 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.196 s
2018-02-08 15:47:03,186 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.338518 s
2018-02-08 15:47:03,994 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:62598 in memory (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:47:03,997 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:62598 in memory (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:47:04,621 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:47:04,630 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:47:04,635 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:47:04,649 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:47:04,976 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 196.554303 ms
2018-02-08 15:47:04,989 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:47:05,003 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:47:05,004 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:62598 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:47:05,005 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:47:05,016 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:47:05,068 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningClustering.java:26
2018-02-08 15:47:05,069 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (show at MachineLeaningClustering.java:26) with 1 output partitions
2018-02-08 15:47:05,069 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (show at MachineLeaningClustering.java:26)
2018-02-08 15:47:05,069 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:47:05,069 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:47:05,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[8] at show at MachineLeaningClustering.java:26), which has no missing parents
2018-02-08 15:47:05,094 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 7.2 KB, free 631.5 MB)
2018-02-08 15:47:05,097 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 631.4 MB)
2018-02-08 15:47:05,097 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:62598 (size: 4.0 KB, free: 631.8 MB)
2018-02-08 15:47:05,098 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:05,099 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at MachineLeaningClustering.java:26) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:05,099 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 15:47:05,106 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:47:05,107 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 15:47:05,119 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:47:05,166 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 33.478411 ms
2018-02-08 15:47:05,256 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 39.505932 ms
2018-02-08 15:47:05,264 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 1301 bytes result sent to driver
2018-02-08 15:47:05,266 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 166 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:05,266 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 15:47:05,267 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (show at MachineLeaningClustering.java:26) finished in 0.168 s
2018-02-08 15:47:05,270 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: show at MachineLeaningClustering.java:26, took 0.201724 s
2018-02-08 15:47:05,299 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.228165 ms
2018-02-08 15:47:05,378 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:47:05,379 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:47:05,379 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:47:05,380 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:47:05,388 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 322.9 KB, free 631.1 MB)
2018-02-08 15:47:05,404 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.1 MB)
2018-02-08 15:47:05,406 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:62598 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:47:05,407 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:47:05,407 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:47:05,460 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:47:05,461 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:47:05,461 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:47:05,462 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:47:05,469 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 322.9 KB, free 630.8 MB)
2018-02-08 15:47:05,487 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 27.6 KB, free 630.8 MB)
2018-02-08 15:47:05,489 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:62598 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:47:05,490 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:47:05,491 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:47:05,513 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_eb510cb894d7-1994394587-1: training: numPartitions=1 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
2018-02-08 15:47:05,536 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_eb510cb894d7-1994394587-1: {"k":2,"seed":1}
2018-02-08 15:47:05,568 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at KMeans.scala:353
2018-02-08 15:47:05,569 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (takeSample at KMeans.scala:353) with 1 output partitions
2018-02-08 15:47:05,569 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (takeSample at KMeans.scala:353)
2018-02-08 15:47:05,569 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:47:05,571 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:47:05,574 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[20] at map at KMeans.scala:224), which has no missing parents
2018-02-08 15:47:05,601 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 11.9 KB, free 630.8 MB)
2018-02-08 15:47:05,604 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.2 KB, free 630.7 MB)
2018-02-08 15:47:05,605 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:62598 (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:47:05,606 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:05,606 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[20] at map at KMeans.scala:224) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:05,607 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 15:47:05,609 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5605 bytes)
2018-02-08 15:47:05,610 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 15:47:05,626 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.789763 ms
2018-02-08 15:47:05,627 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:47:05,642 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.185924 ms
2018-02-08 15:47:05,662 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.772804 ms
2018-02-08 15:47:05,675 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_0 stored as values in memory (estimated size 576.0 B, free 630.7 MB)
2018-02-08 15:47:05,677 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_0 in memory on 192.168.11.26:62598 (size: 576.0 B, free: 631.7 MB)
2018-02-08 15:47:05,680 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:47:05,682 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_18_0 stored as values in memory (estimated size 64.0 B, free 630.7 MB)
2018-02-08 15:47:05,683 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_18_0 in memory on 192.168.11.26:62598 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:47:05,690 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 2117 bytes result sent to driver
2018-02-08 15:47:05,692 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 85 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:05,692 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 15:47:05,693 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (takeSample at KMeans.scala:353) finished in 0.086 s
2018-02-08 15:47:05,693 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: takeSample at KMeans.scala:353, took 0.125091 s
2018-02-08 15:47:05,719 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at KMeans.scala:353
2018-02-08 15:47:05,720 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (takeSample at KMeans.scala:353) with 1 output partitions
2018-02-08 15:47:05,720 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (takeSample at KMeans.scala:353)
2018-02-08 15:47:05,721 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:47:05,724 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:47:05,725 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (PartitionwiseSampledRDD[22] at takeSample at KMeans.scala:353), which has no missing parents
2018-02-08 15:47:05,728 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 12.6 KB, free 630.7 MB)
2018-02-08 15:47:05,731 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 630.7 MB)
2018-02-08 15:47:05,735 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:62598 (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:47:05,736 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:05,739 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (PartitionwiseSampledRDD[22] at takeSample at KMeans.scala:353) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:05,739 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 15:47:05,743 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5714 bytes)
2018-02-08 15:47:05,744 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 15:47:05,753 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:47:05,753 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:47:05,756 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 2061 bytes result sent to driver
2018-02-08 15:47:05,766 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 24 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:05,768 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 15:47:05,771 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (takeSample at KMeans.scala:353) finished in 0.029 s
2018-02-08 15:47:05,776 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: takeSample at KMeans.scala:353, took 0.055998 s
2018-02-08 15:47:05,786 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 144.0 B, free 630.7 MB)
2018-02-08 15:47:05,790 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 339.0 B, free 630.7 MB)
2018-02-08 15:47:05,791 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:62598 (size: 339.0 B, free: 631.7 MB)
2018-02-08 15:47:05,792 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at KMeans.scala:367
2018-02-08 15:47:05,809 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeans.scala:373
2018-02-08 15:47:05,810 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (sum at KMeans.scala:373) with 1 output partitions
2018-02-08 15:47:05,811 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (sum at KMeans.scala:373)
2018-02-08 15:47:05,811 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:47:05,813 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:47:05,814 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[24] at map at KMeans.scala:370), which has no missing parents
2018-02-08 15:47:05,816 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 12.7 KB, free 630.7 MB)
2018-02-08 15:47:05,820 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.6 KB, free 630.7 MB)
2018-02-08 15:47:05,822 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.11.26:62598 (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:47:05,823 INFO[org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:05,824 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at map at KMeans.scala:370) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:05,824 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
2018-02-08 15:47:05,825 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5637 bytes)
2018-02-08 15:47:05,826 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 15:47:05,830 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:47:05,831 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:47:05,831 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:47:05,831 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:47:05,839 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_24_0 stored as values in memory (estimated size 64.0 B, free 630.7 MB)
2018-02-08 15:47:05,841 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_24_0 in memory on 192.168.11.26:62598 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:47:05,842 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 2072 bytes result sent to driver
2018-02-08 15:47:05,843 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 18 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:05,843 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 15:47:05,844 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (sum at KMeans.scala:373) finished in 0.018 s
2018-02-08 15:47:05,844 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: sum at KMeans.scala:373, took 0.034375 s
2018-02-08 15:47:05,846 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 21 from persistence list
2018-02-08 15:47:05,849 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 21
2018-02-08 15:47:05,868 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at KMeans.scala:381
2018-02-08 15:47:05,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (collect at KMeans.scala:381) with 1 output partitions
2018-02-08 15:47:05,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (collect at KMeans.scala:381)
2018-02-08 15:47:05,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:47:05,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:47:05,870 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[26] at mapPartitionsWithIndex at KMeans.scala:378), which has no missing parents
2018-02-08 15:47:05,873 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 13.3 KB, free 630.7 MB)
2018-02-08 15:47:05,882 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.7 MB)
2018-02-08 15:47:05,885 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.11.26:62598 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:47:05,886 INFO[org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:05,887 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at mapPartitionsWithIndex at KMeans.scala:378) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:05,887 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
2018-02-08 15:47:05,888 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5669 bytes)
2018-02-08 15:47:05,888 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 6)
2018-02-08 15:47:05,896 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:47:05,896 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:47:05,897 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_24_0 locally
2018-02-08 15:47:05,898 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 6). 1864 bytes result sent to driver
2018-02-08 15:47:05,899 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 6) in 11 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:05,900 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 15:47:05,901 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (collect at KMeans.scala:381) finished in 0.013 s
2018-02-08 15:47:05,901 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: collect at KMeans.scala:381, took 0.033314 s
2018-02-08 15:47:05,906 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 320.0 B, free 630.7 MB)
2018-02-08 15:47:05,914 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 413.0 B, free 630.7 MB)
2018-02-08 15:47:05,916 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.11.26:62598 (size: 413.0 B, free: 631.7 MB)
2018-02-08 15:47:05,918 INFO[org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at KMeans.scala:367
2018-02-08 15:47:05,933 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeans.scala:373
2018-02-08 15:47:05,934 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (sum at KMeans.scala:373) with 1 output partitions
2018-02-08 15:47:05,935 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (sum at KMeans.scala:373)
2018-02-08 15:47:05,935 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:47:05,936 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:47:05,937 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[28] at map at KMeans.scala:370), which has no missing parents
2018-02-08 15:47:05,946 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 12.9 KB, free 630.7 MB)
2018-02-08 15:47:05,950 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.7 KB, free 630.7 MB)
2018-02-08 15:47:05,954 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.11.26:62598 (size: 6.7 KB, free: 631.7 MB)
2018-02-08 15:47:05,956 INFO[org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:05,957 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at map at KMeans.scala:370) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:05,957 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
2018-02-08 15:47:05,960 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5669 bytes)
2018-02-08 15:47:05,960 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 7)
2018-02-08 15:47:05,964 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:47:05,964 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:47:05,965 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_24_0 locally
2018-02-08 15:47:05,967 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_28_0 stored as values in memory (estimated size 64.0 B, free 630.7 MB)
2018-02-08 15:47:05,969 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_28_0 in memory on 192.168.11.26:62598 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:47:05,971 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 7). 2072 bytes result sent to driver
2018-02-08 15:47:05,972 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 7) in 13 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:05,972 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 15:47:05,973 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (sum at KMeans.scala:373) finished in 0.014 s
2018-02-08 15:47:05,975 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: sum at KMeans.scala:373, took 0.040998 s
2018-02-08 15:47:05,977 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 24 from persistence list
2018-02-08 15:47:05,979 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 24
2018-02-08 15:47:06,004 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at KMeans.scala:381
2018-02-08 15:47:06,006 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (collect at KMeans.scala:381) with 1 output partitions
2018-02-08 15:47:06,006 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 7 (collect at KMeans.scala:381)
2018-02-08 15:47:06,006 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:47:06,007 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:47:06,007 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 7 (MapPartitionsRDD[30] at mapPartitionsWithIndex at KMeans.scala:378), which has no missing parents
2018-02-08 15:47:06,011 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 13.5 KB, free 630.7 MB)
2018-02-08 15:47:06,015 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.6 MB)
2018-02-08 15:47:06,017 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.11.26:62598 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:47:06,017 INFO[org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:06,018 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[30] at mapPartitionsWithIndex at KMeans.scala:378) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:06,018 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
2018-02-08 15:47:06,019 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5701 bytes)
2018-02-08 15:47:06,020 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 8)
2018-02-08 15:47:06,023 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:47:06,023 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:47:06,023 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_28_0 locally
2018-02-08 15:47:06,024 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 8). 1654 bytes result sent to driver
2018-02-08 15:47:06,025 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 8) in 6 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:06,025 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-02-08 15:47:06,026 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 7 (collect at KMeans.scala:381) finished in 0.007 s
2018-02-08 15:47:06,027 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: collect at KMeans.scala:381, took 0.022060 s
2018-02-08 15:47:06,028 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 28 from persistence list
2018-02-08 15:47:06,032 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 28
2018-02-08 15:47:06,034 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(8) (from destroy at KMeans.scala:388)
2018-02-08 15:47:06,036 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(11) (from destroy at KMeans.scala:388)
2018-02-08 15:47:06,039 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.11.26:62598 in memory (size: 339.0 B, free: 631.7 MB)
2018-02-08 15:47:06,043 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.11.26:62598 in memory (size: 413.0 B, free: 631.7 MB)
2018-02-08 15:47:06,045 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 488.0 B, free 630.6 MB)
2018-02-08 15:47:06,070 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 498.0 B, free 630.6 MB)
2018-02-08 15:47:06,071 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.11.26:62598 (size: 498.0 B, free: 631.7 MB)
2018-02-08 15:47:06,072 INFO[org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at KMeans.scala:398
2018-02-08 15:47:06,088 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_13_piece0 on 192.168.11.26:62598 in memory (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:47:06,100 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.11.26:62598 in memory (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:47:06,108 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.11.26:62598 in memory (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:47:06,120 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:62598 in memory (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:47:06,122 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_3_piece0 on 192.168.11.26:62598 in memory (size: 4.0 KB, free: 631.7 MB)
2018-02-08 15:47:06,129 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:62598 in memory (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:47:06,131 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_12_piece0 on 192.168.11.26:62598 in memory (size: 6.7 KB, free: 631.7 MB)
2018-02-08 15:47:06,158 INFO[org.apache.spark.SparkContext:54] - Starting job: countByValue at KMeans.scala:399
2018-02-08 15:47:06,307 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 33 (countByValue at KMeans.scala:399)
2018-02-08 15:47:06,307 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (countByValue at KMeans.scala:399) with 1 output partitions
2018-02-08 15:47:06,307 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 9 (countByValue at KMeans.scala:399)
2018-02-08 15:47:06,307 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 8)
2018-02-08 15:47:06,307 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 8)
2018-02-08 15:47:06,310 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at countByValue at KMeans.scala:399), which has no missing parents
2018-02-08 15:47:06,318 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 13.8 KB, free 630.8 MB)
2018-02-08 15:47:06,321 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.1 KB, free 630.8 MB)
2018-02-08 15:47:06,321 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.11.26:62598 (size: 7.1 KB, free: 631.7 MB)
2018-02-08 15:47:06,326 INFO[org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:06,330 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at countByValue at KMeans.scala:399) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:06,330 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 1 tasks
2018-02-08 15:47:06,333 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:47:06,334 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 9)
2018-02-08 15:47:06,339 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:47:06,340 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:47:06,397 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 9). 1711 bytes result sent to driver
2018-02-08 15:47:06,399 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 9) in 67 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:06,399 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 15:47:06,400 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 8 (countByValue at KMeans.scala:399) finished in 0.068 s
2018-02-08 15:47:06,401 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:47:06,401 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:47:06,402 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 9)
2018-02-08 15:47:06,402 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:47:06,407 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 9 (ShuffledRDD[34] at countByValue at KMeans.scala:399), which has no missing parents
2018-02-08 15:47:06,411 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16 stored as values in memory (estimated size 3.2 KB, free 630.7 MB)
2018-02-08 15:47:06,414 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 1971.0 B, free 630.7 MB)
2018-02-08 15:47:06,415 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_16_piece0 in memory on 192.168.11.26:62598 (size: 1971.0 B, free: 631.7 MB)
2018-02-08 15:47:06,415 INFO[org.apache.spark.SparkContext:54] - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:06,416 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[34] at countByValue at KMeans.scala:399) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:06,416 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 1 tasks
2018-02-08 15:47:06,418 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:47:06,419 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 10)
2018-02-08 15:47:06,430 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:47:06,431 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 15:47:06,454 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 10). 1294 bytes result sent to driver
2018-02-08 15:47:06,456 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 10) in 39 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:06,456 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-02-08 15:47:06,457 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 9 (countByValue at KMeans.scala:399) finished in 0.039 s
2018-02-08 15:47:06,457 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: countByValue at KMeans.scala:399, took 0.298758 s
2018-02-08 15:47:06,459 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(14) (from destroy at KMeans.scala:401)
2018-02-08 15:47:06,460 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_14_piece0 on 192.168.11.26:62598 in memory (size: 498.0 B, free: 631.7 MB)
2018-02-08 15:47:06,466 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 15:47:06,467 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 15:47:06,473 INFO[org.apache.spark.mllib.clustering.LocalKMeans:54] - Local KMeans++ converged in 2 iterations.
2018-02-08 15:47:06,474 INFO[org.apache.spark.mllib.clustering.KMeans:54] - Initialization with k-means|| took 0.917 seconds.
2018-02-08 15:47:06,475 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_eb510cb894d7-1994394587-1: {"numFeatures":3}
2018-02-08 15:47:06,476 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17 stored as values in memory (estimated size 208.0 B, free 630.7 MB)
2018-02-08 15:47:06,478 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 310.0 B, free 630.7 MB)
2018-02-08 15:47:06,479 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_17_piece0 in memory on 192.168.11.26:62598 (size: 310.0 B, free: 631.7 MB)
2018-02-08 15:47:06,479 INFO[org.apache.spark.SparkContext:54] - Created broadcast 17 from broadcast at KMeans.scala:273
2018-02-08 15:47:06,496 INFO[org.apache.spark.SparkContext:54] - Starting job: collectAsMap at KMeans.scala:295
2018-02-08 15:47:06,497 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 35 (mapPartitions at KMeans.scala:276)
2018-02-08 15:47:06,498 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (collectAsMap at KMeans.scala:295) with 1 output partitions
2018-02-08 15:47:06,498 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 11 (collectAsMap at KMeans.scala:295)
2018-02-08 15:47:06,498 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 10)
2018-02-08 15:47:06,498 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 10)
2018-02-08 15:47:06,499 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 10 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:276), which has no missing parents
2018-02-08 15:47:06,502 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18 stored as values in memory (estimated size 13.2 KB, free 630.7 MB)
2018-02-08 15:47:06,504 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.7 MB)
2018-02-08 15:47:06,505 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_18_piece0 in memory on 192.168.11.26:62598 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:47:06,505 INFO[org.apache.spark.SparkContext:54] - Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:06,506 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:06,506 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 1 tasks
2018-02-08 15:47:06,507 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:47:06,507 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 11)
2018-02-08 15:47:06,510 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:47:06,510 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:47:06,519 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 11). 1781 bytes result sent to driver
2018-02-08 15:47:06,522 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 11) in 16 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:06,522 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 15:47:06,522 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 10 (mapPartitions at KMeans.scala:276) finished in 0.016 s
2018-02-08 15:47:06,523 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:47:06,523 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:47:06,523 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 11)
2018-02-08 15:47:06,523 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:47:06,523 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 11 (ShuffledRDD[36] at reduceByKey at KMeans.scala:292), which has no missing parents
2018-02-08 15:47:06,524 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19 stored as values in memory (estimated size 2.8 KB, free 630.7 MB)
2018-02-08 15:47:06,526 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 1654.0 B, free 630.7 MB)
2018-02-08 15:47:06,527 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_19_piece0 in memory on 192.168.11.26:62598 (size: 1654.0 B, free: 631.7 MB)
2018-02-08 15:47:06,528 INFO[org.apache.spark.SparkContext:54] - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:06,529 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 11 (ShuffledRDD[36] at reduceByKey at KMeans.scala:292) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:06,529 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 1 tasks
2018-02-08 15:47:06,533 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 12, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:47:06,533 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 12)
2018-02-08 15:47:06,537 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:47:06,537 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:47:06,539 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 12). 1393 bytes result sent to driver
2018-02-08 15:47:06,540 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 12) in 8 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:06,540 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 15:47:06,541 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 11 (collectAsMap at KMeans.scala:295) finished in 0.012 s
2018-02-08 15:47:06,541 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: collectAsMap at KMeans.scala:295, took 0.044630 s
2018-02-08 15:47:06,544 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(17) (from destroy at KMeans.scala:297)
2018-02-08 15:47:06,548 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20 stored as values in memory (estimated size 208.0 B, free 630.7 MB)
2018-02-08 15:47:06,549 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_17_piece0 on 192.168.11.26:62598 in memory (size: 310.0 B, free: 631.7 MB)
2018-02-08 15:47:06,552 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 311.0 B, free 630.7 MB)
2018-02-08 15:47:06,554 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_20_piece0 in memory on 192.168.11.26:62598 (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:47:06,554 INFO[org.apache.spark.SparkContext:54] - Created broadcast 20 from broadcast at KMeans.scala:273
2018-02-08 15:47:06,573 INFO[org.apache.spark.SparkContext:54] - Starting job: collectAsMap at KMeans.scala:295
2018-02-08 15:47:06,573 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 37 (mapPartitions at KMeans.scala:276)
2018-02-08 15:47:06,574 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 10 (collectAsMap at KMeans.scala:295) with 1 output partitions
2018-02-08 15:47:06,574 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 13 (collectAsMap at KMeans.scala:295)
2018-02-08 15:47:06,574 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 12)
2018-02-08 15:47:06,574 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 12)
2018-02-08 15:47:06,574 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 12 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:276), which has no missing parents
2018-02-08 15:47:06,576 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21 stored as values in memory (estimated size 13.2 KB, free 630.7 MB)
2018-02-08 15:47:06,577 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.7 MB)
2018-02-08 15:47:06,578 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_21_piece0 in memory on 192.168.11.26:62598 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:47:06,579 INFO[org.apache.spark.SparkContext:54] - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:06,580 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:06,580 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 12.0 with 1 tasks
2018-02-08 15:47:06,583 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:47:06,584 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 12.0 (TID 13)
2018-02-08 15:47:06,587 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:47:06,587 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:47:06,597 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 12.0 (TID 13). 1781 bytes result sent to driver
2018-02-08 15:47:06,600 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 12.0 (TID 13) in 19 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:06,601 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2018-02-08 15:47:06,612 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 12 (mapPartitions at KMeans.scala:276) finished in 0.031 s
2018-02-08 15:47:06,612 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:47:06,612 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:47:06,612 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 13)
2018-02-08 15:47:06,612 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:47:06,613 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 13 (ShuffledRDD[38] at reduceByKey at KMeans.scala:292), which has no missing parents
2018-02-08 15:47:06,615 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22 stored as values in memory (estimated size 2.8 KB, free 630.7 MB)
2018-02-08 15:47:06,619 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 1659.0 B, free 630.7 MB)
2018-02-08 15:47:06,619 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_22_piece0 in memory on 192.168.11.26:62598 (size: 1659.0 B, free: 631.7 MB)
2018-02-08 15:47:06,620 INFO[org.apache.spark.SparkContext:54] - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:06,620 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 13 (ShuffledRDD[38] at reduceByKey at KMeans.scala:292) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:06,620 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 13.0 with 1 tasks
2018-02-08 15:47:06,621 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:47:06,621 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 13.0 (TID 14)
2018-02-08 15:47:06,623 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:47:06,624 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:47:06,626 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 13.0 (TID 14). 1436 bytes result sent to driver
2018-02-08 15:47:06,627 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 13.0 (TID 14) in 6 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:06,627 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2018-02-08 15:47:06,628 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 13 (collectAsMap at KMeans.scala:295) finished in 0.007 s
2018-02-08 15:47:06,629 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 10 finished: collectAsMap at KMeans.scala:295, took 0.055640 s
2018-02-08 15:47:06,630 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(20) (from destroy at KMeans.scala:297)
2018-02-08 15:47:06,631 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_20_piece0 on 192.168.11.26:62598 in memory (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:47:06,631 INFO[org.apache.spark.mllib.clustering.KMeans:54] - Iterations took 0.156 seconds.
2018-02-08 15:47:06,632 INFO[org.apache.spark.mllib.clustering.KMeans:54] - KMeans converged in 2 iterations.
2018-02-08 15:47:06,633 INFO[org.apache.spark.mllib.clustering.KMeans:54] - The cost is 0.11999999999994547.
2018-02-08 15:47:06,635 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 18 from persistence list
2018-02-08 15:47:06,635 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 18
2018-02-08 15:47:06,933 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_eb510cb894d7-1994394587-1: training finished
2018-02-08 15:47:06,934 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 17 from persistence list
2018-02-08 15:47:06,934 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 17
2018-02-08 15:47:06,942 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:47:06,942 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:47:06,942 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:47:06,942 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:47:06,947 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23 stored as values in memory (estimated size 322.9 KB, free 630.4 MB)
2018-02-08 15:47:06,961 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 27.6 KB, free 630.4 MB)
2018-02-08 15:47:06,963 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_23_piece0 in memory on 192.168.11.26:62598 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:47:06,964 INFO[org.apache.spark.SparkContext:54] - Created broadcast 23 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:47:06,965 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:47:06,976 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24 stored as values in memory (estimated size 208.0 B, free 630.4 MB)
2018-02-08 15:47:06,979 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 311.0 B, free 630.4 MB)
2018-02-08 15:47:06,980 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_24_piece0 in memory on 192.168.11.26:62598 (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:47:06,980 INFO[org.apache.spark.SparkContext:54] - Created broadcast 24 from broadcast at KMeansModel.scala:87
2018-02-08 15:47:06,987 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeansModel.scala:88
2018-02-08 15:47:06,987 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 11 (sum at KMeansModel.scala:88) with 1 output partitions
2018-02-08 15:47:06,988 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 14 (sum at KMeansModel.scala:88)
2018-02-08 15:47:06,988 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:47:06,988 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:47:06,989 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 14 (MapPartitionsRDD[44] at map at KMeansModel.scala:88), which has no missing parents
2018-02-08 15:47:06,992 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25 stored as values in memory (estimated size 11.8 KB, free 630.3 MB)
2018-02-08 15:47:06,996 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.2 KB, free 630.3 MB)
2018-02-08 15:47:06,996 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_25_piece0 in memory on 192.168.11.26:62598 (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:47:06,997 INFO[org.apache.spark.SparkContext:54] - Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:47:06,998 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[44] at map at KMeansModel.scala:88) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:47:06,998 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 14.0 with 1 tasks
2018-02-08 15:47:07,000 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:47:07,001 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 14.0 (TID 15)
2018-02-08 15:47:07,004 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:47:07,013 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 14.0 (TID 15). 1348 bytes result sent to driver
2018-02-08 15:47:07,014 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 14.0 (TID 15) in 14 ms on localhost (executor driver) (1/1)
2018-02-08 15:47:07,014 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-02-08 15:47:07,014 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 14 (sum at KMeansModel.scala:88) finished in 0.015 s
2018-02-08 15:47:07,015 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 11 finished: sum at KMeansModel.scala:88, took 0.027688 s
2018-02-08 15:47:07,023 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:47:07,029 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@5e6e1c10{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:47:07,034 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:47:07,042 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:47:07,099 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:47:07,100 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:47:07,101 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:47:07,102 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:47:07,105 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:47:07,105 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:47:07,106 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-34777f0b-a035-495a-a66b-59cdb0433022
2018-02-08 15:51:01,151 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:51:01,824 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:51:01,845 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:51:01,846 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:51:01,847 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:51:01,847 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:51:01,848 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:51:02,192 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62652.
2018-02-08 15:51:02,209 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:51:02,255 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:51:02,258 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:51:02,259 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:51:02,267 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-3d9fa06f-c31d-4b1b-ba5f-e61fb4d079b5
2018-02-08 15:51:02,288 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:51:02,344 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:51:02,425 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2841ms
2018-02-08 15:51:02,489 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:51:02,503 INFO[org.spark_project.jetty.server.Server:403] - Started @2922ms
2018-02-08 15:51:02,524 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@7e94e0bb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:51:02,525 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:51:02,546 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2488b073{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,547 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,548 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,549 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@631e06ab{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,550 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@34a75079{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,551 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,551 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@186978a6{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,554 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,555 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,556 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,556 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,558 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,559 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,559 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,560 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,561 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,561 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,562 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,563 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,564 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,571 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/static,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,572 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@305f031{/,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,573 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d1f7216{/api,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,574 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4ebea12c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,575 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6256ac4f{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,577 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:51:02,653 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:51:02,677 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62666.
2018-02-08 15:51:02,678 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62666
2018-02-08 15:51:02,679 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:51:02,681 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62666, None)
2018-02-08 15:51:02,684 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62666 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62666, None)
2018-02-08 15:51:02,688 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62666, None)
2018-02-08 15:51:02,689 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62666, None)
2018-02-08 15:51:02,847 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5a6d5a8f{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,908 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:51:02,909 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:51:02,916 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@325f7fa9{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,916 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63a5d002{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,917 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@91c4a3f{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,918 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@150d80c4{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:51:02,919 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41c89d2f{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:51:04,031 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:51:04,412 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 15:51:04,468 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 15:51:04,471 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:62666 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:51:04,476 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at MLUtils.scala:99
2018-02-08 15:51:04,584 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 15:51:04,596 INFO[org.apache.spark.SparkContext:54] - Starting job: reduce at MLUtils.scala:92
2018-02-08 15:51:04,613 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (reduce at MLUtils.scala:92) with 2 output partitions
2018-02-08 15:51:04,614 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
2018-02-08 15:51:04,614 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:51:04,616 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:51:04,626 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
2018-02-08 15:51:04,673 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 15:51:04,676 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 15:51:04,677 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:62666 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:51:04,677 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:04,689 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 15:51:04,690 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 15:51:04,723 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:51:04,725 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4894 bytes)
2018-02-08 15:51:04,734 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:51:04,734 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 15:51:04,797 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:60+60
2018-02-08 15:51:04,799 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt:0+60
2018-02-08 15:51:04,866 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 867 bytes result sent to driver
2018-02-08 15:51:04,866 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 867 bytes result sent to driver
2018-02-08 15:51:04,873 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 148 ms on localhost (executor driver) (1/2)
2018-02-08 15:51:04,877 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 166 ms on localhost (executor driver) (2/2)
2018-02-08 15:51:04,878 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:51:04,882 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.180 s
2018-02-08 15:51:04,886 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: reduce at MLUtils.scala:92, took 0.289258 s
2018-02-08 15:51:05,216 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:62666 in memory (size: 2.3 KB, free: 631.8 MB)
2018-02-08 15:51:06,345 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_0_piece0 on 192.168.11.26:62666 in memory (size: 27.3 KB, free: 631.8 MB)
2018-02-08 15:51:06,346 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:51:06,351 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:51:06,355 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:51:06,362 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:51:06,673 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 196.684863 ms
2018-02-08 15:51:06,684 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:51:06,698 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:51:06,700 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:62666 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:51:06,701 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:51:06,710 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:51:06,754 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningClustering.java:26
2018-02-08 15:51:06,756 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (show at MachineLeaningClustering.java:26) with 1 output partitions
2018-02-08 15:51:06,756 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (show at MachineLeaningClustering.java:26)
2018-02-08 15:51:06,756 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:51:06,756 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:51:06,757 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[8] at show at MachineLeaningClustering.java:26), which has no missing parents
2018-02-08 15:51:06,780 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 7.2 KB, free 631.5 MB)
2018-02-08 15:51:06,784 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 631.4 MB)
2018-02-08 15:51:06,785 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:62666 (size: 4.0 KB, free: 631.8 MB)
2018-02-08 15:51:06,786 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:06,787 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at show at MachineLeaningClustering.java:26) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:06,787 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 15:51:06,794 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:51:06,794 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 15:51:06,805 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:51:06,849 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 28.844809 ms
2018-02-08 15:51:06,927 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 39.921293 ms
2018-02-08 15:51:06,934 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 1344 bytes result sent to driver
2018-02-08 15:51:06,936 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 149 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:06,936 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 15:51:06,936 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (show at MachineLeaningClustering.java:26) finished in 0.149 s
2018-02-08 15:51:06,939 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: show at MachineLeaningClustering.java:26, took 0.184129 s
2018-02-08 15:51:06,963 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.719044 ms
2018-02-08 15:51:07,035 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:51:07,036 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:51:07,036 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<label: double, features: vector>
2018-02-08 15:51:07,037 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:51:07,046 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 322.9 KB, free 631.1 MB)
2018-02-08 15:51:07,061 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.1 MB)
2018-02-08 15:51:07,063 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:62666 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:51:07,064 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:51:07,065 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:51:07,119 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:51:07,120 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:51:07,120 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:51:07,120 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:51:07,127 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 322.9 KB, free 630.8 MB)
2018-02-08 15:51:07,143 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 27.6 KB, free 630.8 MB)
2018-02-08 15:51:07,146 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:62666 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:51:07,147 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:51:07,150 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:51:07,171 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_644038e69493-1994394587-1: training: numPartitions=1 storageLevel=StorageLevel(disk, memory, deserialized, 1 replicas)
2018-02-08 15:51:07,193 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_644038e69493-1994394587-1: {"k":2,"seed":1}
2018-02-08 15:51:07,225 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at KMeans.scala:353
2018-02-08 15:51:07,227 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (takeSample at KMeans.scala:353) with 1 output partitions
2018-02-08 15:51:07,227 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (takeSample at KMeans.scala:353)
2018-02-08 15:51:07,227 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:51:07,231 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:51:07,232 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[20] at map at KMeans.scala:224), which has no missing parents
2018-02-08 15:51:07,258 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 11.9 KB, free 630.8 MB)
2018-02-08 15:51:07,261 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.2 KB, free 630.7 MB)
2018-02-08 15:51:07,263 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:62666 (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:51:07,263 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:07,264 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[20] at map at KMeans.scala:224) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:07,264 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 15:51:07,266 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5605 bytes)
2018-02-08 15:51:07,266 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 15:51:07,284 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.882883 ms
2018-02-08 15:51:07,285 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:51:07,300 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.711685 ms
2018-02-08 15:51:07,317 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.491524 ms
2018-02-08 15:51:07,328 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_0 stored as values in memory (estimated size 576.0 B, free 630.7 MB)
2018-02-08 15:51:07,330 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_0 in memory on 192.168.11.26:62666 (size: 576.0 B, free: 631.7 MB)
2018-02-08 15:51:07,333 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:51:07,335 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_18_0 stored as values in memory (estimated size 64.0 B, free 630.7 MB)
2018-02-08 15:51:07,335 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_18_0 in memory on 192.168.11.26:62666 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:51:07,339 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 2117 bytes result sent to driver
2018-02-08 15:51:07,340 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 76 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:07,340 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 15:51:07,341 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (takeSample at KMeans.scala:353) finished in 0.077 s
2018-02-08 15:51:07,341 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: takeSample at KMeans.scala:353, took 0.115815 s
2018-02-08 15:51:07,363 INFO[org.apache.spark.SparkContext:54] - Starting job: takeSample at KMeans.scala:353
2018-02-08 15:51:07,365 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (takeSample at KMeans.scala:353) with 1 output partitions
2018-02-08 15:51:07,365 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (takeSample at KMeans.scala:353)
2018-02-08 15:51:07,365 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:51:07,368 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:51:07,368 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (PartitionwiseSampledRDD[22] at takeSample at KMeans.scala:353), which has no missing parents
2018-02-08 15:51:07,370 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 12.6 KB, free 630.7 MB)
2018-02-08 15:51:07,375 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KB, free 630.7 MB)
2018-02-08 15:51:07,380 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:62666 (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:51:07,381 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:07,384 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (PartitionwiseSampledRDD[22] at takeSample at KMeans.scala:353) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:07,384 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 15:51:07,390 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 5714 bytes)
2018-02-08 15:51:07,391 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 4)
2018-02-08 15:51:07,396 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:51:07,397 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:51:07,403 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 4). 2061 bytes result sent to driver
2018-02-08 15:51:07,407 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 4) in 20 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:07,407 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 15:51:07,408 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (takeSample at KMeans.scala:353) finished in 0.021 s
2018-02-08 15:51:07,409 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: takeSample at KMeans.scala:353, took 0.045164 s
2018-02-08 15:51:07,414 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 144.0 B, free 630.7 MB)
2018-02-08 15:51:07,418 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 339.0 B, free 630.7 MB)
2018-02-08 15:51:07,419 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:62666 (size: 339.0 B, free: 631.7 MB)
2018-02-08 15:51:07,422 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at KMeans.scala:367
2018-02-08 15:51:07,445 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeans.scala:373
2018-02-08 15:51:07,446 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (sum at KMeans.scala:373) with 1 output partitions
2018-02-08 15:51:07,446 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 4 (sum at KMeans.scala:373)
2018-02-08 15:51:07,448 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:51:07,451 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:51:07,454 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 4 (MapPartitionsRDD[24] at map at KMeans.scala:370), which has no missing parents
2018-02-08 15:51:07,456 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 12.7 KB, free 630.7 MB)
2018-02-08 15:51:07,461 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.6 KB, free 630.7 MB)
2018-02-08 15:51:07,463 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.11.26:62666 (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:51:07,463 INFO[org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:07,464 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at map at KMeans.scala:370) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:07,464 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 4.0 with 1 tasks
2018-02-08 15:51:07,466 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 5637 bytes)
2018-02-08 15:51:07,466 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 4.0 (TID 5)
2018-02-08 15:51:07,471 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:51:07,471 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:51:07,471 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:51:07,472 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:51:07,481 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_24_0 stored as values in memory (estimated size 64.0 B, free 630.7 MB)
2018-02-08 15:51:07,486 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_24_0 in memory on 192.168.11.26:62666 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:51:07,487 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 4.0 (TID 5). 2072 bytes result sent to driver
2018-02-08 15:51:07,488 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 4.0 (TID 5) in 23 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:07,489 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2018-02-08 15:51:07,489 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 4 (sum at KMeans.scala:373) finished in 0.024 s
2018-02-08 15:51:07,490 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: sum at KMeans.scala:373, took 0.044385 s
2018-02-08 15:51:07,492 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 21 from persistence list
2018-02-08 15:51:07,495 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 21
2018-02-08 15:51:07,516 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at KMeans.scala:381
2018-02-08 15:51:07,518 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (collect at KMeans.scala:381) with 1 output partitions
2018-02-08 15:51:07,518 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 5 (collect at KMeans.scala:381)
2018-02-08 15:51:07,518 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:51:07,519 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:51:07,521 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 5 (MapPartitionsRDD[26] at mapPartitionsWithIndex at KMeans.scala:378), which has no missing parents
2018-02-08 15:51:07,523 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 13.3 KB, free 630.7 MB)
2018-02-08 15:51:07,527 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.7 MB)
2018-02-08 15:51:07,528 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.11.26:62666 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:51:07,529 INFO[org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:07,530 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at mapPartitionsWithIndex at KMeans.scala:378) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:07,531 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
2018-02-08 15:51:07,533 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 5669 bytes)
2018-02-08 15:51:07,533 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 6)
2018-02-08 15:51:07,537 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:51:07,537 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:51:07,537 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_24_0 locally
2018-02-08 15:51:07,539 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 6). 1778 bytes result sent to driver
2018-02-08 15:51:07,540 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 6) in 8 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:07,540 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 15:51:07,541 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 5 (collect at KMeans.scala:381) finished in 0.010 s
2018-02-08 15:51:07,541 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: collect at KMeans.scala:381, took 0.024614 s
2018-02-08 15:51:07,544 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 320.0 B, free 630.7 MB)
2018-02-08 15:51:07,551 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 413.0 B, free 630.7 MB)
2018-02-08 15:51:07,554 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.11.26:62666 (size: 413.0 B, free: 631.7 MB)
2018-02-08 15:51:07,555 INFO[org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at KMeans.scala:367
2018-02-08 15:51:07,569 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeans.scala:373
2018-02-08 15:51:07,571 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (sum at KMeans.scala:373) with 1 output partitions
2018-02-08 15:51:07,572 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (sum at KMeans.scala:373)
2018-02-08 15:51:07,572 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:51:07,574 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:51:07,574 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[28] at map at KMeans.scala:370), which has no missing parents
2018-02-08 15:51:07,577 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 12.9 KB, free 630.7 MB)
2018-02-08 15:51:07,587 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.7 KB, free 630.7 MB)
2018-02-08 15:51:07,608 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.11.26:62666 (size: 6.7 KB, free: 631.7 MB)
2018-02-08 15:51:07,609 INFO[org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:07,610 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[28] at map at KMeans.scala:370) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:07,610 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
2018-02-08 15:51:07,611 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_3_piece0 on 192.168.11.26:62666 in memory (size: 4.0 KB, free: 631.7 MB)
2018-02-08 15:51:07,611 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 5669 bytes)
2018-02-08 15:51:07,613 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 7)
2018-02-08 15:51:07,621 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.11.26:62666 in memory (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:51:07,622 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:51:07,622 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:51:07,622 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_24_0 locally
2018-02-08 15:51:07,625 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_28_0 stored as values in memory (estimated size 64.0 B, free 630.7 MB)
2018-02-08 15:51:07,627 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_28_0 in memory on 192.168.11.26:62666 (size: 64.0 B, free: 631.7 MB)
2018-02-08 15:51:07,631 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:62666 in memory (size: 6.6 KB, free: 631.7 MB)
2018-02-08 15:51:07,633 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 7). 2115 bytes result sent to driver
2018-02-08 15:51:07,634 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:62666 in memory (size: 6.2 KB, free: 631.7 MB)
2018-02-08 15:51:07,634 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 7) in 23 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:07,635 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 15:51:07,636 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (sum at KMeans.scala:373) finished in 0.025 s
2018-02-08 15:51:07,636 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: sum at KMeans.scala:373, took 0.067005 s
2018-02-08 15:51:07,636 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.11.26:62666 in memory (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:51:07,637 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 24 from persistence list
2018-02-08 15:51:07,639 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 24
2018-02-08 15:51:07,663 INFO[org.apache.spark.SparkContext:54] - Starting job: collect at KMeans.scala:381
2018-02-08 15:51:07,664 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (collect at KMeans.scala:381) with 1 output partitions
2018-02-08 15:51:07,664 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 7 (collect at KMeans.scala:381)
2018-02-08 15:51:07,665 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:51:07,666 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:51:07,667 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 7 (MapPartitionsRDD[30] at mapPartitionsWithIndex at KMeans.scala:378), which has no missing parents
2018-02-08 15:51:07,669 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 13.5 KB, free 630.7 MB)
2018-02-08 15:51:07,671 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.7 MB)
2018-02-08 15:51:07,673 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.11.26:62666 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:51:07,674 INFO[org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:07,674 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[30] at mapPartitionsWithIndex at KMeans.scala:378) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:07,674 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 7.0 with 1 tasks
2018-02-08 15:51:07,675 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5701 bytes)
2018-02-08 15:51:07,676 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 7.0 (TID 8)
2018-02-08 15:51:07,679 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:51:07,679 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:51:07,679 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_28_0 locally
2018-02-08 15:51:07,680 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 7.0 (TID 8). 1654 bytes result sent to driver
2018-02-08 15:51:07,682 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 7.0 (TID 8) in 7 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:07,682 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2018-02-08 15:51:07,682 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 7 (collect at KMeans.scala:381) finished in 0.007 s
2018-02-08 15:51:07,684 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: collect at KMeans.scala:381, took 0.020437 s
2018-02-08 15:51:07,685 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 28 from persistence list
2018-02-08 15:51:07,688 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 28
2018-02-08 15:51:07,691 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(8) (from destroy at KMeans.scala:388)
2018-02-08 15:51:07,692 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(11) (from destroy at KMeans.scala:388)
2018-02-08 15:51:07,692 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.11.26:62666 in memory (size: 339.0 B, free: 631.7 MB)
2018-02-08 15:51:07,694 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.11.26:62666 in memory (size: 413.0 B, free: 631.7 MB)
2018-02-08 15:51:07,696 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 488.0 B, free 630.7 MB)
2018-02-08 15:51:07,699 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 498.0 B, free 630.7 MB)
2018-02-08 15:51:07,700 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.11.26:62666 (size: 498.0 B, free: 631.7 MB)
2018-02-08 15:51:07,700 INFO[org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at KMeans.scala:398
2018-02-08 15:51:07,741 INFO[org.apache.spark.SparkContext:54] - Starting job: countByValue at KMeans.scala:399
2018-02-08 15:51:07,941 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 33 (countByValue at KMeans.scala:399)
2018-02-08 15:51:07,941 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (countByValue at KMeans.scala:399) with 1 output partitions
2018-02-08 15:51:07,942 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 9 (countByValue at KMeans.scala:399)
2018-02-08 15:51:07,942 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 8)
2018-02-08 15:51:07,942 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 8)
2018-02-08 15:51:07,944 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 8 (MapPartitionsRDD[33] at countByValue at KMeans.scala:399), which has no missing parents
2018-02-08 15:51:07,951 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 13.8 KB, free 630.7 MB)
2018-02-08 15:51:07,953 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.1 KB, free 630.7 MB)
2018-02-08 15:51:07,954 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.11.26:62666 (size: 7.1 KB, free: 631.7 MB)
2018-02-08 15:51:07,954 INFO[org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:07,957 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[33] at countByValue at KMeans.scala:399) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:07,957 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 8.0 with 1 tasks
2018-02-08 15:51:07,959 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:51:07,960 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 8.0 (TID 9)
2018-02-08 15:51:07,964 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:51:07,964 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:51:08,039 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 8.0 (TID 9). 1711 bytes result sent to driver
2018-02-08 15:51:08,042 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 8.0 (TID 9) in 84 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:08,042 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2018-02-08 15:51:08,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 8 (countByValue at KMeans.scala:399) finished in 0.085 s
2018-02-08 15:51:08,044 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:51:08,044 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:51:08,044 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 9)
2018-02-08 15:51:08,045 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:51:08,048 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 9 (ShuffledRDD[34] at countByValue at KMeans.scala:399), which has no missing parents
2018-02-08 15:51:08,052 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16 stored as values in memory (estimated size 3.2 KB, free 630.7 MB)
2018-02-08 15:51:08,055 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 1971.0 B, free 630.7 MB)
2018-02-08 15:51:08,056 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_16_piece0 in memory on 192.168.11.26:62666 (size: 1971.0 B, free: 631.7 MB)
2018-02-08 15:51:08,057 INFO[org.apache.spark.SparkContext:54] - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:08,058 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 9 (ShuffledRDD[34] at countByValue at KMeans.scala:399) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:08,059 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 1 tasks
2018-02-08 15:51:08,062 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:51:08,062 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 10)
2018-02-08 15:51:08,077 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:51:08,078 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 15:51:08,108 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 10). 1337 bytes result sent to driver
2018-02-08 15:51:08,111 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 10) in 51 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:08,111 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-02-08 15:51:08,112 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 9 (countByValue at KMeans.scala:399) finished in 0.052 s
2018-02-08 15:51:08,115 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: countByValue at KMeans.scala:399, took 0.373512 s
2018-02-08 15:51:08,116 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(14) (from destroy at KMeans.scala:401)
2018-02-08 15:51:08,120 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_14_piece0 on 192.168.11.26:62666 in memory (size: 498.0 B, free: 631.7 MB)
2018-02-08 15:51:08,125 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 15:51:08,126 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 15:51:08,132 INFO[org.apache.spark.mllib.clustering.LocalKMeans:54] - Local KMeans++ converged in 2 iterations.
2018-02-08 15:51:08,133 INFO[org.apache.spark.mllib.clustering.KMeans:54] - Initialization with k-means|| took 0.918 seconds.
2018-02-08 15:51:08,134 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_644038e69493-1994394587-1: {"numFeatures":3}
2018-02-08 15:51:08,135 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17 stored as values in memory (estimated size 208.0 B, free 630.7 MB)
2018-02-08 15:51:08,138 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 310.0 B, free 630.7 MB)
2018-02-08 15:51:08,139 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_17_piece0 in memory on 192.168.11.26:62666 (size: 310.0 B, free: 631.7 MB)
2018-02-08 15:51:08,139 INFO[org.apache.spark.SparkContext:54] - Created broadcast 17 from broadcast at KMeans.scala:273
2018-02-08 15:51:08,168 INFO[org.apache.spark.SparkContext:54] - Starting job: collectAsMap at KMeans.scala:295
2018-02-08 15:51:08,169 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 35 (mapPartitions at KMeans.scala:276)
2018-02-08 15:51:08,171 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (collectAsMap at KMeans.scala:295) with 1 output partitions
2018-02-08 15:51:08,171 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 11 (collectAsMap at KMeans.scala:295)
2018-02-08 15:51:08,171 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 10)
2018-02-08 15:51:08,171 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 10)
2018-02-08 15:51:08,173 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 10 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:276), which has no missing parents
2018-02-08 15:51:08,177 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18 stored as values in memory (estimated size 13.2 KB, free 630.7 MB)
2018-02-08 15:51:08,179 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.7 MB)
2018-02-08 15:51:08,180 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_18_piece0 in memory on 192.168.11.26:62666 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:51:08,181 INFO[org.apache.spark.SparkContext:54] - Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:08,182 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[35] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:08,182 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 1 tasks
2018-02-08 15:51:08,184 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:51:08,184 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 11)
2018-02-08 15:51:08,188 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:51:08,188 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:51:08,200 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 11). 1781 bytes result sent to driver
2018-02-08 15:51:08,200 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 11) in 17 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:08,200 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 15:51:08,201 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 10 (mapPartitions at KMeans.scala:276) finished in 0.018 s
2018-02-08 15:51:08,201 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:51:08,201 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:51:08,201 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 11)
2018-02-08 15:51:08,201 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:51:08,201 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 11 (ShuffledRDD[36] at reduceByKey at KMeans.scala:292), which has no missing parents
2018-02-08 15:51:08,203 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19 stored as values in memory (estimated size 2.8 KB, free 630.7 MB)
2018-02-08 15:51:08,209 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 1654.0 B, free 630.7 MB)
2018-02-08 15:51:08,210 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_19_piece0 in memory on 192.168.11.26:62666 (size: 1654.0 B, free: 631.7 MB)
2018-02-08 15:51:08,211 INFO[org.apache.spark.SparkContext:54] - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:08,211 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 11 (ShuffledRDD[36] at reduceByKey at KMeans.scala:292) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:08,211 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 1 tasks
2018-02-08 15:51:08,212 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 12, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:51:08,212 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 12)
2018-02-08 15:51:08,216 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:51:08,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:51:08,223 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 12). 1436 bytes result sent to driver
2018-02-08 15:51:08,224 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 12) in 12 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:08,224 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 15:51:08,224 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 11 (collectAsMap at KMeans.scala:295) finished in 0.012 s
2018-02-08 15:51:08,225 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: collectAsMap at KMeans.scala:295, took 0.056228 s
2018-02-08 15:51:08,227 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(17) (from destroy at KMeans.scala:297)
2018-02-08 15:51:08,232 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20 stored as values in memory (estimated size 208.0 B, free 630.7 MB)
2018-02-08 15:51:08,232 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_17_piece0 on 192.168.11.26:62666 in memory (size: 310.0 B, free: 631.7 MB)
2018-02-08 15:51:08,235 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 311.0 B, free 630.7 MB)
2018-02-08 15:51:08,237 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_20_piece0 in memory on 192.168.11.26:62666 (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:51:08,240 INFO[org.apache.spark.SparkContext:54] - Created broadcast 20 from broadcast at KMeans.scala:273
2018-02-08 15:51:08,259 INFO[org.apache.spark.SparkContext:54] - Starting job: collectAsMap at KMeans.scala:295
2018-02-08 15:51:08,259 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 37 (mapPartitions at KMeans.scala:276)
2018-02-08 15:51:08,260 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 10 (collectAsMap at KMeans.scala:295) with 1 output partitions
2018-02-08 15:51:08,261 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 13 (collectAsMap at KMeans.scala:295)
2018-02-08 15:51:08,261 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 12)
2018-02-08 15:51:08,261 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 12)
2018-02-08 15:51:08,262 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 12 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:276), which has no missing parents
2018-02-08 15:51:08,264 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21 stored as values in memory (estimated size 13.2 KB, free 630.7 MB)
2018-02-08 15:51:08,266 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 6.9 KB, free 630.7 MB)
2018-02-08 15:51:08,267 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_21_piece0 in memory on 192.168.11.26:62666 (size: 6.9 KB, free: 631.7 MB)
2018-02-08 15:51:08,268 INFO[org.apache.spark.SparkContext:54] - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:08,271 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[37] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:08,271 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 12.0 with 1 tasks
2018-02-08 15:51:08,272 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 5594 bytes)
2018-02-08 15:51:08,272 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 12.0 (TID 13)
2018-02-08 15:51:08,275 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:51:08,275 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_18_0 locally
2018-02-08 15:51:08,282 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 12.0 (TID 13). 1781 bytes result sent to driver
2018-02-08 15:51:08,284 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 12.0 (TID 13) in 13 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:08,284 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2018-02-08 15:51:08,285 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 12 (mapPartitions at KMeans.scala:276) finished in 0.014 s
2018-02-08 15:51:08,285 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:51:08,285 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:51:08,285 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 13)
2018-02-08 15:51:08,286 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:51:08,286 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 13 (ShuffledRDD[38] at reduceByKey at KMeans.scala:292), which has no missing parents
2018-02-08 15:51:08,287 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22 stored as values in memory (estimated size 2.8 KB, free 630.7 MB)
2018-02-08 15:51:08,290 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 1659.0 B, free 630.7 MB)
2018-02-08 15:51:08,291 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_22_piece0 in memory on 192.168.11.26:62666 (size: 1659.0 B, free: 631.7 MB)
2018-02-08 15:51:08,291 INFO[org.apache.spark.SparkContext:54] - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:08,292 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 13 (ShuffledRDD[38] at reduceByKey at KMeans.scala:292) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:08,292 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 13.0 with 1 tasks
2018-02-08 15:51:08,292 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:51:08,293 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 13.0 (TID 14)
2018-02-08 15:51:08,295 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:51:08,295 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:51:08,298 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 13.0 (TID 14). 1436 bytes result sent to driver
2018-02-08 15:51:08,299 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 13.0 (TID 14) in 7 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:08,299 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2018-02-08 15:51:08,300 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 13 (collectAsMap at KMeans.scala:295) finished in 0.008 s
2018-02-08 15:51:08,301 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 10 finished: collectAsMap at KMeans.scala:295, took 0.041642 s
2018-02-08 15:51:08,302 INFO[org.apache.spark.broadcast.TorrentBroadcast:54] - Destroying Broadcast(20) (from destroy at KMeans.scala:297)
2018-02-08 15:51:08,303 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_20_piece0 on 192.168.11.26:62666 in memory (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:51:08,304 INFO[org.apache.spark.mllib.clustering.KMeans:54] - Iterations took 0.170 seconds.
2018-02-08 15:51:08,305 INFO[org.apache.spark.mllib.clustering.KMeans:54] - KMeans converged in 2 iterations.
2018-02-08 15:51:08,306 INFO[org.apache.spark.mllib.clustering.KMeans:54] - The cost is 0.11999999999994547.
2018-02-08 15:51:08,308 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 18 from persistence list
2018-02-08 15:51:08,309 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 18
2018-02-08 15:51:08,630 INFO[org.apache.spark.ml.util.Instrumentation:54] - KMeans-kmeans_644038e69493-1994394587-1: training finished
2018-02-08 15:51:08,630 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 17 from persistence list
2018-02-08 15:51:08,631 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 17
2018-02-08 15:51:08,642 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:51:08,643 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:51:08,643 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<features: vector>
2018-02-08 15:51:08,643 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:51:08,650 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23 stored as values in memory (estimated size 322.9 KB, free 630.3 MB)
2018-02-08 15:51:08,662 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 27.6 KB, free 630.3 MB)
2018-02-08 15:51:08,664 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_23_piece0 in memory on 192.168.11.26:62666 (size: 27.6 KB, free: 631.7 MB)
2018-02-08 15:51:08,664 INFO[org.apache.spark.SparkContext:54] - Created broadcast 23 from broadcast at LibSVMRelation.scala:153
2018-02-08 15:51:08,665 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:51:08,679 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24 stored as values in memory (estimated size 208.0 B, free 630.3 MB)
2018-02-08 15:51:08,682 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 311.0 B, free 630.3 MB)
2018-02-08 15:51:08,683 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_24_piece0 in memory on 192.168.11.26:62666 (size: 311.0 B, free: 631.7 MB)
2018-02-08 15:51:08,684 INFO[org.apache.spark.SparkContext:54] - Created broadcast 24 from broadcast at KMeansModel.scala:87
2018-02-08 15:51:08,692 INFO[org.apache.spark.SparkContext:54] - Starting job: sum at KMeansModel.scala:88
2018-02-08 15:51:08,693 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 11 (sum at KMeansModel.scala:88) with 1 output partitions
2018-02-08 15:51:08,693 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 14 (sum at KMeansModel.scala:88)
2018-02-08 15:51:08,693 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:51:08,693 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:51:08,694 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 14 (MapPartitionsRDD[44] at map at KMeansModel.scala:88), which has no missing parents
2018-02-08 15:51:08,695 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25 stored as values in memory (estimated size 11.8 KB, free 630.3 MB)
2018-02-08 15:51:08,698 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.2 KB, free 630.3 MB)
2018-02-08 15:51:08,699 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_25_piece0 in memory on 192.168.11.26:62666 (size: 6.2 KB, free: 631.6 MB)
2018-02-08 15:51:08,699 INFO[org.apache.spark.SparkContext:54] - Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:51:08,702 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[44] at map at KMeansModel.scala:88) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:51:08,702 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 14.0 with 1 tasks
2018-02-08 15:51:08,703 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 5314 bytes)
2018-02-08 15:51:08,703 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 14.0 (TID 15)
2018-02-08 15:51:08,707 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/sample_kmeans_data.txt, range: 0-120, partition values: [empty row]
2018-02-08 15:51:08,716 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 14.0 (TID 15). 1348 bytes result sent to driver
2018-02-08 15:51:08,718 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 14.0 (TID 15) in 15 ms on localhost (executor driver) (1/1)
2018-02-08 15:51:08,718 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-02-08 15:51:08,719 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 14 (sum at KMeansModel.scala:88) finished in 0.016 s
2018-02-08 15:51:08,719 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 11 finished: sum at KMeansModel.scala:88, took 0.026892 s
2018-02-08 15:51:08,727 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:51:08,734 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@7e94e0bb{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:51:08,736 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:51:08,744 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:51:08,813 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:51:08,814 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:51:08,815 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:51:08,817 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:51:08,820 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:51:08,821 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:51:08,821 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-9b1f7f86-2a7c-43dc-bbd9-fc11ab7fe385
2018-02-08 15:54:00,421 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:54:00,984 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:54:01,006 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:54:01,007 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:54:01,007 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:54:01,008 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:54:01,009 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:54:01,378 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62764.
2018-02-08 15:54:01,395 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:54:01,438 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:54:01,440 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:54:01,441 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:54:01,449 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-a90d9c5b-7ae2-4d70-8077-37eba91ce1ae
2018-02-08 15:54:01,469 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:54:01,517 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:54:01,587 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2654ms
2018-02-08 15:54:01,655 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:54:01,667 INFO[org.spark_project.jetty.server.Server:403] - Started @2736ms
2018-02-08 15:54:01,687 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@34a1d21f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:54:01,687 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:54:01,710 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1c9f0a20{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,711 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,711 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,712 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a3591c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,713 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@346a361{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,714 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1643d68f{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,714 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2e029d61{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,716 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,716 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,717 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,718 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,718 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,719 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,720 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,721 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,721 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,723 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,724 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,725 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,725 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,732 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/static,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,733 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@592e843a{/,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,735 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@423e4cbb{/api,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,736 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a1edad4{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,736 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@44c79f32{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:54:01,738 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:54:01,817 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:54:01,840 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62777.
2018-02-08 15:54:01,840 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62777
2018-02-08 15:54:01,842 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:54:01,843 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62777, None)
2018-02-08 15:54:01,847 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62777 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62777, None)
2018-02-08 15:54:01,850 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62777, None)
2018-02-08 15:54:01,851 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62777, None)
2018-02-08 15:54:02,010 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4a67318f{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:02,068 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:54:02,070 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:54:02,076 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@408613cc{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:54:02,077 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@11ce2e22{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:02,079 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@771158fb{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:54:02,079 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62d0ac62{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:54:02,082 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:54:03,063 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:54:04,666 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:54:04,669 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:54:04,671 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<value: string>
2018-02-08 15:54:04,678 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:54:05,155 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 196.039103 ms
2018-02-08 15:54:05,203 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:54:05,360 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:54:05,364 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:62777 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:54:05,372 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from javaRDD at MachineLeaningFiltering.java:27
2018-02-08 15:54:05,382 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:54:05,819 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 43.221774 ms
2018-02-08 15:54:05,903 INFO[org.apache.spark.ml.util.Instrumentation:54] - ALS-als_8fe24e49f7b5-627727856-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
2018-02-08 15:54:05,928 INFO[org.apache.spark.ml.util.Instrumentation:54] - ALS-als_8fe24e49f7b5-627727856-1: {"ratingCol":"rating","itemCol":"movieId","userCol":"userId","regParam":0.01,"maxIter":5}
2018-02-08 15:54:05,955 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at ALS.scala:843
2018-02-08 15:54:05,973 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (isEmpty at ALS.scala:843) with 1 output partitions
2018-02-08 15:54:05,973 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (isEmpty at ALS.scala:843)
2018-02-08 15:54:05,974 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:54:05,975 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:54:05,979 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[10] at map at ALS.scala:613), which has no missing parents
2018-02-08 15:54:06,001 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 28.6 KB, free 631.4 MB)
2018-02-08 15:54:06,005 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.6 KB, free 631.4 MB)
2018-02-08 15:54:06,006 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:62777 (size: 12.6 KB, free: 631.8 MB)
2018-02-08 15:54:06,007 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:06,018 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[10] at map at ALS.scala:613) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:54:06,019 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
2018-02-08 15:54:06,056 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5324 bytes)
2018-02-08 15:54:06,067 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:54:06,183 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.962242 ms
2018-02-08 15:54:06,203 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.937923 ms
2018-02-08 15:54:06,233 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.263046 ms
2018-02-08 15:54:06,254 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.105603 ms
2018-02-08 15:54:06,277 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.839682 ms
2018-02-08 15:54:06,279 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/als/sample_movielens_ratings.txt, range: 0-32363, partition values: [empty row]
2018-02-08 15:54:06,289 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.096002 ms
2018-02-08 15:54:06,412 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 2224 bytes result sent to driver
2018-02-08 15:54:06,419 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 370 ms on localhost (executor driver) (1/1)
2018-02-08 15:54:06,421 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:54:06,424 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (isEmpty at ALS.scala:843) finished in 0.386 s
2018-02-08 15:54:06,429 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: isEmpty at ALS.scala:843, took 0.472465 s
2018-02-08 15:54:06,534 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:857
2018-02-08 15:54:06,539 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 11 (mapPartitions at ALS.scala:1101)
2018-02-08 15:54:06,540 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 14 (map at ALS.scala:1344)
2018-02-08 15:54:06,540 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (count at ALS.scala:857) with 10 output partitions
2018-02-08 15:54:06,540 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (count at ALS.scala:857)
2018-02-08 15:54:06,540 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 2)
2018-02-08 15:54:06,543 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 2)
2018-02-08 15:54:06,545 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at mapPartitions at ALS.scala:1101), which has no missing parents
2018-02-08 15:54:06,552 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 30.7 KB, free 631.4 MB)
2018-02-08 15:54:06,555 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 13.6 KB, free 631.4 MB)
2018-02-08 15:54:06,557 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:62777 (size: 13.6 KB, free: 631.7 MB)
2018-02-08 15:54:06,557 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:06,559 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at mapPartitions at ALS.scala:1101) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:54:06,559 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 15:54:06,561 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5313 bytes)
2018-02-08 15:54:06,562 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
2018-02-08 15:54:06,585 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/als/sample_movielens_ratings.txt, range: 0-32363, partition values: [empty row]
2018-02-08 15:54:06,666 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 2117 bytes result sent to driver
2018-02-08 15:54:06,669 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 108 ms on localhost (executor driver) (1/1)
2018-02-08 15:54:06,669 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 15:54:06,670 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (mapPartitions at ALS.scala:1101) finished in 0.110 s
2018-02-08 15:54:06,670 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:06,671 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:06,674 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 2, ResultStage 3)
2018-02-08 15:54:06,674 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:06,678 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at map at ALS.scala:1344), which has no missing parents
2018-02-08 15:54:06,695 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 32.0 KB, free 631.3 MB)
2018-02-08 15:54:06,700 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.1 KB, free 631.3 MB)
2018-02-08 15:54:06,701 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:62777 (size: 14.1 KB, free: 631.7 MB)
2018-02-08 15:54:06,701 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:06,702 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:54:06,702 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 15:54:06,709 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4610 bytes)
2018-02-08 15:54:06,709 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
2018-02-08 15:54:06,766 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:06,770 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 15 ms
2018-02-08 15:54:06,893 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_13_0 stored as values in memory (estimated size 27.3 KB, free 631.3 MB)
2018-02-08 15:54:06,894 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_13_0 in memory on 192.168.11.26:62777 (size: 27.3 KB, free: 631.7 MB)
2018-02-08 15:54:07,038 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:62777 in memory (size: 12.6 KB, free: 631.7 MB)
2018-02-08 15:54:07,069 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.11.26:62777 in memory (size: 13.6 KB, free: 631.7 MB)
2018-02-08 15:54:07,182 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 3065 bytes result sent to driver
2018-02-08 15:54:07,184 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 478 ms on localhost (executor driver) (1/1)
2018-02-08 15:54:07,184 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 15:54:07,185 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 2 (map at ALS.scala:1344) finished in 0.479 s
2018-02-08 15:54:07,185 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:07,185 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:07,185 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 3)
2018-02-08 15:54:07,186 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:07,187 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (userOutBlocks MapPartitionsRDD[17] at mapValues at ALS.scala:1381), which has no missing parents
2018-02-08 15:54:07,191 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 32.6 KB, free 631.4 MB)
2018-02-08 15:54:07,194 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.5 KB, free 631.3 MB)
2018-02-08 15:54:07,195 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:62777 (size: 14.5 KB, free: 631.7 MB)
2018-02-08 15:54:07,195 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:07,196 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 3 (userOutBlocks MapPartitionsRDD[17] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:07,196 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 10 tasks
2018-02-08 15:54:07,197 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:54:07,197 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, ANY, 4621 bytes)
2018-02-08 15:54:07,197 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 3)
2018-02-08 15:54:07,198 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 3.0 (TID 4)
2018-02-08 15:54:07,209 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,210 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,210 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:54:07,210 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:07,222 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_0 stored as values in memory (estimated size 1056.0 B, free 631.3 MB)
2018-02-08 15:54:07,222 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_1 stored as values in memory (estimated size 1136.0 B, free 631.3 MB)
2018-02-08 15:54:07,224 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_0 in memory on 192.168.11.26:62777 (size: 1056.0 B, free: 631.7 MB)
2018-02-08 15:54:07,224 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_1 in memory on 192.168.11.26:62777 (size: 1136.0 B, free: 631.7 MB)
2018-02-08 15:54:07,225 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_0 stored as values in memory (estimated size 432.0 B, free 631.3 MB)
2018-02-08 15:54:07,225 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_1 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:54:07,226 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_0 in memory on 192.168.11.26:62777 (size: 432.0 B, free: 631.7 MB)
2018-02-08 15:54:07,227 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_1 in memory on 192.168.11.26:62777 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:54:07,228 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 3). 2910 bytes result sent to driver
2018-02-08 15:54:07,228 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 3.0 (TID 4). 2867 bytes result sent to driver
2018-02-08 15:54:07,229 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, ANY, 4621 bytes)
2018-02-08 15:54:07,229 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 3.0 (TID 5)
2018-02-08 15:54:07,230 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, ANY, 4621 bytes)
2018-02-08 15:54:07,231 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 3.0 (TID 6)
2018-02-08 15:54:07,236 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 3.0 (TID 4) in 38 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:07,242 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,242 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:07,243 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,243 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:07,246 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_2 stored as values in memory (estimated size 1264.0 B, free 631.3 MB)
2018-02-08 15:54:07,246 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_3 stored as values in memory (estimated size 1120.0 B, free 631.3 MB)
2018-02-08 15:54:07,248 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_2 in memory on 192.168.11.26:62777 (size: 1264.0 B, free: 631.7 MB)
2018-02-08 15:54:07,254 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_3 in memory on 192.168.11.26:62777 (size: 1120.0 B, free: 631.7 MB)
2018-02-08 15:54:07,259 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_3 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:54:07,262 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_2 stored as values in memory (estimated size 432.0 B, free 631.3 MB)
2018-02-08 15:54:07,263 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_3 in memory on 192.168.11.26:62777 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:54:07,266 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 3.0 (TID 6). 2867 bytes result sent to driver
2018-02-08 15:54:07,272 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_2 in memory on 192.168.11.26:62777 (size: 432.0 B, free: 631.7 MB)
2018-02-08 15:54:07,274 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 3.0 (TID 7, localhost, executor driver, partition 4, ANY, 4621 bytes)
2018-02-08 15:54:07,276 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 3.0 (TID 5). 2910 bytes result sent to driver
2018-02-08 15:54:07,276 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 3.0 (TID 7)
2018-02-08 15:54:07,277 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 3.0 (TID 8, localhost, executor driver, partition 5, ANY, 4621 bytes)
2018-02-08 15:54:07,278 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 3.0 (TID 6) in 49 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:07,280 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 3.0 (TID 5) in 51 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:07,284 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 3.0 (TID 8)
2018-02-08 15:54:07,292 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,293 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:07,297 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 3) in 99 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:07,298 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_4 stored as values in memory (estimated size 1184.0 B, free 631.3 MB)
2018-02-08 15:54:07,300 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_4 in memory on 192.168.11.26:62777 (size: 1184.0 B, free: 631.7 MB)
2018-02-08 15:54:07,302 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_4 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:54:07,303 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_4 in memory on 192.168.11.26:62777 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:54:07,313 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 3.0 (TID 7). 2867 bytes result sent to driver
2018-02-08 15:54:07,317 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 3.0 (TID 9, localhost, executor driver, partition 6, ANY, 4621 bytes)
2018-02-08 15:54:07,324 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 3.0 (TID 7) in 52 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:07,324 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 3.0 (TID 9)
2018-02-08 15:54:07,326 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,326 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:07,333 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_5 stored as values in memory (estimated size 1072.0 B, free 631.3 MB)
2018-02-08 15:54:07,345 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_5 in memory on 192.168.11.26:62777 (size: 1072.0 B, free: 631.7 MB)
2018-02-08 15:54:07,348 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_5 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:54:07,351 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_5 in memory on 192.168.11.26:62777 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:54:07,356 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 3.0 (TID 8). 2867 bytes result sent to driver
2018-02-08 15:54:07,357 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 3.0 (TID 10, localhost, executor driver, partition 7, ANY, 4621 bytes)
2018-02-08 15:54:07,358 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 3.0 (TID 10)
2018-02-08 15:54:07,358 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 3.0 (TID 8) in 81 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:07,366 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,366 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:07,367 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,368 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_7 stored as values in memory (estimated size 1184.0 B, free 631.3 MB)
2018-02-08 15:54:07,370 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 15:54:07,371 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_7 in memory on 192.168.11.26:62777 (size: 1184.0 B, free: 631.7 MB)
2018-02-08 15:54:07,372 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_7 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:54:07,373 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_7 in memory on 192.168.11.26:62777 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:54:07,374 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 3.0 (TID 10). 2867 bytes result sent to driver
2018-02-08 15:54:07,374 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 3.0 (TID 11, localhost, executor driver, partition 8, ANY, 4621 bytes)
2018-02-08 15:54:07,375 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 3.0 (TID 11)
2018-02-08 15:54:07,375 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 3.0 (TID 10) in 18 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:07,381 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,382 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:07,388 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_8 stored as values in memory (estimated size 1104.0 B, free 631.3 MB)
2018-02-08 15:54:07,388 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_8 in memory on 192.168.11.26:62777 (size: 1104.0 B, free: 631.7 MB)
2018-02-08 15:54:07,389 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_8 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:54:07,390 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_6 stored as values in memory (estimated size 1056.0 B, free 631.3 MB)
2018-02-08 15:54:07,391 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_6 in memory on 192.168.11.26:62777 (size: 1056.0 B, free: 631.7 MB)
2018-02-08 15:54:07,392 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_8 in memory on 192.168.11.26:62777 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:54:07,395 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 3.0 (TID 11). 2910 bytes result sent to driver
2018-02-08 15:54:07,395 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_6 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:54:07,396 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_6 in memory on 192.168.11.26:62777 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:54:07,396 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 3.0 (TID 12, localhost, executor driver, partition 9, ANY, 4621 bytes)
2018-02-08 15:54:07,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 3.0 (TID 11) in 23 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:07,398 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 3.0 (TID 9). 2953 bytes result sent to driver
2018-02-08 15:54:07,399 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 3.0 (TID 12)
2018-02-08 15:54:07,402 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 3.0 (TID 9) in 86 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:07,407 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,407 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:07,411 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_9 stored as values in memory (estimated size 1168.0 B, free 631.3 MB)
2018-02-08 15:54:07,411 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_9 in memory on 192.168.11.26:62777 (size: 1168.0 B, free: 631.7 MB)
2018-02-08 15:54:07,412 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_9 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:54:07,414 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_9 in memory on 192.168.11.26:62777 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:54:07,415 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 3.0 (TID 12). 2910 bytes result sent to driver
2018-02-08 15:54:07,416 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 3.0 (TID 12) in 20 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:07,417 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 15:54:07,418 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (count at ALS.scala:857) finished in 0.220 s
2018-02-08 15:54:07,418 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: count at ALS.scala:857, took 0.883279 s
2018-02-08 15:54:07,448 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:865
2018-02-08 15:54:07,454 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:54:07,456 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 19 (map at ALS.scala:1344)
2018-02-08 15:54:07,457 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (count at ALS.scala:865) with 10 output partitions
2018-02-08 15:54:07,457 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (count at ALS.scala:865)
2018-02-08 15:54:07,457 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 5)
2018-02-08 15:54:07,460 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 5)
2018-02-08 15:54:07,467 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 5 (MapPartitionsRDD[19] at map at ALS.scala:1344), which has no missing parents
2018-02-08 15:54:07,473 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 32.2 KB, free 631.3 MB)
2018-02-08 15:54:07,479 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 14.2 KB, free 631.3 MB)
2018-02-08 15:54:07,480 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:62777 (size: 14.2 KB, free: 631.7 MB)
2018-02-08 15:54:07,484 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:07,486 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[19] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:54:07,487 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
2018-02-08 15:54:07,491 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:54:07,492 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 13)
2018-02-08 15:54:07,500 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_13_0 locally
2018-02-08 15:54:07,550 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_4_piece0 on 192.168.11.26:62777 in memory (size: 14.5 KB, free: 631.7 MB)
2018-02-08 15:54:07,759 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 13). 2126 bytes result sent to driver
2018-02-08 15:54:07,760 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 13) in 271 ms on localhost (executor driver) (1/1)
2018-02-08 15:54:07,760 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 15:54:07,760 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 5 (map at ALS.scala:1344) finished in 0.271 s
2018-02-08 15:54:07,761 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:07,761 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:07,762 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 6)
2018-02-08 15:54:07,762 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:07,763 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (itemOutBlocks MapPartitionsRDD[22] at mapValues at ALS.scala:1381), which has no missing parents
2018-02-08 15:54:07,766 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 32.8 KB, free 631.3 MB)
2018-02-08 15:54:07,770 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.5 KB, free 631.3 MB)
2018-02-08 15:54:07,771 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:62777 (size: 14.5 KB, free: 631.7 MB)
2018-02-08 15:54:07,772 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:07,773 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 6 (itemOutBlocks MapPartitionsRDD[22] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:07,773 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 10 tasks
2018-02-08 15:54:07,774 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 14, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:54:07,774 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 6.0 (TID 15, localhost, executor driver, partition 1, ANY, 4621 bytes)
2018-02-08 15:54:07,774 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 14)
2018-02-08 15:54:07,774 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 6.0 (TID 15)
2018-02-08 15:54:07,783 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,784 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:07,788 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_1 stored as values in memory (estimated size 1176.0 B, free 631.3 MB)
2018-02-08 15:54:07,790 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_1 in memory on 192.168.11.26:62777 (size: 1176.0 B, free: 631.7 MB)
2018-02-08 15:54:07,791 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_1 stored as values in memory (estimated size 600.0 B, free 631.3 MB)
2018-02-08 15:54:07,794 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_1 in memory on 192.168.11.26:62777 (size: 600.0 B, free: 631.7 MB)
2018-02-08 15:54:07,798 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 6.0 (TID 15). 2910 bytes result sent to driver
2018-02-08 15:54:07,799 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 6.0 (TID 16, localhost, executor driver, partition 2, ANY, 4621 bytes)
2018-02-08 15:54:07,799 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 6.0 (TID 15) in 25 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:07,802 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 6.0 (TID 16)
2018-02-08 15:54:07,806 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,807 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:07,810 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,811 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:07,810 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_0 stored as values in memory (estimated size 1144.0 B, free 631.3 MB)
2018-02-08 15:54:07,816 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_2 stored as values in memory (estimated size 1144.0 B, free 631.3 MB)
2018-02-08 15:54:07,817 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_0 in memory on 192.168.11.26:62777 (size: 1144.0 B, free: 631.7 MB)
2018-02-08 15:54:07,818 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_2 in memory on 192.168.11.26:62777 (size: 1144.0 B, free: 631.7 MB)
2018-02-08 15:54:07,819 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_0 stored as values in memory (estimated size 616.0 B, free 631.3 MB)
2018-02-08 15:54:07,821 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_0 in memory on 192.168.11.26:62777 (size: 616.0 B, free: 631.7 MB)
2018-02-08 15:54:07,822 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_2 stored as values in memory (estimated size 592.0 B, free 631.3 MB)
2018-02-08 15:54:07,824 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_2 in memory on 192.168.11.26:62777 (size: 592.0 B, free: 631.7 MB)
2018-02-08 15:54:07,825 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 14). 2953 bytes result sent to driver
2018-02-08 15:54:07,827 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 6.0 (TID 16). 2867 bytes result sent to driver
2018-02-08 15:54:07,828 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 6.0 (TID 17, localhost, executor driver, partition 3, ANY, 4621 bytes)
2018-02-08 15:54:07,828 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 6.0 (TID 18, localhost, executor driver, partition 4, ANY, 4621 bytes)
2018-02-08 15:54:07,829 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 14) in 56 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:07,829 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 6.0 (TID 16) in 30 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:07,830 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 6.0 (TID 17)
2018-02-08 15:54:07,831 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 6.0 (TID 18)
2018-02-08 15:54:07,840 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,840 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:07,843 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_4 stored as values in memory (estimated size 1240.0 B, free 631.3 MB)
2018-02-08 15:54:07,843 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_4 in memory on 192.168.11.26:62777 (size: 1240.0 B, free: 631.7 MB)
2018-02-08 15:54:07,843 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,844 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:07,845 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_4 stored as values in memory (estimated size 632.0 B, free 631.3 MB)
2018-02-08 15:54:07,846 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_4 in memory on 192.168.11.26:62777 (size: 632.0 B, free: 631.7 MB)
2018-02-08 15:54:07,848 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_3 stored as values in memory (estimated size 1192.0 B, free 631.3 MB)
2018-02-08 15:54:07,850 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 6.0 (TID 18). 2910 bytes result sent to driver
2018-02-08 15:54:07,851 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 6.0 (TID 19, localhost, executor driver, partition 5, ANY, 4621 bytes)
2018-02-08 15:54:07,851 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_3 in memory on 192.168.11.26:62777 (size: 1192.0 B, free: 631.7 MB)
2018-02-08 15:54:07,852 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 6.0 (TID 18) in 24 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:07,853 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 6.0 (TID 19)
2018-02-08 15:54:07,854 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_3 stored as values in memory (estimated size 616.0 B, free 631.3 MB)
2018-02-08 15:54:07,855 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_3 in memory on 192.168.11.26:62777 (size: 616.0 B, free: 631.7 MB)
2018-02-08 15:54:07,858 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 6.0 (TID 17). 2867 bytes result sent to driver
2018-02-08 15:54:07,859 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 6.0 (TID 20, localhost, executor driver, partition 6, ANY, 4621 bytes)
2018-02-08 15:54:07,860 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 6.0 (TID 17) in 32 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:07,860 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,860 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:07,863 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 6.0 (TID 20)
2018-02-08 15:54:07,866 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_5 stored as values in memory (estimated size 1192.0 B, free 631.3 MB)
2018-02-08 15:54:07,867 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_5 in memory on 192.168.11.26:62777 (size: 1192.0 B, free: 631.7 MB)
2018-02-08 15:54:07,869 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_5 stored as values in memory (estimated size 600.0 B, free 631.3 MB)
2018-02-08 15:54:07,870 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,870 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:07,871 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_5 in memory on 192.168.11.26:62777 (size: 600.0 B, free: 631.7 MB)
2018-02-08 15:54:07,875 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_6 stored as values in memory (estimated size 1224.0 B, free 631.3 MB)
2018-02-08 15:54:07,876 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_6 in memory on 192.168.11.26:62777 (size: 1224.0 B, free: 631.7 MB)
2018-02-08 15:54:07,877 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 6.0 (TID 19). 2910 bytes result sent to driver
2018-02-08 15:54:07,878 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_6 stored as values in memory (estimated size 632.0 B, free 631.3 MB)
2018-02-08 15:54:07,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 6.0 (TID 21, localhost, executor driver, partition 7, ANY, 4621 bytes)
2018-02-08 15:54:07,879 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 6.0 (TID 19) in 28 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:07,879 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 6.0 (TID 21)
2018-02-08 15:54:07,898 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_6 in memory on 192.168.11.26:62777 (size: 632.0 B, free: 631.7 MB)
2018-02-08 15:54:07,901 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 6.0 (TID 20). 2867 bytes result sent to driver
2018-02-08 15:54:07,902 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,902 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:07,902 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 6.0 (TID 22, localhost, executor driver, partition 8, ANY, 4621 bytes)
2018-02-08 15:54:07,904 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 6.0 (TID 20) in 45 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:07,905 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 6.0 (TID 22)
2018-02-08 15:54:07,905 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_7 stored as values in memory (estimated size 1224.0 B, free 631.3 MB)
2018-02-08 15:54:07,910 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_7 in memory on 192.168.11.26:62777 (size: 1224.0 B, free: 631.7 MB)
2018-02-08 15:54:07,911 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_7 stored as values in memory (estimated size 624.0 B, free 631.3 MB)
2018-02-08 15:54:07,912 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_7 in memory on 192.168.11.26:62777 (size: 624.0 B, free: 631.7 MB)
2018-02-08 15:54:07,914 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 6.0 (TID 21). 2867 bytes result sent to driver
2018-02-08 15:54:07,915 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,916 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:07,916 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 6.0 (TID 23, localhost, executor driver, partition 9, ANY, 4621 bytes)
2018-02-08 15:54:07,918 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_8 stored as values in memory (estimated size 1240.0 B, free 631.3 MB)
2018-02-08 15:54:07,918 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 6.0 (TID 21) in 40 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:07,919 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 6.0 (TID 23)
2018-02-08 15:54:07,919 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_8 in memory on 192.168.11.26:62777 (size: 1240.0 B, free: 631.7 MB)
2018-02-08 15:54:07,924 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_8 stored as values in memory (estimated size 600.0 B, free 631.3 MB)
2018-02-08 15:54:07,924 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_8 in memory on 192.168.11.26:62777 (size: 600.0 B, free: 631.7 MB)
2018-02-08 15:54:07,925 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:54:07,926 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:07,925 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 6.0 (TID 22). 2867 bytes result sent to driver
2018-02-08 15:54:07,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 6.0 (TID 22) in 25 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:07,928 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_9 stored as values in memory (estimated size 1112.0 B, free 631.3 MB)
2018-02-08 15:54:07,932 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_9 in memory on 192.168.11.26:62777 (size: 1112.0 B, free: 631.7 MB)
2018-02-08 15:54:07,932 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_9 stored as values in memory (estimated size 600.0 B, free 631.3 MB)
2018-02-08 15:54:07,934 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_9 in memory on 192.168.11.26:62777 (size: 600.0 B, free: 631.7 MB)
2018-02-08 15:54:07,936 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 6.0 (TID 23). 2910 bytes result sent to driver
2018-02-08 15:54:07,938 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 6.0 (TID 23) in 21 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:07,938 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 15:54:07,939 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (count at ALS.scala:865) finished in 0.165 s
2018-02-08 15:54:07,939 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: count at ALS.scala:865, took 0.491656 s
2018-02-08 15:54:08,263 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:944
2018-02-08 15:54:08,267 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:54:08,268 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 157 bytes
2018-02-08 15:54:08,269 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 23 (map at ALS.scala:1017)
2018-02-08 15:54:08,269 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 2 is 154 bytes
2018-02-08 15:54:08,269 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 28 (flatMap at ALS.scala:1433)
2018-02-08 15:54:08,270 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 37 (flatMap at ALS.scala:1433)
2018-02-08 15:54:08,270 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 46 (flatMap at ALS.scala:1433)
2018-02-08 15:54:08,271 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 55 (flatMap at ALS.scala:1433)
2018-02-08 15:54:08,271 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 64 (flatMap at ALS.scala:1433)
2018-02-08 15:54:08,271 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 73 (flatMap at ALS.scala:1433)
2018-02-08 15:54:08,272 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 82 (flatMap at ALS.scala:1433)
2018-02-08 15:54:08,272 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 91 (flatMap at ALS.scala:1433)
2018-02-08 15:54:08,272 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 100 (flatMap at ALS.scala:1433)
2018-02-08 15:54:08,273 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 109 (flatMap at ALS.scala:1433)
2018-02-08 15:54:08,273 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (count at ALS.scala:944) with 10 output partitions
2018-02-08 15:54:08,273 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 21 (count at ALS.scala:944)
2018-02-08 15:54:08,273 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 8)
2018-02-08 15:54:08,274 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 20)
2018-02-08 15:54:08,279 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[23] at map at ALS.scala:1017), which has no missing parents
2018-02-08 15:54:08,283 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 32.6 KB, free 631.2 MB)
2018-02-08 15:54:08,286 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.6 KB, free 631.2 MB)
2018-02-08 15:54:08,287 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:62777 (size: 14.6 KB, free: 631.7 MB)
2018-02-08 15:54:08,287 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:08,288 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[23] at map at ALS.scala:1017) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:08,288 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 10 tasks
2018-02-08 15:54:08,289 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:54:08,290 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 9.0 (TID 25, localhost, executor driver, partition 1, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:54:08,290 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 24)
2018-02-08 15:54:08,290 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 9.0 (TID 25)
2018-02-08 15:54:08,294 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:54:08,296 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:54:08,304 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 15:54:08,305 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 15:54:08,321 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 24). 2083 bytes result sent to driver
2018-02-08 15:54:08,327 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 9.0 (TID 26, localhost, executor driver, partition 2, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:54:08,330 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 9.0 (TID 25). 2040 bytes result sent to driver
2018-02-08 15:54:08,331 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 9.0 (TID 26)
2018-02-08 15:54:08,330 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 24) in 41 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:08,333 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 9.0 (TID 27, localhost, executor driver, partition 3, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:54:08,334 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 9.0 (TID 25) in 45 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:08,334 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 9.0 (TID 27)
2018-02-08 15:54:08,335 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:54:08,337 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:54:08,350 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 9.0 (TID 26). 2040 bytes result sent to driver
2018-02-08 15:54:08,351 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 9.0 (TID 28, localhost, executor driver, partition 4, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:54:08,351 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 9.0 (TID 26) in 25 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:08,352 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 9.0 (TID 28)
2018-02-08 15:54:08,352 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 9.0 (TID 27). 1997 bytes result sent to driver
2018-02-08 15:54:08,353 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 9.0 (TID 29, localhost, executor driver, partition 5, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:54:08,353 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 9.0 (TID 27) in 20 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:08,353 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 9.0 (TID 29)
2018-02-08 15:54:08,356 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:54:08,366 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:54:08,376 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 9.0 (TID 28). 1997 bytes result sent to driver
2018-02-08 15:54:08,376 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 9.0 (TID 30, localhost, executor driver, partition 6, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:54:08,377 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 9.0 (TID 30)
2018-02-08 15:54:08,377 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 9.0 (TID 28) in 27 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:08,381 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:54:08,387 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 9.0 (TID 29). 2040 bytes result sent to driver
2018-02-08 15:54:08,388 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 9.0 (TID 31, localhost, executor driver, partition 7, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:54:08,388 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 9.0 (TID 29) in 35 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:08,388 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 9.0 (TID 31)
2018-02-08 15:54:08,391 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:54:08,398 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 9.0 (TID 30). 1997 bytes result sent to driver
2018-02-08 15:54:08,399 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 9.0 (TID 32, localhost, executor driver, partition 8, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:54:08,399 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 9.0 (TID 30) in 23 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:08,399 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 9.0 (TID 32)
2018-02-08 15:54:08,403 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:54:08,420 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 9.0 (TID 32). 2040 bytes result sent to driver
2018-02-08 15:54:08,422 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 9.0 (TID 33, localhost, executor driver, partition 9, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:54:08,422 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 9.0 (TID 32) in 24 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:08,422 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 9.0 (TID 33)
2018-02-08 15:54:08,426 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:54:08,436 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 9.0 (TID 31). 2040 bytes result sent to driver
2018-02-08 15:54:08,438 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 9.0 (TID 31) in 51 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:08,447 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 9.0 (TID 33). 1997 bytes result sent to driver
2018-02-08 15:54:08,448 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 9.0 (TID 33) in 26 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:08,448 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-02-08 15:54:08,449 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 9 (map at ALS.scala:1017) finished in 0.160 s
2018-02-08 15:54:08,449 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:08,449 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:08,449 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 14, ShuffleMapStage 11)
2018-02-08 15:54:08,449 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:08,450 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 11 (MapPartitionsRDD[28] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:54:08,452 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 33.7 KB, free 631.2 MB)
2018-02-08 15:54:08,454 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.9 KB, free 631.2 MB)
2018-02-08 15:54:08,455 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:62777 (size: 14.9 KB, free: 631.6 MB)
2018-02-08 15:54:08,455 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:08,455 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[28] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:08,456 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 10 tasks
2018-02-08 15:54:08,460 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:54:08,460 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 11.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:54:08,461 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 34)
2018-02-08 15:54:08,463 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 11.0 (TID 35)
2018-02-08 15:54:08,467 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:54:08,468 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:54:08,468 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:08,471 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:54:08,472 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:54:08,472 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:08,551 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 11.0 (TID 35). 2427 bytes result sent to driver
2018-02-08 15:54:08,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 11.0 (TID 36, localhost, executor driver, partition 2, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:54:08,559 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 11.0 (TID 35) in 99 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:08,561 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 11.0 (TID 36)
2018-02-08 15:54:08,577 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:54:08,578 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:54:08,578 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:08,593 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 34). 2427 bytes result sent to driver
2018-02-08 15:54:08,595 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 11.0 (TID 37, localhost, executor driver, partition 3, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:54:08,595 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 34) in 139 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:08,595 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 11.0 (TID 37)
2018-02-08 15:54:08,599 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:54:08,599 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:54:08,600 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:08,666 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 11.0 (TID 36). 2470 bytes result sent to driver
2018-02-08 15:54:08,667 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 11.0 (TID 37). 2427 bytes result sent to driver
2018-02-08 15:54:08,667 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 11.0 (TID 37) in 72 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:08,668 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 11.0 (TID 38, localhost, executor driver, partition 4, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:54:08,669 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 11.0 (TID 38)
2018-02-08 15:54:08,671 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 11.0 (TID 39, localhost, executor driver, partition 5, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:54:08,672 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 11.0 (TID 36) in 118 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:08,672 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 11.0 (TID 39)
2018-02-08 15:54:08,673 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:54:08,677 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:54:08,677 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:08,681 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:54:08,682 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:54:08,682 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:08,795 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 11.0 (TID 38). 2470 bytes result sent to driver
2018-02-08 15:54:08,801 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 11.0 (TID 40, localhost, executor driver, partition 6, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:54:08,801 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 11.0 (TID 38) in 133 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:08,802 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 11.0 (TID 40)
2018-02-08 15:54:08,805 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:54:08,806 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:54:08,806 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:08,848 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 11.0 (TID 39). 2427 bytes result sent to driver
2018-02-08 15:54:08,850 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 11.0 (TID 41, localhost, executor driver, partition 7, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:54:08,850 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 11.0 (TID 39) in 179 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:08,853 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 11.0 (TID 41)
2018-02-08 15:54:08,899 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:54:08,900 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 11.0 (TID 40). 2427 bytes result sent to driver
2018-02-08 15:54:08,901 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 11.0 (TID 42, localhost, executor driver, partition 8, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:54:08,901 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 11.0 (TID 40) in 100 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:08,901 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 11.0 (TID 42)
2018-02-08 15:54:08,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:54:08,908 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:54:08,911 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:54:08,911 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:08,910 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
2018-02-08 15:54:09,026 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 11.0 (TID 42). 2427 bytes result sent to driver
2018-02-08 15:54:09,026 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 11.0 (TID 43, localhost, executor driver, partition 9, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:54:09,027 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 11.0 (TID 42) in 127 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:09,027 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 11.0 (TID 43)
2018-02-08 15:54:09,031 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:54:09,033 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,033 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,133 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 11.0 (TID 43). 2470 bytes result sent to driver
2018-02-08 15:54:09,137 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 11.0 (TID 43) in 111 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:09,139 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 11.0 (TID 41). 2427 bytes result sent to driver
2018-02-08 15:54:09,141 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 11.0 (TID 41) in 291 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:09,141 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 15:54:09,142 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 11 (flatMap at ALS.scala:1433) finished in 0.685 s
2018-02-08 15:54:09,142 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:09,142 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:09,142 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 14)
2018-02-08 15:54:09,142 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:09,144 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 12 (MapPartitionsRDD[37] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:54:09,146 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 35.9 KB, free 631.1 MB)
2018-02-08 15:54:09,154 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.7 KB, free 631.1 MB)
2018-02-08 15:54:09,155 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.11.26:62777 (size: 15.7 KB, free: 631.6 MB)
2018-02-08 15:54:09,156 INFO[org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:09,157 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[37] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:09,157 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 12.0 with 10 tasks
2018-02-08 15:54:09,158 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 12.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,159 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 12.0 (TID 45, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,160 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 12.0 (TID 44)
2018-02-08 15:54:09,160 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 12.0 (TID 45)
2018-02-08 15:54:09,166 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:54:09,166 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:54:09,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,168 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:54:09,169 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:54:09,169 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,170 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:09,192 WARN[com.github.fommil.netlib.LAPACK:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2018-02-08 15:54:09,192 WARN[com.github.fommil.netlib.LAPACK:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2018-02-08 15:54:09,316 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 12.0 (TID 44). 2427 bytes result sent to driver
2018-02-08 15:54:09,318 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 12.0 (TID 46, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,321 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 12.0 (TID 44) in 164 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:09,322 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 12.0 (TID 46)
2018-02-08 15:54:09,328 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:54:09,329 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:54:09,329 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,329 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,338 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 12.0 (TID 45). 2427 bytes result sent to driver
2018-02-08 15:54:09,339 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 12.0 (TID 47, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,340 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 12.0 (TID 47)
2018-02-08 15:54:09,340 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 12.0 (TID 45) in 182 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:09,345 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:54:09,346 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:54:09,347 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,347 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:09,409 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 12.0 (TID 47). 2427 bytes result sent to driver
2018-02-08 15:54:09,411 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 12.0 (TID 48, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,412 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 12.0 (TID 47) in 73 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:09,412 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 12.0 (TID 48)
2018-02-08 15:54:09,417 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:54:09,417 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:54:09,418 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,421 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 15:54:09,418 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 12.0 (TID 46). 2427 bytes result sent to driver
2018-02-08 15:54:09,460 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 12.0 (TID 49, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,469 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 12.0 (TID 46) in 151 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:09,470 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 12.0 (TID 49)
2018-02-08 15:54:09,475 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:54:09,476 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:54:09,477 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,477 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,576 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 12.0 (TID 48). 2427 bytes result sent to driver
2018-02-08 15:54:09,577 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 12.0 (TID 50, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,578 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 12.0 (TID 48) in 166 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:09,578 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 12.0 (TID 50)
2018-02-08 15:54:09,591 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:54:09,592 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:54:09,594 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,594 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,635 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 12.0 (TID 49). 2427 bytes result sent to driver
2018-02-08 15:54:09,635 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 12.0 (TID 51, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,636 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 12.0 (TID 51)
2018-02-08 15:54:09,636 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 12.0 (TID 49) in 177 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:09,643 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:54:09,643 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:54:09,645 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,645 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,684 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 12.0 (TID 50). 2470 bytes result sent to driver
2018-02-08 15:54:09,686 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 12.0 (TID 52, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,687 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 12.0 (TID 50) in 111 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:09,688 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 12.0 (TID 52)
2018-02-08 15:54:09,693 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:54:09,693 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:54:09,693 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:09,712 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 12.0 (TID 51). 2470 bytes result sent to driver
2018-02-08 15:54:09,714 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 12.0 (TID 53, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,715 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 12.0 (TID 51) in 80 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:09,715 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 12.0 (TID 53)
2018-02-08 15:54:09,718 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:54:09,719 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:54:09,719 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,719 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,750 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 12.0 (TID 52). 2427 bytes result sent to driver
2018-02-08 15:54:09,752 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 12.0 (TID 52) in 66 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:09,765 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 12.0 (TID 53). 2470 bytes result sent to driver
2018-02-08 15:54:09,765 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 12.0 (TID 53) in 51 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:09,766 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2018-02-08 15:54:09,766 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 12 (flatMap at ALS.scala:1433) finished in 0.609 s
2018-02-08 15:54:09,766 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:09,766 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:09,766 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 14)
2018-02-08 15:54:09,767 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:09,768 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 13 (MapPartitionsRDD[46] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:54:09,773 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 36.9 KB, free 631.1 MB)
2018-02-08 15:54:09,776 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.0 KB, free 631.1 MB)
2018-02-08 15:54:09,777 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.11.26:62777 (size: 16.0 KB, free: 631.6 MB)
2018-02-08 15:54:09,778 INFO[org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:09,778 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[46] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:09,778 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 13.0 with 10 tasks
2018-02-08 15:54:09,779 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 13.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,779 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 13.0 (TID 55, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,780 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 13.0 (TID 55)
2018-02-08 15:54:09,780 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 13.0 (TID 54)
2018-02-08 15:54:09,790 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:54:09,790 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:54:09,791 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,791 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:09,795 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:54:09,795 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:54:09,806 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,807 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:09,848 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 13.0 (TID 55). 2427 bytes result sent to driver
2018-02-08 15:54:09,849 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 13.0 (TID 56, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,849 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 13.0 (TID 55) in 70 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:09,850 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 13.0 (TID 56)
2018-02-08 15:54:09,854 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:54:09,855 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:54:09,855 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,855 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,868 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 13.0 (TID 54). 2427 bytes result sent to driver
2018-02-08 15:54:09,869 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 13.0 (TID 57, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,870 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 13.0 (TID 54) in 90 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:09,870 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 13.0 (TID 57)
2018-02-08 15:54:09,873 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:54:09,873 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:54:09,873 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,873 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,897 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 13.0 (TID 56). 2427 bytes result sent to driver
2018-02-08 15:54:09,898 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 13.0 (TID 58, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,898 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 13.0 (TID 58)
2018-02-08 15:54:09,898 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 13.0 (TID 56) in 49 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:09,902 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:54:09,902 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:54:09,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,911 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 13.0 (TID 57). 2427 bytes result sent to driver
2018-02-08 15:54:09,912 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 13.0 (TID 59, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,912 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 13.0 (TID 57) in 43 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:09,912 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 13.0 (TID 59)
2018-02-08 15:54:09,916 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:54:09,916 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:54:09,917 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,917 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,937 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 13.0 (TID 58). 2427 bytes result sent to driver
2018-02-08 15:54:09,939 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 13.0 (TID 60, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,940 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 13.0 (TID 58) in 43 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:09,940 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 13.0 (TID 60)
2018-02-08 15:54:09,943 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:54:09,943 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:54:09,943 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:09,949 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 13.0 (TID 59). 2427 bytes result sent to driver
2018-02-08 15:54:09,950 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 13.0 (TID 61, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,950 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 13.0 (TID 59) in 38 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:09,951 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 13.0 (TID 61)
2018-02-08 15:54:09,954 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:54:09,954 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:54:09,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:09,978 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 13.0 (TID 60). 2427 bytes result sent to driver
2018-02-08 15:54:09,989 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 13.0 (TID 62, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:09,990 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 13.0 (TID 60) in 51 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:09,991 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 13.0 (TID 62)
2018-02-08 15:54:09,998 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:54:09,998 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:54:09,998 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:09,999 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:10,004 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 13.0 (TID 61). 2470 bytes result sent to driver
2018-02-08 15:54:10,004 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 13.0 (TID 63, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,004 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 13.0 (TID 63)
2018-02-08 15:54:10,004 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 13.0 (TID 61) in 54 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:10,009 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:54:10,009 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:54:10,010 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,010 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,059 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 13.0 (TID 62). 2427 bytes result sent to driver
2018-02-08 15:54:10,062 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 13.0 (TID 62) in 73 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:10,068 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 13.0 (TID 63). 2427 bytes result sent to driver
2018-02-08 15:54:10,069 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 13.0 (TID 63) in 65 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:10,070 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2018-02-08 15:54:10,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 13 (flatMap at ALS.scala:1433) finished in 0.291 s
2018-02-08 15:54:10,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:10,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:10,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 14)
2018-02-08 15:54:10,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:10,071 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 14 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:54:10,073 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 37.8 KB, free 631.0 MB)
2018-02-08 15:54:10,084 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 16.2 KB, free 631.0 MB)
2018-02-08 15:54:10,084 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.11.26:62777 in memory (size: 15.7 KB, free: 631.6 MB)
2018-02-08 15:54:10,085 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.11.26:62777 (size: 16.2 KB, free: 631.6 MB)
2018-02-08 15:54:10,085 INFO[org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:10,085 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:10,085 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 14.0 with 10 tasks
2018-02-08 15:54:10,086 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:62777 in memory (size: 14.5 KB, free: 631.6 MB)
2018-02-08 15:54:10,086 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 14.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,086 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 14.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,086 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.11.26:62777 in memory (size: 14.9 KB, free: 631.6 MB)
2018-02-08 15:54:10,086 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 14.0 (TID 64)
2018-02-08 15:54:10,086 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 14.0 (TID 65)
2018-02-08 15:54:10,087 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:62777 in memory (size: 14.6 KB, free: 631.7 MB)
2018-02-08 15:54:10,089 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:54:10,090 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:54:10,090 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,090 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,091 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:54:10,091 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:54:10,092 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,092 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,124 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 14.0 (TID 64). 2427 bytes result sent to driver
2018-02-08 15:54:10,125 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 14.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,125 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 14.0 (TID 66)
2018-02-08 15:54:10,125 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 14.0 (TID 64) in 39 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:10,127 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 14.0 (TID 65). 2427 bytes result sent to driver
2018-02-08 15:54:10,128 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 14.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,128 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 14.0 (TID 65) in 42 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:10,129 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:54:10,129 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:54:10,129 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 14.0 (TID 67)
2018-02-08 15:54:10,129 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,129 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,134 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:54:10,135 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:54:10,135 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,135 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,159 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 14.0 (TID 66). 2427 bytes result sent to driver
2018-02-08 15:54:10,159 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 14.0 (TID 68, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,160 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 14.0 (TID 66) in 35 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:10,161 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 14.0 (TID 68)
2018-02-08 15:54:10,165 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:54:10,165 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:54:10,165 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 14.0 (TID 67). 2427 bytes result sent to driver
2018-02-08 15:54:10,165 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,166 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 14.0 (TID 69, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,166 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:10,166 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 14.0 (TID 69)
2018-02-08 15:54:10,166 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 14.0 (TID 67) in 39 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:10,169 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:54:10,169 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:54:10,169 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,170 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:10,197 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 14.0 (TID 68). 2427 bytes result sent to driver
2018-02-08 15:54:10,198 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 14.0 (TID 70, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,199 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 14.0 (TID 68) in 40 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:10,199 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 14.0 (TID 70)
2018-02-08 15:54:10,203 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:54:10,203 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:54:10,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,206 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:54:10,216 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 14.0 (TID 69). 2427 bytes result sent to driver
2018-02-08 15:54:10,217 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 14.0 (TID 71, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,218 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 14.0 (TID 69) in 52 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:10,218 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 14.0 (TID 71)
2018-02-08 15:54:10,224 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:54:10,225 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:54:10,225 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,226 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:10,246 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 14.0 (TID 70). 2470 bytes result sent to driver
2018-02-08 15:54:10,246 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 14.0 (TID 72, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,247 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 14.0 (TID 72)
2018-02-08 15:54:10,247 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 14.0 (TID 70) in 49 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:10,251 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:54:10,251 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:54:10,251 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,251 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,267 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 14.0 (TID 71). 2427 bytes result sent to driver
2018-02-08 15:54:10,267 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 14.0 (TID 73, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,268 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 14.0 (TID 71) in 51 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:10,270 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 14.0 (TID 73)
2018-02-08 15:54:10,276 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:54:10,276 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:54:10,276 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,277 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:10,291 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 14.0 (TID 72). 2470 bytes result sent to driver
2018-02-08 15:54:10,291 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 14.0 (TID 72) in 45 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:10,310 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 14.0 (TID 73). 2427 bytes result sent to driver
2018-02-08 15:54:10,310 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 14.0 (TID 73) in 43 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:10,310 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-02-08 15:54:10,311 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 14 (flatMap at ALS.scala:1433) finished in 0.224 s
2018-02-08 15:54:10,311 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:10,311 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:10,311 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:54:10,311 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:10,312 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[64] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:54:10,315 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 38.7 KB, free 631.2 MB)
2018-02-08 15:54:10,319 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 16.5 KB, free 631.2 MB)
2018-02-08 15:54:10,319 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.11.26:62777 (size: 16.5 KB, free: 631.6 MB)
2018-02-08 15:54:10,320 INFO[org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:10,320 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[64] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:10,320 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 15.0 with 10 tasks
2018-02-08 15:54:10,321 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 15.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,321 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 15.0 (TID 75, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,322 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 15.0 (TID 75)
2018-02-08 15:54:10,322 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 15.0 (TID 74)
2018-02-08 15:54:10,324 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:54:10,324 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:54:10,325 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:54:10,325 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:54:10,325 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,325 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,325 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,325 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,368 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 15.0 (TID 74). 2427 bytes result sent to driver
2018-02-08 15:54:10,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 15.0 (TID 76, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 15.0 (TID 74) in 48 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:10,369 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 15.0 (TID 76)
2018-02-08 15:54:10,373 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:54:10,373 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:54:10,375 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,376 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 15:54:10,377 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 15.0 (TID 75). 2427 bytes result sent to driver
2018-02-08 15:54:10,377 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 15.0 (TID 77, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,378 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 15.0 (TID 75) in 57 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:10,378 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 15.0 (TID 77)
2018-02-08 15:54:10,381 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:54:10,382 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:54:10,382 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,382 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,409 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 15.0 (TID 76). 2427 bytes result sent to driver
2018-02-08 15:54:10,410 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 15.0 (TID 78, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,411 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 15.0 (TID 76) in 42 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:10,411 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 15.0 (TID 78)
2018-02-08 15:54:10,416 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:54:10,416 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:54:10,417 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,417 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,418 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 15.0 (TID 77). 2427 bytes result sent to driver
2018-02-08 15:54:10,420 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 15.0 (TID 79, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,420 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 15.0 (TID 77) in 43 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:10,420 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 15.0 (TID 79)
2018-02-08 15:54:10,437 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:54:10,437 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:54:10,441 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,441 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:54:10,480 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 15.0 (TID 78). 2427 bytes result sent to driver
2018-02-08 15:54:10,481 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 15.0 (TID 80, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,481 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 15.0 (TID 80)
2018-02-08 15:54:10,481 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 15.0 (TID 78) in 71 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:10,485 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:54:10,486 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:54:10,486 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,486 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,506 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 15.0 (TID 79). 2470 bytes result sent to driver
2018-02-08 15:54:10,506 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 15.0 (TID 81, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,508 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 15.0 (TID 79) in 88 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:10,509 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 15.0 (TID 81)
2018-02-08 15:54:10,514 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:54:10,514 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:54:10,516 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,516 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,527 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 15.0 (TID 80). 2470 bytes result sent to driver
2018-02-08 15:54:10,528 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 15.0 (TID 82, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,529 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 15.0 (TID 80) in 49 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:10,529 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 15.0 (TID 82)
2018-02-08 15:54:10,533 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:54:10,533 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:54:10,534 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,534 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,557 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 15.0 (TID 81). 2427 bytes result sent to driver
2018-02-08 15:54:10,557 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 15.0 (TID 83, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,558 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 15.0 (TID 81) in 51 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:10,558 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 15.0 (TID 83)
2018-02-08 15:54:10,561 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:54:10,561 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:54:10,561 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,561 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,568 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 15.0 (TID 82). 2427 bytes result sent to driver
2018-02-08 15:54:10,570 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 15.0 (TID 82) in 42 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:10,586 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 15.0 (TID 83). 2427 bytes result sent to driver
2018-02-08 15:54:10,586 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 15.0 (TID 83) in 29 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:10,586 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2018-02-08 15:54:10,586 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 15 (flatMap at ALS.scala:1433) finished in 0.265 s
2018-02-08 15:54:10,587 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:10,587 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:10,587 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:54:10,587 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:10,587 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 16 (MapPartitionsRDD[73] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:54:10,590 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 39.6 KB, free 631.1 MB)
2018-02-08 15:54:10,592 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.6 KB, free 631.1 MB)
2018-02-08 15:54:10,592 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.11.26:62777 (size: 16.6 KB, free: 631.6 MB)
2018-02-08 15:54:10,593 INFO[org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:10,593 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[73] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:10,593 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 16.0 with 10 tasks
2018-02-08 15:54:10,594 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 16.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,594 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 16.0 (TID 85, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,594 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 16.0 (TID 85)
2018-02-08 15:54:10,594 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 16.0 (TID 84)
2018-02-08 15:54:10,597 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:54:10,597 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:54:10,597 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:54:10,597 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:54:10,598 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,598 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,598 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,598 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,635 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 16.0 (TID 84). 2427 bytes result sent to driver
2018-02-08 15:54:10,637 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 16.0 (TID 86, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,638 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 16.0 (TID 84) in 44 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:10,638 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 16.0 (TID 86)
2018-02-08 15:54:10,639 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 16.0 (TID 85). 2427 bytes result sent to driver
2018-02-08 15:54:10,640 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 16.0 (TID 87, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,640 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 16.0 (TID 85) in 46 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:10,640 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 16.0 (TID 87)
2018-02-08 15:54:10,644 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:54:10,645 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:54:10,645 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,646 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:10,644 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:54:10,646 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:54:10,647 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,647 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,684 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 16.0 (TID 87). 2427 bytes result sent to driver
2018-02-08 15:54:10,686 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 16.0 (TID 88, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,687 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 16.0 (TID 87) in 48 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:10,687 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 16.0 (TID 88)
2018-02-08 15:54:10,693 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:54:10,694 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:54:10,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,696 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 16.0 (TID 86). 2470 bytes result sent to driver
2018-02-08 15:54:10,697 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 16.0 (TID 89, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,697 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 16.0 (TID 86) in 62 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:10,697 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 16.0 (TID 89)
2018-02-08 15:54:10,702 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:54:10,702 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:54:10,703 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,703 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,751 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 16.0 (TID 88). 2427 bytes result sent to driver
2018-02-08 15:54:10,752 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 16.0 (TID 90, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,752 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 16.0 (TID 88) in 66 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:10,752 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 16.0 (TID 90)
2018-02-08 15:54:10,754 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 16.0 (TID 89). 2470 bytes result sent to driver
2018-02-08 15:54:10,755 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 16.0 (TID 91, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,755 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 16.0 (TID 89) in 59 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:10,757 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:54:10,757 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:54:10,757 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,757 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,757 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 16.0 (TID 91)
2018-02-08 15:54:10,761 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:54:10,762 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:54:10,762 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,763 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:10,786 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 16.0 (TID 90). 2427 bytes result sent to driver
2018-02-08 15:54:10,787 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 16.0 (TID 92, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,787 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 16.0 (TID 90) in 35 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:10,787 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 16.0 (TID 92)
2018-02-08 15:54:10,790 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:54:10,790 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:54:10,790 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,791 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:10,812 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 16.0 (TID 91). 2427 bytes result sent to driver
2018-02-08 15:54:10,813 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 16.0 (TID 93, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,814 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 16.0 (TID 91) in 59 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:10,814 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 16.0 (TID 93)
2018-02-08 15:54:10,820 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:54:10,821 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:54:10,824 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,824 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,828 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 16.0 (TID 92). 2427 bytes result sent to driver
2018-02-08 15:54:10,829 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 16.0 (TID 92) in 43 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:10,859 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 16.0 (TID 93). 2427 bytes result sent to driver
2018-02-08 15:54:10,860 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 16.0 (TID 93) in 48 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:10,861 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2018-02-08 15:54:10,861 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 16 (flatMap at ALS.scala:1433) finished in 0.267 s
2018-02-08 15:54:10,861 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:10,861 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:10,861 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:54:10,861 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:10,863 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 17 (MapPartitionsRDD[82] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:54:10,865 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 40.5 KB, free 631.1 MB)
2018-02-08 15:54:10,867 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 16.9 KB, free 631.0 MB)
2018-02-08 15:54:10,868 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.11.26:62777 (size: 16.9 KB, free: 631.6 MB)
2018-02-08 15:54:10,868 INFO[org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:10,869 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[82] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:10,869 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 17.0 with 10 tasks
2018-02-08 15:54:10,870 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 17.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,870 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 17.0 (TID 95, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,870 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 17.0 (TID 94)
2018-02-08 15:54:10,870 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 17.0 (TID 95)
2018-02-08 15:54:10,877 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:54:10,877 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:54:10,878 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,878 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,878 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:54:10,879 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:54:10,879 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,879 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,920 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 17.0 (TID 94). 2470 bytes result sent to driver
2018-02-08 15:54:10,921 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 17.0 (TID 96, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,922 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 17.0 (TID 96)
2018-02-08 15:54:10,922 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 17.0 (TID 94) in 53 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:10,927 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 17.0 (TID 95). 2427 bytes result sent to driver
2018-02-08 15:54:10,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 17.0 (TID 97, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,929 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:54:10,929 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:54:10,929 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,929 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 17.0 (TID 95) in 59 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:10,929 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 17.0 (TID 97)
2018-02-08 15:54:10,929 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,937 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:54:10,937 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:54:10,938 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,939 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:10,963 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 17.0 (TID 96). 2427 bytes result sent to driver
2018-02-08 15:54:10,964 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 17.0 (TID 98, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,964 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 17.0 (TID 96) in 43 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:10,964 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 17.0 (TID 98)
2018-02-08 15:54:10,967 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:54:10,967 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:54:10,968 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,968 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:10,969 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 17.0 (TID 97). 2470 bytes result sent to driver
2018-02-08 15:54:10,970 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 17.0 (TID 99, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,971 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 17.0 (TID 97) in 43 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:10,971 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 17.0 (TID 99)
2018-02-08 15:54:10,974 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:54:10,974 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:54:10,974 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:10,975 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:10,994 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 17.0 (TID 98). 2427 bytes result sent to driver
2018-02-08 15:54:10,995 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 17.0 (TID 100, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:10,996 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 17.0 (TID 98) in 32 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:10,996 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 17.0 (TID 100)
2018-02-08 15:54:11,001 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 17.0 (TID 99). 2427 bytes result sent to driver
2018-02-08 15:54:11,002 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:54:11,002 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:54:11,003 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 17.0 (TID 101, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,003 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 17.0 (TID 101)
2018-02-08 15:54:11,003 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 17.0 (TID 99) in 33 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:11,004 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,005 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 15:54:11,006 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:54:11,006 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:54:11,006 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,006 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,031 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 17.0 (TID 100). 2427 bytes result sent to driver
2018-02-08 15:54:11,032 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 17.0 (TID 102, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,032 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 17.0 (TID 100) in 37 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:11,032 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 17.0 (TID 102)
2018-02-08 15:54:11,034 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 17.0 (TID 101). 2427 bytes result sent to driver
2018-02-08 15:54:11,035 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 17.0 (TID 103, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,035 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 17.0 (TID 101) in 32 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:11,035 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 17.0 (TID 103)
2018-02-08 15:54:11,035 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:54:11,036 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:54:11,037 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,037 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,045 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:54:11,046 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:54:11,046 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,046 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,073 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 17.0 (TID 102). 2427 bytes result sent to driver
2018-02-08 15:54:11,075 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 17.0 (TID 102) in 43 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:11,083 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 17.0 (TID 103). 2427 bytes result sent to driver
2018-02-08 15:54:11,083 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 17.0 (TID 103) in 49 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:11,083 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2018-02-08 15:54:11,084 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 17 (flatMap at ALS.scala:1433) finished in 0.215 s
2018-02-08 15:54:11,084 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:11,084 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:11,085 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 20, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:54:11,085 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:11,086 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[91] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:54:11,088 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 41.4 KB, free 631.0 MB)
2018-02-08 15:54:11,090 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 17.1 KB, free 631.0 MB)
2018-02-08 15:54:11,091 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.11.26:62777 (size: 17.1 KB, free: 631.6 MB)
2018-02-08 15:54:11,091 INFO[org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:11,092 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[91] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:11,092 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 18.0 with 10 tasks
2018-02-08 15:54:11,093 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 18.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,093 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 18.0 (TID 105, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,093 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 18.0 (TID 104)
2018-02-08 15:54:11,094 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 18.0 (TID 105)
2018-02-08 15:54:11,098 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:54:11,098 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:54:11,098 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:54:11,099 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,099 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:54:11,099 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,099 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,100 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,153 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 18.0 (TID 105). 2427 bytes result sent to driver
2018-02-08 15:54:11,153 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 18.0 (TID 106, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,154 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 18.0 (TID 106)
2018-02-08 15:54:11,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 18.0 (TID 105) in 61 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:11,157 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:54:11,157 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:54:11,158 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,158 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,170 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 18.0 (TID 104). 2427 bytes result sent to driver
2018-02-08 15:54:11,171 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 18.0 (TID 107, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,171 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 18.0 (TID 104) in 79 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:11,172 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 18.0 (TID 107)
2018-02-08 15:54:11,175 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:54:11,175 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:54:11,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,198 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 18.0 (TID 106). 2427 bytes result sent to driver
2018-02-08 15:54:11,199 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 18.0 (TID 108, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,199 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 18.0 (TID 106) in 46 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:11,199 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 18.0 (TID 108)
2018-02-08 15:54:11,202 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:54:11,203 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:54:11,203 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,203 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,212 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 18.0 (TID 107). 2427 bytes result sent to driver
2018-02-08 15:54:11,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 18.0 (TID 109, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 18.0 (TID 107) in 43 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:11,213 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 18.0 (TID 109)
2018-02-08 15:54:11,217 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:54:11,217 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:54:11,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,232 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 18.0 (TID 108). 2427 bytes result sent to driver
2018-02-08 15:54:11,232 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 18.0 (TID 110, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,233 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 18.0 (TID 110)
2018-02-08 15:54:11,233 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 18.0 (TID 108) in 35 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:11,236 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:54:11,236 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:54:11,237 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,237 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,254 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 18.0 (TID 109). 2427 bytes result sent to driver
2018-02-08 15:54:11,254 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 18.0 (TID 111, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,255 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 18.0 (TID 109) in 42 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:11,255 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 18.0 (TID 111)
2018-02-08 15:54:11,258 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:54:11,258 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:54:11,259 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,259 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,276 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 18.0 (TID 110). 2470 bytes result sent to driver
2018-02-08 15:54:11,277 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 18.0 (TID 112, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,277 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 18.0 (TID 112)
2018-02-08 15:54:11,277 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 18.0 (TID 110) in 45 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:11,294 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 18.0 (TID 111). 2427 bytes result sent to driver
2018-02-08 15:54:11,294 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:54:11,294 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 18.0 (TID 113, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,294 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:54:11,294 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 18.0 (TID 111) in 40 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:11,294 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 18.0 (TID 113)
2018-02-08 15:54:11,294 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,295 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,297 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:54:11,297 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:54:11,297 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,297 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,324 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 18.0 (TID 112). 2427 bytes result sent to driver
2018-02-08 15:54:11,326 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 18.0 (TID 112) in 50 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:11,346 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 18.0 (TID 113). 2470 bytes result sent to driver
2018-02-08 15:54:11,347 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 18.0 (TID 113) in 52 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:11,347 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2018-02-08 15:54:11,347 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 18 (flatMap at ALS.scala:1433) finished in 0.255 s
2018-02-08 15:54:11,347 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:11,347 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:11,347 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 20, ResultStage 21)
2018-02-08 15:54:11,347 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:11,348 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 19 (MapPartitionsRDD[100] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:54:11,350 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16 stored as values in memory (estimated size 42.4 KB, free 630.9 MB)
2018-02-08 15:54:11,353 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 17.3 KB, free 630.9 MB)
2018-02-08 15:54:11,354 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_16_piece0 in memory on 192.168.11.26:62777 (size: 17.3 KB, free: 631.6 MB)
2018-02-08 15:54:11,354 INFO[org.apache.spark.SparkContext:54] - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:11,354 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[100] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:11,355 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 19.0 with 10 tasks
2018-02-08 15:54:11,355 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 19.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,355 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 19.0 (TID 115, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,356 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 19.0 (TID 114)
2018-02-08 15:54:11,356 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 19.0 (TID 115)
2018-02-08 15:54:11,361 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:54:11,361 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:54:11,361 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:54:11,362 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:54:11,362 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,362 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,362 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,363 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,399 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 19.0 (TID 115). 2427 bytes result sent to driver
2018-02-08 15:54:11,399 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 19.0 (TID 116, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,400 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 19.0 (TID 115) in 45 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:11,400 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 19.0 (TID 116)
2018-02-08 15:54:11,402 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 19.0 (TID 114). 2427 bytes result sent to driver
2018-02-08 15:54:11,402 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 19.0 (TID 117, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,402 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 19.0 (TID 117)
2018-02-08 15:54:11,402 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 19.0 (TID 114) in 47 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:11,407 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:54:11,407 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:54:11,408 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,408 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,408 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:54:11,408 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:54:11,410 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,410 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,437 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 19.0 (TID 117). 2470 bytes result sent to driver
2018-02-08 15:54:11,438 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 19.0 (TID 118, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,438 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 19.0 (TID 117) in 36 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:11,438 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 19.0 (TID 118)
2018-02-08 15:54:11,441 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 19.0 (TID 116). 2427 bytes result sent to driver
2018-02-08 15:54:11,442 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 19.0 (TID 119, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,442 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 19.0 (TID 116) in 43 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:11,442 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 19.0 (TID 119)
2018-02-08 15:54:11,442 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:54:11,443 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:54:11,443 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,443 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,445 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:54:11,445 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:54:11,446 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,446 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,469 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 19.0 (TID 118). 2427 bytes result sent to driver
2018-02-08 15:54:11,469 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 19.0 (TID 120, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,470 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 19.0 (TID 120)
2018-02-08 15:54:11,470 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 19.0 (TID 118) in 32 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:11,474 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:54:11,474 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:54:11,474 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 19.0 (TID 119). 2427 bytes result sent to driver
2018-02-08 15:54:11,474 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,474 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,475 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 19.0 (TID 121, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,475 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 19.0 (TID 119) in 33 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:11,475 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 19.0 (TID 121)
2018-02-08 15:54:11,478 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:54:11,479 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:54:11,479 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,479 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,503 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 19.0 (TID 120). 2427 bytes result sent to driver
2018-02-08 15:54:11,504 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 19.0 (TID 122, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,504 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 19.0 (TID 120) in 35 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:11,504 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 19.0 (TID 122)
2018-02-08 15:54:11,506 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 19.0 (TID 121). 2427 bytes result sent to driver
2018-02-08 15:54:11,507 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 19.0 (TID 123, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,507 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 19.0 (TID 123)
2018-02-08 15:54:11,507 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 19.0 (TID 121) in 33 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:11,509 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:54:11,509 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:54:11,509 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,509 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,510 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:54:11,511 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:54:11,511 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,511 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,537 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 19.0 (TID 122). 2427 bytes result sent to driver
2018-02-08 15:54:11,538 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 19.0 (TID 122) in 35 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:11,540 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 19.0 (TID 123). 2427 bytes result sent to driver
2018-02-08 15:54:11,541 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 19.0 (TID 123) in 34 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:11,542 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2018-02-08 15:54:11,542 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 19 (flatMap at ALS.scala:1433) finished in 0.187 s
2018-02-08 15:54:11,542 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:11,542 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:11,543 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 20, ResultStage 21)
2018-02-08 15:54:11,543 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:11,544 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[109] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:54:11,547 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17 stored as values in memory (estimated size 43.3 KB, free 630.9 MB)
2018-02-08 15:54:11,549 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 17.5 KB, free 630.9 MB)
2018-02-08 15:54:11,551 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_17_piece0 in memory on 192.168.11.26:62777 (size: 17.5 KB, free: 631.6 MB)
2018-02-08 15:54:11,551 INFO[org.apache.spark.SparkContext:54] - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:11,552 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[109] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:11,552 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 20.0 with 10 tasks
2018-02-08 15:54:11,553 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 20.0 (TID 124, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,553 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 20.0 (TID 125, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,554 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 20.0 (TID 124)
2018-02-08 15:54:11,554 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 20.0 (TID 125)
2018-02-08 15:54:11,557 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:54:11,557 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:54:11,558 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:54:11,558 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:54:11,558 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,558 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,558 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,558 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,590 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 20.0 (TID 125). 2427 bytes result sent to driver
2018-02-08 15:54:11,591 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 20.0 (TID 126, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,593 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 20.0 (TID 125) in 40 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:11,594 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 20.0 (TID 126)
2018-02-08 15:54:11,593 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 20.0 (TID 124). 2427 bytes result sent to driver
2018-02-08 15:54:11,595 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 20.0 (TID 127, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,595 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 20.0 (TID 124) in 42 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:11,596 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 20.0 (TID 127)
2018-02-08 15:54:11,598 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:54:11,599 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:54:11,599 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,599 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,600 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:54:11,601 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:54:11,602 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,602 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,628 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 20.0 (TID 127). 2427 bytes result sent to driver
2018-02-08 15:54:11,629 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 20.0 (TID 128, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,630 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 20.0 (TID 127) in 35 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:11,630 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 20.0 (TID 128)
2018-02-08 15:54:11,635 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:54:11,636 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:54:11,636 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 20.0 (TID 126). 2427 bytes result sent to driver
2018-02-08 15:54:11,636 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,637 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,637 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 20.0 (TID 129, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,637 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 20.0 (TID 129)
2018-02-08 15:54:11,637 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 20.0 (TID 126) in 46 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:11,640 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:54:11,641 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:54:11,642 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,642 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,680 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 20.0 (TID 129). 2513 bytes result sent to driver
2018-02-08 15:54:11,681 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 20.0 (TID 130, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,681 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 20.0 (TID 129) in 44 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:11,682 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 20.0 (TID 130)
2018-02-08 15:54:11,684 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 20.0 (TID 128). 2427 bytes result sent to driver
2018-02-08 15:54:11,684 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 20.0 (TID 131, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,684 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 20.0 (TID 128) in 55 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:11,684 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 20.0 (TID 131)
2018-02-08 15:54:11,685 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:54:11,685 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:54:11,685 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,687 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:54:11,687 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:54:11,687 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,688 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,711 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 20.0 (TID 130). 2427 bytes result sent to driver
2018-02-08 15:54:11,712 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 20.0 (TID 132, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,712 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 20.0 (TID 130) in 31 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:11,712 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 20.0 (TID 132)
2018-02-08 15:54:11,715 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 20.0 (TID 131). 2470 bytes result sent to driver
2018-02-08 15:54:11,717 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:54:11,717 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:54:11,718 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,719 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,718 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 20.0 (TID 133, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:54:11,719 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 20.0 (TID 131) in 35 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:11,719 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 20.0 (TID 133)
2018-02-08 15:54:11,723 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:54:11,723 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:54:11,724 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,724 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,751 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 20.0 (TID 132). 2427 bytes result sent to driver
2018-02-08 15:54:11,752 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 20.0 (TID 132) in 40 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:11,755 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 20.0 (TID 133). 2427 bytes result sent to driver
2018-02-08 15:54:11,756 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 20.0 (TID 133) in 38 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:11,756 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2018-02-08 15:54:11,757 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 20 (flatMap at ALS.scala:1433) finished in 0.205 s
2018-02-08 15:54:11,757 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:11,757 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:11,758 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 21)
2018-02-08 15:54:11,758 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:11,759 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 21 (userFactors MapPartitionsRDD[119] at mapPartitions at ALS.scala:924), which has no missing parents
2018-02-08 15:54:11,762 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18 stored as values in memory (estimated size 44.4 KB, free 630.8 MB)
2018-02-08 15:54:11,764 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 17.8 KB, free 630.8 MB)
2018-02-08 15:54:11,764 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_18_piece0 in memory on 192.168.11.26:62777 (size: 17.8 KB, free: 631.5 MB)
2018-02-08 15:54:11,765 INFO[org.apache.spark.SparkContext:54] - Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:11,766 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 21 (userFactors MapPartitionsRDD[119] at mapPartitions at ALS.scala:924) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:11,766 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 21.0 with 10 tasks
2018-02-08 15:54:11,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 21.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 21.0 (TID 135, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,767 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 21.0 (TID 135)
2018-02-08 15:54:11,767 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 21.0 (TID 134)
2018-02-08 15:54:11,771 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:54:11,771 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:54:11,771 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:54:11,771 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:54:11,772 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,772 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,772 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,772 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,778 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_1 stored as values in memory (estimated size 320.0 B, free 630.8 MB)
2018-02-08 15:54:11,780 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_0 stored as values in memory (estimated size 320.0 B, free 630.8 MB)
2018-02-08 15:54:11,781 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_1 in memory on 192.168.11.26:62777 (size: 320.0 B, free: 631.5 MB)
2018-02-08 15:54:11,782 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_0 in memory on 192.168.11.26:62777 (size: 320.0 B, free: 631.5 MB)
2018-02-08 15:54:11,783 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 21.0 (TID 135). 2906 bytes result sent to driver
2018-02-08 15:54:11,784 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 21.0 (TID 134). 2949 bytes result sent to driver
2018-02-08 15:54:11,784 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 21.0 (TID 136, localhost, executor driver, partition 2, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,784 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 21.0 (TID 137, localhost, executor driver, partition 3, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,785 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 21.0 (TID 135) in 18 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:11,786 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 21.0 (TID 134) in 20 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:11,786 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 21.0 (TID 136)
2018-02-08 15:54:11,794 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 21.0 (TID 137)
2018-02-08 15:54:11,795 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:54:11,796 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:54:11,796 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,796 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,798 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:54:11,798 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:54:11,798 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,798 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,804 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_3 stored as values in memory (estimated size 320.0 B, free 630.8 MB)
2018-02-08 15:54:11,806 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_2 stored as values in memory (estimated size 320.0 B, free 630.8 MB)
2018-02-08 15:54:11,807 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_3 in memory on 192.168.11.26:62777 (size: 320.0 B, free: 631.5 MB)
2018-02-08 15:54:11,807 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_2 in memory on 192.168.11.26:62777 (size: 320.0 B, free: 631.5 MB)
2018-02-08 15:54:11,808 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 21.0 (TID 137). 2949 bytes result sent to driver
2018-02-08 15:54:11,808 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 21.0 (TID 136). 2949 bytes result sent to driver
2018-02-08 15:54:11,808 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 21.0 (TID 138, localhost, executor driver, partition 4, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,808 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 21.0 (TID 139, localhost, executor driver, partition 5, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,808 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 21.0 (TID 138)
2018-02-08 15:54:11,809 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 21.0 (TID 136) in 25 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:11,809 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 21.0 (TID 137) in 25 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:11,816 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:54:11,816 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:54:11,817 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,817 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,818 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 21.0 (TID 139)
2018-02-08 15:54:11,823 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_4 stored as values in memory (estimated size 320.0 B, free 630.8 MB)
2018-02-08 15:54:11,824 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_4 in memory on 192.168.11.26:62777 (size: 320.0 B, free: 631.5 MB)
2018-02-08 15:54:11,825 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 21.0 (TID 138). 2949 bytes result sent to driver
2018-02-08 15:54:11,825 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 21.0 (TID 140, localhost, executor driver, partition 6, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,825 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:54:11,825 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 21.0 (TID 138) in 17 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:11,825 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 21.0 (TID 140)
2018-02-08 15:54:11,826 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:54:11,826 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,827 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,829 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:54:11,829 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:54:11,830 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,830 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,831 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_5 stored as values in memory (estimated size 320.0 B, free 630.8 MB)
2018-02-08 15:54:11,831 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_5 in memory on 192.168.11.26:62777 (size: 320.0 B, free: 631.5 MB)
2018-02-08 15:54:11,832 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 21.0 (TID 139). 2949 bytes result sent to driver
2018-02-08 15:54:11,833 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 21.0 (TID 141, localhost, executor driver, partition 7, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,833 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 21.0 (TID 141)
2018-02-08 15:54:11,833 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 21.0 (TID 139) in 25 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:11,835 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_6 stored as values in memory (estimated size 320.0 B, free 630.8 MB)
2018-02-08 15:54:11,835 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_6 in memory on 192.168.11.26:62777 (size: 320.0 B, free: 631.5 MB)
2018-02-08 15:54:11,836 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 21.0 (TID 140). 2949 bytes result sent to driver
2018-02-08 15:54:11,836 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 21.0 (TID 142, localhost, executor driver, partition 8, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,837 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 21.0 (TID 140) in 11 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:11,837 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 21.0 (TID 142)
2018-02-08 15:54:11,838 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:54:11,838 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:54:11,839 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,839 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,841 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:54:11,841 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:54:11,841 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,841 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,843 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_7 stored as values in memory (estimated size 320.0 B, free 630.8 MB)
2018-02-08 15:54:11,844 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_7 in memory on 192.168.11.26:62777 (size: 320.0 B, free: 631.5 MB)
2018-02-08 15:54:11,844 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 21.0 (TID 141). 2949 bytes result sent to driver
2018-02-08 15:54:11,845 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 21.0 (TID 143, localhost, executor driver, partition 9, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,845 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 21.0 (TID 141) in 13 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:11,845 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 21.0 (TID 143)
2018-02-08 15:54:11,845 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_8 stored as values in memory (estimated size 320.0 B, free 630.8 MB)
2018-02-08 15:54:11,846 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_8 in memory on 192.168.11.26:62777 (size: 320.0 B, free: 631.5 MB)
2018-02-08 15:54:11,847 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 21.0 (TID 142). 2949 bytes result sent to driver
2018-02-08 15:54:11,848 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 21.0 (TID 142) in 12 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:11,849 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:54:11,849 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:54:11,849 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,849 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,852 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_9 stored as values in memory (estimated size 320.0 B, free 630.8 MB)
2018-02-08 15:54:11,853 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_9 in memory on 192.168.11.26:62777 (size: 320.0 B, free: 631.5 MB)
2018-02-08 15:54:11,854 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 21.0 (TID 143). 2906 bytes result sent to driver
2018-02-08 15:54:11,854 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 21.0 (TID 143) in 9 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:11,854 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2018-02-08 15:54:11,854 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 21 (count at ALS.scala:944) finished in 0.088 s
2018-02-08 15:54:11,855 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: count at ALS.scala:944, took 3.592314 s
2018-02-08 15:54:11,861 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 105 from persistence list
2018-02-08 15:54:11,864 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 105
2018-02-08 15:54:11,867 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:946
2018-02-08 15:54:11,868 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:54:11,869 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 157 bytes
2018-02-08 15:54:11,870 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 13 is 197 bytes
2018-02-08 15:54:11,871 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 2 is 154 bytes
2018-02-08 15:54:11,871 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 12 is 169 bytes
2018-02-08 15:54:11,872 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 11 is 245 bytes
2018-02-08 15:54:11,872 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 10 is 169 bytes
2018-02-08 15:54:11,873 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 9 is 244 bytes
2018-02-08 15:54:11,874 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 8 is 169 bytes
2018-02-08 15:54:11,875 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 7 is 244 bytes
2018-02-08 15:54:11,876 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 6 is 169 bytes
2018-02-08 15:54:11,876 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 5 is 244 bytes
2018-02-08 15:54:11,877 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 4 is 169 bytes
2018-02-08 15:54:11,878 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (count at ALS.scala:946) with 10 output partitions
2018-02-08 15:54:11,878 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 35 (count at ALS.scala:946)
2018-02-08 15:54:11,878 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 34, ShuffleMapStage 25)
2018-02-08 15:54:11,878 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:54:11,879 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 35 (itemFactors MapPartitionsRDD[124] at mapPartitions at ALS.scala:936), which has no missing parents
2018-02-08 15:54:11,882 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19 stored as values in memory (estimated size 43.5 KB, free 630.8 MB)
2018-02-08 15:54:11,886 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 17.6 KB, free 630.7 MB)
2018-02-08 15:54:11,887 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_19_piece0 in memory on 192.168.11.26:62777 (size: 17.6 KB, free: 631.5 MB)
2018-02-08 15:54:11,887 INFO[org.apache.spark.SparkContext:54] - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:11,888 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 35 (itemFactors MapPartitionsRDD[124] at mapPartitions at ALS.scala:936) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:54:11,888 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 35.0 with 10 tasks
2018-02-08 15:54:11,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 35.0 (TID 144, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 35.0 (TID 145, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,889 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 35.0 (TID 145)
2018-02-08 15:54:11,889 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 35.0 (TID 144)
2018-02-08 15:54:11,893 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:54:11,893 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:54:11,893 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:54:11,893 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:54:11,893 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,893 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,893 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,894 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,897 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_1 stored as values in memory (estimated size 1016.0 B, free 630.7 MB)
2018-02-08 15:54:11,897 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_0 stored as values in memory (estimated size 1016.0 B, free 630.7 MB)
2018-02-08 15:54:11,897 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_1 in memory on 192.168.11.26:62777 (size: 1016.0 B, free: 631.5 MB)
2018-02-08 15:54:11,898 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_0 in memory on 192.168.11.26:62777 (size: 1016.0 B, free: 631.5 MB)
2018-02-08 15:54:11,898 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 35.0 (TID 145). 2949 bytes result sent to driver
2018-02-08 15:54:11,898 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 35.0 (TID 144). 2949 bytes result sent to driver
2018-02-08 15:54:11,898 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 35.0 (TID 146, localhost, executor driver, partition 2, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,899 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 35.0 (TID 147, localhost, executor driver, partition 3, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,899 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 35.0 (TID 146)
2018-02-08 15:54:11,899 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 35.0 (TID 144) in 10 ms on localhost (executor driver) (1/10)
2018-02-08 15:54:11,899 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 35.0 (TID 145) in 10 ms on localhost (executor driver) (2/10)
2018-02-08 15:54:11,899 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 35.0 (TID 147)
2018-02-08 15:54:11,902 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:54:11,902 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:54:11,903 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:54:11,903 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:54:11,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,907 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_2 stored as values in memory (estimated size 1016.0 B, free 630.7 MB)
2018-02-08 15:54:11,907 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_3 stored as values in memory (estimated size 1016.0 B, free 630.7 MB)
2018-02-08 15:54:11,907 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_2 in memory on 192.168.11.26:62777 (size: 1016.0 B, free: 631.5 MB)
2018-02-08 15:54:11,908 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_3 in memory on 192.168.11.26:62777 (size: 1016.0 B, free: 631.5 MB)
2018-02-08 15:54:11,908 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 35.0 (TID 146). 2949 bytes result sent to driver
2018-02-08 15:54:11,909 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 35.0 (TID 148, localhost, executor driver, partition 4, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,909 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 35.0 (TID 147). 2949 bytes result sent to driver
2018-02-08 15:54:11,909 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 35.0 (TID 146) in 11 ms on localhost (executor driver) (3/10)
2018-02-08 15:54:11,909 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 35.0 (TID 148)
2018-02-08 15:54:11,909 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 35.0 (TID 149, localhost, executor driver, partition 5, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,910 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 35.0 (TID 147) in 11 ms on localhost (executor driver) (4/10)
2018-02-08 15:54:11,910 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 35.0 (TID 149)
2018-02-08 15:54:11,912 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:54:11,913 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:54:11,913 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,913 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:54:11,913 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,913 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:54:11,914 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,914 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,916 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_4 stored as values in memory (estimated size 1016.0 B, free 630.7 MB)
2018-02-08 15:54:11,916 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_5 stored as values in memory (estimated size 1016.0 B, free 630.7 MB)
2018-02-08 15:54:11,917 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_4 in memory on 192.168.11.26:62777 (size: 1016.0 B, free: 631.5 MB)
2018-02-08 15:54:11,917 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_5 in memory on 192.168.11.26:62777 (size: 1016.0 B, free: 631.5 MB)
2018-02-08 15:54:11,917 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 35.0 (TID 148). 2906 bytes result sent to driver
2018-02-08 15:54:11,918 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 35.0 (TID 149). 2906 bytes result sent to driver
2018-02-08 15:54:11,918 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 35.0 (TID 150, localhost, executor driver, partition 6, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,918 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 35.0 (TID 150)
2018-02-08 15:54:11,918 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 35.0 (TID 148) in 10 ms on localhost (executor driver) (5/10)
2018-02-08 15:54:11,918 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 35.0 (TID 151, localhost, executor driver, partition 7, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,919 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 35.0 (TID 149) in 10 ms on localhost (executor driver) (6/10)
2018-02-08 15:54:11,919 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 35.0 (TID 151)
2018-02-08 15:54:11,921 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:54:11,921 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:54:11,922 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:54:11,922 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:54:11,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:11,926 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_7 stored as values in memory (estimated size 1016.0 B, free 630.7 MB)
2018-02-08 15:54:11,927 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_7 in memory on 192.168.11.26:62777 (size: 1016.0 B, free: 631.5 MB)
2018-02-08 15:54:11,928 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 35.0 (TID 151). 2949 bytes result sent to driver
2018-02-08 15:54:11,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 35.0 (TID 152, localhost, executor driver, partition 8, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,929 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 35.0 (TID 151) in 11 ms on localhost (executor driver) (7/10)
2018-02-08 15:54:11,930 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 35.0 (TID 152)
2018-02-08 15:54:11,930 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_6 stored as values in memory (estimated size 1016.0 B, free 630.7 MB)
2018-02-08 15:54:11,931 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_6 in memory on 192.168.11.26:62777 (size: 1016.0 B, free: 631.5 MB)
2018-02-08 15:54:11,933 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 35.0 (TID 150). 2949 bytes result sent to driver
2018-02-08 15:54:11,935 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 35.0 (TID 153, localhost, executor driver, partition 9, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:54:11,935 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 35.0 (TID 150) in 17 ms on localhost (executor driver) (8/10)
2018-02-08 15:54:11,936 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 35.0 (TID 153)
2018-02-08 15:54:11,941 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:54:11,941 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:54:11,941 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:54:11,941 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:54:11,941 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,941 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:54:11,942 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,942 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:11,945 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_9 stored as values in memory (estimated size 1016.0 B, free 630.7 MB)
2018-02-08 15:54:11,945 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_8 stored as values in memory (estimated size 1016.0 B, free 630.7 MB)
2018-02-08 15:54:11,946 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_9 in memory on 192.168.11.26:62777 (size: 1016.0 B, free: 631.5 MB)
2018-02-08 15:54:11,947 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_8 in memory on 192.168.11.26:62777 (size: 1016.0 B, free: 631.5 MB)
2018-02-08 15:54:11,948 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 35.0 (TID 153). 2949 bytes result sent to driver
2018-02-08 15:54:11,948 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 35.0 (TID 152). 2906 bytes result sent to driver
2018-02-08 15:54:11,951 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 35.0 (TID 152) in 23 ms on localhost (executor driver) (9/10)
2018-02-08 15:54:11,951 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 35.0 (TID 153) in 16 ms on localhost (executor driver) (10/10)
2018-02-08 15:54:11,952 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2018-02-08 15:54:11,952 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 35 (count at ALS.scala:946) finished in 0.064 s
2018-02-08 15:54:11,952 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: count at ALS.scala:946, took 0.085208 s
2018-02-08 15:54:11,953 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 16 from persistence list
2018-02-08 15:54:11,955 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 16
2018-02-08 15:54:11,956 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 17 from persistence list
2018-02-08 15:54:11,957 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 17
2018-02-08 15:54:11,959 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 21 from persistence list
2018-02-08 15:54:11,960 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 21
2018-02-08 15:54:11,961 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 22 from persistence list
2018-02-08 15:54:11,962 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 22
2018-02-08 15:54:11,962 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 13 from persistence list
2018-02-08 15:54:11,963 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 13
2018-02-08 15:54:12,131 INFO[org.apache.spark.ml.util.Instrumentation:54] - ALS-als_8fe24e49f7b5-627727856-1: training finished
2018-02-08 15:54:12,603 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_18_piece0 on 192.168.11.26:62777 in memory (size: 17.8 KB, free: 631.6 MB)
2018-02-08 15:54:12,608 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_16_piece0 on 192.168.11.26:62777 in memory (size: 17.3 KB, free: 631.6 MB)
2018-02-08 15:54:12,610 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_19_piece0 on 192.168.11.26:62777 in memory (size: 17.6 KB, free: 631.6 MB)
2018-02-08 15:54:12,617 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.11.26:62777 in memory (size: 16.2 KB, free: 631.6 MB)
2018-02-08 15:54:12,622 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_14_piece0 on 192.168.11.26:62777 in memory (size: 16.9 KB, free: 631.7 MB)
2018-02-08 15:54:12,626 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_15_piece0 on 192.168.11.26:62777 in memory (size: 17.1 KB, free: 631.7 MB)
2018-02-08 15:54:12,628 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_12_piece0 on 192.168.11.26:62777 in memory (size: 16.5 KB, free: 631.7 MB)
2018-02-08 15:54:12,630 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_13_piece0 on 192.168.11.26:62777 in memory (size: 16.6 KB, free: 631.7 MB)
2018-02-08 15:54:12,632 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_17_piece0 on 192.168.11.26:62777 in memory (size: 17.5 KB, free: 631.7 MB)
2018-02-08 15:54:12,888 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 35.600011 ms
2018-02-08 15:54:12,919 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 26.093129 ms
2018-02-08 15:54:12,964 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 29.008969 ms
2018-02-08 15:54:13,003 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:42
2018-02-08 15:54:13,007 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 3 is 244 bytes
2018-02-08 15:54:13,008 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 141 (show at MachineLeaningFiltering.java:42)
2018-02-08 15:54:13,008 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (show at MachineLeaningFiltering.java:42) with 1 output partitions
2018-02-08 15:54:13,008 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 51 (show at MachineLeaningFiltering.java:42)
2018-02-08 15:54:13,009 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 50)
2018-02-08 15:54:13,009 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 50)
2018-02-08 15:54:13,011 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 50 (MapPartitionsRDD[141] at show at MachineLeaningFiltering.java:42), which has no missing parents
2018-02-08 15:54:13,070 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20 stored as values in memory (estimated size 95.9 KB, free 631.2 MB)
2018-02-08 15:54:13,072 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 34.4 KB, free 631.2 MB)
2018-02-08 15:54:13,073 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_20_piece0 in memory on 192.168.11.26:62777 (size: 34.4 KB, free: 631.7 MB)
2018-02-08 15:54:13,073 INFO[org.apache.spark.SparkContext:54] - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:13,074 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 100 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[141] at show at MachineLeaningFiltering.java:42) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-02-08 15:54:13,074 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 50.0 with 100 tasks
2018-02-08 15:54:13,076 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 50.0 (TID 154, localhost, executor driver, partition 0, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,076 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 50.0 (TID 155, localhost, executor driver, partition 1, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,076 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 50.0 (TID 154)
2018-02-08 15:54:13,076 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 50.0 (TID 155)
2018-02-08 15:54:13,107 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:13,107 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:13,121 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.197442 ms
2018-02-08 15:54:13,127 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:13,128 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:13,147 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.887363 ms
2018-02-08 15:54:13,207 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 28.083849 ms
2018-02-08 15:54:13,224 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.388485 ms
2018-02-08 15:54:13,235 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.789762 ms
2018-02-08 15:54:13,243 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 5.152002 ms
2018-02-08 15:54:13,280 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 4.827841 ms
2018-02-08 15:54:13,290 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 4.232321 ms
2018-02-08 15:54:13,299 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 5.808962 ms
2018-02-08 15:54:13,309 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 4.994242 ms
2018-02-08 15:54:13,325 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.926084 ms
2018-02-08 15:54:13,345 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.864004 ms
2018-02-08 15:54:13,388 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.291206 ms
2018-02-08 15:54:13,539 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 50.0 (TID 154). 2975 bytes result sent to driver
2018-02-08 15:54:13,539 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 50.0 (TID 156, localhost, executor driver, partition 2, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,540 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 50.0 (TID 154) in 466 ms on localhost (executor driver) (1/100)
2018-02-08 15:54:13,540 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 50.0 (TID 156)
2018-02-08 15:54:13,541 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 50.0 (TID 155). 2975 bytes result sent to driver
2018-02-08 15:54:13,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 50.0 (TID 157, localhost, executor driver, partition 3, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 50.0 (TID 155) in 466 ms on localhost (executor driver) (2/100)
2018-02-08 15:54:13,542 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 50.0 (TID 157)
2018-02-08 15:54:13,545 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:13,547 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:13,556 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:13,557 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:13,605 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 50.0 (TID 156). 2932 bytes result sent to driver
2018-02-08 15:54:13,606 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 50.0 (TID 158, localhost, executor driver, partition 4, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,606 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 50.0 (TID 156) in 67 ms on localhost (executor driver) (3/100)
2018-02-08 15:54:13,606 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 50.0 (TID 158)
2018-02-08 15:54:13,612 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:13,613 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:13,622 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 50.0 (TID 157). 2932 bytes result sent to driver
2018-02-08 15:54:13,624 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 50.0 (TID 159, localhost, executor driver, partition 5, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,624 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 50.0 (TID 159)
2018-02-08 15:54:13,624 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 50.0 (TID 157) in 82 ms on localhost (executor driver) (4/100)
2018-02-08 15:54:13,629 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:13,630 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:13,651 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 50.0 (TID 158). 2975 bytes result sent to driver
2018-02-08 15:54:13,652 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 50.0 (TID 160, localhost, executor driver, partition 6, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,653 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 50.0 (TID 158) in 47 ms on localhost (executor driver) (5/100)
2018-02-08 15:54:13,653 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 50.0 (TID 160)
2018-02-08 15:54:13,658 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:13,660 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:13,672 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 50.0 (TID 159). 2932 bytes result sent to driver
2018-02-08 15:54:13,673 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 50.0 (TID 161, localhost, executor driver, partition 7, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,673 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 50.0 (TID 161)
2018-02-08 15:54:13,673 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 50.0 (TID 159) in 49 ms on localhost (executor driver) (6/100)
2018-02-08 15:54:13,677 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:13,678 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:13,717 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 50.0 (TID 161). 2932 bytes result sent to driver
2018-02-08 15:54:13,718 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 50.0 (TID 162, localhost, executor driver, partition 8, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,718 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 50.0 (TID 161) in 45 ms on localhost (executor driver) (7/100)
2018-02-08 15:54:13,719 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 50.0 (TID 162)
2018-02-08 15:54:13,720 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 50.0 (TID 160). 2975 bytes result sent to driver
2018-02-08 15:54:13,720 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 50.0 (TID 163, localhost, executor driver, partition 9, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,721 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 50.0 (TID 160) in 69 ms on localhost (executor driver) (8/100)
2018-02-08 15:54:13,721 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 50.0 (TID 163)
2018-02-08 15:54:13,725 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:13,725 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:13,726 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:13,726 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:13,805 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 50.0 (TID 162). 2975 bytes result sent to driver
2018-02-08 15:54:13,806 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 50.0 (TID 164, localhost, executor driver, partition 10, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,811 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 50.0 (TID 162) in 93 ms on localhost (executor driver) (9/100)
2018-02-08 15:54:13,810 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 50.0 (TID 163). 2932 bytes result sent to driver
2018-02-08 15:54:13,813 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 50.0 (TID 164)
2018-02-08 15:54:13,813 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 50.0 (TID 165, localhost, executor driver, partition 11, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,814 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 50.0 (TID 163) in 94 ms on localhost (executor driver) (10/100)
2018-02-08 15:54:13,816 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 50.0 (TID 165)
2018-02-08 15:54:13,818 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:13,821 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:13,822 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:13,825 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:13,879 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 50.0 (TID 164). 2932 bytes result sent to driver
2018-02-08 15:54:13,880 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 50.0 (TID 166, localhost, executor driver, partition 12, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,880 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 50.0 (TID 164) in 74 ms on localhost (executor driver) (11/100)
2018-02-08 15:54:13,880 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 50.0 (TID 166)
2018-02-08 15:54:13,885 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:13,886 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:13,916 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 50.0 (TID 166). 2932 bytes result sent to driver
2018-02-08 15:54:13,916 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 50.0 (TID 167, localhost, executor driver, partition 13, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,917 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 50.0 (TID 167)
2018-02-08 15:54:13,917 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 50.0 (TID 166) in 37 ms on localhost (executor driver) (12/100)
2018-02-08 15:54:13,918 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 50.0 (TID 165). 2889 bytes result sent to driver
2018-02-08 15:54:13,919 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 50.0 (TID 168, localhost, executor driver, partition 14, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,919 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 50.0 (TID 165) in 106 ms on localhost (executor driver) (13/100)
2018-02-08 15:54:13,920 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 50.0 (TID 168)
2018-02-08 15:54:13,923 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:13,924 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:13,931 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:13,933 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:13,954 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 50.0 (TID 167). 2975 bytes result sent to driver
2018-02-08 15:54:13,955 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 50.0 (TID 169, localhost, executor driver, partition 15, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,955 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 50.0 (TID 169)
2018-02-08 15:54:13,955 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 50.0 (TID 167) in 39 ms on localhost (executor driver) (14/100)
2018-02-08 15:54:13,959 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:13,960 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:13,990 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 50.0 (TID 168). 2975 bytes result sent to driver
2018-02-08 15:54:13,991 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 50.0 (TID 170, localhost, executor driver, partition 16, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:13,991 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 50.0 (TID 168) in 72 ms on localhost (executor driver) (15/100)
2018-02-08 15:54:13,991 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 50.0 (TID 170)
2018-02-08 15:54:14,001 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:14,007 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 50.0 (TID 169). 2932 bytes result sent to driver
2018-02-08 15:54:14,009 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 50.0 (TID 171, localhost, executor driver, partition 17, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,009 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 50.0 (TID 171)
2018-02-08 15:54:14,010 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 50.0 (TID 169) in 54 ms on localhost (executor driver) (16/100)
2018-02-08 15:54:14,011 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:14,016 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:14,017 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:14,073 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 50.0 (TID 171). 2932 bytes result sent to driver
2018-02-08 15:54:14,074 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 50.0 (TID 172, localhost, executor driver, partition 18, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,074 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 50.0 (TID 172)
2018-02-08 15:54:14,074 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 50.0 (TID 171) in 65 ms on localhost (executor driver) (17/100)
2018-02-08 15:54:14,078 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:14,079 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:14,086 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 50.0 (TID 170). 2975 bytes result sent to driver
2018-02-08 15:54:14,087 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 50.0 (TID 173, localhost, executor driver, partition 19, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,087 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 50.0 (TID 173)
2018-02-08 15:54:14,087 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 50.0 (TID 170) in 97 ms on localhost (executor driver) (18/100)
2018-02-08 15:54:14,090 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:14,091 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:14,120 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 50.0 (TID 172). 2975 bytes result sent to driver
2018-02-08 15:54:14,121 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 50.0 (TID 174, localhost, executor driver, partition 20, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,121 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 50.0 (TID 174)
2018-02-08 15:54:14,121 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 50.0 (TID 172) in 48 ms on localhost (executor driver) (19/100)
2018-02-08 15:54:14,125 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:14,127 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:14,131 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 50.0 (TID 173). 2932 bytes result sent to driver
2018-02-08 15:54:14,132 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 50.0 (TID 175, localhost, executor driver, partition 21, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,132 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 50.0 (TID 175)
2018-02-08 15:54:14,132 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 50.0 (TID 173) in 46 ms on localhost (executor driver) (20/100)
2018-02-08 15:54:14,136 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:14,137 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:14,163 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 50.0 (TID 174). 2975 bytes result sent to driver
2018-02-08 15:54:14,164 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 50.0 (TID 176, localhost, executor driver, partition 22, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,165 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 50.0 (TID 174) in 44 ms on localhost (executor driver) (21/100)
2018-02-08 15:54:14,165 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 50.0 (TID 176)
2018-02-08 15:54:14,167 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 50.0 (TID 175). 2932 bytes result sent to driver
2018-02-08 15:54:14,167 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 50.0 (TID 177, localhost, executor driver, partition 23, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,168 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 50.0 (TID 175) in 36 ms on localhost (executor driver) (22/100)
2018-02-08 15:54:14,168 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 50.0 (TID 177)
2018-02-08 15:54:14,169 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:14,170 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:14,173 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:14,174 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:14,200 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 50.0 (TID 176). 2932 bytes result sent to driver
2018-02-08 15:54:14,201 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 50.0 (TID 178, localhost, executor driver, partition 24, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,201 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 50.0 (TID 178)
2018-02-08 15:54:14,201 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 50.0 (TID 176) in 37 ms on localhost (executor driver) (23/100)
2018-02-08 15:54:14,203 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 50.0 (TID 177). 2975 bytes result sent to driver
2018-02-08 15:54:14,203 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 50.0 (TID 179, localhost, executor driver, partition 25, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,203 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 50.0 (TID 179)
2018-02-08 15:54:14,203 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 50.0 (TID 177) in 36 ms on localhost (executor driver) (24/100)
2018-02-08 15:54:14,205 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:14,206 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:14,207 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:14,208 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:14,246 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 50.0 (TID 178). 2975 bytes result sent to driver
2018-02-08 15:54:14,247 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 50.0 (TID 180, localhost, executor driver, partition 26, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,248 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 50.0 (TID 178) in 46 ms on localhost (executor driver) (25/100)
2018-02-08 15:54:14,248 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 50.0 (TID 180)
2018-02-08 15:54:14,253 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:14,254 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:14,265 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 50.0 (TID 179). 2932 bytes result sent to driver
2018-02-08 15:54:14,265 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 50.0 (TID 181, localhost, executor driver, partition 27, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,265 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 50.0 (TID 181)
2018-02-08 15:54:14,265 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 50.0 (TID 179) in 62 ms on localhost (executor driver) (26/100)
2018-02-08 15:54:14,273 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:14,274 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:14,299 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 50.0 (TID 180). 2975 bytes result sent to driver
2018-02-08 15:54:14,301 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 50.0 (TID 182, localhost, executor driver, partition 28, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,302 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 50.0 (TID 180) in 55 ms on localhost (executor driver) (27/100)
2018-02-08 15:54:14,302 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 50.0 (TID 182)
2018-02-08 15:54:14,311 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:14,312 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:14,325 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 50.0 (TID 181). 2932 bytes result sent to driver
2018-02-08 15:54:14,325 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 50.0 (TID 183, localhost, executor driver, partition 29, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,325 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 50.0 (TID 183)
2018-02-08 15:54:14,325 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 50.0 (TID 181) in 60 ms on localhost (executor driver) (28/100)
2018-02-08 15:54:14,331 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:14,332 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:14,350 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 50.0 (TID 182). 2932 bytes result sent to driver
2018-02-08 15:54:14,351 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 50.0 (TID 184, localhost, executor driver, partition 30, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,351 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 50.0 (TID 184)
2018-02-08 15:54:14,351 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 50.0 (TID 182) in 50 ms on localhost (executor driver) (29/100)
2018-02-08 15:54:14,356 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:14,357 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:14,362 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 50.0 (TID 183). 2975 bytes result sent to driver
2018-02-08 15:54:14,363 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 50.0 (TID 185, localhost, executor driver, partition 31, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,363 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 50.0 (TID 185)
2018-02-08 15:54:14,363 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 50.0 (TID 183) in 38 ms on localhost (executor driver) (30/100)
2018-02-08 15:54:14,367 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:14,368 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:14,388 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 50.0 (TID 184). 2932 bytes result sent to driver
2018-02-08 15:54:14,389 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 50.0 (TID 186, localhost, executor driver, partition 32, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,389 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 50.0 (TID 184) in 39 ms on localhost (executor driver) (31/100)
2018-02-08 15:54:14,389 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 50.0 (TID 186)
2018-02-08 15:54:14,393 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:14,394 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:14,395 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 50.0 (TID 185). 2975 bytes result sent to driver
2018-02-08 15:54:14,396 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 50.0 (TID 187, localhost, executor driver, partition 33, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,396 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 50.0 (TID 185) in 33 ms on localhost (executor driver) (32/100)
2018-02-08 15:54:14,396 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 50.0 (TID 187)
2018-02-08 15:54:14,400 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:14,401 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:14,424 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 50.0 (TID 186). 2975 bytes result sent to driver
2018-02-08 15:54:14,425 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 50.0 (TID 188, localhost, executor driver, partition 34, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,425 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 50.0 (TID 186) in 36 ms on localhost (executor driver) (33/100)
2018-02-08 15:54:14,425 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 50.0 (TID 188)
2018-02-08 15:54:14,430 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:14,431 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:14,435 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 50.0 (TID 187). 2932 bytes result sent to driver
2018-02-08 15:54:14,436 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 50.0 (TID 189, localhost, executor driver, partition 35, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,437 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 50.0 (TID 187) in 42 ms on localhost (executor driver) (34/100)
2018-02-08 15:54:14,437 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 50.0 (TID 189)
2018-02-08 15:54:14,442 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:14,442 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:14,474 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 50.0 (TID 188). 2932 bytes result sent to driver
2018-02-08 15:54:14,476 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 50.0 (TID 190, localhost, executor driver, partition 36, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,477 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 50.0 (TID 188) in 53 ms on localhost (executor driver) (35/100)
2018-02-08 15:54:14,477 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 50.0 (TID 190)
2018-02-08 15:54:14,478 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 50.0 (TID 189). 2932 bytes result sent to driver
2018-02-08 15:54:14,482 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 50.0 (TID 191, localhost, executor driver, partition 37, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,484 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 50.0 (TID 189) in 48 ms on localhost (executor driver) (36/100)
2018-02-08 15:54:14,485 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 50.0 (TID 191)
2018-02-08 15:54:14,487 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:14,489 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:14,492 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:14,492 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:14,524 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 50.0 (TID 190). 2975 bytes result sent to driver
2018-02-08 15:54:14,525 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 50.0 (TID 192, localhost, executor driver, partition 38, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,525 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 50.0 (TID 192)
2018-02-08 15:54:14,525 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 50.0 (TID 190) in 49 ms on localhost (executor driver) (37/100)
2018-02-08 15:54:14,527 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 50.0 (TID 191). 2932 bytes result sent to driver
2018-02-08 15:54:14,527 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 50.0 (TID 193, localhost, executor driver, partition 39, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,528 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 50.0 (TID 191) in 46 ms on localhost (executor driver) (38/100)
2018-02-08 15:54:14,528 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 50.0 (TID 193)
2018-02-08 15:54:14,531 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:14,532 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:14,535 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:14,537 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:14,567 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 50.0 (TID 192). 2975 bytes result sent to driver
2018-02-08 15:54:14,567 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 50.0 (TID 194, localhost, executor driver, partition 40, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,568 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 50.0 (TID 192) in 44 ms on localhost (executor driver) (39/100)
2018-02-08 15:54:14,568 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 50.0 (TID 194)
2018-02-08 15:54:14,569 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 50.0 (TID 193). 2975 bytes result sent to driver
2018-02-08 15:54:14,570 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 50.0 (TID 195, localhost, executor driver, partition 41, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,570 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 50.0 (TID 193) in 43 ms on localhost (executor driver) (40/100)
2018-02-08 15:54:14,570 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 50.0 (TID 195)
2018-02-08 15:54:14,572 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:14,573 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:14,574 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:14,574 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:14,611 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 50.0 (TID 195). 2932 bytes result sent to driver
2018-02-08 15:54:14,611 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 50.0 (TID 196, localhost, executor driver, partition 42, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,612 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 50.0 (TID 196)
2018-02-08 15:54:14,612 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 50.0 (TID 195) in 43 ms on localhost (executor driver) (41/100)
2018-02-08 15:54:14,616 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:14,617 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:14,621 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 50.0 (TID 194). 2889 bytes result sent to driver
2018-02-08 15:54:14,621 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 50.0 (TID 197, localhost, executor driver, partition 43, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,621 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 50.0 (TID 197)
2018-02-08 15:54:14,621 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 50.0 (TID 194) in 54 ms on localhost (executor driver) (42/100)
2018-02-08 15:54:14,625 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:14,626 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:14,644 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 50.0 (TID 196). 2932 bytes result sent to driver
2018-02-08 15:54:14,644 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 50.0 (TID 198, localhost, executor driver, partition 44, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,645 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 50.0 (TID 196) in 34 ms on localhost (executor driver) (43/100)
2018-02-08 15:54:14,645 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 50.0 (TID 198)
2018-02-08 15:54:14,650 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:14,650 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:14,654 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 50.0 (TID 197). 2975 bytes result sent to driver
2018-02-08 15:54:14,654 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 50.0 (TID 199, localhost, executor driver, partition 45, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,655 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 50.0 (TID 199)
2018-02-08 15:54:14,655 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 50.0 (TID 197) in 34 ms on localhost (executor driver) (44/100)
2018-02-08 15:54:14,660 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:14,661 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:14,709 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 50.0 (TID 199). 2975 bytes result sent to driver
2018-02-08 15:54:14,710 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 50.0 (TID 200, localhost, executor driver, partition 46, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,711 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 50.0 (TID 199) in 57 ms on localhost (executor driver) (45/100)
2018-02-08 15:54:14,713 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 50.0 (TID 200)
2018-02-08 15:54:14,719 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:14,722 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:14,723 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 50.0 (TID 198). 2932 bytes result sent to driver
2018-02-08 15:54:14,727 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 50.0 (TID 201, localhost, executor driver, partition 47, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,728 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 50.0 (TID 201)
2018-02-08 15:54:14,728 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 50.0 (TID 198) in 84 ms on localhost (executor driver) (46/100)
2018-02-08 15:54:14,733 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:14,740 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:14,809 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 50.0 (TID 200). 2975 bytes result sent to driver
2018-02-08 15:54:14,809 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 50.0 (TID 202, localhost, executor driver, partition 48, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,809 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 50.0 (TID 200) in 99 ms on localhost (executor driver) (47/100)
2018-02-08 15:54:14,810 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 50.0 (TID 202)
2018-02-08 15:54:14,814 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:14,816 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:14,829 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 50.0 (TID 201). 2932 bytes result sent to driver
2018-02-08 15:54:14,830 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 50.0 (TID 203, localhost, executor driver, partition 49, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,831 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 50.0 (TID 201) in 104 ms on localhost (executor driver) (48/100)
2018-02-08 15:54:14,831 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 50.0 (TID 203)
2018-02-08 15:54:14,851 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 50.0 (TID 202). 2975 bytes result sent to driver
2018-02-08 15:54:14,852 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 50.0 (TID 204, localhost, executor driver, partition 50, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,852 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 50.0 (TID 202) in 43 ms on localhost (executor driver) (49/100)
2018-02-08 15:54:14,852 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 50.0 (TID 204)
2018-02-08 15:54:14,855 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:14,856 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:14,857 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:14,858 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:14,887 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 50.0 (TID 204). 2932 bytes result sent to driver
2018-02-08 15:54:14,888 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 50.0 (TID 205, localhost, executor driver, partition 51, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,888 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 50.0 (TID 205)
2018-02-08 15:54:14,888 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 50.0 (TID 204) in 37 ms on localhost (executor driver) (50/100)
2018-02-08 15:54:14,893 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:14,894 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:14,930 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 50.0 (TID 203). 2932 bytes result sent to driver
2018-02-08 15:54:14,930 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 50.0 (TID 206, localhost, executor driver, partition 52, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,931 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 50.0 (TID 206)
2018-02-08 15:54:14,931 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 50.0 (TID 203) in 101 ms on localhost (executor driver) (51/100)
2018-02-08 15:54:14,938 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:14,939 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 50.0 (TID 205). 2975 bytes result sent to driver
2018-02-08 15:54:14,940 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:14,940 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 50.0 (TID 207, localhost, executor driver, partition 53, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:14,941 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 50.0 (TID 205) in 54 ms on localhost (executor driver) (52/100)
2018-02-08 15:54:14,941 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 50.0 (TID 207)
2018-02-08 15:54:14,951 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:14,952 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:14,999 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 50.0 (TID 206). 2975 bytes result sent to driver
2018-02-08 15:54:15,001 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 50.0 (TID 208, localhost, executor driver, partition 54, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,003 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 50.0 (TID 206) in 73 ms on localhost (executor driver) (53/100)
2018-02-08 15:54:15,003 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 50.0 (TID 208)
2018-02-08 15:54:15,008 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:15,010 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:15,013 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 50.0 (TID 207). 2975 bytes result sent to driver
2018-02-08 15:54:15,013 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 50.0 (TID 209, localhost, executor driver, partition 55, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,014 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 50.0 (TID 207) in 74 ms on localhost (executor driver) (54/100)
2018-02-08 15:54:15,014 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 50.0 (TID 209)
2018-02-08 15:54:15,020 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:15,021 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:15,058 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 50.0 (TID 209). 2975 bytes result sent to driver
2018-02-08 15:54:15,058 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 50.0 (TID 210, localhost, executor driver, partition 56, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,059 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 50.0 (TID 209) in 45 ms on localhost (executor driver) (55/100)
2018-02-08 15:54:15,059 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 50.0 (TID 210)
2018-02-08 15:54:15,060 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 50.0 (TID 208). 2932 bytes result sent to driver
2018-02-08 15:54:15,061 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 50.0 (TID 211, localhost, executor driver, partition 57, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,061 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 50.0 (TID 208) in 60 ms on localhost (executor driver) (56/100)
2018-02-08 15:54:15,061 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 50.0 (TID 211)
2018-02-08 15:54:15,063 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:15,064 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:15,066 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:15,067 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:15,108 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 491
2018-02-08 15:54:15,116 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 50.0 (TID 210). 3018 bytes result sent to driver
2018-02-08 15:54:15,116 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 50.0 (TID 212, localhost, executor driver, partition 58, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,117 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 50.0 (TID 210) in 59 ms on localhost (executor driver) (57/100)
2018-02-08 15:54:15,117 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 50.0 (TID 212)
2018-02-08 15:54:15,118 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 50.0 (TID 211). 3018 bytes result sent to driver
2018-02-08 15:54:15,120 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 50.0 (TID 213, localhost, executor driver, partition 59, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,121 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 50.0 (TID 211) in 60 ms on localhost (executor driver) (58/100)
2018-02-08 15:54:15,121 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 50.0 (TID 213)
2018-02-08 15:54:15,121 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:15,123 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:15,125 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:15,126 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:15,163 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 50.0 (TID 213). 2932 bytes result sent to driver
2018-02-08 15:54:15,164 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 50.0 (TID 214, localhost, executor driver, partition 60, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,173 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 50.0 (TID 212). 2932 bytes result sent to driver
2018-02-08 15:54:15,174 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 50.0 (TID 213) in 53 ms on localhost (executor driver) (59/100)
2018-02-08 15:54:15,174 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 50.0 (TID 214)
2018-02-08 15:54:15,175 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 50.0 (TID 215, localhost, executor driver, partition 61, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,179 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:15,180 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:15,180 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 50.0 (TID 212) in 64 ms on localhost (executor driver) (60/100)
2018-02-08 15:54:15,192 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 50.0 (TID 215)
2018-02-08 15:54:15,209 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:15,210 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:15,214 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 50.0 (TID 214). 2932 bytes result sent to driver
2018-02-08 15:54:15,215 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 50.0 (TID 216, localhost, executor driver, partition 62, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,217 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 50.0 (TID 214) in 52 ms on localhost (executor driver) (61/100)
2018-02-08 15:54:15,219 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 50.0 (TID 216)
2018-02-08 15:54:15,225 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:15,226 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:15,258 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 50.0 (TID 216). 2932 bytes result sent to driver
2018-02-08 15:54:15,259 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 50.0 (TID 217, localhost, executor driver, partition 63, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,260 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 50.0 (TID 216) in 45 ms on localhost (executor driver) (62/100)
2018-02-08 15:54:15,260 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 50.0 (TID 217)
2018-02-08 15:54:15,262 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 50.0 (TID 215). 2932 bytes result sent to driver
2018-02-08 15:54:15,263 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 50.0 (TID 218, localhost, executor driver, partition 64, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,263 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 50.0 (TID 215) in 89 ms on localhost (executor driver) (63/100)
2018-02-08 15:54:15,263 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 50.0 (TID 218)
2018-02-08 15:54:15,266 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:15,267 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:15,269 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:15,270 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:15,294 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 50.0 (TID 217). 2975 bytes result sent to driver
2018-02-08 15:54:15,295 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 50.0 (TID 219, localhost, executor driver, partition 65, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,296 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 50.0 (TID 217) in 37 ms on localhost (executor driver) (64/100)
2018-02-08 15:54:15,296 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 50.0 (TID 219)
2018-02-08 15:54:15,302 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:15,302 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:15,307 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 50.0 (TID 218). 2932 bytes result sent to driver
2018-02-08 15:54:15,310 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 50.0 (TID 220, localhost, executor driver, partition 66, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,312 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 50.0 (TID 218) in 50 ms on localhost (executor driver) (65/100)
2018-02-08 15:54:15,317 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 50.0 (TID 220)
2018-02-08 15:54:15,321 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:15,322 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:15,337 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 50.0 (TID 219). 2932 bytes result sent to driver
2018-02-08 15:54:15,338 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 50.0 (TID 221, localhost, executor driver, partition 67, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,338 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 50.0 (TID 219) in 43 ms on localhost (executor driver) (66/100)
2018-02-08 15:54:15,338 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 50.0 (TID 221)
2018-02-08 15:54:15,343 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:15,346 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:15,367 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 50.0 (TID 220). 2932 bytes result sent to driver
2018-02-08 15:54:15,367 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 50.0 (TID 222, localhost, executor driver, partition 68, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,368 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 50.0 (TID 220) in 58 ms on localhost (executor driver) (67/100)
2018-02-08 15:54:15,368 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 50.0 (TID 222)
2018-02-08 15:54:15,372 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:15,373 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:15,398 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 50.0 (TID 221). 2975 bytes result sent to driver
2018-02-08 15:54:15,398 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 50.0 (TID 223, localhost, executor driver, partition 69, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,399 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 50.0 (TID 221) in 62 ms on localhost (executor driver) (68/100)
2018-02-08 15:54:15,399 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 50.0 (TID 223)
2018-02-08 15:54:15,404 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:15,405 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:15,430 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 50.0 (TID 222). 2932 bytes result sent to driver
2018-02-08 15:54:15,430 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 50.0 (TID 224, localhost, executor driver, partition 70, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,431 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 50.0 (TID 222) in 64 ms on localhost (executor driver) (69/100)
2018-02-08 15:54:15,431 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 50.0 (TID 224)
2018-02-08 15:54:15,437 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:15,438 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:15,463 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 50.0 (TID 223). 2932 bytes result sent to driver
2018-02-08 15:54:15,463 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 50.0 (TID 225, localhost, executor driver, partition 71, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,464 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 50.0 (TID 223) in 66 ms on localhost (executor driver) (70/100)
2018-02-08 15:54:15,464 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 50.0 (TID 225)
2018-02-08 15:54:15,470 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:15,474 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:15,495 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 50.0 (TID 224). 2975 bytes result sent to driver
2018-02-08 15:54:15,495 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 50.0 (TID 226, localhost, executor driver, partition 72, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,496 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 50.0 (TID 224) in 66 ms on localhost (executor driver) (71/100)
2018-02-08 15:54:15,496 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 50.0 (TID 226)
2018-02-08 15:54:15,500 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:15,501 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:15,522 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 50.0 (TID 225). 2975 bytes result sent to driver
2018-02-08 15:54:15,523 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 50.0 (TID 227, localhost, executor driver, partition 73, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,523 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 50.0 (TID 227)
2018-02-08 15:54:15,523 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 50.0 (TID 225) in 60 ms on localhost (executor driver) (72/100)
2018-02-08 15:54:15,529 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:15,530 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:15,531 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 50.0 (TID 226). 2975 bytes result sent to driver
2018-02-08 15:54:15,531 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 50.0 (TID 228, localhost, executor driver, partition 74, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,532 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 50.0 (TID 228)
2018-02-08 15:54:15,532 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 50.0 (TID 226) in 37 ms on localhost (executor driver) (73/100)
2018-02-08 15:54:15,536 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:15,537 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:15,555 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 50.0 (TID 227). 2932 bytes result sent to driver
2018-02-08 15:54:15,555 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 50.0 (TID 229, localhost, executor driver, partition 75, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 50.0 (TID 227) in 33 ms on localhost (executor driver) (74/100)
2018-02-08 15:54:15,556 INFO[org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 50.0 (TID 229)
2018-02-08 15:54:15,559 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:15,560 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:15,560 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 50.0 (TID 228). 2932 bytes result sent to driver
2018-02-08 15:54:15,560 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 50.0 (TID 230, localhost, executor driver, partition 76, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,561 INFO[org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 50.0 (TID 230)
2018-02-08 15:54:15,561 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 50.0 (TID 228) in 30 ms on localhost (executor driver) (75/100)
2018-02-08 15:54:15,565 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:15,566 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:15,585 INFO[org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 50.0 (TID 229). 2932 bytes result sent to driver
2018-02-08 15:54:15,586 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 50.0 (TID 231, localhost, executor driver, partition 77, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,586 INFO[org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 50.0 (TID 231)
2018-02-08 15:54:15,586 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 50.0 (TID 229) in 31 ms on localhost (executor driver) (76/100)
2018-02-08 15:54:15,588 INFO[org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 50.0 (TID 230). 2975 bytes result sent to driver
2018-02-08 15:54:15,590 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 50.0 (TID 232, localhost, executor driver, partition 78, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,590 INFO[org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 50.0 (TID 232)
2018-02-08 15:54:15,591 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 50.0 (TID 230) in 31 ms on localhost (executor driver) (77/100)
2018-02-08 15:54:15,591 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:15,591 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:15,596 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:15,598 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:15,628 INFO[org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 50.0 (TID 232). 2975 bytes result sent to driver
2018-02-08 15:54:15,629 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 50.0 (TID 233, localhost, executor driver, partition 79, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,629 INFO[org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 50.0 (TID 233)
2018-02-08 15:54:15,629 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 50.0 (TID 232) in 39 ms on localhost (executor driver) (78/100)
2018-02-08 15:54:15,634 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:15,636 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:15,638 INFO[org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 50.0 (TID 231). 2932 bytes result sent to driver
2018-02-08 15:54:15,639 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 50.0 (TID 234, localhost, executor driver, partition 80, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,639 INFO[org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 50.0 (TID 234)
2018-02-08 15:54:15,639 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 50.0 (TID 231) in 53 ms on localhost (executor driver) (79/100)
2018-02-08 15:54:15,642 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:15,643 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:15,665 INFO[org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 50.0 (TID 233). 2932 bytes result sent to driver
2018-02-08 15:54:15,665 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 50.0 (TID 235, localhost, executor driver, partition 81, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,666 INFO[org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 50.0 (TID 235)
2018-02-08 15:54:15,666 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 50.0 (TID 233) in 37 ms on localhost (executor driver) (80/100)
2018-02-08 15:54:15,676 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:15,676 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:15,686 INFO[org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 50.0 (TID 234). 2975 bytes result sent to driver
2018-02-08 15:54:15,687 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 50.0 (TID 236, localhost, executor driver, partition 82, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,687 INFO[org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 50.0 (TID 236)
2018-02-08 15:54:15,687 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 50.0 (TID 234) in 49 ms on localhost (executor driver) (81/100)
2018-02-08 15:54:15,691 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:15,692 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:15,716 INFO[org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 50.0 (TID 235). 2932 bytes result sent to driver
2018-02-08 15:54:15,717 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 50.0 (TID 237, localhost, executor driver, partition 83, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,717 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 50.0 (TID 235) in 52 ms on localhost (executor driver) (82/100)
2018-02-08 15:54:15,717 INFO[org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 50.0 (TID 237)
2018-02-08 15:54:15,722 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:15,723 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:15,724 INFO[org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 50.0 (TID 236). 2932 bytes result sent to driver
2018-02-08 15:54:15,725 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 50.0 (TID 238, localhost, executor driver, partition 84, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,726 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 50.0 (TID 236) in 39 ms on localhost (executor driver) (83/100)
2018-02-08 15:54:15,726 INFO[org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 50.0 (TID 238)
2018-02-08 15:54:15,730 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:15,731 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:15,750 INFO[org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 50.0 (TID 237). 2932 bytes result sent to driver
2018-02-08 15:54:15,750 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 50.0 (TID 239, localhost, executor driver, partition 85, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,751 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 50.0 (TID 237) in 34 ms on localhost (executor driver) (84/100)
2018-02-08 15:54:15,751 INFO[org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 50.0 (TID 239)
2018-02-08 15:54:15,755 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:15,756 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:15,757 INFO[org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 50.0 (TID 238). 2932 bytes result sent to driver
2018-02-08 15:54:15,757 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 50.0 (TID 240, localhost, executor driver, partition 86, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,757 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 50.0 (TID 238) in 32 ms on localhost (executor driver) (85/100)
2018-02-08 15:54:15,757 INFO[org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 50.0 (TID 240)
2018-02-08 15:54:15,762 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:15,762 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:15,780 INFO[org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 50.0 (TID 239). 2932 bytes result sent to driver
2018-02-08 15:54:15,780 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 50.0 (TID 241, localhost, executor driver, partition 87, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,781 INFO[org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 50.0 (TID 241)
2018-02-08 15:54:15,781 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 50.0 (TID 239) in 31 ms on localhost (executor driver) (86/100)
2018-02-08 15:54:15,788 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:15,789 INFO[org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 50.0 (TID 240). 2932 bytes result sent to driver
2018-02-08 15:54:15,789 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:15,789 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 50.0 (TID 242, localhost, executor driver, partition 88, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,790 INFO[org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 50.0 (TID 242)
2018-02-08 15:54:15,790 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 50.0 (TID 240) in 33 ms on localhost (executor driver) (87/100)
2018-02-08 15:54:15,793 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:15,794 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:15,819 INFO[org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 50.0 (TID 241). 2932 bytes result sent to driver
2018-02-08 15:54:15,820 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 50.0 (TID 243, localhost, executor driver, partition 89, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,820 INFO[org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 50.0 (TID 243)
2018-02-08 15:54:15,820 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 50.0 (TID 241) in 40 ms on localhost (executor driver) (88/100)
2018-02-08 15:54:15,822 INFO[org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 50.0 (TID 242). 2932 bytes result sent to driver
2018-02-08 15:54:15,823 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 50.0 (TID 244, localhost, executor driver, partition 90, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,823 INFO[org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 50.0 (TID 244)
2018-02-08 15:54:15,823 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 50.0 (TID 242) in 34 ms on localhost (executor driver) (89/100)
2018-02-08 15:54:15,824 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:15,824 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:15,828 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:15,829 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:15,856 INFO[org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 50.0 (TID 243). 2932 bytes result sent to driver
2018-02-08 15:54:15,857 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 50.0 (TID 245, localhost, executor driver, partition 91, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,859 INFO[org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 50.0 (TID 245)
2018-02-08 15:54:15,859 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 50.0 (TID 243) in 40 ms on localhost (executor driver) (90/100)
2018-02-08 15:54:15,864 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:15,864 INFO[org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 50.0 (TID 244). 2975 bytes result sent to driver
2018-02-08 15:54:15,865 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 50.0 (TID 246, localhost, executor driver, partition 92, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,865 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:15,865 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 50.0 (TID 244) in 43 ms on localhost (executor driver) (91/100)
2018-02-08 15:54:15,865 INFO[org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 50.0 (TID 246)
2018-02-08 15:54:15,869 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:15,870 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:15,895 INFO[org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 50.0 (TID 245). 2932 bytes result sent to driver
2018-02-08 15:54:15,896 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 50.0 (TID 247, localhost, executor driver, partition 93, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,896 INFO[org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 50.0 (TID 247)
2018-02-08 15:54:15,896 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 50.0 (TID 245) in 39 ms on localhost (executor driver) (92/100)
2018-02-08 15:54:15,900 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:15,901 INFO[org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 50.0 (TID 246). 2932 bytes result sent to driver
2018-02-08 15:54:15,901 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:15,901 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 50.0 (TID 248, localhost, executor driver, partition 94, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,902 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 50.0 (TID 246) in 38 ms on localhost (executor driver) (93/100)
2018-02-08 15:54:15,902 INFO[org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 50.0 (TID 248)
2018-02-08 15:54:15,909 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:15,910 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:15,930 INFO[org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 50.0 (TID 247). 2932 bytes result sent to driver
2018-02-08 15:54:15,931 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 50.0 (TID 249, localhost, executor driver, partition 95, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,931 INFO[org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 50.0 (TID 249)
2018-02-08 15:54:15,931 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 50.0 (TID 247) in 36 ms on localhost (executor driver) (94/100)
2018-02-08 15:54:15,933 INFO[org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 50.0 (TID 248). 2975 bytes result sent to driver
2018-02-08 15:54:15,934 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 50.0 (TID 250, localhost, executor driver, partition 96, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,934 INFO[org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 50.0 (TID 250)
2018-02-08 15:54:15,934 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 50.0 (TID 248) in 33 ms on localhost (executor driver) (95/100)
2018-02-08 15:54:15,935 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:15,936 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:15,938 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:15,940 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:15,962 INFO[org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 50.0 (TID 249). 2932 bytes result sent to driver
2018-02-08 15:54:15,963 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 50.0 (TID 251, localhost, executor driver, partition 97, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,963 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 50.0 (TID 249) in 32 ms on localhost (executor driver) (96/100)
2018-02-08 15:54:15,963 INFO[org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 50.0 (TID 251)
2018-02-08 15:54:15,965 INFO[org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 50.0 (TID 250). 2975 bytes result sent to driver
2018-02-08 15:54:15,965 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 50.0 (TID 252, localhost, executor driver, partition 98, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,966 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 50.0 (TID 250) in 33 ms on localhost (executor driver) (97/100)
2018-02-08 15:54:15,966 INFO[org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 50.0 (TID 252)
2018-02-08 15:54:15,968 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:15,968 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:15,971 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:15,972 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:15,997 INFO[org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 50.0 (TID 251). 2975 bytes result sent to driver
2018-02-08 15:54:15,998 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 50.0 (TID 253, localhost, executor driver, partition 99, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:15,998 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 50.0 (TID 251) in 35 ms on localhost (executor driver) (98/100)
2018-02-08 15:54:16,001 INFO[org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 50.0 (TID 253)
2018-02-08 15:54:16,009 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:16,010 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:16,048 INFO[org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 50.0 (TID 253). 2932 bytes result sent to driver
2018-02-08 15:54:16,052 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 50.0 (TID 253) in 54 ms on localhost (executor driver) (99/100)
2018-02-08 15:54:16,086 INFO[org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 50.0 (TID 252). 2975 bytes result sent to driver
2018-02-08 15:54:16,086 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 50.0 (TID 252) in 121 ms on localhost (executor driver) (100/100)
2018-02-08 15:54:16,087 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2018-02-08 15:54:16,087 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 50 (show at MachineLeaningFiltering.java:42) finished in 3.013 s
2018-02-08 15:54:16,087 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:16,087 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:16,087 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 51)
2018-02-08 15:54:16,087 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:16,088 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 51 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42), which has no missing parents
2018-02-08 15:54:16,104 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21 stored as values in memory (estimated size 64.2 KB, free 631.1 MB)
2018-02-08 15:54:16,109 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 26.6 KB, free 631.1 MB)
2018-02-08 15:54:16,110 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_21_piece0 in memory on 192.168.11.26:62777 (size: 26.6 KB, free: 631.7 MB)
2018-02-08 15:54:16,110 INFO[org.apache.spark.SparkContext:54] - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:16,111 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:54:16,111 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 51.0 with 1 tasks
2018-02-08 15:54:16,112 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 51.0 (TID 254, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,113 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 51.0 (TID 254)
2018-02-08 15:54:16,118 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,119 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,128 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 51.0 (TID 254). 2762 bytes result sent to driver
2018-02-08 15:54:16,128 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 51.0 (TID 254) in 17 ms on localhost (executor driver) (1/1)
2018-02-08 15:54:16,128 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2018-02-08 15:54:16,129 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 51 (show at MachineLeaningFiltering.java:42) finished in 0.018 s
2018-02-08 15:54:16,129 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: show at MachineLeaningFiltering.java:42, took 3.125803 s
2018-02-08 15:54:16,136 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:42
2018-02-08 15:54:16,137 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:54:16,138 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 2 is 154 bytes
2018-02-08 15:54:16,138 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 157 bytes
2018-02-08 15:54:16,139 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 13 is 197 bytes
2018-02-08 15:54:16,139 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 12 is 169 bytes
2018-02-08 15:54:16,139 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 11 is 245 bytes
2018-02-08 15:54:16,140 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 10 is 169 bytes
2018-02-08 15:54:16,140 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 9 is 244 bytes
2018-02-08 15:54:16,141 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 8 is 169 bytes
2018-02-08 15:54:16,141 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 7 is 244 bytes
2018-02-08 15:54:16,141 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 6 is 169 bytes
2018-02-08 15:54:16,142 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 5 is 244 bytes
2018-02-08 15:54:16,142 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 4 is 169 bytes
2018-02-08 15:54:16,142 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 3 is 244 bytes
2018-02-08 15:54:16,143 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 14 is 435 bytes
2018-02-08 15:54:16,144 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (show at MachineLeaningFiltering.java:42) with 4 output partitions
2018-02-08 15:54:16,144 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 67 (show at MachineLeaningFiltering.java:42)
2018-02-08 15:54:16,144 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 66)
2018-02-08 15:54:16,144 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:54:16,144 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 67 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42), which has no missing parents
2018-02-08 15:54:16,147 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22 stored as values in memory (estimated size 64.2 KB, free 631.0 MB)
2018-02-08 15:54:16,149 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 26.6 KB, free 631.0 MB)
2018-02-08 15:54:16,149 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_22_piece0 in memory on 192.168.11.26:62777 (size: 26.6 KB, free: 631.6 MB)
2018-02-08 15:54:16,150 INFO[org.apache.spark.SparkContext:54] - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:16,150 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 4 missing tasks from ResultStage 67 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2018-02-08 15:54:16,150 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 67.0 with 4 tasks
2018-02-08 15:54:16,150 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 67.0 (TID 255, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,151 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 67.0 (TID 256, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,151 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 67.0 (TID 256)
2018-02-08 15:54:16,151 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 67.0 (TID 255)
2018-02-08 15:54:16,155 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,155 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,155 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,155 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,156 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 67.0 (TID 256). 2805 bytes result sent to driver
2018-02-08 15:54:16,156 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 67.0 (TID 255). 2805 bytes result sent to driver
2018-02-08 15:54:16,156 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 67.0 (TID 257, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,156 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 67.0 (TID 258, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,156 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 67.0 (TID 257)
2018-02-08 15:54:16,157 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 67.0 (TID 255) in 6 ms on localhost (executor driver) (1/4)
2018-02-08 15:54:16,157 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 67.0 (TID 256) in 6 ms on localhost (executor driver) (2/4)
2018-02-08 15:54:16,157 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 67.0 (TID 258)
2018-02-08 15:54:16,161 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,161 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,162 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,162 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,162 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 67.0 (TID 258). 2762 bytes result sent to driver
2018-02-08 15:54:16,162 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 67.0 (TID 257). 2762 bytes result sent to driver
2018-02-08 15:54:16,162 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 67.0 (TID 258) in 6 ms on localhost (executor driver) (3/4)
2018-02-08 15:54:16,163 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 67.0 (TID 257) in 7 ms on localhost (executor driver) (4/4)
2018-02-08 15:54:16,163 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2018-02-08 15:54:16,163 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 67 (show at MachineLeaningFiltering.java:42) finished in 0.013 s
2018-02-08 15:54:16,163 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: show at MachineLeaningFiltering.java:42, took 0.026801 s
2018-02-08 15:54:16,165 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:42
2018-02-08 15:54:16,168 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (show at MachineLeaningFiltering.java:42) with 20 output partitions
2018-02-08 15:54:16,168 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 83 (show at MachineLeaningFiltering.java:42)
2018-02-08 15:54:16,168 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 82)
2018-02-08 15:54:16,168 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:54:16,169 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 83 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42), which has no missing parents
2018-02-08 15:54:16,172 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23 stored as values in memory (estimated size 64.2 KB, free 630.9 MB)
2018-02-08 15:54:16,175 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 26.6 KB, free 630.9 MB)
2018-02-08 15:54:16,175 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_23_piece0 in memory on 192.168.11.26:62777 (size: 26.6 KB, free: 631.6 MB)
2018-02-08 15:54:16,176 INFO[org.apache.spark.SparkContext:54] - Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:16,176 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 20 missing tasks from ResultStage 83 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19))
2018-02-08 15:54:16,177 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 83.0 with 20 tasks
2018-02-08 15:54:16,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 83.0 (TID 259, localhost, executor driver, partition 5, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 83.0 (TID 260, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,177 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 83.0 (TID 259)
2018-02-08 15:54:16,177 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 83.0 (TID 260)
2018-02-08 15:54:16,181 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,181 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,181 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,181 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,181 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 83.0 (TID 259). 2719 bytes result sent to driver
2018-02-08 15:54:16,181 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 83.0 (TID 260). 2719 bytes result sent to driver
2018-02-08 15:54:16,182 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 83.0 (TID 261, localhost, executor driver, partition 7, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,182 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 83.0 (TID 259) in 5 ms on localhost (executor driver) (1/20)
2018-02-08 15:54:16,182 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 83.0 (TID 261)
2018-02-08 15:54:16,182 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 83.0 (TID 262, localhost, executor driver, partition 8, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,182 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 83.0 (TID 262)
2018-02-08 15:54:16,182 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 83.0 (TID 260) in 5 ms on localhost (executor driver) (2/20)
2018-02-08 15:54:16,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,186 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,186 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 83.0 (TID 262). 2805 bytes result sent to driver
2018-02-08 15:54:16,186 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 83.0 (TID 261). 2762 bytes result sent to driver
2018-02-08 15:54:16,187 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 83.0 (TID 263, localhost, executor driver, partition 9, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,187 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 83.0 (TID 263)
2018-02-08 15:54:16,187 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 83.0 (TID 262) in 5 ms on localhost (executor driver) (3/20)
2018-02-08 15:54:16,187 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 83.0 (TID 264, localhost, executor driver, partition 10, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,187 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 83.0 (TID 261) in 5 ms on localhost (executor driver) (4/20)
2018-02-08 15:54:16,187 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 83.0 (TID 264)
2018-02-08 15:54:16,190 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,190 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,190 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,190 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,191 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 83.0 (TID 263). 2762 bytes result sent to driver
2018-02-08 15:54:16,191 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 83.0 (TID 264). 2762 bytes result sent to driver
2018-02-08 15:54:16,191 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 83.0 (TID 265, localhost, executor driver, partition 11, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,191 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 83.0 (TID 263) in 5 ms on localhost (executor driver) (5/20)
2018-02-08 15:54:16,191 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 83.0 (TID 265)
2018-02-08 15:54:16,191 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 83.0 (TID 264) in 4 ms on localhost (executor driver) (6/20)
2018-02-08 15:54:16,192 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 83.0 (TID 266, localhost, executor driver, partition 12, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,192 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 83.0 (TID 266)
2018-02-08 15:54:16,196 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,196 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,196 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 83.0 (TID 266). 2762 bytes result sent to driver
2018-02-08 15:54:16,196 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,196 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,196 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 83.0 (TID 267, localhost, executor driver, partition 13, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,197 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 83.0 (TID 265). 2762 bytes result sent to driver
2018-02-08 15:54:16,197 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 83.0 (TID 267)
2018-02-08 15:54:16,197 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 83.0 (TID 266) in 5 ms on localhost (executor driver) (7/20)
2018-02-08 15:54:16,197 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 83.0 (TID 268, localhost, executor driver, partition 15, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,198 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 83.0 (TID 265) in 7 ms on localhost (executor driver) (8/20)
2018-02-08 15:54:16,198 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 83.0 (TID 268)
2018-02-08 15:54:16,200 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,201 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,201 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 83.0 (TID 267). 2762 bytes result sent to driver
2018-02-08 15:54:16,201 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 83.0 (TID 269, localhost, executor driver, partition 16, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,201 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 83.0 (TID 267) in 5 ms on localhost (executor driver) (9/20)
2018-02-08 15:54:16,201 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 83.0 (TID 269)
2018-02-08 15:54:16,202 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,202 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,202 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 83.0 (TID 268). 2762 bytes result sent to driver
2018-02-08 15:54:16,202 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 83.0 (TID 270, localhost, executor driver, partition 17, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,202 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 83.0 (TID 268) in 5 ms on localhost (executor driver) (10/20)
2018-02-08 15:54:16,202 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 83.0 (TID 270)
2018-02-08 15:54:16,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,206 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 83.0 (TID 270). 2719 bytes result sent to driver
2018-02-08 15:54:16,206 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 83.0 (TID 269). 2762 bytes result sent to driver
2018-02-08 15:54:16,206 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 83.0 (TID 271, localhost, executor driver, partition 18, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,207 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 83.0 (TID 272, localhost, executor driver, partition 20, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,207 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 83.0 (TID 271)
2018-02-08 15:54:16,207 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 83.0 (TID 269) in 6 ms on localhost (executor driver) (11/20)
2018-02-08 15:54:16,207 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 83.0 (TID 270) in 5 ms on localhost (executor driver) (12/20)
2018-02-08 15:54:16,207 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 83.0 (TID 272)
2018-02-08 15:54:16,211 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,211 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,211 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,211 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,211 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 83.0 (TID 272). 2762 bytes result sent to driver
2018-02-08 15:54:16,211 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 83.0 (TID 271). 2719 bytes result sent to driver
2018-02-08 15:54:16,212 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 83.0 (TID 273, localhost, executor driver, partition 21, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,212 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 83.0 (TID 273)
2018-02-08 15:54:16,212 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 83.0 (TID 274, localhost, executor driver, partition 22, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 83.0 (TID 272) in 6 ms on localhost (executor driver) (13/20)
2018-02-08 15:54:16,213 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 83.0 (TID 274)
2018-02-08 15:54:16,215 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 83.0 (TID 271) in 9 ms on localhost (executor driver) (14/20)
2018-02-08 15:54:16,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,218 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,218 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,218 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 83.0 (TID 273). 2805 bytes result sent to driver
2018-02-08 15:54:16,218 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 83.0 (TID 274). 2762 bytes result sent to driver
2018-02-08 15:54:16,219 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 83.0 (TID 275, localhost, executor driver, partition 23, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,219 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 83.0 (TID 275)
2018-02-08 15:54:16,219 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 83.0 (TID 276, localhost, executor driver, partition 14, ANY, 4726 bytes)
2018-02-08 15:54:16,220 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 83.0 (TID 274) in 7 ms on localhost (executor driver) (15/20)
2018-02-08 15:54:16,220 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 83.0 (TID 276)
2018-02-08 15:54:16,223 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 83.0 (TID 273) in 11 ms on localhost (executor driver) (16/20)
2018-02-08 15:54:16,224 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,224 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,225 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,225 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,225 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 83.0 (TID 275). 2762 bytes result sent to driver
2018-02-08 15:54:16,225 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 83.0 (TID 277, localhost, executor driver, partition 19, ANY, 4726 bytes)
2018-02-08 15:54:16,226 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 83.0 (TID 275) in 7 ms on localhost (executor driver) (17/20)
2018-02-08 15:54:16,226 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 83.0 (TID 277)
2018-02-08 15:54:16,230 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 20 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,230 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,248 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.834884 ms
2018-02-08 15:54:16,257 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 5.774722 ms
2018-02-08 15:54:16,269 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.036163 ms
2018-02-08 15:54:16,315 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.881285 ms
2018-02-08 15:54:16,318 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 83.0 (TID 276). 2991 bytes result sent to driver
2018-02-08 15:54:16,318 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 83.0 (TID 277). 3118 bytes result sent to driver
2018-02-08 15:54:16,318 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 83.0 (TID 278, localhost, executor driver, partition 24, ANY, 4726 bytes)
2018-02-08 15:54:16,319 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 83.0 (TID 276) in 99 ms on localhost (executor driver) (18/20)
2018-02-08 15:54:16,319 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 83.0 (TID 278)
2018-02-08 15:54:16,319 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 83.0 (TID 277) in 94 ms on localhost (executor driver) (19/20)
2018-02-08 15:54:16,323 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,323 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,335 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 83.0 (TID 278). 2991 bytes result sent to driver
2018-02-08 15:54:16,335 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 83.0 (TID 278) in 17 ms on localhost (executor driver) (20/20)
2018-02-08 15:54:16,335 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 83.0, whose tasks have all completed, from pool 
2018-02-08 15:54:16,336 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 83 (show at MachineLeaningFiltering.java:42) finished in 0.159 s
2018-02-08 15:54:16,336 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: show at MachineLeaningFiltering.java:42, took 0.171040 s
2018-02-08 15:54:16,340 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:42
2018-02-08 15:54:16,343 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (show at MachineLeaningFiltering.java:42) with 100 output partitions
2018-02-08 15:54:16,344 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 99 (show at MachineLeaningFiltering.java:42)
2018-02-08 15:54:16,344 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 98)
2018-02-08 15:54:16,344 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:54:16,344 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 99 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42), which has no missing parents
2018-02-08 15:54:16,349 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24 stored as values in memory (estimated size 64.2 KB, free 630.8 MB)
2018-02-08 15:54:16,351 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 26.6 KB, free 630.8 MB)
2018-02-08 15:54:16,351 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_24_piece0 in memory on 192.168.11.26:62777 (size: 26.6 KB, free: 631.6 MB)
2018-02-08 15:54:16,351 INFO[org.apache.spark.SparkContext:54] - Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:16,352 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 100 missing tasks from ResultStage 99 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42) (first 15 tasks are for partitions Vector(25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39))
2018-02-08 15:54:16,352 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 99.0 with 100 tasks
2018-02-08 15:54:16,353 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 99.0 (TID 279, localhost, executor driver, partition 25, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,354 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 99.0 (TID 280, localhost, executor driver, partition 26, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,354 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 99.0 (TID 279)
2018-02-08 15:54:16,354 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 99.0 (TID 280)
2018-02-08 15:54:16,357 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,357 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,357 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,357 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,358 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 99.0 (TID 280). 2805 bytes result sent to driver
2018-02-08 15:54:16,358 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 99.0 (TID 279). 2805 bytes result sent to driver
2018-02-08 15:54:16,358 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 99.0 (TID 281, localhost, executor driver, partition 27, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,358 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 99.0 (TID 281)
2018-02-08 15:54:16,358 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 99.0 (TID 280) in 4 ms on localhost (executor driver) (1/100)
2018-02-08 15:54:16,358 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 99.0 (TID 282, localhost, executor driver, partition 28, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,359 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 99.0 (TID 279) in 6 ms on localhost (executor driver) (2/100)
2018-02-08 15:54:16,359 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 99.0 (TID 282)
2018-02-08 15:54:16,363 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,363 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,363 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,363 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,363 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 99.0 (TID 282). 2762 bytes result sent to driver
2018-02-08 15:54:16,363 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 99.0 (TID 281). 2762 bytes result sent to driver
2018-02-08 15:54:16,364 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 99.0 (TID 283, localhost, executor driver, partition 29, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,364 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 99.0 (TID 282) in 6 ms on localhost (executor driver) (3/100)
2018-02-08 15:54:16,364 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 99.0 (TID 283)
2018-02-08 15:54:16,364 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 99.0 (TID 284, localhost, executor driver, partition 31, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,364 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 99.0 (TID 284)
2018-02-08 15:54:16,364 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 99.0 (TID 281) in 6 ms on localhost (executor driver) (4/100)
2018-02-08 15:54:16,367 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,367 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,367 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,367 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,368 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 99.0 (TID 283). 2762 bytes result sent to driver
2018-02-08 15:54:16,368 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 99.0 (TID 284). 2762 bytes result sent to driver
2018-02-08 15:54:16,368 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 99.0 (TID 285, localhost, executor driver, partition 32, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,368 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 99.0 (TID 283) in 4 ms on localhost (executor driver) (5/100)
2018-02-08 15:54:16,368 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 99.0 (TID 285)
2018-02-08 15:54:16,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 99.0 (TID 284) in 5 ms on localhost (executor driver) (6/100)
2018-02-08 15:54:16,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 99.0 (TID 286, localhost, executor driver, partition 33, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,369 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 99.0 (TID 286)
2018-02-08 15:54:16,372 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,372 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,372 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,372 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,372 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 99.0 (TID 286). 2762 bytes result sent to driver
2018-02-08 15:54:16,372 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 99.0 (TID 285). 2762 bytes result sent to driver
2018-02-08 15:54:16,373 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 99.0 (TID 287, localhost, executor driver, partition 34, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,373 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 99.0 (TID 286) in 4 ms on localhost (executor driver) (7/100)
2018-02-08 15:54:16,373 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 99.0 (TID 287)
2018-02-08 15:54:16,373 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 99.0 (TID 285) in 5 ms on localhost (executor driver) (8/100)
2018-02-08 15:54:16,373 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 99.0 (TID 288, localhost, executor driver, partition 35, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,373 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 99.0 (TID 288)
2018-02-08 15:54:16,377 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,377 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,377 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,377 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,378 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 99.0 (TID 287). 2762 bytes result sent to driver
2018-02-08 15:54:16,378 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 99.0 (TID 288). 2762 bytes result sent to driver
2018-02-08 15:54:16,378 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 99.0 (TID 289, localhost, executor driver, partition 36, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,378 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 99.0 (TID 289)
2018-02-08 15:54:16,378 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 99.0 (TID 290, localhost, executor driver, partition 37, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,378 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 99.0 (TID 288) in 5 ms on localhost (executor driver) (9/100)
2018-02-08 15:54:16,378 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 99.0 (TID 290)
2018-02-08 15:54:16,378 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 99.0 (TID 287) in 5 ms on localhost (executor driver) (10/100)
2018-02-08 15:54:16,381 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,381 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,381 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,381 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,382 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 99.0 (TID 289). 2762 bytes result sent to driver
2018-02-08 15:54:16,382 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 99.0 (TID 290). 2762 bytes result sent to driver
2018-02-08 15:54:16,382 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 99.0 (TID 291, localhost, executor driver, partition 38, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,382 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 99.0 (TID 289) in 4 ms on localhost (executor driver) (11/100)
2018-02-08 15:54:16,382 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 99.0 (TID 291)
2018-02-08 15:54:16,382 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 99.0 (TID 292, localhost, executor driver, partition 39, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,383 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 99.0 (TID 290) in 5 ms on localhost (executor driver) (12/100)
2018-02-08 15:54:16,383 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 99.0 (TID 292)
2018-02-08 15:54:16,385 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,385 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,386 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,386 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,386 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 99.0 (TID 292). 2762 bytes result sent to driver
2018-02-08 15:54:16,386 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 99.0 (TID 291). 2762 bytes result sent to driver
2018-02-08 15:54:16,386 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 99.0 (TID 293, localhost, executor driver, partition 40, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,387 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 99.0 (TID 292) in 5 ms on localhost (executor driver) (13/100)
2018-02-08 15:54:16,387 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 99.0 (TID 293)
2018-02-08 15:54:16,387 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 99.0 (TID 294, localhost, executor driver, partition 41, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,387 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 99.0 (TID 291) in 5 ms on localhost (executor driver) (14/100)
2018-02-08 15:54:16,387 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 99.0 (TID 294)
2018-02-08 15:54:16,391 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,391 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,391 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,391 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,392 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 99.0 (TID 294). 2762 bytes result sent to driver
2018-02-08 15:54:16,392 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 99.0 (TID 293). 2762 bytes result sent to driver
2018-02-08 15:54:16,392 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 99.0 (TID 295, localhost, executor driver, partition 42, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,392 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 99.0 (TID 294) in 5 ms on localhost (executor driver) (15/100)
2018-02-08 15:54:16,392 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 99.0 (TID 295)
2018-02-08 15:54:16,392 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 99.0 (TID 296, localhost, executor driver, partition 44, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,392 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 99.0 (TID 296)
2018-02-08 15:54:16,392 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 99.0 (TID 293) in 6 ms on localhost (executor driver) (16/100)
2018-02-08 15:54:16,395 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,395 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,396 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,396 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,396 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 99.0 (TID 296). 2762 bytes result sent to driver
2018-02-08 15:54:16,397 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 99.0 (TID 295). 2762 bytes result sent to driver
2018-02-08 15:54:16,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 99.0 (TID 297, localhost, executor driver, partition 45, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 99.0 (TID 298, localhost, executor driver, partition 46, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,397 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 99.0 (TID 297)
2018-02-08 15:54:16,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 99.0 (TID 295) in 5 ms on localhost (executor driver) (17/100)
2018-02-08 15:54:16,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 99.0 (TID 296) in 5 ms on localhost (executor driver) (18/100)
2018-02-08 15:54:16,398 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 99.0 (TID 298)
2018-02-08 15:54:16,401 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,401 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,403 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 99.0 (TID 297). 2762 bytes result sent to driver
2018-02-08 15:54:16,403 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,403 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,403 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 99.0 (TID 299, localhost, executor driver, partition 47, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,404 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 99.0 (TID 298). 2762 bytes result sent to driver
2018-02-08 15:54:16,404 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 99.0 (TID 297) in 7 ms on localhost (executor driver) (19/100)
2018-02-08 15:54:16,404 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 99.0 (TID 299)
2018-02-08 15:54:16,404 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 99.0 (TID 300, localhost, executor driver, partition 50, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,404 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 99.0 (TID 298) in 7 ms on localhost (executor driver) (20/100)
2018-02-08 15:54:16,404 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 99.0 (TID 300)
2018-02-08 15:54:16,408 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,408 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,408 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,408 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,409 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 99.0 (TID 299). 2805 bytes result sent to driver
2018-02-08 15:54:16,409 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 99.0 (TID 300). 2805 bytes result sent to driver
2018-02-08 15:54:16,409 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 99.0 (TID 301, localhost, executor driver, partition 52, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,409 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 99.0 (TID 301)
2018-02-08 15:54:16,409 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 99.0 (TID 302, localhost, executor driver, partition 54, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,410 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 99.0 (TID 299) in 7 ms on localhost (executor driver) (21/100)
2018-02-08 15:54:16,410 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 99.0 (TID 300) in 6 ms on localhost (executor driver) (22/100)
2018-02-08 15:54:16,410 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 99.0 (TID 302)
2018-02-08 15:54:16,413 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,413 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,413 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 99.0 (TID 301). 2762 bytes result sent to driver
2018-02-08 15:54:16,414 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,414 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,414 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 99.0 (TID 303, localhost, executor driver, partition 55, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,414 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 99.0 (TID 302). 2719 bytes result sent to driver
2018-02-08 15:54:16,415 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 99.0 (TID 303)
2018-02-08 15:54:16,415 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 99.0 (TID 301) in 6 ms on localhost (executor driver) (23/100)
2018-02-08 15:54:16,415 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 99.0 (TID 304, localhost, executor driver, partition 56, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,415 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 99.0 (TID 302) in 6 ms on localhost (executor driver) (24/100)
2018-02-08 15:54:16,416 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 99.0 (TID 304)
2018-02-08 15:54:16,419 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,419 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,419 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,420 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,420 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 99.0 (TID 304). 2762 bytes result sent to driver
2018-02-08 15:54:16,420 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 99.0 (TID 305, localhost, executor driver, partition 57, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,420 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 99.0 (TID 304) in 5 ms on localhost (executor driver) (25/100)
2018-02-08 15:54:16,421 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 99.0 (TID 305)
2018-02-08 15:54:16,422 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 99.0 (TID 303). 2762 bytes result sent to driver
2018-02-08 15:54:16,422 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 99.0 (TID 306, localhost, executor driver, partition 58, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,423 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 99.0 (TID 303) in 9 ms on localhost (executor driver) (26/100)
2018-02-08 15:54:16,424 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 99.0 (TID 306)
2018-02-08 15:54:16,427 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,427 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,428 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 99.0 (TID 305). 2805 bytes result sent to driver
2018-02-08 15:54:16,428 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 99.0 (TID 307, localhost, executor driver, partition 59, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,430 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,430 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,431 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 99.0 (TID 306). 2762 bytes result sent to driver
2018-02-08 15:54:16,431 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 99.0 (TID 307)
2018-02-08 15:54:16,431 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 99.0 (TID 305) in 11 ms on localhost (executor driver) (27/100)
2018-02-08 15:54:16,433 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 99.0 (TID 308, localhost, executor driver, partition 60, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,434 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 99.0 (TID 306) in 12 ms on localhost (executor driver) (28/100)
2018-02-08 15:54:16,434 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 99.0 (TID 308)
2018-02-08 15:54:16,436 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,436 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,436 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 99.0 (TID 307). 2762 bytes result sent to driver
2018-02-08 15:54:16,436 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 99.0 (TID 309, localhost, executor driver, partition 61, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,437 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 99.0 (TID 307) in 9 ms on localhost (executor driver) (29/100)
2018-02-08 15:54:16,437 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 99.0 (TID 309)
2018-02-08 15:54:16,437 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,438 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,438 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 99.0 (TID 308). 2805 bytes result sent to driver
2018-02-08 15:54:16,438 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 99.0 (TID 310, localhost, executor driver, partition 62, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,439 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 99.0 (TID 308) in 5 ms on localhost (executor driver) (30/100)
2018-02-08 15:54:16,440 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 99.0 (TID 310)
2018-02-08 15:54:16,441 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,441 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,442 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 99.0 (TID 309). 2762 bytes result sent to driver
2018-02-08 15:54:16,443 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 99.0 (TID 311, localhost, executor driver, partition 63, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,443 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 99.0 (TID 309) in 7 ms on localhost (executor driver) (31/100)
2018-02-08 15:54:16,443 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 99.0 (TID 311)
2018-02-08 15:54:16,444 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,444 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,444 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 99.0 (TID 310). 2719 bytes result sent to driver
2018-02-08 15:54:16,445 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 99.0 (TID 312, localhost, executor driver, partition 64, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,445 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 99.0 (TID 310) in 7 ms on localhost (executor driver) (32/100)
2018-02-08 15:54:16,445 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 99.0 (TID 312)
2018-02-08 15:54:16,446 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,446 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,446 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 99.0 (TID 311). 2719 bytes result sent to driver
2018-02-08 15:54:16,447 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 99.0 (TID 313, localhost, executor driver, partition 65, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,447 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 99.0 (TID 311) in 5 ms on localhost (executor driver) (33/100)
2018-02-08 15:54:16,447 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 99.0 (TID 313)
2018-02-08 15:54:16,448 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,448 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,448 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 99.0 (TID 312). 2719 bytes result sent to driver
2018-02-08 15:54:16,449 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 99.0 (TID 314, localhost, executor driver, partition 67, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,449 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 99.0 (TID 312) in 4 ms on localhost (executor driver) (34/100)
2018-02-08 15:54:16,449 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 99.0 (TID 314)
2018-02-08 15:54:16,451 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,451 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,452 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 99.0 (TID 313). 2805 bytes result sent to driver
2018-02-08 15:54:16,452 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 99.0 (TID 315, localhost, executor driver, partition 68, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,452 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 99.0 (TID 313) in 5 ms on localhost (executor driver) (35/100)
2018-02-08 15:54:16,453 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 99.0 (TID 315)
2018-02-08 15:54:16,454 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,454 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,456 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 99.0 (TID 314). 2762 bytes result sent to driver
2018-02-08 15:54:16,456 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 99.0 (TID 316, localhost, executor driver, partition 70, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,457 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 99.0 (TID 314) in 8 ms on localhost (executor driver) (36/100)
2018-02-08 15:54:16,457 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,458 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,458 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 99.0 (TID 316)
2018-02-08 15:54:16,459 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 99.0 (TID 315). 2762 bytes result sent to driver
2018-02-08 15:54:16,460 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 99.0 (TID 317, localhost, executor driver, partition 71, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,460 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 99.0 (TID 317)
2018-02-08 15:54:16,460 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 99.0 (TID 315) in 8 ms on localhost (executor driver) (37/100)
2018-02-08 15:54:16,463 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,463 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,463 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,463 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,463 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 99.0 (TID 316). 2762 bytes result sent to driver
2018-02-08 15:54:16,463 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 99.0 (TID 317). 2719 bytes result sent to driver
2018-02-08 15:54:16,464 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 99.0 (TID 318, localhost, executor driver, partition 72, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,464 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 99.0 (TID 319, localhost, executor driver, partition 73, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,464 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 99.0 (TID 318)
2018-02-08 15:54:16,464 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 99.0 (TID 317) in 5 ms on localhost (executor driver) (38/100)
2018-02-08 15:54:16,464 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 99.0 (TID 316) in 8 ms on localhost (executor driver) (39/100)
2018-02-08 15:54:16,465 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 99.0 (TID 319)
2018-02-08 15:54:16,471 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,471 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,472 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,472 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,472 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 99.0 (TID 318). 2762 bytes result sent to driver
2018-02-08 15:54:16,472 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 99.0 (TID 319). 2762 bytes result sent to driver
2018-02-08 15:54:16,472 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 99.0 (TID 320, localhost, executor driver, partition 74, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,473 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 99.0 (TID 320)
2018-02-08 15:54:16,473 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 99.0 (TID 321, localhost, executor driver, partition 75, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,473 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 99.0 (TID 318) in 9 ms on localhost (executor driver) (40/100)
2018-02-08 15:54:16,473 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 99.0 (TID 319) in 9 ms on localhost (executor driver) (41/100)
2018-02-08 15:54:16,473 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 99.0 (TID 321)
2018-02-08 15:54:16,477 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,477 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,477 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,477 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,478 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 99.0 (TID 320). 2762 bytes result sent to driver
2018-02-08 15:54:16,478 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 99.0 (TID 321). 2762 bytes result sent to driver
2018-02-08 15:54:16,478 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 99.0 (TID 322, localhost, executor driver, partition 76, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,478 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 99.0 (TID 322)
2018-02-08 15:54:16,478 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 99.0 (TID 323, localhost, executor driver, partition 78, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,479 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 99.0 (TID 320) in 7 ms on localhost (executor driver) (42/100)
2018-02-08 15:54:16,479 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 99.0 (TID 323)
2018-02-08 15:54:16,479 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 99.0 (TID 321) in 6 ms on localhost (executor driver) (43/100)
2018-02-08 15:54:16,483 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,483 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,483 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,484 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,484 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 99.0 (TID 322). 2805 bytes result sent to driver
2018-02-08 15:54:16,484 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 99.0 (TID 323). 2762 bytes result sent to driver
2018-02-08 15:54:16,485 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 99.0 (TID 324, localhost, executor driver, partition 79, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,485 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 99.0 (TID 324)
2018-02-08 15:54:16,485 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 99.0 (TID 325, localhost, executor driver, partition 80, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,485 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 99.0 (TID 323) in 7 ms on localhost (executor driver) (44/100)
2018-02-08 15:54:16,485 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 99.0 (TID 325)
2018-02-08 15:54:16,485 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 99.0 (TID 322) in 7 ms on localhost (executor driver) (45/100)
2018-02-08 15:54:16,488 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,488 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,488 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,488 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,489 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 99.0 (TID 324). 2762 bytes result sent to driver
2018-02-08 15:54:16,489 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 99.0 (TID 325). 2762 bytes result sent to driver
2018-02-08 15:54:16,489 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 99.0 (TID 326, localhost, executor driver, partition 81, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,490 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 99.0 (TID 326)
2018-02-08 15:54:16,490 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 99.0 (TID 327, localhost, executor driver, partition 82, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,490 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 99.0 (TID 325) in 5 ms on localhost (executor driver) (46/100)
2018-02-08 15:54:16,490 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 99.0 (TID 327)
2018-02-08 15:54:16,491 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 99.0 (TID 324) in 6 ms on localhost (executor driver) (47/100)
2018-02-08 15:54:16,493 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,493 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,494 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,494 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,494 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 99.0 (TID 327). 2762 bytes result sent to driver
2018-02-08 15:54:16,494 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 99.0 (TID 326). 2762 bytes result sent to driver
2018-02-08 15:54:16,494 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 99.0 (TID 328, localhost, executor driver, partition 83, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,495 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 99.0 (TID 328)
2018-02-08 15:54:16,495 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 99.0 (TID 329, localhost, executor driver, partition 84, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,495 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 99.0 (TID 329)
2018-02-08 15:54:16,495 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 99.0 (TID 327) in 5 ms on localhost (executor driver) (48/100)
2018-02-08 15:54:16,495 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 99.0 (TID 326) in 6 ms on localhost (executor driver) (49/100)
2018-02-08 15:54:16,497 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,497 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,498 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,498 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,498 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 99.0 (TID 329). 2762 bytes result sent to driver
2018-02-08 15:54:16,498 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 99.0 (TID 328). 2762 bytes result sent to driver
2018-02-08 15:54:16,499 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 99.0 (TID 330, localhost, executor driver, partition 85, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,500 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 99.0 (TID 330)
2018-02-08 15:54:16,500 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 99.0 (TID 331, localhost, executor driver, partition 86, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,501 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 99.0 (TID 328) in 7 ms on localhost (executor driver) (50/100)
2018-02-08 15:54:16,501 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 99.0 (TID 329) in 6 ms on localhost (executor driver) (51/100)
2018-02-08 15:54:16,501 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 99.0 (TID 331)
2018-02-08 15:54:16,504 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,504 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,504 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,505 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,505 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 99.0 (TID 330). 2762 bytes result sent to driver
2018-02-08 15:54:16,505 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 99.0 (TID 331). 2762 bytes result sent to driver
2018-02-08 15:54:16,505 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 99.0 (TID 332, localhost, executor driver, partition 87, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,505 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 99.0 (TID 332)
2018-02-08 15:54:16,505 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 99.0 (TID 333, localhost, executor driver, partition 88, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,506 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 99.0 (TID 330) in 7 ms on localhost (executor driver) (52/100)
2018-02-08 15:54:16,506 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 99.0 (TID 333)
2018-02-08 15:54:16,506 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 99.0 (TID 331) in 6 ms on localhost (executor driver) (53/100)
2018-02-08 15:54:16,508 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,508 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,509 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,509 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,509 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 99.0 (TID 333). 2762 bytes result sent to driver
2018-02-08 15:54:16,509 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 99.0 (TID 332). 2762 bytes result sent to driver
2018-02-08 15:54:16,509 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 99.0 (TID 334, localhost, executor driver, partition 90, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,509 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 99.0 (TID 333) in 4 ms on localhost (executor driver) (54/100)
2018-02-08 15:54:16,509 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 99.0 (TID 334)
2018-02-08 15:54:16,510 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 99.0 (TID 335, localhost, executor driver, partition 91, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,510 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 99.0 (TID 335)
2018-02-08 15:54:16,510 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 99.0 (TID 332) in 5 ms on localhost (executor driver) (55/100)
2018-02-08 15:54:16,513 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,514 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,515 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:54:16,515 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,516 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 99.0 (TID 334). 2805 bytes result sent to driver
2018-02-08 15:54:16,516 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 99.0 (TID 335). 2762 bytes result sent to driver
2018-02-08 15:54:16,517 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 99.0 (TID 336, localhost, executor driver, partition 92, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,517 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 99.0 (TID 336)
2018-02-08 15:54:16,517 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 99.0 (TID 337, localhost, executor driver, partition 93, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,517 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 99.0 (TID 334) in 8 ms on localhost (executor driver) (56/100)
2018-02-08 15:54:16,517 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 99.0 (TID 337)
2018-02-08 15:54:16,517 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 99.0 (TID 335) in 7 ms on localhost (executor driver) (57/100)
2018-02-08 15:54:16,520 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,520 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,520 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,520 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,521 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 99.0 (TID 337). 2719 bytes result sent to driver
2018-02-08 15:54:16,521 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 99.0 (TID 336). 2719 bytes result sent to driver
2018-02-08 15:54:16,521 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 99.0 (TID 338, localhost, executor driver, partition 94, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,521 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 99.0 (TID 338)
2018-02-08 15:54:16,521 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 99.0 (TID 339, localhost, executor driver, partition 95, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,521 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 99.0 (TID 336) in 5 ms on localhost (executor driver) (58/100)
2018-02-08 15:54:16,521 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 99.0 (TID 339)
2018-02-08 15:54:16,521 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 99.0 (TID 337) in 4 ms on localhost (executor driver) (59/100)
2018-02-08 15:54:16,525 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,525 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,525 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,525 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,526 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 99.0 (TID 339). 2762 bytes result sent to driver
2018-02-08 15:54:16,526 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 99.0 (TID 338). 2762 bytes result sent to driver
2018-02-08 15:54:16,526 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 99.0 (TID 340, localhost, executor driver, partition 96, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,526 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 99.0 (TID 340)
2018-02-08 15:54:16,526 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 99.0 (TID 341, localhost, executor driver, partition 97, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,526 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 99.0 (TID 338) in 5 ms on localhost (executor driver) (60/100)
2018-02-08 15:54:16,526 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 99.0 (TID 341)
2018-02-08 15:54:16,526 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 99.0 (TID 339) in 5 ms on localhost (executor driver) (61/100)
2018-02-08 15:54:16,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,531 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 99.0 (TID 341). 2762 bytes result sent to driver
2018-02-08 15:54:16,532 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 99.0 (TID 340). 2805 bytes result sent to driver
2018-02-08 15:54:16,532 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 99.0 (TID 342, localhost, executor driver, partition 98, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,532 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 99.0 (TID 342)
2018-02-08 15:54:16,532 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 99.0 (TID 343, localhost, executor driver, partition 99, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,532 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 99.0 (TID 340) in 6 ms on localhost (executor driver) (62/100)
2018-02-08 15:54:16,533 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 99.0 (TID 341) in 7 ms on localhost (executor driver) (63/100)
2018-02-08 15:54:16,533 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 99.0 (TID 343)
2018-02-08 15:54:16,536 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,536 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,537 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 99.0 (TID 342). 2762 bytes result sent to driver
2018-02-08 15:54:16,537 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 99.0 (TID 344, localhost, executor driver, partition 100, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,537 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,537 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 99.0 (TID 342) in 5 ms on localhost (executor driver) (64/100)
2018-02-08 15:54:16,537 INFO[org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 99.0 (TID 344)
2018-02-08 15:54:16,537 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,538 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 99.0 (TID 343). 2762 bytes result sent to driver
2018-02-08 15:54:16,538 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 99.0 (TID 345, localhost, executor driver, partition 101, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,538 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 99.0 (TID 343) in 6 ms on localhost (executor driver) (65/100)
2018-02-08 15:54:16,538 INFO[org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 99.0 (TID 345)
2018-02-08 15:54:16,541 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,541 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,541 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,541 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,541 INFO[org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 99.0 (TID 344). 2762 bytes result sent to driver
2018-02-08 15:54:16,541 INFO[org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 99.0 (TID 345). 2719 bytes result sent to driver
2018-02-08 15:54:16,541 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 99.0 (TID 346, localhost, executor driver, partition 104, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,542 INFO[org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 99.0 (TID 346)
2018-02-08 15:54:16,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 99.0 (TID 347, localhost, executor driver, partition 106, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 99.0 (TID 345) in 4 ms on localhost (executor driver) (66/100)
2018-02-08 15:54:16,542 INFO[org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 99.0 (TID 347)
2018-02-08 15:54:16,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 99.0 (TID 344) in 5 ms on localhost (executor driver) (67/100)
2018-02-08 15:54:16,545 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,545 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,545 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,545 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,545 INFO[org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 99.0 (TID 346). 2762 bytes result sent to driver
2018-02-08 15:54:16,545 INFO[org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 99.0 (TID 347). 2762 bytes result sent to driver
2018-02-08 15:54:16,545 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 99.0 (TID 348, localhost, executor driver, partition 108, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,547 INFO[org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 99.0 (TID 348)
2018-02-08 15:54:16,547 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 99.0 (TID 349, localhost, executor driver, partition 109, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,548 INFO[org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 99.0 (TID 349)
2018-02-08 15:54:16,548 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 99.0 (TID 346) in 7 ms on localhost (executor driver) (68/100)
2018-02-08 15:54:16,548 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 99.0 (TID 347) in 6 ms on localhost (executor driver) (69/100)
2018-02-08 15:54:16,551 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,551 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,551 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,551 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,551 INFO[org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 99.0 (TID 349). 2762 bytes result sent to driver
2018-02-08 15:54:16,551 INFO[org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 99.0 (TID 348). 2762 bytes result sent to driver
2018-02-08 15:54:16,552 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 99.0 (TID 350, localhost, executor driver, partition 110, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,552 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 99.0 (TID 349) in 6 ms on localhost (executor driver) (70/100)
2018-02-08 15:54:16,552 INFO[org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 99.0 (TID 350)
2018-02-08 15:54:16,552 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 99.0 (TID 351, localhost, executor driver, partition 111, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,552 INFO[org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 99.0 (TID 351)
2018-02-08 15:54:16,552 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 99.0 (TID 348) in 7 ms on localhost (executor driver) (71/100)
2018-02-08 15:54:16,555 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,555 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,555 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,555 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,555 INFO[org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 99.0 (TID 350). 2762 bytes result sent to driver
2018-02-08 15:54:16,555 INFO[org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 99.0 (TID 351). 2762 bytes result sent to driver
2018-02-08 15:54:16,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 99.0 (TID 352, localhost, executor driver, partition 112, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,556 INFO[org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 99.0 (TID 352)
2018-02-08 15:54:16,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 99.0 (TID 353, localhost, executor driver, partition 113, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,556 INFO[org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 99.0 (TID 353)
2018-02-08 15:54:16,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 99.0 (TID 351) in 4 ms on localhost (executor driver) (72/100)
2018-02-08 15:54:16,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 99.0 (TID 350) in 5 ms on localhost (executor driver) (73/100)
2018-02-08 15:54:16,559 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,559 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,559 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,559 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,559 INFO[org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 99.0 (TID 352). 2719 bytes result sent to driver
2018-02-08 15:54:16,559 INFO[org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 99.0 (TID 353). 2719 bytes result sent to driver
2018-02-08 15:54:16,560 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 99.0 (TID 354, localhost, executor driver, partition 114, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,560 INFO[org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 99.0 (TID 354)
2018-02-08 15:54:16,560 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 99.0 (TID 355, localhost, executor driver, partition 115, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,560 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 99.0 (TID 352) in 4 ms on localhost (executor driver) (74/100)
2018-02-08 15:54:16,560 INFO[org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 99.0 (TID 355)
2018-02-08 15:54:16,560 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 99.0 (TID 353) in 4 ms on localhost (executor driver) (75/100)
2018-02-08 15:54:16,563 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,563 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,564 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,564 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,564 INFO[org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 99.0 (TID 354). 2805 bytes result sent to driver
2018-02-08 15:54:16,564 INFO[org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 99.0 (TID 355). 2805 bytes result sent to driver
2018-02-08 15:54:16,564 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 99.0 (TID 356, localhost, executor driver, partition 116, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,565 INFO[org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 99.0 (TID 356)
2018-02-08 15:54:16,565 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 99.0 (TID 357, localhost, executor driver, partition 117, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,565 INFO[org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 99.0 (TID 357)
2018-02-08 15:54:16,565 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 99.0 (TID 355) in 5 ms on localhost (executor driver) (76/100)
2018-02-08 15:54:16,565 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 99.0 (TID 354) in 5 ms on localhost (executor driver) (77/100)
2018-02-08 15:54:16,568 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,568 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,568 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,568 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,568 INFO[org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 99.0 (TID 357). 2762 bytes result sent to driver
2018-02-08 15:54:16,568 INFO[org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 99.0 (TID 356). 2762 bytes result sent to driver
2018-02-08 15:54:16,569 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 99.0 (TID 358, localhost, executor driver, partition 118, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,569 INFO[org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 99.0 (TID 358)
2018-02-08 15:54:16,569 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 99.0 (TID 359, localhost, executor driver, partition 119, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,569 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 99.0 (TID 357) in 4 ms on localhost (executor driver) (78/100)
2018-02-08 15:54:16,569 INFO[org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 99.0 (TID 359)
2018-02-08 15:54:16,570 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 99.0 (TID 356) in 6 ms on localhost (executor driver) (79/100)
2018-02-08 15:54:16,572 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,572 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,572 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,572 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,573 INFO[org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 99.0 (TID 358). 2762 bytes result sent to driver
2018-02-08 15:54:16,573 INFO[org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 99.0 (TID 359). 2762 bytes result sent to driver
2018-02-08 15:54:16,573 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 99.0 (TID 360, localhost, executor driver, partition 120, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,573 INFO[org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 99.0 (TID 360)
2018-02-08 15:54:16,573 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 99.0 (TID 361, localhost, executor driver, partition 121, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,574 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 99.0 (TID 358) in 6 ms on localhost (executor driver) (80/100)
2018-02-08 15:54:16,574 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 99.0 (TID 359) in 5 ms on localhost (executor driver) (81/100)
2018-02-08 15:54:16,574 INFO[org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 99.0 (TID 361)
2018-02-08 15:54:16,577 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,577 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,577 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,577 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,578 INFO[org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 99.0 (TID 361). 2805 bytes result sent to driver
2018-02-08 15:54:16,578 INFO[org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 99.0 (TID 360). 2805 bytes result sent to driver
2018-02-08 15:54:16,578 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 99.0 (TID 362, localhost, executor driver, partition 123, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,578 INFO[org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 99.0 (TID 362)
2018-02-08 15:54:16,578 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 99.0 (TID 363, localhost, executor driver, partition 124, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:16,579 INFO[org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 99.0 (TID 363)
2018-02-08 15:54:16,579 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 99.0 (TID 361) in 6 ms on localhost (executor driver) (82/100)
2018-02-08 15:54:16,579 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 99.0 (TID 360) in 6 ms on localhost (executor driver) (83/100)
2018-02-08 15:54:16,582 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,582 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,582 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,582 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,583 INFO[org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 99.0 (TID 363). 2762 bytes result sent to driver
2018-02-08 15:54:16,583 INFO[org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 99.0 (TID 362). 2762 bytes result sent to driver
2018-02-08 15:54:16,583 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 99.0 (TID 364, localhost, executor driver, partition 30, ANY, 4726 bytes)
2018-02-08 15:54:16,583 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 99.0 (TID 364)
2018-02-08 15:54:16,583 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 99.0 (TID 365, localhost, executor driver, partition 43, ANY, 4726 bytes)
2018-02-08 15:54:16,583 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 99.0 (TID 363) in 5 ms on localhost (executor driver) (84/100)
2018-02-08 15:54:16,583 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 99.0 (TID 365)
2018-02-08 15:54:16,584 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 99.0 (TID 362) in 6 ms on localhost (executor driver) (85/100)
2018-02-08 15:54:16,586 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,586 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,587 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,587 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,598 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 99.0 (TID 365). 2990 bytes result sent to driver
2018-02-08 15:54:16,599 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 99.0 (TID 366, localhost, executor driver, partition 48, ANY, 4726 bytes)
2018-02-08 15:54:16,601 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 99.0 (TID 365) in 18 ms on localhost (executor driver) (86/100)
2018-02-08 15:54:16,602 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 99.0 (TID 364). 2989 bytes result sent to driver
2018-02-08 15:54:16,603 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 99.0 (TID 367, localhost, executor driver, partition 49, ANY, 4726 bytes)
2018-02-08 15:54:16,603 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 99.0 (TID 367)
2018-02-08 15:54:16,603 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 99.0 (TID 364) in 20 ms on localhost (executor driver) (87/100)
2018-02-08 15:54:16,604 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 99.0 (TID 366)
2018-02-08 15:54:16,607 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,607 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,612 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,612 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,620 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 99.0 (TID 367). 3104 bytes result sent to driver
2018-02-08 15:54:16,620 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 99.0 (TID 368, localhost, executor driver, partition 51, ANY, 4726 bytes)
2018-02-08 15:54:16,620 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 99.0 (TID 367) in 17 ms on localhost (executor driver) (88/100)
2018-02-08 15:54:16,620 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 99.0 (TID 368)
2018-02-08 15:54:16,624 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,624 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,651 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 99.0 (TID 368). 2993 bytes result sent to driver
2018-02-08 15:54:16,651 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 99.0 (TID 369, localhost, executor driver, partition 53, ANY, 4726 bytes)
2018-02-08 15:54:16,653 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 99.0 (TID 368) in 33 ms on localhost (executor driver) (89/100)
2018-02-08 15:54:16,654 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 99.0 (TID 369)
2018-02-08 15:54:16,663 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 99.0 (TID 366). 2990 bytes result sent to driver
2018-02-08 15:54:16,664 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 99.0 (TID 370, localhost, executor driver, partition 66, ANY, 4726 bytes)
2018-02-08 15:54:16,664 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 99.0 (TID 366) in 65 ms on localhost (executor driver) (90/100)
2018-02-08 15:54:16,664 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 99.0 (TID 370)
2018-02-08 15:54:16,664 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,665 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,676 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,676 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,715 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 99.0 (TID 369). 3034 bytes result sent to driver
2018-02-08 15:54:16,718 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 99.0 (TID 371, localhost, executor driver, partition 69, ANY, 4726 bytes)
2018-02-08 15:54:16,719 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 99.0 (TID 369) in 68 ms on localhost (executor driver) (91/100)
2018-02-08 15:54:16,720 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 99.0 (TID 371)
2018-02-08 15:54:16,725 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 99.0 (TID 370). 3076 bytes result sent to driver
2018-02-08 15:54:16,726 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 99.0 (TID 372, localhost, executor driver, partition 77, ANY, 4726 bytes)
2018-02-08 15:54:16,726 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_21_piece0 on 192.168.11.26:62777 in memory (size: 26.6 KB, free: 631.6 MB)
2018-02-08 15:54:16,727 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 99.0 (TID 370) in 63 ms on localhost (executor driver) (92/100)
2018-02-08 15:54:16,727 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 99.0 (TID 372)
2018-02-08 15:54:16,728 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,728 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,734 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,734 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,741 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_22_piece0 on 192.168.11.26:62777 in memory (size: 26.6 KB, free: 631.6 MB)
2018-02-08 15:54:16,746 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_20_piece0 on 192.168.11.26:62777 in memory (size: 34.4 KB, free: 631.7 MB)
2018-02-08 15:54:16,750 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 99.0 (TID 371). 3007 bytes result sent to driver
2018-02-08 15:54:16,752 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 99.0 (TID 373, localhost, executor driver, partition 89, ANY, 4726 bytes)
2018-02-08 15:54:16,753 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 99.0 (TID 371) in 36 ms on localhost (executor driver) (93/100)
2018-02-08 15:54:16,753 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 99.0 (TID 373)
2018-02-08 15:54:16,760 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_23_piece0 on 192.168.11.26:62777 in memory (size: 26.6 KB, free: 631.7 MB)
2018-02-08 15:54:16,760 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 99.0 (TID 372). 2960 bytes result sent to driver
2018-02-08 15:54:16,760 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 99.0 (TID 374, localhost, executor driver, partition 102, ANY, 4726 bytes)
2018-02-08 15:54:16,761 INFO[org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 99.0 (TID 374)
2018-02-08 15:54:16,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 99.0 (TID 372) in 34 ms on localhost (executor driver) (94/100)
2018-02-08 15:54:16,763 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 20 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,763 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,764 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,764 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,777 INFO[org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 99.0 (TID 374). 2997 bytes result sent to driver
2018-02-08 15:54:16,777 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 99.0 (TID 375, localhost, executor driver, partition 103, ANY, 4726 bytes)
2018-02-08 15:54:16,778 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 99.0 (TID 374) in 18 ms on localhost (executor driver) (95/100)
2018-02-08 15:54:16,778 INFO[org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 99.0 (TID 375)
2018-02-08 15:54:16,779 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 99.0 (TID 373). 3103 bytes result sent to driver
2018-02-08 15:54:16,779 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 99.0 (TID 376, localhost, executor driver, partition 105, ANY, 4726 bytes)
2018-02-08 15:54:16,780 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 99.0 (TID 373) in 28 ms on localhost (executor driver) (96/100)
2018-02-08 15:54:16,780 INFO[org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 99.0 (TID 376)
2018-02-08 15:54:16,783 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,784 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,785 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,786 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,796 INFO[org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 99.0 (TID 376). 3032 bytes result sent to driver
2018-02-08 15:54:16,796 INFO[org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 99.0 (TID 375). 3036 bytes result sent to driver
2018-02-08 15:54:16,796 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 99.0 (TID 377, localhost, executor driver, partition 107, ANY, 4726 bytes)
2018-02-08 15:54:16,797 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 99.0 (TID 378, localhost, executor driver, partition 122, ANY, 4726 bytes)
2018-02-08 15:54:16,797 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 99.0 (TID 376) in 18 ms on localhost (executor driver) (97/100)
2018-02-08 15:54:16,797 INFO[org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 99.0 (TID 378)
2018-02-08 15:54:16,797 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 99.0 (TID 375) in 20 ms on localhost (executor driver) (98/100)
2018-02-08 15:54:16,797 INFO[org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 99.0 (TID 377)
2018-02-08 15:54:16,801 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,802 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:16,804 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:16,804 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:16,816 INFO[org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 99.0 (TID 378). 2986 bytes result sent to driver
2018-02-08 15:54:16,816 INFO[org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 99.0 (TID 377). 2948 bytes result sent to driver
2018-02-08 15:54:16,816 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 99.0 (TID 377) in 20 ms on localhost (executor driver) (99/100)
2018-02-08 15:54:16,817 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 99.0 (TID 378) in 21 ms on localhost (executor driver) (100/100)
2018-02-08 15:54:16,817 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 99.0, whose tasks have all completed, from pool 
2018-02-08 15:54:16,817 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 99 (show at MachineLeaningFiltering.java:42) finished in 0.464 s
2018-02-08 15:54:16,817 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: show at MachineLeaningFiltering.java:42, took 0.476956 s
2018-02-08 15:54:16,831 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.091524 ms
2018-02-08 15:54:17,272 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 24.433288 ms
2018-02-08 15:54:17,303 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 17.011206 ms
2018-02-08 15:54:17,322 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:46
2018-02-08 15:54:17,325 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 161 (show at MachineLeaningFiltering.java:46)
2018-02-08 15:54:17,325 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (show at MachineLeaningFiltering.java:46) with 1 output partitions
2018-02-08 15:54:17,325 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 115 (show at MachineLeaningFiltering.java:46)
2018-02-08 15:54:17,325 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 114)
2018-02-08 15:54:17,325 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 114)
2018-02-08 15:54:17,326 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 114 (MapPartitionsRDD[161] at show at MachineLeaningFiltering.java:46), which has no missing parents
2018-02-08 15:54:17,342 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25 stored as values in memory (estimated size 95.9 KB, free 631.1 MB)
2018-02-08 15:54:17,345 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 34.7 KB, free 631.1 MB)
2018-02-08 15:54:17,345 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_25_piece0 in memory on 192.168.11.26:62777 (size: 34.7 KB, free: 631.7 MB)
2018-02-08 15:54:17,346 INFO[org.apache.spark.SparkContext:54] - Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:17,347 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 100 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[161] at show at MachineLeaningFiltering.java:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-02-08 15:54:17,347 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 114.0 with 100 tasks
2018-02-08 15:54:17,348 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 114.0 (TID 379, localhost, executor driver, partition 0, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,348 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 114.0 (TID 380, localhost, executor driver, partition 1, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,349 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 114.0 (TID 379)
2018-02-08 15:54:17,349 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 114.0 (TID 380)
2018-02-08 15:54:17,354 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:17,357 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:17,358 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:17,359 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:17,376 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.220485 ms
2018-02-08 15:54:17,431 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 114.0 (TID 380). 2975 bytes result sent to driver
2018-02-08 15:54:17,433 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 114.0 (TID 381, localhost, executor driver, partition 2, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,433 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 114.0 (TID 381)
2018-02-08 15:54:17,433 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 114.0 (TID 380) in 85 ms on localhost (executor driver) (1/100)
2018-02-08 15:54:17,437 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:17,438 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:17,440 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 114.0 (TID 379). 2932 bytes result sent to driver
2018-02-08 15:54:17,441 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 114.0 (TID 382, localhost, executor driver, partition 3, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,441 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 114.0 (TID 382)
2018-02-08 15:54:17,441 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 114.0 (TID 379) in 93 ms on localhost (executor driver) (2/100)
2018-02-08 15:54:17,447 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:17,447 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:17,493 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 114.0 (TID 381). 2975 bytes result sent to driver
2018-02-08 15:54:17,496 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 114.0 (TID 383, localhost, executor driver, partition 4, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,497 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 114.0 (TID 381) in 66 ms on localhost (executor driver) (3/100)
2018-02-08 15:54:17,497 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 114.0 (TID 383)
2018-02-08 15:54:17,516 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:17,518 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:17,592 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 114.0 (TID 382). 2932 bytes result sent to driver
2018-02-08 15:54:17,593 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 114.0 (TID 384, localhost, executor driver, partition 5, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,594 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 114.0 (TID 382) in 153 ms on localhost (executor driver) (4/100)
2018-02-08 15:54:17,595 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 114.0 (TID 384)
2018-02-08 15:54:17,599 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:17,600 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:17,629 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 114.0 (TID 383). 2975 bytes result sent to driver
2018-02-08 15:54:17,630 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 114.0 (TID 385, localhost, executor driver, partition 6, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,630 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 114.0 (TID 383) in 135 ms on localhost (executor driver) (5/100)
2018-02-08 15:54:17,630 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 114.0 (TID 385)
2018-02-08 15:54:17,635 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:17,635 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:17,662 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 114.0 (TID 384). 2932 bytes result sent to driver
2018-02-08 15:54:17,663 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 114.0 (TID 386, localhost, executor driver, partition 7, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,663 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 114.0 (TID 386)
2018-02-08 15:54:17,663 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 114.0 (TID 384) in 70 ms on localhost (executor driver) (6/100)
2018-02-08 15:54:17,668 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:17,669 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:17,688 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 114.0 (TID 385). 2932 bytes result sent to driver
2018-02-08 15:54:17,689 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 114.0 (TID 387, localhost, executor driver, partition 8, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,690 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 114.0 (TID 387)
2018-02-08 15:54:17,690 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 114.0 (TID 385) in 60 ms on localhost (executor driver) (7/100)
2018-02-08 15:54:17,694 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:17,695 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:17,723 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 114.0 (TID 386). 2932 bytes result sent to driver
2018-02-08 15:54:17,728 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 114.0 (TID 388, localhost, executor driver, partition 9, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,735 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 114.0 (TID 386) in 73 ms on localhost (executor driver) (8/100)
2018-02-08 15:54:17,766 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 114.0 (TID 388)
2018-02-08 15:54:17,767 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 114.0 (TID 387). 2932 bytes result sent to driver
2018-02-08 15:54:17,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 114.0 (TID 389, localhost, executor driver, partition 10, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 114.0 (TID 387) in 79 ms on localhost (executor driver) (9/100)
2018-02-08 15:54:17,767 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 114.0 (TID 389)
2018-02-08 15:54:17,773 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:17,774 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:17,776 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:17,776 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:54:17,836 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 114.0 (TID 389). 2932 bytes result sent to driver
2018-02-08 15:54:17,837 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 114.0 (TID 390, localhost, executor driver, partition 11, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,837 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 114.0 (TID 390)
2018-02-08 15:54:17,837 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 114.0 (TID 389) in 70 ms on localhost (executor driver) (10/100)
2018-02-08 15:54:17,841 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:17,842 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:17,889 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 114.0 (TID 388). 2932 bytes result sent to driver
2018-02-08 15:54:17,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 114.0 (TID 391, localhost, executor driver, partition 12, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,890 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 114.0 (TID 388) in 162 ms on localhost (executor driver) (11/100)
2018-02-08 15:54:17,890 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 114.0 (TID 391)
2018-02-08 15:54:17,895 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:17,895 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:17,895 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 114.0 (TID 390). 2932 bytes result sent to driver
2018-02-08 15:54:17,896 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 114.0 (TID 392, localhost, executor driver, partition 13, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,897 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 114.0 (TID 390) in 61 ms on localhost (executor driver) (12/100)
2018-02-08 15:54:17,897 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 114.0 (TID 392)
2018-02-08 15:54:17,902 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:17,903 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:17,973 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 114.0 (TID 392). 2932 bytes result sent to driver
2018-02-08 15:54:17,974 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 114.0 (TID 393, localhost, executor driver, partition 14, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:17,974 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 114.0 (TID 392) in 78 ms on localhost (executor driver) (13/100)
2018-02-08 15:54:17,975 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 114.0 (TID 393)
2018-02-08 15:54:17,980 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:17,982 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:18,017 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 114.0 (TID 391). 2932 bytes result sent to driver
2018-02-08 15:54:18,019 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 114.0 (TID 394, localhost, executor driver, partition 15, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,021 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 114.0 (TID 391) in 132 ms on localhost (executor driver) (14/100)
2018-02-08 15:54:18,021 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 114.0 (TID 394)
2018-02-08 15:54:18,032 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:18,034 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:18,062 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 114.0 (TID 393). 2932 bytes result sent to driver
2018-02-08 15:54:18,063 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 114.0 (TID 395, localhost, executor driver, partition 16, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,064 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 114.0 (TID 395)
2018-02-08 15:54:18,064 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 114.0 (TID 393) in 90 ms on localhost (executor driver) (15/100)
2018-02-08 15:54:18,070 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:18,071 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:18,146 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 114.0 (TID 395). 2932 bytes result sent to driver
2018-02-08 15:54:18,146 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 114.0 (TID 396, localhost, executor driver, partition 17, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,147 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 114.0 (TID 395) in 84 ms on localhost (executor driver) (16/100)
2018-02-08 15:54:18,147 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 114.0 (TID 396)
2018-02-08 15:54:18,154 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:18,155 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:18,208 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 114.0 (TID 394). 2932 bytes result sent to driver
2018-02-08 15:54:18,208 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 114.0 (TID 397, localhost, executor driver, partition 18, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,209 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 114.0 (TID 394) in 191 ms on localhost (executor driver) (17/100)
2018-02-08 15:54:18,209 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 114.0 (TID 397)
2018-02-08 15:54:18,216 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:18,219 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:18,244 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 114.0 (TID 396). 2932 bytes result sent to driver
2018-02-08 15:54:18,244 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 114.0 (TID 398, localhost, executor driver, partition 19, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,245 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 114.0 (TID 396) in 98 ms on localhost (executor driver) (18/100)
2018-02-08 15:54:18,245 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 114.0 (TID 398)
2018-02-08 15:54:18,249 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:18,250 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:54:18,303 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 114.0 (TID 397). 2932 bytes result sent to driver
2018-02-08 15:54:18,304 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 114.0 (TID 399, localhost, executor driver, partition 20, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,304 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 114.0 (TID 397) in 96 ms on localhost (executor driver) (19/100)
2018-02-08 15:54:18,304 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 114.0 (TID 399)
2018-02-08 15:54:18,310 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:18,310 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:18,350 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 114.0 (TID 398). 2975 bytes result sent to driver
2018-02-08 15:54:18,351 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 114.0 (TID 400, localhost, executor driver, partition 21, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,352 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 114.0 (TID 398) in 108 ms on localhost (executor driver) (20/100)
2018-02-08 15:54:18,353 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 114.0 (TID 400)
2018-02-08 15:54:18,353 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 114.0 (TID 399). 2932 bytes result sent to driver
2018-02-08 15:54:18,354 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 114.0 (TID 401, localhost, executor driver, partition 22, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,355 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 114.0 (TID 399) in 51 ms on localhost (executor driver) (21/100)
2018-02-08 15:54:18,355 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 114.0 (TID 401)
2018-02-08 15:54:18,359 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:18,360 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:18,364 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:18,367 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:18,431 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 114.0 (TID 400). 2975 bytes result sent to driver
2018-02-08 15:54:18,432 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 114.0 (TID 402, localhost, executor driver, partition 23, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,432 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 114.0 (TID 400) in 81 ms on localhost (executor driver) (22/100)
2018-02-08 15:54:18,432 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 114.0 (TID 402)
2018-02-08 15:54:18,439 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:18,441 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:18,445 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 114.0 (TID 401). 2975 bytes result sent to driver
2018-02-08 15:54:18,446 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 114.0 (TID 403, localhost, executor driver, partition 24, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,446 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 114.0 (TID 401) in 92 ms on localhost (executor driver) (23/100)
2018-02-08 15:54:18,446 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 114.0 (TID 403)
2018-02-08 15:54:18,453 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:18,454 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:18,492 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 114.0 (TID 402). 2975 bytes result sent to driver
2018-02-08 15:54:18,493 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 114.0 (TID 404, localhost, executor driver, partition 25, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,493 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 114.0 (TID 404)
2018-02-08 15:54:18,493 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 114.0 (TID 402) in 61 ms on localhost (executor driver) (24/100)
2018-02-08 15:54:18,498 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:18,499 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:18,514 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 114.0 (TID 403). 2975 bytes result sent to driver
2018-02-08 15:54:18,515 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 114.0 (TID 405, localhost, executor driver, partition 26, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,518 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 114.0 (TID 403) in 73 ms on localhost (executor driver) (25/100)
2018-02-08 15:54:18,518 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 114.0 (TID 405)
2018-02-08 15:54:18,522 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:18,523 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:18,547 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 114.0 (TID 404). 2932 bytes result sent to driver
2018-02-08 15:54:18,548 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 114.0 (TID 406, localhost, executor driver, partition 27, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,549 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 114.0 (TID 404) in 56 ms on localhost (executor driver) (26/100)
2018-02-08 15:54:18,549 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 114.0 (TID 406)
2018-02-08 15:54:18,554 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:18,555 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:18,585 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 114.0 (TID 405). 2932 bytes result sent to driver
2018-02-08 15:54:18,585 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 114.0 (TID 407, localhost, executor driver, partition 28, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,586 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 114.0 (TID 407)
2018-02-08 15:54:18,586 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 114.0 (TID 405) in 70 ms on localhost (executor driver) (27/100)
2018-02-08 15:54:18,590 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:18,591 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:18,633 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 114.0 (TID 406). 2932 bytes result sent to driver
2018-02-08 15:54:18,653 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 114.0 (TID 408, localhost, executor driver, partition 29, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,654 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 114.0 (TID 406) in 106 ms on localhost (executor driver) (28/100)
2018-02-08 15:54:18,654 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 114.0 (TID 408)
2018-02-08 15:54:18,660 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:18,662 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:54:18,691 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 114.0 (TID 407). 2932 bytes result sent to driver
2018-02-08 15:54:18,692 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 114.0 (TID 409, localhost, executor driver, partition 30, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,694 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 114.0 (TID 409)
2018-02-08 15:54:18,694 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 114.0 (TID 407) in 109 ms on localhost (executor driver) (29/100)
2018-02-08 15:54:18,698 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:18,699 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:18,721 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 114.0 (TID 408). 2975 bytes result sent to driver
2018-02-08 15:54:18,722 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 114.0 (TID 410, localhost, executor driver, partition 31, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,722 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 114.0 (TID 408) in 69 ms on localhost (executor driver) (30/100)
2018-02-08 15:54:18,722 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 114.0 (TID 410)
2018-02-08 15:54:18,726 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:18,727 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:18,761 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 114.0 (TID 409). 2932 bytes result sent to driver
2018-02-08 15:54:18,762 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 114.0 (TID 411, localhost, executor driver, partition 32, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,762 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 114.0 (TID 409) in 70 ms on localhost (executor driver) (31/100)
2018-02-08 15:54:18,762 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 114.0 (TID 411)
2018-02-08 15:54:18,766 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:18,767 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:18,790 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 114.0 (TID 410). 2932 bytes result sent to driver
2018-02-08 15:54:18,791 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 114.0 (TID 412, localhost, executor driver, partition 33, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,791 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 114.0 (TID 410) in 69 ms on localhost (executor driver) (32/100)
2018-02-08 15:54:18,791 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 114.0 (TID 412)
2018-02-08 15:54:18,798 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:18,800 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:18,826 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 114.0 (TID 411). 2975 bytes result sent to driver
2018-02-08 15:54:18,826 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 114.0 (TID 413, localhost, executor driver, partition 34, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,826 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 114.0 (TID 413)
2018-02-08 15:54:18,826 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 114.0 (TID 411) in 64 ms on localhost (executor driver) (33/100)
2018-02-08 15:54:18,831 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:18,832 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:18,888 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 114.0 (TID 412). 2975 bytes result sent to driver
2018-02-08 15:54:18,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 114.0 (TID 414, localhost, executor driver, partition 35, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 114.0 (TID 412) in 99 ms on localhost (executor driver) (34/100)
2018-02-08 15:54:18,890 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 114.0 (TID 414)
2018-02-08 15:54:18,896 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:18,896 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:18,908 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 114.0 (TID 413). 2975 bytes result sent to driver
2018-02-08 15:54:18,908 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 114.0 (TID 415, localhost, executor driver, partition 36, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,909 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 114.0 (TID 413) in 83 ms on localhost (executor driver) (35/100)
2018-02-08 15:54:18,909 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 114.0 (TID 415)
2018-02-08 15:54:18,913 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:18,914 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:18,961 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 114.0 (TID 415). 2932 bytes result sent to driver
2018-02-08 15:54:18,962 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 114.0 (TID 416, localhost, executor driver, partition 37, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,962 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 114.0 (TID 416)
2018-02-08 15:54:18,962 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 114.0 (TID 415) in 54 ms on localhost (executor driver) (36/100)
2018-02-08 15:54:18,966 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:18,967 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:18,969 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 114.0 (TID 414). 2932 bytes result sent to driver
2018-02-08 15:54:18,970 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 114.0 (TID 417, localhost, executor driver, partition 38, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:18,970 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 114.0 (TID 417)
2018-02-08 15:54:18,970 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 114.0 (TID 414) in 82 ms on localhost (executor driver) (37/100)
2018-02-08 15:54:18,975 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:18,976 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:19,023 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 114.0 (TID 416). 2932 bytes result sent to driver
2018-02-08 15:54:19,023 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 114.0 (TID 418, localhost, executor driver, partition 39, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,023 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 114.0 (TID 418)
2018-02-08 15:54:19,023 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 114.0 (TID 416) in 61 ms on localhost (executor driver) (38/100)
2018-02-08 15:54:19,027 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:19,031 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:54:19,110 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 114.0 (TID 418). 2932 bytes result sent to driver
2018-02-08 15:54:19,112 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 114.0 (TID 419, localhost, executor driver, partition 40, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,113 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 114.0 (TID 418) in 90 ms on localhost (executor driver) (39/100)
2018-02-08 15:54:19,113 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 114.0 (TID 419)
2018-02-08 15:54:19,118 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:19,118 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:19,128 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 114.0 (TID 417). 2932 bytes result sent to driver
2018-02-08 15:54:19,128 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 114.0 (TID 420, localhost, executor driver, partition 41, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,129 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 114.0 (TID 420)
2018-02-08 15:54:19,129 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 114.0 (TID 417) in 160 ms on localhost (executor driver) (40/100)
2018-02-08 15:54:19,133 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:19,134 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:19,167 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 114.0 (TID 419). 2932 bytes result sent to driver
2018-02-08 15:54:19,168 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 114.0 (TID 421, localhost, executor driver, partition 42, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,168 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 114.0 (TID 421)
2018-02-08 15:54:19,168 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 114.0 (TID 419) in 56 ms on localhost (executor driver) (41/100)
2018-02-08 15:54:19,173 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:19,173 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:19,180 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 114.0 (TID 420). 2932 bytes result sent to driver
2018-02-08 15:54:19,181 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 114.0 (TID 422, localhost, executor driver, partition 43, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,181 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 114.0 (TID 422)
2018-02-08 15:54:19,181 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 114.0 (TID 420) in 53 ms on localhost (executor driver) (42/100)
2018-02-08 15:54:19,184 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:19,185 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:19,215 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 114.0 (TID 421). 2975 bytes result sent to driver
2018-02-08 15:54:19,216 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 114.0 (TID 423, localhost, executor driver, partition 44, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,216 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 114.0 (TID 421) in 48 ms on localhost (executor driver) (43/100)
2018-02-08 15:54:19,216 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 114.0 (TID 423)
2018-02-08 15:54:19,220 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 114.0 (TID 422). 2932 bytes result sent to driver
2018-02-08 15:54:19,221 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 114.0 (TID 424, localhost, executor driver, partition 45, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,221 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 114.0 (TID 424)
2018-02-08 15:54:19,221 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 114.0 (TID 422) in 41 ms on localhost (executor driver) (44/100)
2018-02-08 15:54:19,221 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:19,221 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:19,225 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:19,225 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:19,268 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 114.0 (TID 423). 2975 bytes result sent to driver
2018-02-08 15:54:19,269 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 114.0 (TID 425, localhost, executor driver, partition 46, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,270 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 114.0 (TID 425)
2018-02-08 15:54:19,270 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 114.0 (TID 423) in 55 ms on localhost (executor driver) (45/100)
2018-02-08 15:54:19,275 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:19,276 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:19,277 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 114.0 (TID 424). 2932 bytes result sent to driver
2018-02-08 15:54:19,278 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 114.0 (TID 426, localhost, executor driver, partition 47, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,278 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 114.0 (TID 424) in 58 ms on localhost (executor driver) (46/100)
2018-02-08 15:54:19,278 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 114.0 (TID 426)
2018-02-08 15:54:19,282 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:19,282 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:19,331 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 114.0 (TID 425). 2932 bytes result sent to driver
2018-02-08 15:54:19,332 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 114.0 (TID 427, localhost, executor driver, partition 48, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,334 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 114.0 (TID 427)
2018-02-08 15:54:19,334 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 114.0 (TID 425) in 66 ms on localhost (executor driver) (47/100)
2018-02-08 15:54:19,339 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:19,340 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:19,342 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 114.0 (TID 426). 2975 bytes result sent to driver
2018-02-08 15:54:19,342 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 114.0 (TID 428, localhost, executor driver, partition 49, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,342 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 114.0 (TID 426) in 64 ms on localhost (executor driver) (48/100)
2018-02-08 15:54:19,342 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 114.0 (TID 428)
2018-02-08 15:54:19,347 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:19,348 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:54:19,381 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 114.0 (TID 427). 2932 bytes result sent to driver
2018-02-08 15:54:19,382 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 114.0 (TID 429, localhost, executor driver, partition 50, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,382 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 114.0 (TID 429)
2018-02-08 15:54:19,382 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 114.0 (TID 427) in 51 ms on localhost (executor driver) (49/100)
2018-02-08 15:54:19,386 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:19,387 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:19,389 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 114.0 (TID 428). 2932 bytes result sent to driver
2018-02-08 15:54:19,390 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 114.0 (TID 430, localhost, executor driver, partition 51, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,390 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 114.0 (TID 430)
2018-02-08 15:54:19,390 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 114.0 (TID 428) in 48 ms on localhost (executor driver) (50/100)
2018-02-08 15:54:19,394 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:19,394 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:19,426 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 114.0 (TID 429). 2932 bytes result sent to driver
2018-02-08 15:54:19,426 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 114.0 (TID 431, localhost, executor driver, partition 52, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,426 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 114.0 (TID 429) in 44 ms on localhost (executor driver) (51/100)
2018-02-08 15:54:19,426 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 114.0 (TID 431)
2018-02-08 15:54:19,430 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 114.0 (TID 430). 2932 bytes result sent to driver
2018-02-08 15:54:19,431 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 114.0 (TID 432, localhost, executor driver, partition 53, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,431 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:19,431 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 114.0 (TID 430) in 42 ms on localhost (executor driver) (52/100)
2018-02-08 15:54:19,431 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 114.0 (TID 432)
2018-02-08 15:54:19,432 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:19,435 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:19,435 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:19,471 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 114.0 (TID 431). 2932 bytes result sent to driver
2018-02-08 15:54:19,471 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 114.0 (TID 433, localhost, executor driver, partition 54, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,471 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 114.0 (TID 433)
2018-02-08 15:54:19,471 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 114.0 (TID 431) in 45 ms on localhost (executor driver) (53/100)
2018-02-08 15:54:19,475 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 114.0 (TID 432). 2932 bytes result sent to driver
2018-02-08 15:54:19,475 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 114.0 (TID 434, localhost, executor driver, partition 55, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,475 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:19,475 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 114.0 (TID 434)
2018-02-08 15:54:19,475 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 114.0 (TID 432) in 44 ms on localhost (executor driver) (54/100)
2018-02-08 15:54:19,476 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:19,481 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:19,481 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:19,532 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 114.0 (TID 433). 2932 bytes result sent to driver
2018-02-08 15:54:19,532 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 114.0 (TID 435, localhost, executor driver, partition 56, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,533 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 114.0 (TID 433) in 62 ms on localhost (executor driver) (55/100)
2018-02-08 15:54:19,533 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 114.0 (TID 435)
2018-02-08 15:54:19,538 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:19,539 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:19,550 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 114.0 (TID 434). 2932 bytes result sent to driver
2018-02-08 15:54:19,550 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 114.0 (TID 436, localhost, executor driver, partition 57, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,551 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 114.0 (TID 436)
2018-02-08 15:54:19,551 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 114.0 (TID 434) in 76 ms on localhost (executor driver) (56/100)
2018-02-08 15:54:19,556 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:19,557 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:19,592 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 114.0 (TID 435). 2975 bytes result sent to driver
2018-02-08 15:54:19,592 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 114.0 (TID 437, localhost, executor driver, partition 58, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,593 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 114.0 (TID 437)
2018-02-08 15:54:19,593 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 114.0 (TID 435) in 61 ms on localhost (executor driver) (57/100)
2018-02-08 15:54:19,598 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:19,598 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:19,603 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 114.0 (TID 436). 2932 bytes result sent to driver
2018-02-08 15:54:19,603 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 114.0 (TID 438, localhost, executor driver, partition 59, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,603 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 114.0 (TID 438)
2018-02-08 15:54:19,603 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 114.0 (TID 436) in 53 ms on localhost (executor driver) (58/100)
2018-02-08 15:54:19,608 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:19,609 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:54:19,637 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 114.0 (TID 437). 2932 bytes result sent to driver
2018-02-08 15:54:19,639 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 114.0 (TID 439, localhost, executor driver, partition 60, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,639 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 114.0 (TID 439)
2018-02-08 15:54:19,639 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 114.0 (TID 437) in 47 ms on localhost (executor driver) (59/100)
2018-02-08 15:54:19,644 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:19,645 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:19,650 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 114.0 (TID 438). 2932 bytes result sent to driver
2018-02-08 15:54:19,651 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 114.0 (TID 440, localhost, executor driver, partition 61, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,651 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 114.0 (TID 438) in 48 ms on localhost (executor driver) (60/100)
2018-02-08 15:54:19,651 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 114.0 (TID 440)
2018-02-08 15:54:19,656 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:19,658 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:19,698 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 114.0 (TID 439). 2975 bytes result sent to driver
2018-02-08 15:54:19,699 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 114.0 (TID 441, localhost, executor driver, partition 62, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,699 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 114.0 (TID 439) in 60 ms on localhost (executor driver) (61/100)
2018-02-08 15:54:19,699 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 114.0 (TID 441)
2018-02-08 15:54:19,705 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:19,706 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:19,724 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 114.0 (TID 440). 2975 bytes result sent to driver
2018-02-08 15:54:19,725 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 114.0 (TID 442, localhost, executor driver, partition 63, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,725 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 114.0 (TID 440) in 75 ms on localhost (executor driver) (62/100)
2018-02-08 15:54:19,726 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 114.0 (TID 442)
2018-02-08 15:54:19,731 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:19,732 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:19,758 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 114.0 (TID 441). 2975 bytes result sent to driver
2018-02-08 15:54:19,759 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 114.0 (TID 443, localhost, executor driver, partition 64, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,760 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 114.0 (TID 441) in 61 ms on localhost (executor driver) (63/100)
2018-02-08 15:54:19,761 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 114.0 (TID 443)
2018-02-08 15:54:19,768 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:19,769 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:19,780 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 114.0 (TID 442). 2932 bytes result sent to driver
2018-02-08 15:54:19,780 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 114.0 (TID 444, localhost, executor driver, partition 65, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,780 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 114.0 (TID 444)
2018-02-08 15:54:19,780 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 114.0 (TID 442) in 56 ms on localhost (executor driver) (64/100)
2018-02-08 15:54:19,787 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:19,788 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:19,811 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 114.0 (TID 443). 2975 bytes result sent to driver
2018-02-08 15:54:19,812 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 114.0 (TID 445, localhost, executor driver, partition 66, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,812 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 114.0 (TID 445)
2018-02-08 15:54:19,812 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 114.0 (TID 443) in 54 ms on localhost (executor driver) (65/100)
2018-02-08 15:54:19,818 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:19,818 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:19,826 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 114.0 (TID 444). 2975 bytes result sent to driver
2018-02-08 15:54:19,826 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 114.0 (TID 446, localhost, executor driver, partition 67, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,826 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 114.0 (TID 446)
2018-02-08 15:54:19,826 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 114.0 (TID 444) in 46 ms on localhost (executor driver) (66/100)
2018-02-08 15:54:19,831 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:19,831 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:19,848 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 501
2018-02-08 15:54:19,849 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 498
2018-02-08 15:54:19,849 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 622
2018-02-08 15:54:19,849 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 494
2018-02-08 15:54:19,851 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_24_piece0 on 192.168.11.26:62777 in memory (size: 26.6 KB, free: 631.7 MB)
2018-02-08 15:54:19,852 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 500
2018-02-08 15:54:19,853 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 496
2018-02-08 15:54:19,853 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 497
2018-02-08 15:54:19,859 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 14
2018-02-08 15:54:19,860 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 499
2018-02-08 15:54:19,860 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 492
2018-02-08 15:54:19,860 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 495
2018-02-08 15:54:19,860 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 493
2018-02-08 15:54:19,877 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 114.0 (TID 446). 3018 bytes result sent to driver
2018-02-08 15:54:19,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 114.0 (TID 447, localhost, executor driver, partition 68, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,878 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 114.0 (TID 447)
2018-02-08 15:54:19,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 114.0 (TID 446) in 52 ms on localhost (executor driver) (67/100)
2018-02-08 15:54:19,882 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:19,883 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:19,888 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 114.0 (TID 445). 2975 bytes result sent to driver
2018-02-08 15:54:19,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 114.0 (TID 448, localhost, executor driver, partition 69, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,889 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 114.0 (TID 448)
2018-02-08 15:54:19,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 114.0 (TID 445) in 78 ms on localhost (executor driver) (68/100)
2018-02-08 15:54:19,893 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:19,894 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:54:19,959 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 114.0 (TID 448). 2975 bytes result sent to driver
2018-02-08 15:54:19,961 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 114.0 (TID 449, localhost, executor driver, partition 70, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,961 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 114.0 (TID 448) in 73 ms on localhost (executor driver) (69/100)
2018-02-08 15:54:19,961 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 114.0 (TID 449)
2018-02-08 15:54:19,965 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:19,966 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:19,976 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 114.0 (TID 447). 2932 bytes result sent to driver
2018-02-08 15:54:19,977 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 114.0 (TID 450, localhost, executor driver, partition 71, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:19,977 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 114.0 (TID 450)
2018-02-08 15:54:19,977 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 114.0 (TID 447) in 100 ms on localhost (executor driver) (70/100)
2018-02-08 15:54:19,982 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:19,983 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:20,041 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 114.0 (TID 449). 2932 bytes result sent to driver
2018-02-08 15:54:20,042 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 114.0 (TID 451, localhost, executor driver, partition 72, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,042 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 114.0 (TID 451)
2018-02-08 15:54:20,042 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 114.0 (TID 449) in 82 ms on localhost (executor driver) (71/100)
2018-02-08 15:54:20,047 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:20,047 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:20,062 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 114.0 (TID 450). 2932 bytes result sent to driver
2018-02-08 15:54:20,062 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 114.0 (TID 452, localhost, executor driver, partition 73, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,062 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 114.0 (TID 450) in 86 ms on localhost (executor driver) (72/100)
2018-02-08 15:54:20,062 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 114.0 (TID 452)
2018-02-08 15:54:20,067 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:20,068 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:20,094 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 114.0 (TID 451). 2975 bytes result sent to driver
2018-02-08 15:54:20,095 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 114.0 (TID 453, localhost, executor driver, partition 74, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,095 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 114.0 (TID 451) in 53 ms on localhost (executor driver) (73/100)
2018-02-08 15:54:20,095 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 114.0 (TID 453)
2018-02-08 15:54:20,099 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:20,100 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:20,106 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 114.0 (TID 452). 2932 bytes result sent to driver
2018-02-08 15:54:20,106 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 114.0 (TID 454, localhost, executor driver, partition 75, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,107 INFO[org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 114.0 (TID 454)
2018-02-08 15:54:20,107 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 114.0 (TID 452) in 45 ms on localhost (executor driver) (74/100)
2018-02-08 15:54:20,111 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:20,112 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:20,140 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 114.0 (TID 453). 2932 bytes result sent to driver
2018-02-08 15:54:20,140 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 114.0 (TID 455, localhost, executor driver, partition 76, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,141 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 114.0 (TID 453) in 46 ms on localhost (executor driver) (75/100)
2018-02-08 15:54:20,141 INFO[org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 114.0 (TID 455)
2018-02-08 15:54:20,146 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:20,146 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:20,161 INFO[org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 114.0 (TID 454). 2975 bytes result sent to driver
2018-02-08 15:54:20,161 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 114.0 (TID 456, localhost, executor driver, partition 77, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,162 INFO[org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 114.0 (TID 456)
2018-02-08 15:54:20,162 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 114.0 (TID 454) in 56 ms on localhost (executor driver) (76/100)
2018-02-08 15:54:20,167 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:20,169 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:20,200 INFO[org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 114.0 (TID 455). 2932 bytes result sent to driver
2018-02-08 15:54:20,201 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 114.0 (TID 457, localhost, executor driver, partition 78, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,201 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 114.0 (TID 455) in 61 ms on localhost (executor driver) (77/100)
2018-02-08 15:54:20,201 INFO[org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 114.0 (TID 457)
2018-02-08 15:54:20,211 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:20,212 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:20,259 INFO[org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 114.0 (TID 456). 2932 bytes result sent to driver
2018-02-08 15:54:20,260 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 114.0 (TID 458, localhost, executor driver, partition 79, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,260 INFO[org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 114.0 (TID 458)
2018-02-08 15:54:20,260 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 114.0 (TID 456) in 99 ms on localhost (executor driver) (78/100)
2018-02-08 15:54:20,263 INFO[org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 114.0 (TID 457). 2975 bytes result sent to driver
2018-02-08 15:54:20,264 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 114.0 (TID 459, localhost, executor driver, partition 80, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,264 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 114.0 (TID 457) in 63 ms on localhost (executor driver) (79/100)
2018-02-08 15:54:20,264 INFO[org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 114.0 (TID 459)
2018-02-08 15:54:20,266 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:20,267 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:54:20,270 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:20,271 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:20,331 INFO[org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 114.0 (TID 459). 2975 bytes result sent to driver
2018-02-08 15:54:20,331 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 114.0 (TID 460, localhost, executor driver, partition 81, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,332 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 114.0 (TID 459) in 68 ms on localhost (executor driver) (80/100)
2018-02-08 15:54:20,332 INFO[org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 114.0 (TID 460)
2018-02-08 15:54:20,337 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:20,337 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:20,338 INFO[org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 114.0 (TID 458). 2975 bytes result sent to driver
2018-02-08 15:54:20,339 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 114.0 (TID 461, localhost, executor driver, partition 82, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,339 INFO[org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 114.0 (TID 461)
2018-02-08 15:54:20,339 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 114.0 (TID 458) in 80 ms on localhost (executor driver) (81/100)
2018-02-08 15:54:20,343 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:20,344 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:20,372 INFO[org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 114.0 (TID 460). 2932 bytes result sent to driver
2018-02-08 15:54:20,373 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 114.0 (TID 462, localhost, executor driver, partition 83, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,373 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 114.0 (TID 460) in 42 ms on localhost (executor driver) (82/100)
2018-02-08 15:54:20,373 INFO[org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 114.0 (TID 462)
2018-02-08 15:54:20,378 INFO[org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 114.0 (TID 461). 2975 bytes result sent to driver
2018-02-08 15:54:20,378 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 114.0 (TID 463, localhost, executor driver, partition 84, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,378 INFO[org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 114.0 (TID 463)
2018-02-08 15:54:20,378 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 114.0 (TID 461) in 39 ms on localhost (executor driver) (83/100)
2018-02-08 15:54:20,379 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:20,379 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:20,382 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:20,383 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:20,432 INFO[org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 114.0 (TID 462). 2975 bytes result sent to driver
2018-02-08 15:54:20,432 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 114.0 (TID 464, localhost, executor driver, partition 85, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,433 INFO[org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 114.0 (TID 464)
2018-02-08 15:54:20,433 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 114.0 (TID 462) in 61 ms on localhost (executor driver) (84/100)
2018-02-08 15:54:20,434 INFO[org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 114.0 (TID 463). 2932 bytes result sent to driver
2018-02-08 15:54:20,435 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 114.0 (TID 465, localhost, executor driver, partition 86, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,435 INFO[org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 114.0 (TID 465)
2018-02-08 15:54:20,435 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 114.0 (TID 463) in 57 ms on localhost (executor driver) (85/100)
2018-02-08 15:54:20,437 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:20,437 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:20,440 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:20,441 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:20,485 INFO[org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 114.0 (TID 465). 2932 bytes result sent to driver
2018-02-08 15:54:20,485 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 114.0 (TID 466, localhost, executor driver, partition 87, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,487 INFO[org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 114.0 (TID 466)
2018-02-08 15:54:20,487 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 114.0 (TID 465) in 52 ms on localhost (executor driver) (86/100)
2018-02-08 15:54:20,492 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:20,492 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:20,493 INFO[org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 114.0 (TID 464). 2975 bytes result sent to driver
2018-02-08 15:54:20,494 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 114.0 (TID 467, localhost, executor driver, partition 88, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,494 INFO[org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 114.0 (TID 467)
2018-02-08 15:54:20,494 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 114.0 (TID 464) in 62 ms on localhost (executor driver) (87/100)
2018-02-08 15:54:20,498 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:20,499 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:20,539 INFO[org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 114.0 (TID 466). 2975 bytes result sent to driver
2018-02-08 15:54:20,539 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 114.0 (TID 468, localhost, executor driver, partition 89, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,540 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 114.0 (TID 466) in 55 ms on localhost (executor driver) (88/100)
2018-02-08 15:54:20,540 INFO[org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 114.0 (TID 468)
2018-02-08 15:54:20,541 INFO[org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 114.0 (TID 467). 2932 bytes result sent to driver
2018-02-08 15:54:20,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 114.0 (TID 469, localhost, executor driver, partition 90, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,542 INFO[org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 114.0 (TID 469)
2018-02-08 15:54:20,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 114.0 (TID 467) in 48 ms on localhost (executor driver) (89/100)
2018-02-08 15:54:20,543 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:20,544 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:54:20,545 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:54:20,546 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:20,581 INFO[org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 114.0 (TID 468). 2932 bytes result sent to driver
2018-02-08 15:54:20,581 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 114.0 (TID 470, localhost, executor driver, partition 91, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,581 INFO[org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 114.0 (TID 470)
2018-02-08 15:54:20,581 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 114.0 (TID 468) in 42 ms on localhost (executor driver) (90/100)
2018-02-08 15:54:20,583 INFO[org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 114.0 (TID 469). 2932 bytes result sent to driver
2018-02-08 15:54:20,583 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 114.0 (TID 471, localhost, executor driver, partition 92, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,584 INFO[org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 114.0 (TID 471)
2018-02-08 15:54:20,584 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 114.0 (TID 469) in 43 ms on localhost (executor driver) (91/100)
2018-02-08 15:54:20,586 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:54:20,586 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:20,587 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:54:20,588 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:20,633 INFO[org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 114.0 (TID 471). 2932 bytes result sent to driver
2018-02-08 15:54:20,634 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 114.0 (TID 472, localhost, executor driver, partition 93, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,635 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 114.0 (TID 471) in 52 ms on localhost (executor driver) (92/100)
2018-02-08 15:54:20,635 INFO[org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 114.0 (TID 472)
2018-02-08 15:54:20,640 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:54:20,641 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:20,642 INFO[org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 114.0 (TID 470). 2932 bytes result sent to driver
2018-02-08 15:54:20,643 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 114.0 (TID 473, localhost, executor driver, partition 94, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,643 INFO[org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 114.0 (TID 473)
2018-02-08 15:54:20,643 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 114.0 (TID 470) in 62 ms on localhost (executor driver) (93/100)
2018-02-08 15:54:20,649 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:54:20,650 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:20,690 INFO[org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 114.0 (TID 472). 3018 bytes result sent to driver
2018-02-08 15:54:20,691 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 114.0 (TID 474, localhost, executor driver, partition 95, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,691 INFO[org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 114.0 (TID 474)
2018-02-08 15:54:20,691 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 114.0 (TID 472) in 57 ms on localhost (executor driver) (94/100)
2018-02-08 15:54:20,693 INFO[org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 114.0 (TID 473). 2975 bytes result sent to driver
2018-02-08 15:54:20,693 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 114.0 (TID 475, localhost, executor driver, partition 96, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,693 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 114.0 (TID 473) in 50 ms on localhost (executor driver) (95/100)
2018-02-08 15:54:20,693 INFO[org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 114.0 (TID 475)
2018-02-08 15:54:20,697 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:54:20,698 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:20,699 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:54:20,700 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:20,735 INFO[org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 114.0 (TID 474). 2932 bytes result sent to driver
2018-02-08 15:54:20,736 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 114.0 (TID 476, localhost, executor driver, partition 97, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,736 INFO[org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 114.0 (TID 476)
2018-02-08 15:54:20,736 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 114.0 (TID 474) in 45 ms on localhost (executor driver) (96/100)
2018-02-08 15:54:20,738 INFO[org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 114.0 (TID 475). 2932 bytes result sent to driver
2018-02-08 15:54:20,738 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 114.0 (TID 477, localhost, executor driver, partition 98, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,738 INFO[org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 114.0 (TID 477)
2018-02-08 15:54:20,738 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 114.0 (TID 475) in 45 ms on localhost (executor driver) (97/100)
2018-02-08 15:54:20,740 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:54:20,740 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:20,741 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:54:20,742 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:20,774 INFO[org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 114.0 (TID 476). 2932 bytes result sent to driver
2018-02-08 15:54:20,775 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 114.0 (TID 478, localhost, executor driver, partition 99, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:54:20,775 INFO[org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 114.0 (TID 478)
2018-02-08 15:54:20,775 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 114.0 (TID 476) in 39 ms on localhost (executor driver) (98/100)
2018-02-08 15:54:20,778 INFO[org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 114.0 (TID 477). 2932 bytes result sent to driver
2018-02-08 15:54:20,779 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 114.0 (TID 477) in 41 ms on localhost (executor driver) (99/100)
2018-02-08 15:54:20,779 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:54:20,780 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:54:20,821 INFO[org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 114.0 (TID 478). 2932 bytes result sent to driver
2018-02-08 15:54:20,822 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 114.0 (TID 478) in 48 ms on localhost (executor driver) (100/100)
2018-02-08 15:54:20,822 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2018-02-08 15:54:20,822 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 114 (show at MachineLeaningFiltering.java:46) finished in 3.474 s
2018-02-08 15:54:20,822 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:54:20,822 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:54:20,822 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 115)
2018-02-08 15:54:20,822 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:54:20,823 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 115 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46), which has no missing parents
2018-02-08 15:54:20,825 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_26 stored as values in memory (estimated size 64.2 KB, free 631.1 MB)
2018-02-08 15:54:20,827 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 26.6 KB, free 631.1 MB)
2018-02-08 15:54:20,827 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_26_piece0 in memory on 192.168.11.26:62777 (size: 26.6 KB, free: 631.7 MB)
2018-02-08 15:54:20,828 INFO[org.apache.spark.SparkContext:54] - Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:20,828 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:54:20,828 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 115.0 with 1 tasks
2018-02-08 15:54:20,828 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 115.0 (TID 479, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,829 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 115.0 (TID 479)
2018-02-08 15:54:20,832 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,832 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,833 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 115.0 (TID 479). 2762 bytes result sent to driver
2018-02-08 15:54:20,833 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 115.0 (TID 479) in 5 ms on localhost (executor driver) (1/1)
2018-02-08 15:54:20,833 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 115.0, whose tasks have all completed, from pool 
2018-02-08 15:54:20,833 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 115 (show at MachineLeaningFiltering.java:46) finished in 0.005 s
2018-02-08 15:54:20,834 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: show at MachineLeaningFiltering.java:46, took 3.510772 s
2018-02-08 15:54:20,836 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:46
2018-02-08 15:54:20,837 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:54:20,837 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 2 is 154 bytes
2018-02-08 15:54:20,837 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 157 bytes
2018-02-08 15:54:20,838 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 13 is 197 bytes
2018-02-08 15:54:20,838 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 12 is 169 bytes
2018-02-08 15:54:20,838 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 11 is 245 bytes
2018-02-08 15:54:20,839 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 10 is 169 bytes
2018-02-08 15:54:20,839 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 9 is 244 bytes
2018-02-08 15:54:20,839 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 8 is 169 bytes
2018-02-08 15:54:20,840 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 7 is 244 bytes
2018-02-08 15:54:20,840 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 6 is 169 bytes
2018-02-08 15:54:20,840 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 5 is 244 bytes
2018-02-08 15:54:20,841 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 4 is 169 bytes
2018-02-08 15:54:20,841 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 3 is 244 bytes
2018-02-08 15:54:20,842 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 15 is 558 bytes
2018-02-08 15:54:20,843 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 10 (show at MachineLeaningFiltering.java:46) with 4 output partitions
2018-02-08 15:54:20,843 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 131 (show at MachineLeaningFiltering.java:46)
2018-02-08 15:54:20,843 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 130)
2018-02-08 15:54:20,843 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:54:20,844 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 131 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46), which has no missing parents
2018-02-08 15:54:20,848 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_27 stored as values in memory (estimated size 64.2 KB, free 631.0 MB)
2018-02-08 15:54:20,849 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 26.6 KB, free 631.0 MB)
2018-02-08 15:54:20,850 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_27_piece0 in memory on 192.168.11.26:62777 (size: 26.6 KB, free: 631.6 MB)
2018-02-08 15:54:20,850 INFO[org.apache.spark.SparkContext:54] - Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:20,851 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 4 missing tasks from ResultStage 131 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2018-02-08 15:54:20,851 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 131.0 with 4 tasks
2018-02-08 15:54:20,851 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 131.0 (TID 480, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,851 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 131.0 (TID 481, localhost, executor driver, partition 2, ANY, 4726 bytes)
2018-02-08 15:54:20,851 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 131.0 (TID 480)
2018-02-08 15:54:20,851 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 131.0 (TID 481)
2018-02-08 15:54:20,856 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,856 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,856 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,856 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,856 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 131.0 (TID 480). 2719 bytes result sent to driver
2018-02-08 15:54:20,857 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 131.0 (TID 482, localhost, executor driver, partition 3, ANY, 4726 bytes)
2018-02-08 15:54:20,857 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 131.0 (TID 482)
2018-02-08 15:54:20,857 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 131.0 (TID 480) in 6 ms on localhost (executor driver) (1/4)
2018-02-08 15:54:20,862 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,862 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:20,892 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 25.078088 ms
2018-02-08 15:54:20,895 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 131.0 (TID 481). 2997 bytes result sent to driver
2018-02-08 15:54:20,895 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 131.0 (TID 482). 3032 bytes result sent to driver
2018-02-08 15:54:20,895 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 131.0 (TID 483, localhost, executor driver, partition 4, ANY, 4726 bytes)
2018-02-08 15:54:20,895 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 131.0 (TID 481) in 44 ms on localhost (executor driver) (2/4)
2018-02-08 15:54:20,896 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 131.0 (TID 482) in 39 ms on localhost (executor driver) (3/4)
2018-02-08 15:54:20,895 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 131.0 (TID 483)
2018-02-08 15:54:20,901 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,901 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,914 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 131.0 (TID 483). 2989 bytes result sent to driver
2018-02-08 15:54:20,915 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 131.0 (TID 483) in 20 ms on localhost (executor driver) (4/4)
2018-02-08 15:54:20,915 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 131.0, whose tasks have all completed, from pool 
2018-02-08 15:54:20,915 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 131 (show at MachineLeaningFiltering.java:46) finished in 0.064 s
2018-02-08 15:54:20,916 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 10 finished: show at MachineLeaningFiltering.java:46, took 0.079673 s
2018-02-08 15:54:20,919 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:46
2018-02-08 15:54:20,928 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 11 (show at MachineLeaningFiltering.java:46) with 20 output partitions
2018-02-08 15:54:20,928 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 147 (show at MachineLeaningFiltering.java:46)
2018-02-08 15:54:20,928 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 146)
2018-02-08 15:54:20,928 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:54:20,928 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 147 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46), which has no missing parents
2018-02-08 15:54:20,938 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_28 stored as values in memory (estimated size 64.2 KB, free 630.9 MB)
2018-02-08 15:54:20,940 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 26.6 KB, free 630.9 MB)
2018-02-08 15:54:20,941 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_28_piece0 in memory on 192.168.11.26:62777 (size: 26.6 KB, free: 631.6 MB)
2018-02-08 15:54:20,941 INFO[org.apache.spark.SparkContext:54] - Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:20,942 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 20 missing tasks from ResultStage 147 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19))
2018-02-08 15:54:20,942 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 147.0 with 20 tasks
2018-02-08 15:54:20,942 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 147.0 (TID 484, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,943 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 147.0 (TID 485, localhost, executor driver, partition 8, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,943 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 147.0 (TID 484)
2018-02-08 15:54:20,943 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 147.0 (TID 485)
2018-02-08 15:54:20,947 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,947 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,947 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,948 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:20,948 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 147.0 (TID 484). 2762 bytes result sent to driver
2018-02-08 15:54:20,949 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 147.0 (TID 485). 2762 bytes result sent to driver
2018-02-08 15:54:20,949 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 147.0 (TID 486, localhost, executor driver, partition 9, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,950 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 147.0 (TID 487, localhost, executor driver, partition 10, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,951 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 147.0 (TID 486)
2018-02-08 15:54:20,952 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 147.0 (TID 485) in 10 ms on localhost (executor driver) (1/20)
2018-02-08 15:54:20,952 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 147.0 (TID 487)
2018-02-08 15:54:20,953 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 147.0 (TID 484) in 11 ms on localhost (executor driver) (2/20)
2018-02-08 15:54:20,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,956 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:20,956 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 147.0 (TID 487). 2762 bytes result sent to driver
2018-02-08 15:54:20,956 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 147.0 (TID 486). 2762 bytes result sent to driver
2018-02-08 15:54:20,956 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 147.0 (TID 488, localhost, executor driver, partition 12, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,956 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 147.0 (TID 489, localhost, executor driver, partition 15, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,957 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 147.0 (TID 486) in 8 ms on localhost (executor driver) (3/20)
2018-02-08 15:54:20,957 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 147.0 (TID 489)
2018-02-08 15:54:20,957 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 147.0 (TID 487) in 7 ms on localhost (executor driver) (4/20)
2018-02-08 15:54:20,956 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 147.0 (TID 488)
2018-02-08 15:54:20,960 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,960 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,960 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,960 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,961 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 147.0 (TID 489). 2762 bytes result sent to driver
2018-02-08 15:54:20,961 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 147.0 (TID 488). 2762 bytes result sent to driver
2018-02-08 15:54:20,961 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 147.0 (TID 490, localhost, executor driver, partition 16, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,961 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 147.0 (TID 489) in 5 ms on localhost (executor driver) (5/20)
2018-02-08 15:54:20,961 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 147.0 (TID 490)
2018-02-08 15:54:20,962 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 147.0 (TID 488) in 6 ms on localhost (executor driver) (6/20)
2018-02-08 15:54:20,962 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 147.0 (TID 491, localhost, executor driver, partition 17, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,962 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 147.0 (TID 491)
2018-02-08 15:54:20,965 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,965 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,966 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:20,965 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,966 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 147.0 (TID 491). 2762 bytes result sent to driver
2018-02-08 15:54:20,966 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 147.0 (TID 490). 2762 bytes result sent to driver
2018-02-08 15:54:20,968 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 147.0 (TID 492, localhost, executor driver, partition 20, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,968 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 147.0 (TID 491) in 6 ms on localhost (executor driver) (7/20)
2018-02-08 15:54:20,968 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 147.0 (TID 492)
2018-02-08 15:54:20,968 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 147.0 (TID 490) in 7 ms on localhost (executor driver) (8/20)
2018-02-08 15:54:20,968 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 147.0 (TID 493, localhost, executor driver, partition 22, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,968 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 147.0 (TID 493)
2018-02-08 15:54:20,972 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,972 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,972 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,972 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,972 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 147.0 (TID 493). 2719 bytes result sent to driver
2018-02-08 15:54:20,972 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 147.0 (TID 492). 2719 bytes result sent to driver
2018-02-08 15:54:20,973 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 147.0 (TID 494, localhost, executor driver, partition 23, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:20,973 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 147.0 (TID 495, localhost, executor driver, partition 5, ANY, 4726 bytes)
2018-02-08 15:54:20,973 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 147.0 (TID 494)
2018-02-08 15:54:20,973 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 147.0 (TID 492) in 6 ms on localhost (executor driver) (9/20)
2018-02-08 15:54:20,973 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 147.0 (TID 493) in 5 ms on localhost (executor driver) (10/20)
2018-02-08 15:54:20,973 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 147.0 (TID 495)
2018-02-08 15:54:20,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:20,977 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:20,977 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 147.0 (TID 494). 2762 bytes result sent to driver
2018-02-08 15:54:20,977 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 147.0 (TID 496, localhost, executor driver, partition 7, ANY, 4726 bytes)
2018-02-08 15:54:20,978 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 147.0 (TID 494) in 5 ms on localhost (executor driver) (11/20)
2018-02-08 15:54:20,978 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 147.0 (TID 496)
2018-02-08 15:54:20,983 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:20,984 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:20,999 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 147.0 (TID 496). 2995 bytes result sent to driver
2018-02-08 15:54:20,999 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 147.0 (TID 497, localhost, executor driver, partition 11, ANY, 4726 bytes)
2018-02-08 15:54:20,999 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 147.0 (TID 496) in 22 ms on localhost (executor driver) (12/20)
2018-02-08 15:54:21,000 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 147.0 (TID 497)
2018-02-08 15:54:21,001 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 147.0 (TID 495). 2995 bytes result sent to driver
2018-02-08 15:54:21,002 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 147.0 (TID 498, localhost, executor driver, partition 13, ANY, 4726 bytes)
2018-02-08 15:54:21,002 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 147.0 (TID 495) in 29 ms on localhost (executor driver) (13/20)
2018-02-08 15:54:21,002 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 147.0 (TID 498)
2018-02-08 15:54:21,004 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,004 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,005 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,005 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,014 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 147.0 (TID 498). 2999 bytes result sent to driver
2018-02-08 15:54:21,014 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 147.0 (TID 499, localhost, executor driver, partition 14, ANY, 4726 bytes)
2018-02-08 15:54:21,016 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 147.0 (TID 498) in 14 ms on localhost (executor driver) (14/20)
2018-02-08 15:54:21,016 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 147.0 (TID 497). 3005 bytes result sent to driver
2018-02-08 15:54:21,016 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 147.0 (TID 499)
2018-02-08 15:54:21,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 147.0 (TID 500, localhost, executor driver, partition 18, ANY, 4726 bytes)
2018-02-08 15:54:21,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 147.0 (TID 497) in 18 ms on localhost (executor driver) (15/20)
2018-02-08 15:54:21,018 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 147.0 (TID 500)
2018-02-08 15:54:21,020 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,020 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,022 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,022 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,032 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 147.0 (TID 499). 3008 bytes result sent to driver
2018-02-08 15:54:21,033 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 147.0 (TID 501, localhost, executor driver, partition 19, ANY, 4726 bytes)
2018-02-08 15:54:21,034 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 147.0 (TID 499) in 20 ms on localhost (executor driver) (16/20)
2018-02-08 15:54:21,035 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 147.0 (TID 501)
2018-02-08 15:54:21,036 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 147.0 (TID 500). 2990 bytes result sent to driver
2018-02-08 15:54:21,037 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 147.0 (TID 502, localhost, executor driver, partition 21, ANY, 4726 bytes)
2018-02-08 15:54:21,037 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 147.0 (TID 500) in 20 ms on localhost (executor driver) (17/20)
2018-02-08 15:54:21,038 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 147.0 (TID 502)
2018-02-08 15:54:21,039 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 20 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,039 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,041 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,042 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,052 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 147.0 (TID 502). 3010 bytes result sent to driver
2018-02-08 15:54:21,053 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 147.0 (TID 503, localhost, executor driver, partition 24, ANY, 4726 bytes)
2018-02-08 15:54:21,053 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 147.0 (TID 502) in 16 ms on localhost (executor driver) (18/20)
2018-02-08 15:54:21,053 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 147.0 (TID 503)
2018-02-08 15:54:21,057 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 147.0 (TID 501). 3133 bytes result sent to driver
2018-02-08 15:54:21,057 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 147.0 (TID 501) in 24 ms on localhost (executor driver) (19/20)
2018-02-08 15:54:21,058 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,058 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,069 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 147.0 (TID 503). 2990 bytes result sent to driver
2018-02-08 15:54:21,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 147.0 (TID 503) in 17 ms on localhost (executor driver) (20/20)
2018-02-08 15:54:21,070 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 147.0, whose tasks have all completed, from pool 
2018-02-08 15:54:21,070 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 147 (show at MachineLeaningFiltering.java:46) finished in 0.128 s
2018-02-08 15:54:21,071 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 11 finished: show at MachineLeaningFiltering.java:46, took 0.152143 s
2018-02-08 15:54:21,074 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:46
2018-02-08 15:54:21,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 12 (show at MachineLeaningFiltering.java:46) with 35 output partitions
2018-02-08 15:54:21,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 163 (show at MachineLeaningFiltering.java:46)
2018-02-08 15:54:21,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 162)
2018-02-08 15:54:21,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:54:21,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 163 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46), which has no missing parents
2018-02-08 15:54:21,086 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_29 stored as values in memory (estimated size 64.2 KB, free 630.8 MB)
2018-02-08 15:54:21,088 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 26.6 KB, free 630.8 MB)
2018-02-08 15:54:21,089 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_29_piece0 in memory on 192.168.11.26:62777 (size: 26.6 KB, free: 631.6 MB)
2018-02-08 15:54:21,089 INFO[org.apache.spark.SparkContext:54] - Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:54:21,090 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 35 missing tasks from ResultStage 163 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46) (first 15 tasks are for partitions Vector(25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39))
2018-02-08 15:54:21,090 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 163.0 with 35 tasks
2018-02-08 15:54:21,091 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 163.0 (TID 504, localhost, executor driver, partition 25, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,091 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 163.0 (TID 505, localhost, executor driver, partition 26, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,091 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 163.0 (TID 504)
2018-02-08 15:54:21,096 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 163.0 (TID 505)
2018-02-08 15:54:21,098 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,098 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,099 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 163.0 (TID 504). 2762 bytes result sent to driver
2018-02-08 15:54:21,099 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 163.0 (TID 506, localhost, executor driver, partition 28, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,100 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 163.0 (TID 504) in 10 ms on localhost (executor driver) (1/35)
2018-02-08 15:54:21,100 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,100 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,100 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 163.0 (TID 506)
2018-02-08 15:54:21,100 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 163.0 (TID 505). 2762 bytes result sent to driver
2018-02-08 15:54:21,101 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 163.0 (TID 507, localhost, executor driver, partition 29, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,101 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 163.0 (TID 505) in 10 ms on localhost (executor driver) (2/35)
2018-02-08 15:54:21,101 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 163.0 (TID 507)
2018-02-08 15:54:21,106 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,106 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,107 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 163.0 (TID 507). 2719 bytes result sent to driver
2018-02-08 15:54:21,107 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 163.0 (TID 508, localhost, executor driver, partition 31, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,107 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 163.0 (TID 507) in 6 ms on localhost (executor driver) (3/35)
2018-02-08 15:54:21,107 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 163.0 (TID 508)
2018-02-08 15:54:21,108 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,108 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,108 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 163.0 (TID 506). 2762 bytes result sent to driver
2018-02-08 15:54:21,108 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 163.0 (TID 509, localhost, executor driver, partition 33, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,109 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 163.0 (TID 506) in 9 ms on localhost (executor driver) (4/35)
2018-02-08 15:54:21,109 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 163.0 (TID 509)
2018-02-08 15:54:21,112 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,113 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,113 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 163.0 (TID 508). 2805 bytes result sent to driver
2018-02-08 15:54:21,113 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 163.0 (TID 510, localhost, executor driver, partition 34, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 163.0 (TID 508) in 7 ms on localhost (executor driver) (5/35)
2018-02-08 15:54:21,114 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 163.0 (TID 510)
2018-02-08 15:54:21,119 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,120 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,120 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 163.0 (TID 510). 2762 bytes result sent to driver
2018-02-08 15:54:21,120 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 163.0 (TID 511, localhost, executor driver, partition 36, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,121 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 163.0 (TID 510) in 8 ms on localhost (executor driver) (6/35)
2018-02-08 15:54:21,121 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 163.0 (TID 511)
2018-02-08 15:54:21,125 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,125 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,129 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 163.0 (TID 511). 2762 bytes result sent to driver
2018-02-08 15:54:21,130 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 163.0 (TID 512, localhost, executor driver, partition 37, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,130 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 163.0 (TID 511) in 10 ms on localhost (executor driver) (7/35)
2018-02-08 15:54:21,131 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 163.0 (TID 512)
2018-02-08 15:54:21,146 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,146 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,147 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 163.0 (TID 512). 2762 bytes result sent to driver
2018-02-08 15:54:21,147 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 163.0 (TID 513, localhost, executor driver, partition 38, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,147 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 163.0 (TID 512) in 17 ms on localhost (executor driver) (8/35)
2018-02-08 15:54:21,148 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 163.0 (TID 513)
2018-02-08 15:54:21,150 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,163 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 13 ms
2018-02-08 15:54:21,163 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 163.0 (TID 509). 2805 bytes result sent to driver
2018-02-08 15:54:21,164 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 163.0 (TID 514, localhost, executor driver, partition 39, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,164 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 163.0 (TID 514)
2018-02-08 15:54:21,164 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 163.0 (TID 509) in 56 ms on localhost (executor driver) (9/35)
2018-02-08 15:54:21,168 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,168 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,168 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 163.0 (TID 514). 2762 bytes result sent to driver
2018-02-08 15:54:21,169 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 163.0 (TID 515, localhost, executor driver, partition 40, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,169 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 163.0 (TID 514) in 5 ms on localhost (executor driver) (10/35)
2018-02-08 15:54:21,169 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 163.0 (TID 515)
2018-02-08 15:54:21,173 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,173 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,174 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,175 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,176 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 163.0 (TID 515). 2805 bytes result sent to driver
2018-02-08 15:54:21,176 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 163.0 (TID 513). 2805 bytes result sent to driver
2018-02-08 15:54:21,176 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 163.0 (TID 516, localhost, executor driver, partition 41, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 163.0 (TID 517, localhost, executor driver, partition 42, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,177 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 163.0 (TID 516)
2018-02-08 15:54:21,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 163.0 (TID 513) in 30 ms on localhost (executor driver) (11/35)
2018-02-08 15:54:21,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 163.0 (TID 515) in 8 ms on localhost (executor driver) (12/35)
2018-02-08 15:54:21,177 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 163.0 (TID 517)
2018-02-08 15:54:21,180 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,181 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,181 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 163.0 (TID 517). 2762 bytes result sent to driver
2018-02-08 15:54:21,182 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 163.0 (TID 518, localhost, executor driver, partition 45, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,180 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,183 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 15:54:21,183 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 163.0 (TID 516). 2762 bytes result sent to driver
2018-02-08 15:54:21,184 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 163.0 (TID 519, localhost, executor driver, partition 46, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,184 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 163.0 (TID 517) in 7 ms on localhost (executor driver) (13/35)
2018-02-08 15:54:21,184 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 163.0 (TID 516) in 8 ms on localhost (executor driver) (14/35)
2018-02-08 15:54:21,184 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 163.0 (TID 518)
2018-02-08 15:54:21,189 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,192 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 15:54:21,193 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 163.0 (TID 518). 2805 bytes result sent to driver
2018-02-08 15:54:21,193 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 163.0 (TID 520, localhost, executor driver, partition 47, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,194 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 163.0 (TID 519)
2018-02-08 15:54:21,196 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 163.0 (TID 518) in 14 ms on localhost (executor driver) (15/35)
2018-02-08 15:54:21,197 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 163.0 (TID 520)
2018-02-08 15:54:21,198 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,198 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,198 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 163.0 (TID 519). 2762 bytes result sent to driver
2018-02-08 15:54:21,199 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 163.0 (TID 521, localhost, executor driver, partition 50, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,199 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 163.0 (TID 519) in 16 ms on localhost (executor driver) (16/35)
2018-02-08 15:54:21,200 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 163.0 (TID 521)
2018-02-08 15:54:21,200 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,201 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,201 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 163.0 (TID 520). 2762 bytes result sent to driver
2018-02-08 15:54:21,202 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 163.0 (TID 522, localhost, executor driver, partition 52, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,202 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 163.0 (TID 520) in 9 ms on localhost (executor driver) (17/35)
2018-02-08 15:54:21,202 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 163.0 (TID 522)
2018-02-08 15:54:21,203 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,204 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,204 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 163.0 (TID 521). 2805 bytes result sent to driver
2018-02-08 15:54:21,204 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 163.0 (TID 523, localhost, executor driver, partition 54, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,205 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 163.0 (TID 523)
2018-02-08 15:54:21,205 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 163.0 (TID 521) in 6 ms on localhost (executor driver) (18/35)
2018-02-08 15:54:21,206 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,206 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,206 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 163.0 (TID 522). 2719 bytes result sent to driver
2018-02-08 15:54:21,207 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 163.0 (TID 524, localhost, executor driver, partition 55, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,207 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 163.0 (TID 522) in 6 ms on localhost (executor driver) (19/35)
2018-02-08 15:54:21,207 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 163.0 (TID 524)
2018-02-08 15:54:21,208 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,208 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,209 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 163.0 (TID 523). 2762 bytes result sent to driver
2018-02-08 15:54:21,209 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 163.0 (TID 525, localhost, executor driver, partition 56, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,209 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 163.0 (TID 523) in 5 ms on localhost (executor driver) (20/35)
2018-02-08 15:54:21,209 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 163.0 (TID 525)
2018-02-08 15:54:21,211 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,211 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,212 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 163.0 (TID 524). 2719 bytes result sent to driver
2018-02-08 15:54:21,212 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 163.0 (TID 526, localhost, executor driver, partition 59, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:54:21,212 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,213 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,213 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 163.0 (TID 526)
2018-02-08 15:54:21,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 163.0 (TID 524) in 7 ms on localhost (executor driver) (21/35)
2018-02-08 15:54:21,213 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 163.0 (TID 525). 2762 bytes result sent to driver
2018-02-08 15:54:21,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 163.0 (TID 527, localhost, executor driver, partition 27, ANY, 4726 bytes)
2018-02-08 15:54:21,214 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 163.0 (TID 525) in 5 ms on localhost (executor driver) (22/35)
2018-02-08 15:54:21,214 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 163.0 (TID 527)
2018-02-08 15:54:21,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,217 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 163.0 (TID 526). 2762 bytes result sent to driver
2018-02-08 15:54:21,218 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 163.0 (TID 528, localhost, executor driver, partition 30, ANY, 4726 bytes)
2018-02-08 15:54:21,219 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 163.0 (TID 526) in 7 ms on localhost (executor driver) (23/35)
2018-02-08 15:54:21,219 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 163.0 (TID 528)
2018-02-08 15:54:21,222 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,223 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,228 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 163.0 (TID 527). 2989 bytes result sent to driver
2018-02-08 15:54:21,229 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 163.0 (TID 529, localhost, executor driver, partition 32, ANY, 4726 bytes)
2018-02-08 15:54:21,229 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 163.0 (TID 527) in 16 ms on localhost (executor driver) (24/35)
2018-02-08 15:54:21,229 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 163.0 (TID 529)
2018-02-08 15:54:21,232 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 163.0 (TID 528). 2945 bytes result sent to driver
2018-02-08 15:54:21,232 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 163.0 (TID 530, localhost, executor driver, partition 35, ANY, 4726 bytes)
2018-02-08 15:54:21,233 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,233 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 163.0 (TID 530)
2018-02-08 15:54:21,233 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 163.0 (TID 528) in 15 ms on localhost (executor driver) (25/35)
2018-02-08 15:54:21,233 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,236 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,237 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,242 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 163.0 (TID 529). 2988 bytes result sent to driver
2018-02-08 15:54:21,243 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 163.0 (TID 531, localhost, executor driver, partition 43, ANY, 4726 bytes)
2018-02-08 15:54:21,243 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 163.0 (TID 529) in 14 ms on localhost (executor driver) (26/35)
2018-02-08 15:54:21,243 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 163.0 (TID 531)
2018-02-08 15:54:21,245 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 163.0 (TID 530). 2947 bytes result sent to driver
2018-02-08 15:54:21,245 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 163.0 (TID 532, localhost, executor driver, partition 44, ANY, 4726 bytes)
2018-02-08 15:54:21,246 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 163.0 (TID 530) in 14 ms on localhost (executor driver) (27/35)
2018-02-08 15:54:21,246 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 163.0 (TID 532)
2018-02-08 15:54:21,247 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,247 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,265 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 163.0 (TID 531). 2997 bytes result sent to driver
2018-02-08 15:54:21,266 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 163.0 (TID 533, localhost, executor driver, partition 48, ANY, 4726 bytes)
2018-02-08 15:54:21,266 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 163.0 (TID 531) in 24 ms on localhost (executor driver) (28/35)
2018-02-08 15:54:21,266 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 163.0 (TID 533)
2018-02-08 15:54:21,268 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,268 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,273 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,273 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,281 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 163.0 (TID 532). 3010 bytes result sent to driver
2018-02-08 15:54:21,282 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 163.0 (TID 533). 2985 bytes result sent to driver
2018-02-08 15:54:21,282 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 163.0 (TID 534, localhost, executor driver, partition 49, ANY, 4726 bytes)
2018-02-08 15:54:21,282 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 163.0 (TID 534)
2018-02-08 15:54:21,282 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 163.0 (TID 535, localhost, executor driver, partition 51, ANY, 4726 bytes)
2018-02-08 15:54:21,283 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 163.0 (TID 535)
2018-02-08 15:54:21,283 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 163.0 (TID 532) in 38 ms on localhost (executor driver) (29/35)
2018-02-08 15:54:21,283 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 163.0 (TID 533) in 17 ms on localhost (executor driver) (30/35)
2018-02-08 15:54:21,286 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,286 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,287 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,288 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:54:21,297 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 163.0 (TID 535). 3000 bytes result sent to driver
2018-02-08 15:54:21,297 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 163.0 (TID 534). 3230 bytes result sent to driver
2018-02-08 15:54:21,297 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 163.0 (TID 536, localhost, executor driver, partition 53, ANY, 4726 bytes)
2018-02-08 15:54:21,298 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 163.0 (TID 535) in 16 ms on localhost (executor driver) (31/35)
2018-02-08 15:54:21,298 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 163.0 (TID 536)
2018-02-08 15:54:21,298 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 163.0 (TID 537, localhost, executor driver, partition 57, ANY, 4726 bytes)
2018-02-08 15:54:21,298 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 163.0 (TID 537)
2018-02-08 15:54:21,298 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 163.0 (TID 534) in 16 ms on localhost (executor driver) (32/35)
2018-02-08 15:54:21,301 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,301 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,301 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,301 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:54:21,312 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 163.0 (TID 536). 3116 bytes result sent to driver
2018-02-08 15:54:21,312 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 163.0 (TID 537). 2996 bytes result sent to driver
2018-02-08 15:54:21,312 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 163.0 (TID 538, localhost, executor driver, partition 58, ANY, 4726 bytes)
2018-02-08 15:54:21,313 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 163.0 (TID 536) in 16 ms on localhost (executor driver) (33/35)
2018-02-08 15:54:21,313 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 163.0 (TID 538)
2018-02-08 15:54:21,313 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 163.0 (TID 537) in 15 ms on localhost (executor driver) (34/35)
2018-02-08 15:54:21,317 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:54:21,318 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:54:21,332 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 163.0 (TID 538). 2990 bytes result sent to driver
2018-02-08 15:54:21,332 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 163.0 (TID 538) in 20 ms on localhost (executor driver) (35/35)
2018-02-08 15:54:21,333 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 163.0, whose tasks have all completed, from pool 
2018-02-08 15:54:21,333 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 163 (show at MachineLeaningFiltering.java:46) finished in 0.243 s
2018-02-08 15:54:21,334 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 12 finished: show at MachineLeaningFiltering.java:46, took 0.260771 s
2018-02-08 15:54:21,356 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 18.586246 ms
2018-02-08 15:54:21,372 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:54:21,377 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@34a1d21f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:54:21,378 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:54:21,387 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:54:21,889 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:54:21,889 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:54:21,889 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:54:21,891 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:54:21,894 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:54:21,894 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:54:21,895 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-12165748-43b4-45a3-843b-9a408351361e
2018-02-08 15:57:15,883 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:57:16,461 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:57:16,491 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:57:16,492 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:57:16,493 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:57:16,495 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:57:16,496 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:57:16,840 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62821.
2018-02-08 15:57:16,856 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:57:16,897 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:57:16,900 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:57:16,900 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:57:16,908 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-4f552b5d-796e-4dac-8773-69bbaffd2f27
2018-02-08 15:57:16,929 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:57:16,976 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:57:17,050 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2503ms
2018-02-08 15:57:17,108 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:57:17,120 INFO[org.spark_project.jetty.server.Server:403] - Started @2575ms
2018-02-08 15:57:17,139 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@34a1d21f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:57:17,139 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:57:17,160 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1c9f0a20{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,160 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@b40bb6e{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,161 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5049d8b2{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,162 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a3591c5{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,162 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@346a361{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,163 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1643d68f{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,164 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2e029d61{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,165 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@297ea53a{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,166 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5bf22f18{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,167 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a7471ce{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,168 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62e70ea3{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,168 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,169 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,170 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,171 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,171 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6d366c9b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,172 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,172 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,173 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,175 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,180 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/static,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,181 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@592e843a{/,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,182 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@423e4cbb{/api,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,183 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2a1edad4{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,184 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@44c79f32{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,186 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:57:17,257 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:57:17,283 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62834.
2018-02-08 15:57:17,284 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62834
2018-02-08 15:57:17,285 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:57:17,287 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62834, None)
2018-02-08 15:57:17,292 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62834 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62834, None)
2018-02-08 15:57:17,294 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62834, None)
2018-02-08 15:57:17,294 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62834, None)
2018-02-08 15:57:17,489 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4a67318f{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,554 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:57:17,555 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:57:17,561 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@408613cc{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,562 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@11ce2e22{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,562 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@771158fb{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,563 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62d0ac62{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:57:17,565 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@437ebf59{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:57:18,521 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:57:20,185 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:57:20,188 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:57:20,191 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<value: string>
2018-02-08 15:57:20,199 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:57:20,639 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 171.847095 ms
2018-02-08 15:57:20,686 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:57:20,835 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:57:20,838 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:62834 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:57:20,842 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from javaRDD at MachineLeaningFiltering.java:54
2018-02-08 15:57:20,854 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:57:21,229 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 38.777612 ms
2018-02-08 15:57:21,312 INFO[org.apache.spark.ml.util.Instrumentation:54] - ALS-als_915fe4453bac-627727856-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
2018-02-08 15:57:21,338 INFO[org.apache.spark.ml.util.Instrumentation:54] - ALS-als_915fe4453bac-627727856-1: {"ratingCol":"rating","itemCol":"movieId","userCol":"userId","regParam":0.01,"maxIter":5}
2018-02-08 15:57:21,361 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at ALS.scala:843
2018-02-08 15:57:21,379 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (isEmpty at ALS.scala:843) with 1 output partitions
2018-02-08 15:57:21,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (isEmpty at ALS.scala:843)
2018-02-08 15:57:21,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:57:21,381 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:57:21,385 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[10] at map at ALS.scala:613), which has no missing parents
2018-02-08 15:57:21,402 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 28.6 KB, free 631.4 MB)
2018-02-08 15:57:21,406 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.6 KB, free 631.4 MB)
2018-02-08 15:57:21,409 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:62834 (size: 12.6 KB, free: 631.8 MB)
2018-02-08 15:57:21,410 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:21,419 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[10] at map at ALS.scala:613) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:57:21,420 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
2018-02-08 15:57:21,455 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5324 bytes)
2018-02-08 15:57:21,467 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:57:21,572 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.521603 ms
2018-02-08 15:57:21,602 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.916483 ms
2018-02-08 15:57:21,628 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 16.664965 ms
2018-02-08 15:57:21,642 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.089922 ms
2018-02-08 15:57:21,670 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.739524 ms
2018-02-08 15:57:21,674 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/als/sample_movielens_ratings.txt, range: 0-32363, partition values: [empty row]
2018-02-08 15:57:21,685 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.986243 ms
2018-02-08 15:57:21,799 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 2224 bytes result sent to driver
2018-02-08 15:57:21,805 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 357 ms on localhost (executor driver) (1/1)
2018-02-08 15:57:21,807 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:57:21,810 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (isEmpty at ALS.scala:843) finished in 0.375 s
2018-02-08 15:57:21,815 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: isEmpty at ALS.scala:843, took 0.453051 s
2018-02-08 15:57:21,888 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:857
2018-02-08 15:57:21,893 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 11 (mapPartitions at ALS.scala:1101)
2018-02-08 15:57:21,894 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 14 (map at ALS.scala:1344)
2018-02-08 15:57:21,894 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (count at ALS.scala:857) with 10 output partitions
2018-02-08 15:57:21,894 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (count at ALS.scala:857)
2018-02-08 15:57:21,894 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 2)
2018-02-08 15:57:21,897 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 2)
2018-02-08 15:57:21,898 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at mapPartitions at ALS.scala:1101), which has no missing parents
2018-02-08 15:57:21,905 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 30.7 KB, free 631.4 MB)
2018-02-08 15:57:21,910 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 13.6 KB, free 631.4 MB)
2018-02-08 15:57:21,911 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:62834 (size: 13.6 KB, free: 631.7 MB)
2018-02-08 15:57:21,912 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:21,915 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at mapPartitions at ALS.scala:1101) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:57:21,915 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 15:57:21,918 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5313 bytes)
2018-02-08 15:57:21,919 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
2018-02-08 15:57:21,948 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/als/sample_movielens_ratings.txt, range: 0-32363, partition values: [empty row]
2018-02-08 15:57:22,038 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 2160 bytes result sent to driver
2018-02-08 15:57:22,040 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 124 ms on localhost (executor driver) (1/1)
2018-02-08 15:57:22,040 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 15:57:22,041 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (mapPartitions at ALS.scala:1101) finished in 0.125 s
2018-02-08 15:57:22,042 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:22,042 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:22,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 2, ResultStage 3)
2018-02-08 15:57:22,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:22,046 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at map at ALS.scala:1344), which has no missing parents
2018-02-08 15:57:22,053 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 32.0 KB, free 631.3 MB)
2018-02-08 15:57:22,057 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 14.1 KB, free 631.3 MB)
2018-02-08 15:57:22,058 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:62834 (size: 14.1 KB, free: 631.7 MB)
2018-02-08 15:57:22,059 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:22,059 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:57:22,059 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 15:57:22,063 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4610 bytes)
2018-02-08 15:57:22,064 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
2018-02-08 15:57:22,086 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:22,088 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 15:57:22,194 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_13_0 stored as values in memory (estimated size 27.7 KB, free 631.3 MB)
2018-02-08 15:57:22,199 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_13_0 in memory on 192.168.11.26:62834 (size: 27.7 KB, free: 631.7 MB)
2018-02-08 15:57:22,293 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.11.26:62834 in memory (size: 13.6 KB, free: 631.7 MB)
2018-02-08 15:57:22,302 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:62834 in memory (size: 12.6 KB, free: 631.7 MB)
2018-02-08 15:57:22,457 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 3065 bytes result sent to driver
2018-02-08 15:57:22,460 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 397 ms on localhost (executor driver) (1/1)
2018-02-08 15:57:22,460 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 15:57:22,461 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 2 (map at ALS.scala:1344) finished in 0.398 s
2018-02-08 15:57:22,461 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:22,461 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:22,461 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 3)
2018-02-08 15:57:22,461 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:22,463 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (userOutBlocks MapPartitionsRDD[17] at mapValues at ALS.scala:1381), which has no missing parents
2018-02-08 15:57:22,468 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 32.6 KB, free 631.4 MB)
2018-02-08 15:57:22,472 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 14.5 KB, free 631.3 MB)
2018-02-08 15:57:22,474 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:62834 (size: 14.5 KB, free: 631.7 MB)
2018-02-08 15:57:22,474 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:22,475 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 3 (userOutBlocks MapPartitionsRDD[17] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:22,475 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 10 tasks
2018-02-08 15:57:22,476 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:57:22,477 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, ANY, 4621 bytes)
2018-02-08 15:57:22,477 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 3)
2018-02-08 15:57:22,478 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 3.0 (TID 4)
2018-02-08 15:57:22,491 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:22,491 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:22,496 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:22,496 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:22,515 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_1 stored as values in memory (estimated size 1152.0 B, free 631.3 MB)
2018-02-08 15:57:22,515 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_0 stored as values in memory (estimated size 1136.0 B, free 631.3 MB)
2018-02-08 15:57:22,515 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_1 in memory on 192.168.11.26:62834 (size: 1152.0 B, free: 631.7 MB)
2018-02-08 15:57:22,518 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_0 in memory on 192.168.11.26:62834 (size: 1136.0 B, free: 631.7 MB)
2018-02-08 15:57:22,521 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_0 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:57:22,521 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_1 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:57:22,522 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_0 in memory on 192.168.11.26:62834 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:57:22,523 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_1 in memory on 192.168.11.26:62834 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:57:22,524 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 3). 2910 bytes result sent to driver
2018-02-08 15:57:22,525 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, ANY, 4621 bytes)
2018-02-08 15:57:22,526 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 3.0 (TID 4). 2953 bytes result sent to driver
2018-02-08 15:57:22,526 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 3.0 (TID 5)
2018-02-08 15:57:22,527 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, ANY, 4621 bytes)
2018-02-08 15:57:22,528 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 3.0 (TID 4) in 51 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:22,530 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 3.0 (TID 6)
2018-02-08 15:57:22,540 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:22,541 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:22,543 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:22,544 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:22,549 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_2 stored as values in memory (estimated size 1200.0 B, free 631.3 MB)
2018-02-08 15:57:22,551 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_2 in memory on 192.168.11.26:62834 (size: 1200.0 B, free: 631.7 MB)
2018-02-08 15:57:22,552 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_2 stored as values in memory (estimated size 432.0 B, free 631.3 MB)
2018-02-08 15:57:22,556 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_2 in memory on 192.168.11.26:62834 (size: 432.0 B, free: 631.7 MB)
2018-02-08 15:57:22,557 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 3.0 (TID 5). 2867 bytes result sent to driver
2018-02-08 15:57:22,558 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 3.0 (TID 7, localhost, executor driver, partition 4, ANY, 4621 bytes)
2018-02-08 15:57:22,559 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 3.0 (TID 5) in 33 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:22,559 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 3.0 (TID 7)
2018-02-08 15:57:22,562 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_3 stored as values in memory (estimated size 1168.0 B, free 631.3 MB)
2018-02-08 15:57:22,563 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_3 in memory on 192.168.11.26:62834 (size: 1168.0 B, free: 631.7 MB)
2018-02-08 15:57:22,566 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_3 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:57:22,572 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 3) in 96 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:22,574 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:22,574 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:22,577 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_3 in memory on 192.168.11.26:62834 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:57:22,578 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_4 stored as values in memory (estimated size 1200.0 B, free 631.3 MB)
2018-02-08 15:57:22,579 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_4 in memory on 192.168.11.26:62834 (size: 1200.0 B, free: 631.7 MB)
2018-02-08 15:57:22,583 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_4 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:57:22,586 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_4 in memory on 192.168.11.26:62834 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:57:22,588 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 3.0 (TID 7). 2953 bytes result sent to driver
2018-02-08 15:57:22,589 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 3.0 (TID 8, localhost, executor driver, partition 5, ANY, 4621 bytes)
2018-02-08 15:57:22,590 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 3.0 (TID 7) in 32 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:22,590 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 3.0 (TID 8)
2018-02-08 15:57:22,592 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 3.0 (TID 6). 2910 bytes result sent to driver
2018-02-08 15:57:22,593 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 3.0 (TID 9, localhost, executor driver, partition 6, ANY, 4621 bytes)
2018-02-08 15:57:22,595 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 3.0 (TID 6) in 69 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:22,600 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:22,600 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:22,600 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 3.0 (TID 9)
2018-02-08 15:57:22,603 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_5 stored as values in memory (estimated size 1136.0 B, free 631.3 MB)
2018-02-08 15:57:22,604 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_5 in memory on 192.168.11.26:62834 (size: 1136.0 B, free: 631.7 MB)
2018-02-08 15:57:22,606 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_5 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:57:22,608 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_5 in memory on 192.168.11.26:62834 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:57:22,610 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:22,610 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:22,616 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_6 stored as values in memory (estimated size 1104.0 B, free 631.3 MB)
2018-02-08 15:57:22,617 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_6 in memory on 192.168.11.26:62834 (size: 1104.0 B, free: 631.7 MB)
2018-02-08 15:57:22,618 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 3.0 (TID 8). 2953 bytes result sent to driver
2018-02-08 15:57:22,618 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_6 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:57:22,620 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 3.0 (TID 10, localhost, executor driver, partition 7, ANY, 4621 bytes)
2018-02-08 15:57:22,621 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_6 in memory on 192.168.11.26:62834 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:57:22,621 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 3.0 (TID 8) in 32 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:22,622 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 3.0 (TID 10)
2018-02-08 15:57:22,623 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 3.0 (TID 9). 2867 bytes result sent to driver
2018-02-08 15:57:22,624 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 3.0 (TID 11, localhost, executor driver, partition 8, ANY, 4621 bytes)
2018-02-08 15:57:22,627 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 3.0 (TID 9) in 33 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:22,628 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 3.0 (TID 11)
2018-02-08 15:57:22,632 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:22,633 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:22,633 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:22,633 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:22,636 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_8 stored as values in memory (estimated size 1184.0 B, free 631.3 MB)
2018-02-08 15:57:22,638 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_8 in memory on 192.168.11.26:62834 (size: 1184.0 B, free: 631.7 MB)
2018-02-08 15:57:22,638 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_8 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:57:22,640 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_8 in memory on 192.168.11.26:62834 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:57:22,641 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 3.0 (TID 11). 2867 bytes result sent to driver
2018-02-08 15:57:22,641 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 3.0 (TID 12, localhost, executor driver, partition 9, ANY, 4621 bytes)
2018-02-08 15:57:22,642 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 3.0 (TID 11) in 18 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:22,642 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 3.0 (TID 12)
2018-02-08 15:57:22,649 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:22,649 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:22,652 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_7 stored as values in memory (estimated size 1184.0 B, free 631.3 MB)
2018-02-08 15:57:22,653 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_7 in memory on 192.168.11.26:62834 (size: 1184.0 B, free: 631.7 MB)
2018-02-08 15:57:22,655 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_7 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:57:22,656 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_7 in memory on 192.168.11.26:62834 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:57:22,658 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_9 stored as values in memory (estimated size 1184.0 B, free 631.3 MB)
2018-02-08 15:57:22,658 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 3.0 (TID 10). 2910 bytes result sent to driver
2018-02-08 15:57:22,659 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_9 in memory on 192.168.11.26:62834 (size: 1184.0 B, free: 631.7 MB)
2018-02-08 15:57:22,659 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 3.0 (TID 10) in 39 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:22,660 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_9 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:57:22,661 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_9 in memory on 192.168.11.26:62834 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:57:22,662 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 3.0 (TID 12). 2867 bytes result sent to driver
2018-02-08 15:57:22,667 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 3.0 (TID 12) in 26 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:22,667 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 15:57:22,669 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (count at ALS.scala:857) finished in 0.193 s
2018-02-08 15:57:22,673 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: count at ALS.scala:857, took 0.783961 s
2018-02-08 15:57:22,726 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:865
2018-02-08 15:57:22,730 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:57:22,732 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 19 (map at ALS.scala:1344)
2018-02-08 15:57:22,733 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (count at ALS.scala:865) with 10 output partitions
2018-02-08 15:57:22,733 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (count at ALS.scala:865)
2018-02-08 15:57:22,733 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 5)
2018-02-08 15:57:22,735 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 5)
2018-02-08 15:57:22,737 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 5 (MapPartitionsRDD[19] at map at ALS.scala:1344), which has no missing parents
2018-02-08 15:57:22,740 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 32.2 KB, free 631.3 MB)
2018-02-08 15:57:22,744 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 14.2 KB, free 631.3 MB)
2018-02-08 15:57:22,745 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:62834 (size: 14.2 KB, free: 631.7 MB)
2018-02-08 15:57:22,746 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:22,753 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[19] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:57:22,754 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
2018-02-08 15:57:22,759 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:57:22,762 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 13)
2018-02-08 15:57:22,768 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_13_0 locally
2018-02-08 15:57:22,837 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_4_piece0 on 192.168.11.26:62834 in memory (size: 14.5 KB, free: 631.7 MB)
2018-02-08 15:57:23,075 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 13). 2126 bytes result sent to driver
2018-02-08 15:57:23,077 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 13) in 320 ms on localhost (executor driver) (1/1)
2018-02-08 15:57:23,077 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 15:57:23,077 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 5 (map at ALS.scala:1344) finished in 0.321 s
2018-02-08 15:57:23,078 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:23,078 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:23,078 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 6)
2018-02-08 15:57:23,078 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:23,079 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (itemOutBlocks MapPartitionsRDD[22] at mapValues at ALS.scala:1381), which has no missing parents
2018-02-08 15:57:23,082 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 32.8 KB, free 631.3 MB)
2018-02-08 15:57:23,087 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.5 KB, free 631.3 MB)
2018-02-08 15:57:23,090 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:62834 (size: 14.5 KB, free: 631.7 MB)
2018-02-08 15:57:23,091 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:23,092 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 6 (itemOutBlocks MapPartitionsRDD[22] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:23,092 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 10 tasks
2018-02-08 15:57:23,093 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 14, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:57:23,093 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 6.0 (TID 15, localhost, executor driver, partition 1, ANY, 4621 bytes)
2018-02-08 15:57:23,094 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 14)
2018-02-08 15:57:23,094 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 6.0 (TID 15)
2018-02-08 15:57:23,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:23,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:23,108 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_1 stored as values in memory (estimated size 1144.0 B, free 631.3 MB)
2018-02-08 15:57:23,111 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:23,111 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:23,112 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_1 in memory on 192.168.11.26:62834 (size: 1144.0 B, free: 631.7 MB)
2018-02-08 15:57:23,114 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_0 stored as values in memory (estimated size 1256.0 B, free 631.3 MB)
2018-02-08 15:57:23,115 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_1 stored as values in memory (estimated size 616.0 B, free 631.3 MB)
2018-02-08 15:57:23,117 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_0 in memory on 192.168.11.26:62834 (size: 1256.0 B, free: 631.7 MB)
2018-02-08 15:57:23,118 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_1 in memory on 192.168.11.26:62834 (size: 616.0 B, free: 631.7 MB)
2018-02-08 15:57:23,120 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_0 stored as values in memory (estimated size 640.0 B, free 631.3 MB)
2018-02-08 15:57:23,120 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 6.0 (TID 15). 2910 bytes result sent to driver
2018-02-08 15:57:23,121 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_0 in memory on 192.168.11.26:62834 (size: 640.0 B, free: 631.7 MB)
2018-02-08 15:57:23,122 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 6.0 (TID 16, localhost, executor driver, partition 2, ANY, 4621 bytes)
2018-02-08 15:57:23,123 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 6.0 (TID 16)
2018-02-08 15:57:23,124 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 6.0 (TID 15) in 31 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:23,126 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 14). 2867 bytes result sent to driver
2018-02-08 15:57:23,127 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 6.0 (TID 17, localhost, executor driver, partition 3, ANY, 4621 bytes)
2018-02-08 15:57:23,128 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 6.0 (TID 17)
2018-02-08 15:57:23,129 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 14) in 36 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:23,137 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:23,137 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:23,138 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:23,139 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:23,140 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_3 stored as values in memory (estimated size 1160.0 B, free 631.3 MB)
2018-02-08 15:57:23,141 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_2 stored as values in memory (estimated size 1208.0 B, free 631.3 MB)
2018-02-08 15:57:23,142 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_3 in memory on 192.168.11.26:62834 (size: 1160.0 B, free: 631.7 MB)
2018-02-08 15:57:23,143 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_2 in memory on 192.168.11.26:62834 (size: 1208.0 B, free: 631.7 MB)
2018-02-08 15:57:23,143 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_3 stored as values in memory (estimated size 600.0 B, free 631.3 MB)
2018-02-08 15:57:23,146 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_2 stored as values in memory (estimated size 608.0 B, free 631.3 MB)
2018-02-08 15:57:23,147 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_3 in memory on 192.168.11.26:62834 (size: 600.0 B, free: 631.7 MB)
2018-02-08 15:57:23,147 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_2 in memory on 192.168.11.26:62834 (size: 608.0 B, free: 631.7 MB)
2018-02-08 15:57:23,149 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 6.0 (TID 17). 2910 bytes result sent to driver
2018-02-08 15:57:23,149 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 6.0 (TID 16). 2910 bytes result sent to driver
2018-02-08 15:57:23,149 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 6.0 (TID 18, localhost, executor driver, partition 4, ANY, 4621 bytes)
2018-02-08 15:57:23,150 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 6.0 (TID 19, localhost, executor driver, partition 5, ANY, 4621 bytes)
2018-02-08 15:57:23,150 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 6.0 (TID 18)
2018-02-08 15:57:23,151 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 6.0 (TID 16) in 29 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:23,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 6.0 (TID 17) in 27 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:23,154 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 6.0 (TID 19)
2018-02-08 15:57:23,159 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:23,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:23,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:23,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:23,165 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_5 stored as values in memory (estimated size 1272.0 B, free 631.3 MB)
2018-02-08 15:57:23,165 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_4 stored as values in memory (estimated size 1336.0 B, free 631.3 MB)
2018-02-08 15:57:23,166 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_5 in memory on 192.168.11.26:62834 (size: 1272.0 B, free: 631.7 MB)
2018-02-08 15:57:23,167 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_4 in memory on 192.168.11.26:62834 (size: 1336.0 B, free: 631.7 MB)
2018-02-08 15:57:23,168 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_5 stored as values in memory (estimated size 616.0 B, free 631.3 MB)
2018-02-08 15:57:23,168 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_5 in memory on 192.168.11.26:62834 (size: 616.0 B, free: 631.7 MB)
2018-02-08 15:57:23,168 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_4 stored as values in memory (estimated size 648.0 B, free 631.3 MB)
2018-02-08 15:57:23,169 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_4 in memory on 192.168.11.26:62834 (size: 648.0 B, free: 631.7 MB)
2018-02-08 15:57:23,169 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 6.0 (TID 19). 2910 bytes result sent to driver
2018-02-08 15:57:23,170 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 6.0 (TID 20, localhost, executor driver, partition 6, ANY, 4621 bytes)
2018-02-08 15:57:23,171 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 6.0 (TID 18). 2867 bytes result sent to driver
2018-02-08 15:57:23,171 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 6.0 (TID 19) in 21 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:23,174 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 6.0 (TID 21, localhost, executor driver, partition 7, ANY, 4621 bytes)
2018-02-08 15:57:23,174 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 6.0 (TID 18) in 25 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:23,175 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 6.0 (TID 21)
2018-02-08 15:57:23,179 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 6.0 (TID 20)
2018-02-08 15:57:23,184 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:23,184 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:23,189 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_6 stored as values in memory (estimated size 1192.0 B, free 631.3 MB)
2018-02-08 15:57:23,190 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_6 in memory on 192.168.11.26:62834 (size: 1192.0 B, free: 631.7 MB)
2018-02-08 15:57:23,191 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_6 stored as values in memory (estimated size 632.0 B, free 631.3 MB)
2018-02-08 15:57:23,193 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_6 in memory on 192.168.11.26:62834 (size: 632.0 B, free: 631.7 MB)
2018-02-08 15:57:23,196 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 6.0 (TID 20). 2910 bytes result sent to driver
2018-02-08 15:57:23,197 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 6.0 (TID 22, localhost, executor driver, partition 8, ANY, 4621 bytes)
2018-02-08 15:57:23,198 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 6.0 (TID 22)
2018-02-08 15:57:23,198 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 6.0 (TID 20) in 28 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:23,202 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:23,202 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 6 ms
2018-02-08 15:57:23,204 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:23,204 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:23,207 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_8 stored as values in memory (estimated size 1160.0 B, free 631.3 MB)
2018-02-08 15:57:23,207 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_8 in memory on 192.168.11.26:62834 (size: 1160.0 B, free: 631.7 MB)
2018-02-08 15:57:23,208 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_8 stored as values in memory (estimated size 616.0 B, free 631.3 MB)
2018-02-08 15:57:23,211 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_8 in memory on 192.168.11.26:62834 (size: 616.0 B, free: 631.7 MB)
2018-02-08 15:57:23,211 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_7 stored as values in memory (estimated size 1256.0 B, free 631.3 MB)
2018-02-08 15:57:23,212 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 6.0 (TID 22). 2910 bytes result sent to driver
2018-02-08 15:57:23,212 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_7 in memory on 192.168.11.26:62834 (size: 1256.0 B, free: 631.7 MB)
2018-02-08 15:57:23,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 6.0 (TID 23, localhost, executor driver, partition 9, ANY, 4621 bytes)
2018-02-08 15:57:23,214 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 6.0 (TID 22) in 18 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:23,214 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 6.0 (TID 23)
2018-02-08 15:57:23,219 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_7 stored as values in memory (estimated size 640.0 B, free 631.3 MB)
2018-02-08 15:57:23,220 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_7 in memory on 192.168.11.26:62834 (size: 640.0 B, free: 631.7 MB)
2018-02-08 15:57:23,222 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:23,222 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:23,224 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_9 stored as values in memory (estimated size 1208.0 B, free 631.3 MB)
2018-02-08 15:57:23,225 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_9 in memory on 192.168.11.26:62834 (size: 1208.0 B, free: 631.7 MB)
2018-02-08 15:57:23,225 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_9 stored as values in memory (estimated size 632.0 B, free 631.3 MB)
2018-02-08 15:57:23,227 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_9 in memory on 192.168.11.26:62834 (size: 632.0 B, free: 631.7 MB)
2018-02-08 15:57:23,228 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 6.0 (TID 23). 2910 bytes result sent to driver
2018-02-08 15:57:23,229 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 6.0 (TID 21). 2910 bytes result sent to driver
2018-02-08 15:57:23,229 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 6.0 (TID 23) in 16 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:23,230 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 6.0 (TID 21) in 57 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:23,230 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 15:57:23,230 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (count at ALS.scala:865) finished in 0.138 s
2018-02-08 15:57:23,231 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: count at ALS.scala:865, took 0.504320 s
2018-02-08 15:57:23,599 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:944
2018-02-08 15:57:23,603 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:57:23,604 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 156 bytes
2018-02-08 15:57:23,604 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 23 (map at ALS.scala:1017)
2018-02-08 15:57:23,604 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 2 is 156 bytes
2018-02-08 15:57:23,605 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 28 (flatMap at ALS.scala:1433)
2018-02-08 15:57:23,606 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 37 (flatMap at ALS.scala:1433)
2018-02-08 15:57:23,607 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 46 (flatMap at ALS.scala:1433)
2018-02-08 15:57:23,607 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 55 (flatMap at ALS.scala:1433)
2018-02-08 15:57:23,607 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 64 (flatMap at ALS.scala:1433)
2018-02-08 15:57:23,607 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 73 (flatMap at ALS.scala:1433)
2018-02-08 15:57:23,608 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 82 (flatMap at ALS.scala:1433)
2018-02-08 15:57:23,608 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 91 (flatMap at ALS.scala:1433)
2018-02-08 15:57:23,609 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 100 (flatMap at ALS.scala:1433)
2018-02-08 15:57:23,610 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 109 (flatMap at ALS.scala:1433)
2018-02-08 15:57:23,610 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (count at ALS.scala:944) with 10 output partitions
2018-02-08 15:57:23,611 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 21 (count at ALS.scala:944)
2018-02-08 15:57:23,611 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 8)
2018-02-08 15:57:23,611 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 20)
2018-02-08 15:57:23,618 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[23] at map at ALS.scala:1017), which has no missing parents
2018-02-08 15:57:23,621 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 32.6 KB, free 631.2 MB)
2018-02-08 15:57:23,624 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.6 KB, free 631.2 MB)
2018-02-08 15:57:23,625 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:62834 (size: 14.6 KB, free: 631.7 MB)
2018-02-08 15:57:23,626 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:23,627 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[23] at map at ALS.scala:1017) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:23,628 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 10 tasks
2018-02-08 15:57:23,629 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:57:23,629 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 9.0 (TID 25, localhost, executor driver, partition 1, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:57:23,629 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 24)
2018-02-08 15:57:23,629 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 9.0 (TID 25)
2018-02-08 15:57:23,633 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:57:23,634 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:57:23,642 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 15:57:23,643 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 15:57:23,661 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 24). 2040 bytes result sent to driver
2018-02-08 15:57:23,665 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 9.0 (TID 25). 2040 bytes result sent to driver
2018-02-08 15:57:23,666 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 9.0 (TID 26, localhost, executor driver, partition 2, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:57:23,667 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 9.0 (TID 27, localhost, executor driver, partition 3, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:57:23,670 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 24) in 42 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:23,670 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 9.0 (TID 25) in 41 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:23,670 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 9.0 (TID 26)
2018-02-08 15:57:23,671 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 9.0 (TID 27)
2018-02-08 15:57:23,675 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:57:23,676 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:57:23,696 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 9.0 (TID 27). 1997 bytes result sent to driver
2018-02-08 15:57:23,697 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 9.0 (TID 28, localhost, executor driver, partition 4, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:57:23,698 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 9.0 (TID 28)
2018-02-08 15:57:23,698 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 9.0 (TID 27) in 32 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:23,698 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 9.0 (TID 26). 2040 bytes result sent to driver
2018-02-08 15:57:23,699 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 9.0 (TID 29, localhost, executor driver, partition 5, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:57:23,700 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 9.0 (TID 26) in 35 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:23,700 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 9.0 (TID 29)
2018-02-08 15:57:23,701 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:57:23,703 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:57:23,718 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 9.0 (TID 28). 2040 bytes result sent to driver
2018-02-08 15:57:23,719 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 9.0 (TID 30, localhost, executor driver, partition 6, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:57:23,720 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 9.0 (TID 30)
2018-02-08 15:57:23,720 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 9.0 (TID 28) in 24 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:23,724 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:57:23,736 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 9.0 (TID 30). 2083 bytes result sent to driver
2018-02-08 15:57:23,737 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 9.0 (TID 31, localhost, executor driver, partition 7, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:57:23,737 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 9.0 (TID 30) in 18 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:23,737 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 9.0 (TID 31)
2018-02-08 15:57:23,740 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:57:23,760 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 9.0 (TID 31). 1997 bytes result sent to driver
2018-02-08 15:57:23,760 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 9.0 (TID 29). 2083 bytes result sent to driver
2018-02-08 15:57:23,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 9.0 (TID 32, localhost, executor driver, partition 8, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:57:23,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 9.0 (TID 33, localhost, executor driver, partition 9, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:57:23,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 9.0 (TID 31) in 25 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:23,762 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 9.0 (TID 29) in 63 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:23,763 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 9.0 (TID 32)
2018-02-08 15:57:23,763 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 9.0 (TID 33)
2018-02-08 15:57:23,766 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:57:23,768 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:57:23,826 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 9.0 (TID 33). 2040 bytes result sent to driver
2018-02-08 15:57:23,837 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 9.0 (TID 33) in 76 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:23,838 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 9.0 (TID 32). 2083 bytes result sent to driver
2018-02-08 15:57:23,839 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 9.0 (TID 32) in 78 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:23,839 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-02-08 15:57:23,839 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 9 (map at ALS.scala:1017) finished in 0.211 s
2018-02-08 15:57:23,839 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:23,839 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:23,840 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 14, ShuffleMapStage 11)
2018-02-08 15:57:23,840 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:23,841 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 11 (MapPartitionsRDD[28] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:57:23,843 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 33.7 KB, free 631.2 MB)
2018-02-08 15:57:23,847 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.9 KB, free 631.2 MB)
2018-02-08 15:57:23,848 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:62834 (size: 14.9 KB, free: 631.6 MB)
2018-02-08 15:57:23,849 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:23,849 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[28] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:23,849 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 11.0 with 10 tasks
2018-02-08 15:57:23,852 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 11.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:57:23,852 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 11.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:57:23,853 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 11.0 (TID 34)
2018-02-08 15:57:23,855 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 11.0 (TID 35)
2018-02-08 15:57:23,857 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:57:23,858 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:23,858 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:23,859 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:57:23,860 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:23,860 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:23,919 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 11.0 (TID 35). 2470 bytes result sent to driver
2018-02-08 15:57:23,921 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 11.0 (TID 36, localhost, executor driver, partition 2, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:57:23,922 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 11.0 (TID 36)
2018-02-08 15:57:23,922 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 11.0 (TID 35) in 70 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:23,928 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:57:23,929 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:23,929 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:23,941 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 11.0 (TID 34). 2427 bytes result sent to driver
2018-02-08 15:57:23,942 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 11.0 (TID 37, localhost, executor driver, partition 3, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:57:23,943 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 11.0 (TID 34) in 93 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:23,943 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 11.0 (TID 37)
2018-02-08 15:57:23,947 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:57:23,947 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:23,948 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:23,981 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 11.0 (TID 36). 2427 bytes result sent to driver
2018-02-08 15:57:23,982 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 11.0 (TID 38, localhost, executor driver, partition 4, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:57:23,983 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 11.0 (TID 38)
2018-02-08 15:57:23,983 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 11.0 (TID 36) in 62 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:23,987 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:57:23,988 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:23,988 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,022 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 11.0 (TID 37). 2427 bytes result sent to driver
2018-02-08 15:57:24,024 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 11.0 (TID 39, localhost, executor driver, partition 5, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:57:24,025 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 11.0 (TID 37) in 83 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:24,026 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 11.0 (TID 39)
2018-02-08 15:57:24,037 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:57:24,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,101 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 11.0 (TID 38). 2470 bytes result sent to driver
2018-02-08 15:57:24,101 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 11.0 (TID 40, localhost, executor driver, partition 6, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:57:24,104 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 11.0 (TID 38) in 122 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:24,104 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 11.0 (TID 40)
2018-02-08 15:57:24,112 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:57:24,113 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,113 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,152 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 11.0 (TID 39). 2427 bytes result sent to driver
2018-02-08 15:57:24,153 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 11.0 (TID 41, localhost, executor driver, partition 7, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:57:24,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 11.0 (TID 39) in 131 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:24,154 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 11.0 (TID 41)
2018-02-08 15:57:24,158 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:57:24,158 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,158 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,209 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 11.0 (TID 40). 2427 bytes result sent to driver
2018-02-08 15:57:24,210 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 11.0 (TID 42, localhost, executor driver, partition 8, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:57:24,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 11.0 (TID 40) in 111 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:24,214 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 11.0 (TID 42)
2018-02-08 15:57:24,219 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:57:24,220 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,220 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,260 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 11.0 (TID 41). 2470 bytes result sent to driver
2018-02-08 15:57:24,260 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 11.0 (TID 42). 2513 bytes result sent to driver
2018-02-08 15:57:24,260 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 11.0 (TID 43, localhost, executor driver, partition 9, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:57:24,261 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 11.0 (TID 41) in 108 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:24,261 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 11.0 (TID 42) in 51 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:24,266 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 11.0 (TID 43)
2018-02-08 15:57:24,269 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:57:24,270 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,270 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,305 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 11.0 (TID 43). 2427 bytes result sent to driver
2018-02-08 15:57:24,306 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 11.0 (TID 43) in 46 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:24,306 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2018-02-08 15:57:24,306 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 11 (flatMap at ALS.scala:1433) finished in 0.456 s
2018-02-08 15:57:24,306 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:24,306 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:24,306 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 14)
2018-02-08 15:57:24,306 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:24,307 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 12 (MapPartitionsRDD[37] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:57:24,309 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 35.9 KB, free 631.1 MB)
2018-02-08 15:57:24,313 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 15.7 KB, free 631.1 MB)
2018-02-08 15:57:24,313 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.11.26:62834 (size: 15.7 KB, free: 631.6 MB)
2018-02-08 15:57:24,315 INFO[org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:24,315 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[37] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:24,315 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 12.0 with 10 tasks
2018-02-08 15:57:24,316 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 12.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,317 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 12.0 (TID 45, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,317 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 12.0 (TID 45)
2018-02-08 15:57:24,317 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 12.0 (TID 44)
2018-02-08 15:57:24,321 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:57:24,322 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:57:24,322 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,322 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,323 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:57:24,323 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:57:24,324 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,324 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:24,344 WARN[com.github.fommil.netlib.LAPACK:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2018-02-08 15:57:24,345 WARN[com.github.fommil.netlib.LAPACK:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2018-02-08 15:57:24,429 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 12.0 (TID 45). 2427 bytes result sent to driver
2018-02-08 15:57:24,430 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 12.0 (TID 46, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,431 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 12.0 (TID 46)
2018-02-08 15:57:24,431 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 12.0 (TID 45) in 115 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:24,431 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 12.0 (TID 44). 2427 bytes result sent to driver
2018-02-08 15:57:24,432 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 12.0 (TID 47, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,432 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 12.0 (TID 44) in 116 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:24,432 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 12.0 (TID 47)
2018-02-08 15:57:24,435 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:57:24,435 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:57:24,435 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,435 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,437 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:57:24,437 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:57:24,437 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,437 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,477 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 12.0 (TID 46). 2427 bytes result sent to driver
2018-02-08 15:57:24,477 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 12.0 (TID 48, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,478 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 12.0 (TID 46) in 48 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:24,478 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 12.0 (TID 48)
2018-02-08 15:57:24,483 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:57:24,483 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:57:24,485 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,485 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:24,492 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 12.0 (TID 47). 2427 bytes result sent to driver
2018-02-08 15:57:24,492 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 12.0 (TID 49, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,493 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 12.0 (TID 47) in 61 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:24,493 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 12.0 (TID 49)
2018-02-08 15:57:24,496 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:57:24,496 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:57:24,496 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,497 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:24,556 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 12.0 (TID 49). 2427 bytes result sent to driver
2018-02-08 15:57:24,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 12.0 (TID 50, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,557 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 12.0 (TID 50)
2018-02-08 15:57:24,557 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 12.0 (TID 49) in 65 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:24,559 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 12.0 (TID 48). 2427 bytes result sent to driver
2018-02-08 15:57:24,559 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 12.0 (TID 51, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,560 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 12.0 (TID 48) in 83 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:24,560 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 12.0 (TID 51)
2018-02-08 15:57:24,562 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:57:24,562 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:57:24,563 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,563 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,564 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:57:24,565 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:57:24,565 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,565 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,602 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 12.0 (TID 50). 2427 bytes result sent to driver
2018-02-08 15:57:24,603 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 12.0 (TID 52, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,603 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 12.0 (TID 52)
2018-02-08 15:57:24,603 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 12.0 (TID 50) in 47 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:24,606 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:57:24,606 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:57:24,607 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 12.0 (TID 51). 2427 bytes result sent to driver
2018-02-08 15:57:24,607 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,607 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,607 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 12.0 (TID 53, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,610 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 12.0 (TID 51) in 51 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:24,611 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 12.0 (TID 53)
2018-02-08 15:57:24,613 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:57:24,614 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:57:24,614 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,614 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,663 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 12.0 (TID 52). 2427 bytes result sent to driver
2018-02-08 15:57:24,664 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 12.0 (TID 52) in 61 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:24,664 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 12.0 (TID 53). 2427 bytes result sent to driver
2018-02-08 15:57:24,664 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 12.0 (TID 53) in 57 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:24,664 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2018-02-08 15:57:24,665 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 12 (flatMap at ALS.scala:1433) finished in 0.349 s
2018-02-08 15:57:24,665 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:24,665 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:24,665 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 14)
2018-02-08 15:57:24,665 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:24,666 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 13 (MapPartitionsRDD[46] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:57:24,668 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 36.9 KB, free 631.1 MB)
2018-02-08 15:57:24,670 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 16.0 KB, free 631.1 MB)
2018-02-08 15:57:24,670 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.11.26:62834 (size: 16.0 KB, free: 631.6 MB)
2018-02-08 15:57:24,671 INFO[org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:24,672 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[46] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:24,672 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 13.0 with 10 tasks
2018-02-08 15:57:24,672 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 13.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,672 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 13.0 (TID 55, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,673 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 13.0 (TID 55)
2018-02-08 15:57:24,673 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 13.0 (TID 54)
2018-02-08 15:57:24,675 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:57:24,676 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:57:24,676 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:57:24,676 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:57:24,676 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,676 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,676 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,676 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,721 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 13.0 (TID 55). 2427 bytes result sent to driver
2018-02-08 15:57:24,722 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 13.0 (TID 56, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,722 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 13.0 (TID 55) in 50 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:24,722 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 13.0 (TID 56)
2018-02-08 15:57:24,729 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:57:24,729 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:57:24,729 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,730 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:24,733 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 13.0 (TID 54). 2427 bytes result sent to driver
2018-02-08 15:57:24,733 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 13.0 (TID 57, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,734 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 13.0 (TID 57)
2018-02-08 15:57:24,734 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 13.0 (TID 54) in 62 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:24,737 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:57:24,738 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:57:24,738 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,738 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,780 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 13.0 (TID 56). 2427 bytes result sent to driver
2018-02-08 15:57:24,781 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 13.0 (TID 58, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,781 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 13.0 (TID 58)
2018-02-08 15:57:24,781 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 13.0 (TID 56) in 59 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:24,785 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:57:24,786 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:57:24,786 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,786 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,794 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 13.0 (TID 57). 2427 bytes result sent to driver
2018-02-08 15:57:24,794 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 13.0 (TID 59, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,795 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 13.0 (TID 57) in 62 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:24,795 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 13.0 (TID 59)
2018-02-08 15:57:24,798 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:57:24,798 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:57:24,799 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,799 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,824 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 13.0 (TID 58). 2427 bytes result sent to driver
2018-02-08 15:57:24,825 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 13.0 (TID 60, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,826 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 13.0 (TID 60)
2018-02-08 15:57:24,826 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 13.0 (TID 58) in 45 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:24,829 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:57:24,829 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:57:24,829 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,829 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,835 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 13.0 (TID 59). 2470 bytes result sent to driver
2018-02-08 15:57:24,836 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 13.0 (TID 61, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,836 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 13.0 (TID 59) in 42 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:24,837 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 13.0 (TID 61)
2018-02-08 15:57:24,841 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:57:24,841 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:57:24,842 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,842 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,867 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 13.0 (TID 60). 2470 bytes result sent to driver
2018-02-08 15:57:24,868 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 13.0 (TID 62, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,868 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 13.0 (TID 60) in 43 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:24,868 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 13.0 (TID 62)
2018-02-08 15:57:24,872 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:57:24,872 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:57:24,872 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,872 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,874 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 13.0 (TID 61). 2427 bytes result sent to driver
2018-02-08 15:57:24,875 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 13.0 (TID 63, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,875 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 13.0 (TID 61) in 39 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:24,875 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 13.0 (TID 63)
2018-02-08 15:57:24,878 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:57:24,878 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:57:24,879 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,879 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:24,905 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 13.0 (TID 62). 2427 bytes result sent to driver
2018-02-08 15:57:24,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 13.0 (TID 62) in 39 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:24,907 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 13.0 (TID 63). 2427 bytes result sent to driver
2018-02-08 15:57:24,907 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 13.0 (TID 63) in 33 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:24,908 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2018-02-08 15:57:24,909 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 13 (flatMap at ALS.scala:1433) finished in 0.236 s
2018-02-08 15:57:24,909 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:24,909 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:24,909 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 14)
2018-02-08 15:57:24,910 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:24,911 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 14 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:57:24,913 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 37.8 KB, free 631.0 MB)
2018-02-08 15:57:24,915 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 16.2 KB, free 631.0 MB)
2018-02-08 15:57:24,916 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.11.26:62834 (size: 16.2 KB, free: 631.6 MB)
2018-02-08 15:57:24,917 INFO[org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:24,917 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:24,917 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 14.0 with 10 tasks
2018-02-08 15:57:24,918 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 14.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,918 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 14.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,919 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 14.0 (TID 64)
2018-02-08 15:57:24,919 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 14.0 (TID 65)
2018-02-08 15:57:24,922 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:57:24,922 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:57:24,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,923 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:57:24,923 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:24,923 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:57:24,924 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,924 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:24,962 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 14.0 (TID 64). 2470 bytes result sent to driver
2018-02-08 15:57:24,962 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 14.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:24,963 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 14.0 (TID 66)
2018-02-08 15:57:24,963 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 14.0 (TID 64) in 45 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:24,966 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:57:24,968 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:57:24,968 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:24,969 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,024 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 14.0 (TID 65). 2427 bytes result sent to driver
2018-02-08 15:57:25,025 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 14.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,027 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 14.0 (TID 67)
2018-02-08 15:57:25,027 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 14.0 (TID 65) in 109 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:25,029 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 14.0 (TID 66). 2427 bytes result sent to driver
2018-02-08 15:57:25,030 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 14.0 (TID 68, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,032 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:57:25,032 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 14.0 (TID 66) in 70 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:25,032 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 14.0 (TID 68)
2018-02-08 15:57:25,032 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:57:25,033 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,033 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,035 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:57:25,036 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:57:25,036 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,036 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,064 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 14.0 (TID 67). 2470 bytes result sent to driver
2018-02-08 15:57:25,065 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 14.0 (TID 69, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,065 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 14.0 (TID 69)
2018-02-08 15:57:25,066 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 14.0 (TID 67) in 40 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:25,066 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 14.0 (TID 68). 2427 bytes result sent to driver
2018-02-08 15:57:25,067 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 14.0 (TID 70, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,067 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 14.0 (TID 68) in 37 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:25,067 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 14.0 (TID 70)
2018-02-08 15:57:25,069 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:57:25,069 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:57:25,069 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,069 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,070 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:57:25,070 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:57:25,071 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,071 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,098 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 14.0 (TID 69). 2427 bytes result sent to driver
2018-02-08 15:57:25,099 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 14.0 (TID 71, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,099 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 14.0 (TID 69) in 34 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:25,099 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 14.0 (TID 71)
2018-02-08 15:57:25,100 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 14.0 (TID 70). 2427 bytes result sent to driver
2018-02-08 15:57:25,100 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 14.0 (TID 72, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,101 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 14.0 (TID 70) in 34 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:25,102 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 14.0 (TID 72)
2018-02-08 15:57:25,102 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:57:25,103 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:57:25,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,105 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:57:25,105 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:57:25,106 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,106 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,133 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 14.0 (TID 71). 2427 bytes result sent to driver
2018-02-08 15:57:25,134 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 14.0 (TID 73, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,134 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 14.0 (TID 71) in 35 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:25,136 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 14.0 (TID 72). 2427 bytes result sent to driver
2018-02-08 15:57:25,136 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 14.0 (TID 73)
2018-02-08 15:57:25,137 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 14.0 (TID 72) in 37 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:25,141 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:57:25,142 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:57:25,148 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,149 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,189 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 14.0 (TID 73). 2470 bytes result sent to driver
2018-02-08 15:57:25,189 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 14.0 (TID 73) in 55 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:25,189 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-02-08 15:57:25,190 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 14 (flatMap at ALS.scala:1433) finished in 0.272 s
2018-02-08 15:57:25,190 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:25,190 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:25,190 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:57:25,190 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:25,193 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[64] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:57:25,196 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 38.7 KB, free 631.0 MB)
2018-02-08 15:57:25,197 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 16.5 KB, free 631.0 MB)
2018-02-08 15:57:25,198 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.11.26:62834 (size: 16.5 KB, free: 631.6 MB)
2018-02-08 15:57:25,198 INFO[org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:25,199 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[64] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:25,199 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 15.0 with 10 tasks
2018-02-08 15:57:25,199 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 15.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,200 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 15.0 (TID 75, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,200 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 15.0 (TID 74)
2018-02-08 15:57:25,200 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 15.0 (TID 75)
2018-02-08 15:57:25,203 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:57:25,203 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:57:25,203 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:57:25,203 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:57:25,204 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,204 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,204 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,204 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,235 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 15.0 (TID 75). 2513 bytes result sent to driver
2018-02-08 15:57:25,235 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 15.0 (TID 76, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,236 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 15.0 (TID 76)
2018-02-08 15:57:25,236 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 15.0 (TID 75) in 36 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:25,239 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 15.0 (TID 74). 2470 bytes result sent to driver
2018-02-08 15:57:25,241 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 15.0 (TID 77, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,241 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 15.0 (TID 74) in 42 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:25,243 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:57:25,243 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:57:25,243 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 15.0 (TID 77)
2018-02-08 15:57:25,244 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,244 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,246 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:57:25,246 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:57:25,247 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,247 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,290 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 15.0 (TID 77). 2427 bytes result sent to driver
2018-02-08 15:57:25,291 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 15.0 (TID 76). 2427 bytes result sent to driver
2018-02-08 15:57:25,291 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 15.0 (TID 78, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,291 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 15.0 (TID 78)
2018-02-08 15:57:25,292 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 15.0 (TID 77) in 50 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:25,293 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 15.0 (TID 79, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,293 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 15.0 (TID 76) in 58 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:25,294 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 15.0 (TID 79)
2018-02-08 15:57:25,295 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:57:25,295 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:57:25,295 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,295 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,307 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:57:25,307 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:57:25,308 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,308 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,360 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 15.0 (TID 78). 2427 bytes result sent to driver
2018-02-08 15:57:25,361 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 15.0 (TID 80, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,361 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 15.0 (TID 78) in 71 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:25,362 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 15.0 (TID 80)
2018-02-08 15:57:25,362 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 15.0 (TID 79). 2470 bytes result sent to driver
2018-02-08 15:57:25,363 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 15.0 (TID 81, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,364 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 15.0 (TID 79) in 72 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:25,364 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 15.0 (TID 81)
2018-02-08 15:57:25,365 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:57:25,365 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:57:25,365 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,365 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,375 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:57:25,376 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:57:25,379 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,393 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 14 ms
2018-02-08 15:57:25,414 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 15.0 (TID 80). 2427 bytes result sent to driver
2018-02-08 15:57:25,415 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 15.0 (TID 82, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,417 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 15.0 (TID 80) in 57 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:25,417 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 15.0 (TID 82)
2018-02-08 15:57:25,424 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:57:25,424 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:57:25,424 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,425 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,449 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 15.0 (TID 81). 2427 bytes result sent to driver
2018-02-08 15:57:25,450 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 15.0 (TID 83, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,451 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 15.0 (TID 81) in 88 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:25,451 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 15.0 (TID 83)
2018-02-08 15:57:25,455 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:57:25,455 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:57:25,455 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,456 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,478 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 15.0 (TID 82). 2470 bytes result sent to driver
2018-02-08 15:57:25,479 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 15.0 (TID 82) in 65 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:25,493 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 15.0 (TID 83). 2427 bytes result sent to driver
2018-02-08 15:57:25,494 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 15.0 (TID 83) in 44 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:25,494 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2018-02-08 15:57:25,495 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 15 (flatMap at ALS.scala:1433) finished in 0.295 s
2018-02-08 15:57:25,495 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:25,495 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:25,495 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:57:25,495 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:25,496 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 16 (MapPartitionsRDD[73] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:57:25,498 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 39.6 KB, free 630.9 MB)
2018-02-08 15:57:25,501 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.6 KB, free 630.9 MB)
2018-02-08 15:57:25,502 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.11.26:62834 (size: 16.6 KB, free: 631.6 MB)
2018-02-08 15:57:25,502 INFO[org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:25,503 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[73] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:25,503 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 16.0 with 10 tasks
2018-02-08 15:57:25,504 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 16.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,504 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 16.0 (TID 85, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,505 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 16.0 (TID 84)
2018-02-08 15:57:25,506 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 16.0 (TID 85)
2018-02-08 15:57:25,509 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:57:25,510 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:57:25,510 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,510 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,513 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:57:25,513 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:57:25,513 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,513 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,549 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 16.0 (TID 84). 2427 bytes result sent to driver
2018-02-08 15:57:25,551 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 16.0 (TID 86, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,553 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 16.0 (TID 84) in 49 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:25,554 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 16.0 (TID 86)
2018-02-08 15:57:25,554 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 16.0 (TID 85). 2427 bytes result sent to driver
2018-02-08 15:57:25,555 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 16.0 (TID 87, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,555 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 16.0 (TID 87)
2018-02-08 15:57:25,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 16.0 (TID 85) in 51 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:25,557 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:57:25,557 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:57:25,559 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,559 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,560 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:57:25,560 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:57:25,561 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,561 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,599 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 16.0 (TID 87). 2427 bytes result sent to driver
2018-02-08 15:57:25,600 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 16.0 (TID 88, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,600 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 16.0 (TID 87) in 45 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:25,600 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 16.0 (TID 88)
2018-02-08 15:57:25,601 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 16.0 (TID 86). 2427 bytes result sent to driver
2018-02-08 15:57:25,602 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 16.0 (TID 89, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,602 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 16.0 (TID 86) in 51 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:25,602 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 16.0 (TID 89)
2018-02-08 15:57:25,604 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:57:25,604 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:57:25,604 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,604 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,605 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:57:25,605 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:57:25,605 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,605 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,636 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 16.0 (TID 89). 2470 bytes result sent to driver
2018-02-08 15:57:25,637 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 16.0 (TID 90, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,637 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 16.0 (TID 90)
2018-02-08 15:57:25,637 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 16.0 (TID 89) in 35 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:25,642 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:57:25,642 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:57:25,642 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,642 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,667 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 16.0 (TID 88). 2427 bytes result sent to driver
2018-02-08 15:57:25,667 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 16.0 (TID 91, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,668 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 16.0 (TID 88) in 68 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:25,668 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 16.0 (TID 91)
2018-02-08 15:57:25,674 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:57:25,675 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:57:25,675 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,675 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,705 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 16.0 (TID 90). 2470 bytes result sent to driver
2018-02-08 15:57:25,706 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 16.0 (TID 92, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,706 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 16.0 (TID 92)
2018-02-08 15:57:25,706 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 16.0 (TID 90) in 70 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:25,709 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:57:25,709 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:57:25,709 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,710 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,723 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 16.0 (TID 91). 2470 bytes result sent to driver
2018-02-08 15:57:25,723 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 16.0 (TID 93, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,724 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 16.0 (TID 93)
2018-02-08 15:57:25,724 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 16.0 (TID 91) in 57 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:25,727 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:57:25,727 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:57:25,727 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,727 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,744 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 16.0 (TID 92). 2427 bytes result sent to driver
2018-02-08 15:57:25,745 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 16.0 (TID 92) in 39 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:25,753 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 16.0 (TID 93). 2427 bytes result sent to driver
2018-02-08 15:57:25,753 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 16.0 (TID 93) in 30 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:25,754 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2018-02-08 15:57:25,754 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 16 (flatMap at ALS.scala:1433) finished in 0.250 s
2018-02-08 15:57:25,754 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:25,754 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:25,754 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:57:25,754 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:25,755 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 17 (MapPartitionsRDD[82] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:57:25,757 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 40.5 KB, free 630.9 MB)
2018-02-08 15:57:25,759 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 16.9 KB, free 630.8 MB)
2018-02-08 15:57:25,760 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.11.26:62834 (size: 16.9 KB, free: 631.5 MB)
2018-02-08 15:57:25,760 INFO[org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:25,761 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[82] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:25,761 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 17.0 with 10 tasks
2018-02-08 15:57:25,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 17.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 17.0 (TID 95, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,762 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 17.0 (TID 95)
2018-02-08 15:57:25,762 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 17.0 (TID 94)
2018-02-08 15:57:25,764 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:57:25,764 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:57:25,765 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:57:25,764 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:57:25,765 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,765 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,765 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,765 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,808 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 17.0 (TID 94). 2427 bytes result sent to driver
2018-02-08 15:57:25,809 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 17.0 (TID 96, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,809 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 17.0 (TID 96)
2018-02-08 15:57:25,809 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 17.0 (TID 94) in 48 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:25,810 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 17.0 (TID 95). 2427 bytes result sent to driver
2018-02-08 15:57:25,811 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 17.0 (TID 97, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,811 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 17.0 (TID 95) in 50 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:25,812 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 17.0 (TID 97)
2018-02-08 15:57:25,819 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:57:25,820 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:57:25,820 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,820 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,821 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:57:25,821 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:57:25,821 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,821 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,858 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 17.0 (TID 96). 2470 bytes result sent to driver
2018-02-08 15:57:25,858 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 17.0 (TID 98, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,859 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 17.0 (TID 98)
2018-02-08 15:57:25,859 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 17.0 (TID 96) in 51 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:25,862 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:57:25,862 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:57:25,863 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 17.0 (TID 97). 2427 bytes result sent to driver
2018-02-08 15:57:25,863 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,863 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,863 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 17.0 (TID 99, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,865 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 17.0 (TID 97) in 54 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:25,865 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 17.0 (TID 99)
2018-02-08 15:57:25,869 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:57:25,869 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:57:25,869 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,870 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,898 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 17.0 (TID 98). 2427 bytes result sent to driver
2018-02-08 15:57:25,898 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 17.0 (TID 100, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,899 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 17.0 (TID 100)
2018-02-08 15:57:25,899 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 17.0 (TID 98) in 41 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:25,902 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:57:25,902 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:57:25,902 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,917 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 17.0 (TID 99). 2470 bytes result sent to driver
2018-02-08 15:57:25,917 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 17.0 (TID 101, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,918 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 17.0 (TID 99) in 55 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:25,918 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 17.0 (TID 101)
2018-02-08 15:57:25,919 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_12_piece0 on 192.168.11.26:62834 in memory (size: 16.5 KB, free: 631.6 MB)
2018-02-08 15:57:25,921 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:62834 in memory (size: 14.5 KB, free: 631.6 MB)
2018-02-08 15:57:25,922 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:62834 in memory (size: 14.6 KB, free: 631.6 MB)
2018-02-08 15:57:25,922 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.11.26:62834 in memory (size: 16.2 KB, free: 631.6 MB)
2018-02-08 15:57:25,923 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.11.26:62834 in memory (size: 14.9 KB, free: 631.6 MB)
2018-02-08 15:57:25,924 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:57:25,924 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.11.26:62834 in memory (size: 16.0 KB, free: 631.6 MB)
2018-02-08 15:57:25,924 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:57:25,925 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_13_piece0 on 192.168.11.26:62834 in memory (size: 16.6 KB, free: 631.7 MB)
2018-02-08 15:57:25,925 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.11.26:62834 in memory (size: 15.7 KB, free: 631.7 MB)
2018-02-08 15:57:25,926 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,926 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,949 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 17.0 (TID 100). 2470 bytes result sent to driver
2018-02-08 15:57:25,950 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 17.0 (TID 102, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,951 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 17.0 (TID 100) in 53 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:25,951 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 17.0 (TID 102)
2018-02-08 15:57:25,954 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 17.0 (TID 101). 2427 bytes result sent to driver
2018-02-08 15:57:25,954 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:57:25,954 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:57:25,954 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 17.0 (TID 103, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:25,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,955 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 17.0 (TID 103)
2018-02-08 15:57:25,955 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 17.0 (TID 101) in 38 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:25,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:25,959 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:57:25,959 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:57:25,960 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:25,960 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:25,985 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 17.0 (TID 102). 2470 bytes result sent to driver
2018-02-08 15:57:25,987 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 17.0 (TID 102) in 37 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:25,993 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 17.0 (TID 103). 2427 bytes result sent to driver
2018-02-08 15:57:25,993 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 17.0 (TID 103) in 39 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:25,994 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2018-02-08 15:57:25,994 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 17 (flatMap at ALS.scala:1433) finished in 0.233 s
2018-02-08 15:57:25,994 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:25,994 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:25,994 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 20, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:57:25,994 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:25,995 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[91] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:57:25,997 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 41.4 KB, free 631.2 MB)
2018-02-08 15:57:25,999 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 17.1 KB, free 631.2 MB)
2018-02-08 15:57:26,000 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.11.26:62834 (size: 17.1 KB, free: 631.7 MB)
2018-02-08 15:57:26,001 INFO[org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:26,001 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[91] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:26,002 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 18.0 with 10 tasks
2018-02-08 15:57:26,002 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 18.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,002 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 18.0 (TID 105, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,003 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 18.0 (TID 104)
2018-02-08 15:57:26,003 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 18.0 (TID 105)
2018-02-08 15:57:26,008 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:57:26,008 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:57:26,008 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:57:26,009 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:57:26,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,053 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 18.0 (TID 105). 2427 bytes result sent to driver
2018-02-08 15:57:26,057 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 18.0 (TID 106, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,057 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 18.0 (TID 105) in 55 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:26,058 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 18.0 (TID 106)
2018-02-08 15:57:26,059 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 18.0 (TID 104). 2470 bytes result sent to driver
2018-02-08 15:57:26,060 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 18.0 (TID 107, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,061 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 18.0 (TID 104) in 59 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:26,060 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 18.0 (TID 107)
2018-02-08 15:57:26,062 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:57:26,063 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:57:26,064 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,065 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:57:26,066 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:57:26,066 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:57:26,066 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,066 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,111 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 18.0 (TID 107). 2470 bytes result sent to driver
2018-02-08 15:57:26,113 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 18.0 (TID 108, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 18.0 (TID 107) in 54 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:26,114 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 18.0 (TID 108)
2018-02-08 15:57:26,118 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:57:26,118 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:57:26,119 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,119 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,129 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 18.0 (TID 106). 2470 bytes result sent to driver
2018-02-08 15:57:26,129 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 18.0 (TID 109, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,130 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 18.0 (TID 106) in 76 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:26,130 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 18.0 (TID 109)
2018-02-08 15:57:26,133 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:57:26,133 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:57:26,134 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,134 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,165 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 18.0 (TID 108). 2427 bytes result sent to driver
2018-02-08 15:57:26,165 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 18.0 (TID 110, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,166 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 18.0 (TID 110)
2018-02-08 15:57:26,166 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 18.0 (TID 108) in 53 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:26,169 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:57:26,169 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:57:26,170 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,170 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:26,171 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 18.0 (TID 109). 2427 bytes result sent to driver
2018-02-08 15:57:26,171 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 18.0 (TID 111, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,172 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 18.0 (TID 109) in 43 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:26,172 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 18.0 (TID 111)
2018-02-08 15:57:26,176 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:57:26,176 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:57:26,177 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,177 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:26,210 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 18.0 (TID 111). 2427 bytes result sent to driver
2018-02-08 15:57:26,211 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 18.0 (TID 112, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,211 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 18.0 (TID 112)
2018-02-08 15:57:26,211 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 18.0 (TID 111) in 40 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:26,214 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:57:26,215 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:57:26,215 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 18.0 (TID 110). 2427 bytes result sent to driver
2018-02-08 15:57:26,215 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,215 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,215 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 18.0 (TID 113, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,216 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 18.0 (TID 110) in 51 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:26,216 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 18.0 (TID 113)
2018-02-08 15:57:26,220 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:57:26,220 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:57:26,221 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,221 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:26,250 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 18.0 (TID 112). 2427 bytes result sent to driver
2018-02-08 15:57:26,251 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 18.0 (TID 112) in 40 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:26,254 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 18.0 (TID 113). 2470 bytes result sent to driver
2018-02-08 15:57:26,255 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 18.0 (TID 113) in 40 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:26,255 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2018-02-08 15:57:26,255 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 18 (flatMap at ALS.scala:1433) finished in 0.253 s
2018-02-08 15:57:26,255 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:26,255 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:26,255 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 20, ResultStage 21)
2018-02-08 15:57:26,256 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:26,256 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 19 (MapPartitionsRDD[100] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:57:26,258 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16 stored as values in memory (estimated size 42.4 KB, free 631.2 MB)
2018-02-08 15:57:26,260 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 17.3 KB, free 631.1 MB)
2018-02-08 15:57:26,260 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_16_piece0 in memory on 192.168.11.26:62834 (size: 17.3 KB, free: 631.6 MB)
2018-02-08 15:57:26,260 INFO[org.apache.spark.SparkContext:54] - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:26,261 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[100] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:26,261 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 19.0 with 10 tasks
2018-02-08 15:57:26,261 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 19.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,262 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 19.0 (TID 115, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,262 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 19.0 (TID 114)
2018-02-08 15:57:26,262 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 19.0 (TID 115)
2018-02-08 15:57:26,265 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:57:26,265 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:57:26,265 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:57:26,266 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:57:26,266 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,266 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,266 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,266 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,299 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 19.0 (TID 114). 2470 bytes result sent to driver
2018-02-08 15:57:26,300 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 19.0 (TID 116, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,300 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 19.0 (TID 114) in 39 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:26,300 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 19.0 (TID 116)
2018-02-08 15:57:26,301 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 19.0 (TID 115). 2470 bytes result sent to driver
2018-02-08 15:57:26,303 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 19.0 (TID 117, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,304 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 19.0 (TID 115) in 42 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:26,304 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:57:26,305 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:57:26,306 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,305 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 19.0 (TID 117)
2018-02-08 15:57:26,306 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,309 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:57:26,309 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:57:26,310 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,310 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,348 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 19.0 (TID 117). 2427 bytes result sent to driver
2018-02-08 15:57:26,349 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 19.0 (TID 118, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,349 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 19.0 (TID 118)
2018-02-08 15:57:26,349 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 19.0 (TID 117) in 47 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:26,353 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:57:26,353 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:57:26,354 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,354 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,357 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 19.0 (TID 116). 2427 bytes result sent to driver
2018-02-08 15:57:26,357 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 19.0 (TID 119, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,358 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 19.0 (TID 116) in 58 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:26,358 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 19.0 (TID 119)
2018-02-08 15:57:26,362 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:57:26,363 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:57:26,363 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,363 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,397 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 19.0 (TID 118). 2427 bytes result sent to driver
2018-02-08 15:57:26,398 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 19.0 (TID 120, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,398 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 19.0 (TID 118) in 50 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:26,398 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 19.0 (TID 120)
2018-02-08 15:57:26,402 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:57:26,402 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:57:26,402 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,402 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,402 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 19.0 (TID 119). 2427 bytes result sent to driver
2018-02-08 15:57:26,403 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 19.0 (TID 121, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,403 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 19.0 (TID 121)
2018-02-08 15:57:26,403 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 19.0 (TID 119) in 46 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:26,406 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:57:26,406 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:57:26,407 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,407 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,430 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 19.0 (TID 120). 2470 bytes result sent to driver
2018-02-08 15:57:26,430 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 19.0 (TID 122, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,431 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 19.0 (TID 120) in 33 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:26,431 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 19.0 (TID 122)
2018-02-08 15:57:26,433 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 19.0 (TID 121). 2470 bytes result sent to driver
2018-02-08 15:57:26,433 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 19.0 (TID 123, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,433 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 19.0 (TID 121) in 30 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:26,433 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 19.0 (TID 123)
2018-02-08 15:57:26,439 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:57:26,439 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:57:26,439 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,440 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:26,444 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:57:26,444 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:57:26,444 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,445 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:26,470 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 19.0 (TID 122). 2470 bytes result sent to driver
2018-02-08 15:57:26,473 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 19.0 (TID 122) in 43 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:26,476 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 19.0 (TID 123). 2427 bytes result sent to driver
2018-02-08 15:57:26,477 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 19.0 (TID 123) in 44 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:26,477 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2018-02-08 15:57:26,478 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 19 (flatMap at ALS.scala:1433) finished in 0.216 s
2018-02-08 15:57:26,478 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:26,478 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:26,478 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 20, ResultStage 21)
2018-02-08 15:57:26,478 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:26,479 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[109] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:57:26,480 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17 stored as values in memory (estimated size 43.3 KB, free 631.1 MB)
2018-02-08 15:57:26,482 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 17.5 KB, free 631.1 MB)
2018-02-08 15:57:26,483 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_17_piece0 in memory on 192.168.11.26:62834 (size: 17.5 KB, free: 631.6 MB)
2018-02-08 15:57:26,484 INFO[org.apache.spark.SparkContext:54] - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:26,485 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[109] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:26,485 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 20.0 with 10 tasks
2018-02-08 15:57:26,485 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 20.0 (TID 124, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,486 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 20.0 (TID 125, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,486 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 20.0 (TID 125)
2018-02-08 15:57:26,486 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 20.0 (TID 124)
2018-02-08 15:57:26,491 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:57:26,491 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:57:26,491 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:57:26,491 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:57:26,492 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,492 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,492 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,492 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,525 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 20.0 (TID 125). 2427 bytes result sent to driver
2018-02-08 15:57:26,525 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 20.0 (TID 126, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,526 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 20.0 (TID 125) in 41 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:26,526 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 20.0 (TID 126)
2018-02-08 15:57:26,528 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 20.0 (TID 124). 2427 bytes result sent to driver
2018-02-08 15:57:26,528 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 20.0 (TID 127, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,529 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 20.0 (TID 124) in 44 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:26,529 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 20.0 (TID 127)
2018-02-08 15:57:26,529 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:57:26,530 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:57:26,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,532 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:57:26,533 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:57:26,533 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,533 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,564 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 20.0 (TID 127). 2470 bytes result sent to driver
2018-02-08 15:57:26,565 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 20.0 (TID 128, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,565 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 20.0 (TID 127) in 37 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:26,565 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 20.0 (TID 128)
2018-02-08 15:57:26,566 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 20.0 (TID 126). 2427 bytes result sent to driver
2018-02-08 15:57:26,566 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 20.0 (TID 129, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,567 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 20.0 (TID 129)
2018-02-08 15:57:26,567 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 20.0 (TID 126) in 42 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:26,571 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:57:26,571 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:57:26,572 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,572 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,574 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:57:26,574 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:57:26,574 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,574 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,599 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 20.0 (TID 128). 2427 bytes result sent to driver
2018-02-08 15:57:26,599 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 20.0 (TID 130, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,600 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 20.0 (TID 128) in 36 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:26,600 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 20.0 (TID 130)
2018-02-08 15:57:26,601 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 20.0 (TID 129). 2427 bytes result sent to driver
2018-02-08 15:57:26,602 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 20.0 (TID 131, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,602 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 20.0 (TID 129) in 36 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:26,602 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 20.0 (TID 131)
2018-02-08 15:57:26,603 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:57:26,605 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:57:26,605 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:57:26,605 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:57:26,606 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,606 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,606 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,606 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,629 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 20.0 (TID 131). 2427 bytes result sent to driver
2018-02-08 15:57:26,630 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 20.0 (TID 132, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,630 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 20.0 (TID 132)
2018-02-08 15:57:26,630 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 20.0 (TID 131) in 29 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:26,631 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 20.0 (TID 130). 2427 bytes result sent to driver
2018-02-08 15:57:26,632 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 20.0 (TID 133, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:26,632 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 20.0 (TID 130) in 33 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:26,632 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 20.0 (TID 133)
2018-02-08 15:57:26,633 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:57:26,633 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:57:26,634 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,634 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,635 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:57:26,635 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:57:26,635 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,635 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,660 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 20.0 (TID 132). 2427 bytes result sent to driver
2018-02-08 15:57:26,661 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 20.0 (TID 132) in 31 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:26,674 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 20.0 (TID 133). 2427 bytes result sent to driver
2018-02-08 15:57:26,675 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 20.0 (TID 133) in 44 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:26,675 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2018-02-08 15:57:26,675 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 20 (flatMap at ALS.scala:1433) finished in 0.190 s
2018-02-08 15:57:26,675 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:26,676 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:26,676 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 21)
2018-02-08 15:57:26,676 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:26,676 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 21 (userFactors MapPartitionsRDD[119] at mapPartitions at ALS.scala:924), which has no missing parents
2018-02-08 15:57:26,680 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18 stored as values in memory (estimated size 44.4 KB, free 631.0 MB)
2018-02-08 15:57:26,683 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 17.8 KB, free 631.0 MB)
2018-02-08 15:57:26,683 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_18_piece0 in memory on 192.168.11.26:62834 (size: 17.8 KB, free: 631.6 MB)
2018-02-08 15:57:26,684 INFO[org.apache.spark.SparkContext:54] - Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:26,685 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 21 (userFactors MapPartitionsRDD[119] at mapPartitions at ALS.scala:924) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:26,685 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 21.0 with 10 tasks
2018-02-08 15:57:26,686 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 21.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,686 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 21.0 (TID 135, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,687 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 21.0 (TID 134)
2018-02-08 15:57:26,688 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 21.0 (TID 135)
2018-02-08 15:57:26,692 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:57:26,692 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:57:26,693 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:57:26,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:26,692 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:57:26,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:26,699 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_1 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:57:26,701 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_0 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:57:26,704 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_1 in memory on 192.168.11.26:62834 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:57:26,704 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_0 in memory on 192.168.11.26:62834 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:57:26,705 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 21.0 (TID 135). 2906 bytes result sent to driver
2018-02-08 15:57:26,708 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 21.0 (TID 136, localhost, executor driver, partition 2, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,708 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 21.0 (TID 135) in 22 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:26,709 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 21.0 (TID 136)
2018-02-08 15:57:26,710 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 21.0 (TID 134). 2949 bytes result sent to driver
2018-02-08 15:57:26,710 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 21.0 (TID 137, localhost, executor driver, partition 3, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,719 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 21.0 (TID 137)
2018-02-08 15:57:26,720 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:57:26,720 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:57:26,720 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,720 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,723 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:57:26,723 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 21.0 (TID 134) in 37 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:26,730 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:57:26,731 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,731 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,736 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_2 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:57:26,738 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_2 in memory on 192.168.11.26:62834 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:57:26,739 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 21.0 (TID 136). 2992 bytes result sent to driver
2018-02-08 15:57:26,740 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 21.0 (TID 138, localhost, executor driver, partition 4, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,740 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 21.0 (TID 136) in 32 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:26,740 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 21.0 (TID 138)
2018-02-08 15:57:26,743 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_3 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:57:26,745 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_3 in memory on 192.168.11.26:62834 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:57:26,746 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 21.0 (TID 137). 2906 bytes result sent to driver
2018-02-08 15:57:26,746 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:57:26,746 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:57:26,747 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,747 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,748 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 21.0 (TID 139, localhost, executor driver, partition 5, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,748 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 21.0 (TID 137) in 38 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:26,751 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 21.0 (TID 139)
2018-02-08 15:57:26,753 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_4 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:57:26,753 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_4 in memory on 192.168.11.26:62834 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:57:26,754 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 21.0 (TID 138). 2949 bytes result sent to driver
2018-02-08 15:57:26,755 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 21.0 (TID 140, localhost, executor driver, partition 6, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,755 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:57:26,755 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 21.0 (TID 140)
2018-02-08 15:57:26,755 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 21.0 (TID 138) in 15 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:26,755 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:57:26,756 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,756 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,758 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:57:26,758 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:57:26,759 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,759 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,759 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_5 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:57:26,759 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_5 in memory on 192.168.11.26:62834 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:57:26,762 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 21.0 (TID 139). 2906 bytes result sent to driver
2018-02-08 15:57:26,763 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 21.0 (TID 141, localhost, executor driver, partition 7, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,763 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 21.0 (TID 139) in 16 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:26,764 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 21.0 (TID 141)
2018-02-08 15:57:26,765 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_6 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:57:26,765 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_6 in memory on 192.168.11.26:62834 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:57:26,766 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 21.0 (TID 140). 2949 bytes result sent to driver
2018-02-08 15:57:26,766 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 21.0 (TID 142, localhost, executor driver, partition 8, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 21.0 (TID 140) in 12 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:26,767 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 21.0 (TID 142)
2018-02-08 15:57:26,767 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:57:26,767 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:57:26,768 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,768 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:26,770 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:57:26,770 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:57:26,770 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,770 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,771 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_7 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:57:26,771 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_7 in memory on 192.168.11.26:62834 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:57:26,773 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 21.0 (TID 141). 2949 bytes result sent to driver
2018-02-08 15:57:26,773 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 21.0 (TID 143, localhost, executor driver, partition 9, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,773 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 21.0 (TID 141) in 10 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:26,773 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 21.0 (TID 143)
2018-02-08 15:57:26,774 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_8 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:57:26,775 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_8 in memory on 192.168.11.26:62834 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:57:26,776 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 21.0 (TID 142). 2906 bytes result sent to driver
2018-02-08 15:57:26,778 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 21.0 (TID 142) in 11 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:26,779 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:57:26,779 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:57:26,779 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,779 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,782 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_9 stored as values in memory (estimated size 320.0 B, free 631.0 MB)
2018-02-08 15:57:26,783 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_9 in memory on 192.168.11.26:62834 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:57:26,783 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 21.0 (TID 143). 2949 bytes result sent to driver
2018-02-08 15:57:26,784 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 21.0 (TID 143) in 11 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:26,784 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2018-02-08 15:57:26,784 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 21 (count at ALS.scala:944) finished in 0.098 s
2018-02-08 15:57:26,785 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: count at ALS.scala:944, took 3.185467 s
2018-02-08 15:57:26,791 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 105 from persistence list
2018-02-08 15:57:26,795 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 105
2018-02-08 15:57:26,799 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:946
2018-02-08 15:57:26,799 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:57:26,800 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 156 bytes
2018-02-08 15:57:26,801 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 13 is 197 bytes
2018-02-08 15:57:26,801 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 2 is 156 bytes
2018-02-08 15:57:26,802 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 12 is 165 bytes
2018-02-08 15:57:26,802 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 11 is 245 bytes
2018-02-08 15:57:26,803 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 10 is 165 bytes
2018-02-08 15:57:26,803 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 9 is 246 bytes
2018-02-08 15:57:26,803 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 8 is 165 bytes
2018-02-08 15:57:26,804 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 7 is 247 bytes
2018-02-08 15:57:26,804 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 6 is 165 bytes
2018-02-08 15:57:26,805 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 5 is 242 bytes
2018-02-08 15:57:26,805 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 4 is 165 bytes
2018-02-08 15:57:26,806 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (count at ALS.scala:946) with 10 output partitions
2018-02-08 15:57:26,806 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 35 (count at ALS.scala:946)
2018-02-08 15:57:26,806 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 34, ShuffleMapStage 25)
2018-02-08 15:57:26,806 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:57:26,807 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 35 (itemFactors MapPartitionsRDD[124] at mapPartitions at ALS.scala:936), which has no missing parents
2018-02-08 15:57:26,810 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19 stored as values in memory (estimated size 43.5 KB, free 631.0 MB)
2018-02-08 15:57:26,811 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 17.6 KB, free 631.0 MB)
2018-02-08 15:57:26,812 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_19_piece0 in memory on 192.168.11.26:62834 (size: 17.6 KB, free: 631.6 MB)
2018-02-08 15:57:26,812 INFO[org.apache.spark.SparkContext:54] - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:26,813 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 35 (itemFactors MapPartitionsRDD[124] at mapPartitions at ALS.scala:936) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:26,813 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 35.0 with 10 tasks
2018-02-08 15:57:26,814 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 35.0 (TID 144, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,814 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 35.0 (TID 145, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,815 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 35.0 (TID 144)
2018-02-08 15:57:26,815 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 35.0 (TID 145)
2018-02-08 15:57:26,818 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:57:26,818 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:57:26,818 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:57:26,818 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:57:26,818 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,818 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,819 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:26,819 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:26,822 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_0 stored as values in memory (estimated size 1016.0 B, free 631.0 MB)
2018-02-08 15:57:26,822 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_1 stored as values in memory (estimated size 1016.0 B, free 631.0 MB)
2018-02-08 15:57:26,822 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_0 in memory on 192.168.11.26:62834 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:57:26,822 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_1 in memory on 192.168.11.26:62834 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:57:26,822 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 35.0 (TID 144). 2906 bytes result sent to driver
2018-02-08 15:57:26,823 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 35.0 (TID 145). 2906 bytes result sent to driver
2018-02-08 15:57:26,823 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 35.0 (TID 146, localhost, executor driver, partition 2, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,823 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 35.0 (TID 144) in 9 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:26,823 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 35.0 (TID 146)
2018-02-08 15:57:26,823 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 35.0 (TID 145) in 9 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:26,824 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 35.0 (TID 147, localhost, executor driver, partition 3, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,824 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 35.0 (TID 147)
2018-02-08 15:57:26,826 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:57:26,826 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:57:26,827 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,827 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,827 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:57:26,827 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:57:26,827 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,827 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,830 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_3 stored as values in memory (estimated size 1016.0 B, free 630.9 MB)
2018-02-08 15:57:26,830 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_2 stored as values in memory (estimated size 1016.0 B, free 631.0 MB)
2018-02-08 15:57:26,830 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_3 in memory on 192.168.11.26:62834 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:57:26,831 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_2 in memory on 192.168.11.26:62834 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:57:26,831 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 35.0 (TID 147). 2949 bytes result sent to driver
2018-02-08 15:57:26,832 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 35.0 (TID 148, localhost, executor driver, partition 4, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,832 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 35.0 (TID 146). 2949 bytes result sent to driver
2018-02-08 15:57:26,832 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 35.0 (TID 148)
2018-02-08 15:57:26,833 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 35.0 (TID 149, localhost, executor driver, partition 5, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,833 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 35.0 (TID 147) in 9 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:26,833 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 35.0 (TID 149)
2018-02-08 15:57:26,833 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 35.0 (TID 146) in 10 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:26,835 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:57:26,835 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:57:26,835 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:57:26,835 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,836 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:57:26,836 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:26,836 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,836 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,839 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_4 stored as values in memory (estimated size 1016.0 B, free 630.9 MB)
2018-02-08 15:57:26,839 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_5 stored as values in memory (estimated size 1016.0 B, free 630.9 MB)
2018-02-08 15:57:26,839 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_4 in memory on 192.168.11.26:62834 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:57:26,839 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_5 in memory on 192.168.11.26:62834 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:57:26,842 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 35.0 (TID 148). 2906 bytes result sent to driver
2018-02-08 15:57:26,842 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 35.0 (TID 149). 2906 bytes result sent to driver
2018-02-08 15:57:26,842 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 35.0 (TID 150, localhost, executor driver, partition 6, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,843 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 35.0 (TID 150)
2018-02-08 15:57:26,843 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 35.0 (TID 151, localhost, executor driver, partition 7, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,843 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 35.0 (TID 148) in 11 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:26,843 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 35.0 (TID 151)
2018-02-08 15:57:26,843 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 35.0 (TID 149) in 11 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:26,846 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:57:26,846 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:57:26,846 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:57:26,846 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:57:26,846 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,846 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,846 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,846 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,850 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_7 stored as values in memory (estimated size 1016.0 B, free 630.9 MB)
2018-02-08 15:57:26,850 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_7 in memory on 192.168.11.26:62834 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:57:26,850 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_6 stored as values in memory (estimated size 1016.0 B, free 630.9 MB)
2018-02-08 15:57:26,851 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 35.0 (TID 151). 2906 bytes result sent to driver
2018-02-08 15:57:26,851 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_6 in memory on 192.168.11.26:62834 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:57:26,851 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 35.0 (TID 152, localhost, executor driver, partition 8, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,852 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 35.0 (TID 150). 2906 bytes result sent to driver
2018-02-08 15:57:26,852 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 35.0 (TID 151) in 9 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:26,852 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 35.0 (TID 152)
2018-02-08 15:57:26,853 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 35.0 (TID 153, localhost, executor driver, partition 9, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:57:26,853 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 35.0 (TID 150) in 11 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:26,854 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 35.0 (TID 153)
2018-02-08 15:57:26,856 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:57:26,856 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:57:26,857 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,857 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,858 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:57:26,858 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:57:26,859 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:57:26,859 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:26,861 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_8 stored as values in memory (estimated size 1016.0 B, free 630.9 MB)
2018-02-08 15:57:26,862 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_8 in memory on 192.168.11.26:62834 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:57:26,862 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_9 stored as values in memory (estimated size 1016.0 B, free 630.9 MB)
2018-02-08 15:57:26,862 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 35.0 (TID 152). 2949 bytes result sent to driver
2018-02-08 15:57:26,863 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_9 in memory on 192.168.11.26:62834 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:57:26,864 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 35.0 (TID 153). 2949 bytes result sent to driver
2018-02-08 15:57:26,864 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 35.0 (TID 152) in 13 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:26,864 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 35.0 (TID 153) in 12 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:26,864 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2018-02-08 15:57:26,864 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 35 (count at ALS.scala:946) finished in 0.050 s
2018-02-08 15:57:26,865 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: count at ALS.scala:946, took 0.066144 s
2018-02-08 15:57:26,865 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 16 from persistence list
2018-02-08 15:57:26,867 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 16
2018-02-08 15:57:26,870 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 17 from persistence list
2018-02-08 15:57:26,870 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 17
2018-02-08 15:57:26,871 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 21 from persistence list
2018-02-08 15:57:26,872 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 21
2018-02-08 15:57:26,872 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 22 from persistence list
2018-02-08 15:57:26,873 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 22
2018-02-08 15:57:26,873 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 13 from persistence list
2018-02-08 15:57:26,874 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 13
2018-02-08 15:57:27,044 INFO[org.apache.spark.ml.util.Instrumentation:54] - ALS-als_915fe4453bac-627727856-1: training finished
2018-02-08 15:57:27,260 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 22.069767 ms
2018-02-08 15:57:27,273 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.563524 ms
2018-02-08 15:57:27,286 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.068803 ms
2018-02-08 15:57:27,306 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 17.377926 ms
2018-02-08 15:57:27,357 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.518405 ms
2018-02-08 15:57:27,511 INFO[org.apache.spark.SparkContext:54] - Starting job: aggregate at RegressionMetrics.scala:57
2018-02-08 15:57:27,515 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 142 (rdd at RegressionEvaluator.scala:82)
2018-02-08 15:57:27,516 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 3 is 240 bytes
2018-02-08 15:57:27,517 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 127 (rdd at RegressionEvaluator.scala:82)
2018-02-08 15:57:27,517 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 132 (rdd at RegressionEvaluator.scala:82)
2018-02-08 15:57:27,517 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 137 (rdd at RegressionEvaluator.scala:82)
2018-02-08 15:57:27,517 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (aggregate at RegressionMetrics.scala:57) with 200 output partitions
2018-02-08 15:57:27,517 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 54 (aggregate at RegressionMetrics.scala:57)
2018-02-08 15:57:27,517 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 49, ShuffleMapStage 53)
2018-02-08 15:57:27,518 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 49, ShuffleMapStage 53)
2018-02-08 15:57:27,524 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 49 (MapPartitionsRDD[142] at rdd at RegressionEvaluator.scala:82), which has no missing parents
2018-02-08 15:57:27,529 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20 stored as values in memory (estimated size 50.9 KB, free 631.0 MB)
2018-02-08 15:57:27,531 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 20.7 KB, free 630.9 MB)
2018-02-08 15:57:27,531 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_20_piece0 in memory on 192.168.11.26:62834 (size: 20.7 KB, free: 631.6 MB)
2018-02-08 15:57:27,531 INFO[org.apache.spark.SparkContext:54] - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:27,533 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[142] at rdd at RegressionEvaluator.scala:82) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:27,533 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 49.0 with 10 tasks
2018-02-08 15:57:27,534 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 49.0 (TID 154, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:27,534 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 49.0 (TID 155, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:27,536 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 51 (MapPartitionsRDD[127] at rdd at RegressionEvaluator.scala:82), which has no missing parents
2018-02-08 15:57:27,538 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 49.0 (TID 154)
2018-02-08 15:57:27,541 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:57:27,541 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21 stored as values in memory (estimated size 23.0 KB, free 630.9 MB)
2018-02-08 15:57:27,543 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 10.7 KB, free 630.9 MB)
2018-02-08 15:57:27,543 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 49.0 (TID 155)
2018-02-08 15:57:27,545 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_21_piece0 in memory on 192.168.11.26:62834 (size: 10.7 KB, free: 631.6 MB)
2018-02-08 15:57:27,547 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:57:27,549 INFO[org.apache.spark.SparkContext:54] - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:27,550 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[127] at rdd at RegressionEvaluator.scala:82) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:57:27,550 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 51.0 with 1 tasks
2018-02-08 15:57:27,551 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 52 (MapPartitionsRDD[132] at rdd at RegressionEvaluator.scala:82), which has no missing parents
2018-02-08 15:57:27,554 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22 stored as values in memory (estimated size 51.8 KB, free 630.9 MB)
2018-02-08 15:57:27,556 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 20.8 KB, free 630.8 MB)
2018-02-08 15:57:27,557 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_22_piece0 in memory on 192.168.11.26:62834 (size: 20.8 KB, free: 631.6 MB)
2018-02-08 15:57:27,557 INFO[org.apache.spark.SparkContext:54] - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:27,557 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[132] at rdd at RegressionEvaluator.scala:82) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:57:27,557 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 52.0 with 10 tasks
2018-02-08 15:57:27,565 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.645125 ms
2018-02-08 15:57:27,633 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 49.0 (TID 154). 2476 bytes result sent to driver
2018-02-08 15:57:27,634 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 49.0 (TID 156, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:27,634 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 49.0 (TID 154) in 100 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:27,634 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 49.0 (TID 156)
2018-02-08 15:57:27,637 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:57:27,649 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 49.0 (TID 155). 2519 bytes result sent to driver
2018-02-08 15:57:27,653 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 49.0 (TID 157, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:27,654 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 49.0 (TID 155) in 120 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:27,654 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 49.0 (TID 157)
2018-02-08 15:57:27,658 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:57:27,701 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 49.0 (TID 157). 2519 bytes result sent to driver
2018-02-08 15:57:27,703 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 49.0 (TID 158, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:27,707 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 49.0 (TID 158)
2018-02-08 15:57:27,707 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 49.0 (TID 157) in 54 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:27,711 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:57:27,712 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 49.0 (TID 156). 2476 bytes result sent to driver
2018-02-08 15:57:27,713 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 49.0 (TID 159, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:27,713 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 49.0 (TID 156) in 80 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:27,714 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 49.0 (TID 159)
2018-02-08 15:57:27,724 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:57:27,781 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 49.0 (TID 159). 2476 bytes result sent to driver
2018-02-08 15:57:27,781 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 49.0 (TID 160, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:27,782 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 49.0 (TID 159) in 69 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:27,782 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 49.0 (TID 160)
2018-02-08 15:57:27,783 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 49.0 (TID 158). 2476 bytes result sent to driver
2018-02-08 15:57:27,783 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 49.0 (TID 161, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:27,784 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 49.0 (TID 158) in 82 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:27,784 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 49.0 (TID 161)
2018-02-08 15:57:27,788 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:57:27,789 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:57:27,850 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 49.0 (TID 160). 2476 bytes result sent to driver
2018-02-08 15:57:27,852 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 49.0 (TID 162, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:27,854 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 49.0 (TID 160) in 72 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:27,854 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 49.0 (TID 162)
2018-02-08 15:57:27,858 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:57:27,869 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 49.0 (TID 161). 2476 bytes result sent to driver
2018-02-08 15:57:27,873 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 49.0 (TID 163, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:27,875 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 49.0 (TID 161) in 92 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:27,876 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 49.0 (TID 163)
2018-02-08 15:57:27,879 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:57:27,916 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 49.0 (TID 162). 2476 bytes result sent to driver
2018-02-08 15:57:27,916 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 51.0 (TID 164, localhost, executor driver, partition 0, PROCESS_LOCAL, 5313 bytes)
2018-02-08 15:57:27,917 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 49.0 (TID 162) in 65 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:27,918 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 51.0 (TID 164)
2018-02-08 15:57:27,925 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 49.0 (TID 163). 2476 bytes result sent to driver
2018-02-08 15:57:27,926 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 52.0 (TID 165, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:27,926 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 49.0 (TID 163) in 54 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:27,927 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 49.0, whose tasks have all completed, from pool 
2018-02-08 15:57:27,927 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 52.0 (TID 165)
2018-02-08 15:57:27,927 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 49 (rdd at RegressionEvaluator.scala:82) finished in 0.394 s
2018-02-08 15:57:27,928 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:27,928 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set(ShuffleMapStage 51, ShuffleMapStage 52)
2018-02-08 15:57:27,928 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 53, ResultStage 54)
2018-02-08 15:57:27,928 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:27,936 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:57:27,999 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 57.613138 ms
2018-02-08 15:57:28,001 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/als/sample_movielens_ratings.txt, range: 0-32363, partition values: [empty row]
2018-02-08 15:57:28,063 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 52.0 (TID 165). 2519 bytes result sent to driver
2018-02-08 15:57:28,066 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 52.0 (TID 166, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:28,069 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 52.0 (TID 166)
2018-02-08 15:57:28,069 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 52.0 (TID 165) in 143 ms on localhost (executor driver) (1/10)
2018-02-08 15:57:28,073 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:57:28,114 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 52.0 (TID 166). 2476 bytes result sent to driver
2018-02-08 15:57:28,115 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 52.0 (TID 167, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:28,115 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 52.0 (TID 167)
2018-02-08 15:57:28,115 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 52.0 (TID 166) in 49 ms on localhost (executor driver) (2/10)
2018-02-08 15:57:28,119 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:57:28,133 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 51.0 (TID 164). 2367 bytes result sent to driver
2018-02-08 15:57:28,134 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 52.0 (TID 168, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:28,134 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 51.0 (TID 164) in 218 ms on localhost (executor driver) (1/1)
2018-02-08 15:57:28,134 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 52.0 (TID 168)
2018-02-08 15:57:28,135 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 51 (rdd at RegressionEvaluator.scala:82) finished in 0.584 s
2018-02-08 15:57:28,135 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:28,135 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set(ShuffleMapStage 52)
2018-02-08 15:57:28,135 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 53, ResultStage 54)
2018-02-08 15:57:28,135 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:28,134 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2018-02-08 15:57:28,139 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:57:28,143 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 52.0 (TID 167). 2476 bytes result sent to driver
2018-02-08 15:57:28,144 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 52.0 (TID 169, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:28,144 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 52.0 (TID 169)
2018-02-08 15:57:28,144 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 52.0 (TID 167) in 30 ms on localhost (executor driver) (3/10)
2018-02-08 15:57:28,149 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:57:28,178 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 52.0 (TID 168). 2476 bytes result sent to driver
2018-02-08 15:57:28,178 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 52.0 (TID 170, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:28,179 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 52.0 (TID 168) in 45 ms on localhost (executor driver) (4/10)
2018-02-08 15:57:28,179 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 52.0 (TID 170)
2018-02-08 15:57:28,183 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:57:28,183 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 52.0 (TID 169). 2476 bytes result sent to driver
2018-02-08 15:57:28,183 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 52.0 (TID 171, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:28,184 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 52.0 (TID 169) in 41 ms on localhost (executor driver) (5/10)
2018-02-08 15:57:28,184 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 52.0 (TID 171)
2018-02-08 15:57:28,192 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:57:28,215 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 52.0 (TID 171). 2433 bytes result sent to driver
2018-02-08 15:57:28,216 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 52.0 (TID 172, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:28,216 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 52.0 (TID 171) in 33 ms on localhost (executor driver) (6/10)
2018-02-08 15:57:28,216 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 52.0 (TID 172)
2018-02-08 15:57:28,222 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:57:28,222 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 52.0 (TID 170). 2476 bytes result sent to driver
2018-02-08 15:57:28,228 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 52.0 (TID 173, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:28,229 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 52.0 (TID 170) in 51 ms on localhost (executor driver) (7/10)
2018-02-08 15:57:28,230 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 52.0 (TID 173)
2018-02-08 15:57:28,237 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:57:28,260 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 52.0 (TID 173). 2519 bytes result sent to driver
2018-02-08 15:57:28,261 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 52.0 (TID 174, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:57:28,262 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 52.0 (TID 172). 2519 bytes result sent to driver
2018-02-08 15:57:28,262 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 52.0 (TID 173) in 39 ms on localhost (executor driver) (8/10)
2018-02-08 15:57:28,262 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 52.0 (TID 174)
2018-02-08 15:57:28,263 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 52.0 (TID 172) in 47 ms on localhost (executor driver) (9/10)
2018-02-08 15:57:28,265 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:57:28,294 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 52.0 (TID 174). 2519 bytes result sent to driver
2018-02-08 15:57:28,294 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 52.0 (TID 174) in 34 ms on localhost (executor driver) (10/10)
2018-02-08 15:57:28,294 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2018-02-08 15:57:28,295 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 52 (rdd at RegressionEvaluator.scala:82) finished in 0.737 s
2018-02-08 15:57:28,295 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:28,295 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:28,295 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 53, ResultStage 54)
2018-02-08 15:57:28,295 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:28,295 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 53 (MapPartitionsRDD[137] at rdd at RegressionEvaluator.scala:82), which has no missing parents
2018-02-08 15:57:28,305 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23 stored as values in memory (estimated size 62.5 KB, free 630.8 MB)
2018-02-08 15:57:28,308 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 24.8 KB, free 630.7 MB)
2018-02-08 15:57:28,309 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_23_piece0 in memory on 192.168.11.26:62834 (size: 24.8 KB, free: 631.6 MB)
2018-02-08 15:57:28,309 INFO[org.apache.spark.SparkContext:54] - Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:28,311 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 200 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[137] at rdd at RegressionEvaluator.scala:82) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-02-08 15:57:28,311 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 53.0 with 200 tasks
2018-02-08 15:57:28,340 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 53.0 (TID 175, localhost, executor driver, partition 0, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,341 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 53.0 (TID 176, localhost, executor driver, partition 1, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,342 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 53.0 (TID 175)
2018-02-08 15:57:28,344 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 53.0 (TID 176)
2018-02-08 15:57:28,351 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,351 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,353 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,353 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,441 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 86.527068 ms
2018-02-08 15:57:28,504 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 56.286418 ms
2018-02-08 15:57:28,508 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,508 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,528 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 19.605127 ms
2018-02-08 15:57:28,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,546 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.204483 ms
2018-02-08 15:57:28,562 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.192965 ms
2018-02-08 15:57:28,587 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.110726 ms
2018-02-08 15:57:28,597 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.307842 ms
2018-02-08 15:57:28,644 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 25.248648 ms
2018-02-08 15:57:28,650 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 53.0 (TID 175). 4161 bytes result sent to driver
2018-02-08 15:57:28,652 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 53.0 (TID 177, localhost, executor driver, partition 2, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,652 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 53.0 (TID 176). 4118 bytes result sent to driver
2018-02-08 15:57:28,652 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 53.0 (TID 175) in 340 ms on localhost (executor driver) (1/200)
2018-02-08 15:57:28,653 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 53.0 (TID 177)
2018-02-08 15:57:28,654 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 53.0 (TID 178, localhost, executor driver, partition 3, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,654 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 53.0 (TID 176) in 313 ms on localhost (executor driver) (2/200)
2018-02-08 15:57:28,654 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 53.0 (TID 178)
2018-02-08 15:57:28,662 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,662 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,684 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:57:28,688 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,689 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,693 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,693 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,694 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_15_piece0 on 192.168.11.26:62834 in memory (size: 17.1 KB, free: 631.6 MB)
2018-02-08 15:57:28,712 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 53.0 (TID 177). 4118 bytes result sent to driver
2018-02-08 15:57:28,714 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 53.0 (TID 178). 4204 bytes result sent to driver
2018-02-08 15:57:28,716 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 53.0 (TID 179, localhost, executor driver, partition 4, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,722 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 53.0 (TID 180, localhost, executor driver, partition 5, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,722 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 53.0 (TID 179)
2018-02-08 15:57:28,723 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 53.0 (TID 177) in 72 ms on localhost (executor driver) (3/200)
2018-02-08 15:57:28,723 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 53.0 (TID 178) in 69 ms on localhost (executor driver) (4/200)
2018-02-08 15:57:28,723 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 53.0 (TID 180)
2018-02-08 15:57:28,726 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,727 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,727 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,728 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,727 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_22_piece0 on 192.168.11.26:62834 in memory (size: 20.8 KB, free: 631.6 MB)
2018-02-08 15:57:28,731 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,731 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,736 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,736 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,743 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 53.0 (TID 180). 4075 bytes result sent to driver
2018-02-08 15:57:28,750 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 53.0 (TID 179). 4118 bytes result sent to driver
2018-02-08 15:57:28,752 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 53.0 (TID 181, localhost, executor driver, partition 6, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,752 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 53.0 (TID 182, localhost, executor driver, partition 7, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,755 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 53.0 (TID 180) in 34 ms on localhost (executor driver) (5/200)
2018-02-08 15:57:28,756 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 53.0 (TID 179) in 40 ms on localhost (executor driver) (6/200)
2018-02-08 15:57:28,756 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 53.0 (TID 181)
2018-02-08 15:57:28,757 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 53.0 (TID 182)
2018-02-08 15:57:28,761 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_17_piece0 on 192.168.11.26:62834 in memory (size: 17.5 KB, free: 631.6 MB)
2018-02-08 15:57:28,761 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,764 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 15:57:28,765 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 501
2018-02-08 15:57:28,766 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,766 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,767 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_21_piece0 on 192.168.11.26:62834 in memory (size: 10.7 KB, free: 631.6 MB)
2018-02-08 15:57:28,768 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 491
2018-02-08 15:57:28,768 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 494
2018-02-08 15:57:28,770 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_19_piece0 on 192.168.11.26:62834 in memory (size: 17.6 KB, free: 631.6 MB)
2018-02-08 15:57:28,771 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_16_piece0 on 192.168.11.26:62834 in memory (size: 17.3 KB, free: 631.7 MB)
2018-02-08 15:57:28,772 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 499
2018-02-08 15:57:28,772 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_20_piece0 on 192.168.11.26:62834 in memory (size: 20.7 KB, free: 631.7 MB)
2018-02-08 15:57:28,773 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_18_piece0 on 192.168.11.26:62834 in memory (size: 17.8 KB, free: 631.7 MB)
2018-02-08 15:57:28,773 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 492
2018-02-08 15:57:28,773 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 493
2018-02-08 15:57:28,774 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_14_piece0 on 192.168.11.26:62834 in memory (size: 16.9 KB, free: 631.7 MB)
2018-02-08 15:57:28,775 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 53.0 (TID 181). 4118 bytes result sent to driver
2018-02-08 15:57:28,776 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 53.0 (TID 183, localhost, executor driver, partition 8, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,776 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 53.0 (TID 181) in 24 ms on localhost (executor driver) (7/200)
2018-02-08 15:57:28,776 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 53.0 (TID 183)
2018-02-08 15:57:28,783 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,783 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,783 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,784 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,786 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,786 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,786 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,786 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,791 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 53.0 (TID 183). 4118 bytes result sent to driver
2018-02-08 15:57:28,793 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 53.0 (TID 184, localhost, executor driver, partition 9, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,793 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 53.0 (TID 182). 4075 bytes result sent to driver
2018-02-08 15:57:28,793 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 53.0 (TID 184)
2018-02-08 15:57:28,794 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 53.0 (TID 183) in 19 ms on localhost (executor driver) (8/200)
2018-02-08 15:57:28,798 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 53.0 (TID 185, localhost, executor driver, partition 10, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,798 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 53.0 (TID 182) in 46 ms on localhost (executor driver) (9/200)
2018-02-08 15:57:28,799 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 53.0 (TID 185)
2018-02-08 15:57:28,801 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,801 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,802 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,802 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,802 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,802 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,803 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,803 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,809 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 53.0 (TID 184). 4075 bytes result sent to driver
2018-02-08 15:57:28,811 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 53.0 (TID 185). 4075 bytes result sent to driver
2018-02-08 15:57:28,813 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 53.0 (TID 186, localhost, executor driver, partition 11, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,814 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 53.0 (TID 187, localhost, executor driver, partition 12, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,814 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 53.0 (TID 184) in 21 ms on localhost (executor driver) (10/200)
2018-02-08 15:57:28,815 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 53.0 (TID 185) in 17 ms on localhost (executor driver) (11/200)
2018-02-08 15:57:28,815 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 53.0 (TID 186)
2018-02-08 15:57:28,815 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 53.0 (TID 187)
2018-02-08 15:57:28,818 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,819 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,820 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,820 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,820 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,820 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,821 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,821 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,826 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 53.0 (TID 186). 4075 bytes result sent to driver
2018-02-08 15:57:28,827 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 53.0 (TID 188, localhost, executor driver, partition 13, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,828 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 53.0 (TID 186) in 17 ms on localhost (executor driver) (12/200)
2018-02-08 15:57:28,829 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 53.0 (TID 188)
2018-02-08 15:57:28,832 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 53.0 (TID 187). 4075 bytes result sent to driver
2018-02-08 15:57:28,833 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 53.0 (TID 189, localhost, executor driver, partition 15, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,834 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 53.0 (TID 187) in 21 ms on localhost (executor driver) (13/200)
2018-02-08 15:57:28,836 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 53.0 (TID 189)
2018-02-08 15:57:28,836 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,836 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,838 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,838 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,847 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 53.0 (TID 188). 4075 bytes result sent to driver
2018-02-08 15:57:28,848 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 53.0 (TID 190, localhost, executor driver, partition 16, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,848 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 53.0 (TID 188) in 22 ms on localhost (executor driver) (14/200)
2018-02-08 15:57:28,848 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 53.0 (TID 190)
2018-02-08 15:57:28,850 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,850 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,853 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,853 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,853 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,853 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,863 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,864 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,869 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 53.0 (TID 189). 4118 bytes result sent to driver
2018-02-08 15:57:28,872 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 53.0 (TID 191, localhost, executor driver, partition 17, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,873 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 53.0 (TID 189) in 40 ms on localhost (executor driver) (15/200)
2018-02-08 15:57:28,873 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 53.0 (TID 191)
2018-02-08 15:57:28,877 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 53.0 (TID 190). 4118 bytes result sent to driver
2018-02-08 15:57:28,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 53.0 (TID 192, localhost, executor driver, partition 18, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,878 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 53.0 (TID 192)
2018-02-08 15:57:28,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 53.0 (TID 190) in 31 ms on localhost (executor driver) (16/200)
2018-02-08 15:57:28,879 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,879 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,881 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,881 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,883 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,883 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,885 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,885 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,888 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 53.0 (TID 191). 4118 bytes result sent to driver
2018-02-08 15:57:28,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 53.0 (TID 193, localhost, executor driver, partition 20, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,889 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 53.0 (TID 193)
2018-02-08 15:57:28,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 53.0 (TID 191) in 17 ms on localhost (executor driver) (17/200)
2018-02-08 15:57:28,896 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,896 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,897 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 53.0 (TID 192). 4118 bytes result sent to driver
2018-02-08 15:57:28,898 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 53.0 (TID 194, localhost, executor driver, partition 21, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,898 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,898 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 53.0 (TID 192) in 20 ms on localhost (executor driver) (18/200)
2018-02-08 15:57:28,898 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,898 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 53.0 (TID 194)
2018-02-08 15:57:28,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,904 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,904 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,905 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 53.0 (TID 193). 4118 bytes result sent to driver
2018-02-08 15:57:28,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 53.0 (TID 195, localhost, executor driver, partition 22, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 53.0 (TID 193) in 17 ms on localhost (executor driver) (19/200)
2018-02-08 15:57:28,907 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 53.0 (TID 195)
2018-02-08 15:57:28,911 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 53.0 (TID 194). 4118 bytes result sent to driver
2018-02-08 15:57:28,913 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 53.0 (TID 196, localhost, executor driver, partition 23, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,914 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 53.0 (TID 194) in 16 ms on localhost (executor driver) (20/200)
2018-02-08 15:57:28,914 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 53.0 (TID 196)
2018-02-08 15:57:28,914 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,914 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,916 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,916 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,917 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,918 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,919 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,919 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,926 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 53.0 (TID 195). 4075 bytes result sent to driver
2018-02-08 15:57:28,927 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 53.0 (TID 197, localhost, executor driver, partition 25, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,927 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 53.0 (TID 196). 4118 bytes result sent to driver
2018-02-08 15:57:28,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 53.0 (TID 195) in 23 ms on localhost (executor driver) (21/200)
2018-02-08 15:57:28,928 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 53.0 (TID 197)
2018-02-08 15:57:28,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 53.0 (TID 198, localhost, executor driver, partition 26, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,929 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 53.0 (TID 196) in 16 ms on localhost (executor driver) (22/200)
2018-02-08 15:57:28,929 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 53.0 (TID 198)
2018-02-08 15:57:28,932 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,932 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,933 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,933 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,937 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,937 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,943 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,943 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 15:57:28,946 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 53.0 (TID 197). 4118 bytes result sent to driver
2018-02-08 15:57:28,947 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 53.0 (TID 199, localhost, executor driver, partition 27, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,947 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 53.0 (TID 199)
2018-02-08 15:57:28,947 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 53.0 (TID 197) in 20 ms on localhost (executor driver) (23/200)
2018-02-08 15:57:28,951 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,951 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,952 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 53.0 (TID 198). 4118 bytes result sent to driver
2018-02-08 15:57:28,953 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 53.0 (TID 200, localhost, executor driver, partition 28, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,953 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,956 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 53.0 (TID 200)
2018-02-08 15:57:28,956 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 53.0 (TID 198) in 26 ms on localhost (executor driver) (24/200)
2018-02-08 15:57:28,957 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 15:57:28,961 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,961 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,964 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,964 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,966 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 53.0 (TID 199). 4118 bytes result sent to driver
2018-02-08 15:57:28,967 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 53.0 (TID 201, localhost, executor driver, partition 29, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,967 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 53.0 (TID 199) in 21 ms on localhost (executor driver) (25/200)
2018-02-08 15:57:28,967 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 53.0 (TID 201)
2018-02-08 15:57:28,969 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 53.0 (TID 200). 4118 bytes result sent to driver
2018-02-08 15:57:28,969 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 53.0 (TID 202, localhost, executor driver, partition 31, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,969 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 53.0 (TID 202)
2018-02-08 15:57:28,969 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 53.0 (TID 200) in 17 ms on localhost (executor driver) (26/200)
2018-02-08 15:57:28,973 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,974 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,975 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,975 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,975 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,975 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,980 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 53.0 (TID 201). 4118 bytes result sent to driver
2018-02-08 15:57:28,981 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 53.0 (TID 203, localhost, executor driver, partition 32, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,981 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 53.0 (TID 201) in 15 ms on localhost (executor driver) (27/200)
2018-02-08 15:57:28,981 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 53.0 (TID 203)
2018-02-08 15:57:28,982 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 53.0 (TID 202). 4118 bytes result sent to driver
2018-02-08 15:57:28,982 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 53.0 (TID 204, localhost, executor driver, partition 33, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,982 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 53.0 (TID 204)
2018-02-08 15:57:28,982 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 53.0 (TID 202) in 13 ms on localhost (executor driver) (28/200)
2018-02-08 15:57:28,985 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,986 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:28,988 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:28,988 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:57:28,989 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,989 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,991 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:28,991 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:28,994 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 53.0 (TID 203). 4118 bytes result sent to driver
2018-02-08 15:57:28,995 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 53.0 (TID 205, localhost, executor driver, partition 34, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:28,995 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 53.0 (TID 205)
2018-02-08 15:57:28,995 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 53.0 (TID 203) in 14 ms on localhost (executor driver) (29/200)
2018-02-08 15:57:29,000 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,000 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:57:29,002 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,003 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,003 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 53.0 (TID 204). 4118 bytes result sent to driver
2018-02-08 15:57:29,003 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 53.0 (TID 206, localhost, executor driver, partition 35, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,004 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 53.0 (TID 206)
2018-02-08 15:57:29,004 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 53.0 (TID 204) in 22 ms on localhost (executor driver) (30/200)
2018-02-08 15:57:29,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,009 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 53.0 (TID 205). 4118 bytes result sent to driver
2018-02-08 15:57:29,011 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,011 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,011 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 53.0 (TID 207, localhost, executor driver, partition 36, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,012 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 53.0 (TID 207)
2018-02-08 15:57:29,012 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 53.0 (TID 205) in 18 ms on localhost (executor driver) (31/200)
2018-02-08 15:57:29,015 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,015 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,016 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 53.0 (TID 206). 4118 bytes result sent to driver
2018-02-08 15:57:29,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 53.0 (TID 208, localhost, executor driver, partition 37, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,017 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,017 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,017 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 53.0 (TID 208)
2018-02-08 15:57:29,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 53.0 (TID 206) in 14 ms on localhost (executor driver) (32/200)
2018-02-08 15:57:29,021 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,022 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,023 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 53.0 (TID 207). 4118 bytes result sent to driver
2018-02-08 15:57:29,023 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,023 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,023 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 53.0 (TID 209, localhost, executor driver, partition 38, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,023 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 53.0 (TID 209)
2018-02-08 15:57:29,023 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 53.0 (TID 207) in 12 ms on localhost (executor driver) (33/200)
2018-02-08 15:57:29,027 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,027 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,028 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 53.0 (TID 208). 4075 bytes result sent to driver
2018-02-08 15:57:29,028 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,028 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,028 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 53.0 (TID 210, localhost, executor driver, partition 39, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,029 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 53.0 (TID 210)
2018-02-08 15:57:29,029 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 53.0 (TID 208) in 13 ms on localhost (executor driver) (34/200)
2018-02-08 15:57:29,032 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,033 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,034 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 53.0 (TID 209). 4118 bytes result sent to driver
2018-02-08 15:57:29,034 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,034 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,035 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 53.0 (TID 211, localhost, executor driver, partition 40, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,035 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 53.0 (TID 211)
2018-02-08 15:57:29,035 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 53.0 (TID 209) in 12 ms on localhost (executor driver) (35/200)
2018-02-08 15:57:29,038 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,039 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,040 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 53.0 (TID 210). 4118 bytes result sent to driver
2018-02-08 15:57:29,041 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 53.0 (TID 212, localhost, executor driver, partition 41, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,041 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 53.0 (TID 212)
2018-02-08 15:57:29,041 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 53.0 (TID 210) in 13 ms on localhost (executor driver) (36/200)
2018-02-08 15:57:29,041 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,041 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,045 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,045 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,047 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,047 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,051 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 53.0 (TID 211). 4075 bytes result sent to driver
2018-02-08 15:57:29,052 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 53.0 (TID 213, localhost, executor driver, partition 42, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,052 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 53.0 (TID 213)
2018-02-08 15:57:29,052 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 53.0 (TID 211) in 18 ms on localhost (executor driver) (37/200)
2018-02-08 15:57:29,053 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 53.0 (TID 212). 4118 bytes result sent to driver
2018-02-08 15:57:29,054 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 53.0 (TID 214, localhost, executor driver, partition 44, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,054 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 53.0 (TID 212) in 14 ms on localhost (executor driver) (38/200)
2018-02-08 15:57:29,054 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 53.0 (TID 214)
2018-02-08 15:57:29,056 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,056 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,057 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,057 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,058 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,058 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,059 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,059 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,064 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 53.0 (TID 213). 4075 bytes result sent to driver
2018-02-08 15:57:29,067 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 53.0 (TID 214). 4075 bytes result sent to driver
2018-02-08 15:57:29,068 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 53.0 (TID 215, localhost, executor driver, partition 45, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,068 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 53.0 (TID 216, localhost, executor driver, partition 46, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,069 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 53.0 (TID 215)
2018-02-08 15:57:29,069 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 53.0 (TID 216)
2018-02-08 15:57:29,069 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 53.0 (TID 213) in 17 ms on localhost (executor driver) (39/200)
2018-02-08 15:57:29,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 53.0 (TID 214) in 17 ms on localhost (executor driver) (40/200)
2018-02-08 15:57:29,074 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,074 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,075 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,076 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,076 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,076 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,079 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,080 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,083 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 53.0 (TID 215). 4118 bytes result sent to driver
2018-02-08 15:57:29,090 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 53.0 (TID 217, localhost, executor driver, partition 47, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,091 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 53.0 (TID 215) in 24 ms on localhost (executor driver) (41/200)
2018-02-08 15:57:29,091 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 53.0 (TID 217)
2018-02-08 15:57:29,090 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 53.0 (TID 216). 4118 bytes result sent to driver
2018-02-08 15:57:29,092 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 53.0 (TID 218, localhost, executor driver, partition 50, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,092 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 53.0 (TID 216) in 24 ms on localhost (executor driver) (42/200)
2018-02-08 15:57:29,092 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 53.0 (TID 218)
2018-02-08 15:57:29,096 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,096 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,097 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,097 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,098 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,098 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,098 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,098 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,110 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 53.0 (TID 217). 4118 bytes result sent to driver
2018-02-08 15:57:29,110 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 53.0 (TID 219, localhost, executor driver, partition 52, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,111 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 53.0 (TID 217) in 21 ms on localhost (executor driver) (43/200)
2018-02-08 15:57:29,111 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 53.0 (TID 218). 4161 bytes result sent to driver
2018-02-08 15:57:29,111 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 53.0 (TID 219)
2018-02-08 15:57:29,112 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 53.0 (TID 220, localhost, executor driver, partition 54, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,112 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 53.0 (TID 218) in 20 ms on localhost (executor driver) (44/200)
2018-02-08 15:57:29,112 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 53.0 (TID 220)
2018-02-08 15:57:29,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,118 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,118 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,119 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,120 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,120 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,120 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,126 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 53.0 (TID 220). 4118 bytes result sent to driver
2018-02-08 15:57:29,127 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 53.0 (TID 221, localhost, executor driver, partition 55, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,128 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 53.0 (TID 220) in 16 ms on localhost (executor driver) (45/200)
2018-02-08 15:57:29,128 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 53.0 (TID 221)
2018-02-08 15:57:29,129 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 53.0 (TID 219). 4118 bytes result sent to driver
2018-02-08 15:57:29,129 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 53.0 (TID 222, localhost, executor driver, partition 56, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,129 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 53.0 (TID 222)
2018-02-08 15:57:29,129 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 53.0 (TID 219) in 19 ms on localhost (executor driver) (46/200)
2018-02-08 15:57:29,133 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,133 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,134 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,134 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,135 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,136 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,136 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,136 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,141 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 53.0 (TID 222). 4118 bytes result sent to driver
2018-02-08 15:57:29,141 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 53.0 (TID 223, localhost, executor driver, partition 57, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,141 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 53.0 (TID 223)
2018-02-08 15:57:29,142 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 53.0 (TID 221). 4118 bytes result sent to driver
2018-02-08 15:57:29,142 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 53.0 (TID 222) in 12 ms on localhost (executor driver) (47/200)
2018-02-08 15:57:29,142 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 53.0 (TID 224, localhost, executor driver, partition 58, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,143 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 53.0 (TID 221) in 15 ms on localhost (executor driver) (48/200)
2018-02-08 15:57:29,143 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 53.0 (TID 224)
2018-02-08 15:57:29,146 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,147 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,148 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,148 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,150 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,150 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,150 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,150 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,154 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 53.0 (TID 224). 4075 bytes result sent to driver
2018-02-08 15:57:29,155 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 53.0 (TID 225, localhost, executor driver, partition 59, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,156 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 53.0 (TID 223). 4118 bytes result sent to driver
2018-02-08 15:57:29,156 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 53.0 (TID 225)
2018-02-08 15:57:29,156 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 53.0 (TID 224) in 14 ms on localhost (executor driver) (49/200)
2018-02-08 15:57:29,156 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 53.0 (TID 226, localhost, executor driver, partition 60, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,157 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 53.0 (TID 223) in 16 ms on localhost (executor driver) (50/200)
2018-02-08 15:57:29,157 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 53.0 (TID 226)
2018-02-08 15:57:29,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,162 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,162 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,164 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,164 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,168 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 53.0 (TID 225). 4075 bytes result sent to driver
2018-02-08 15:57:29,169 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 53.0 (TID 227, localhost, executor driver, partition 61, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,169 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 53.0 (TID 225) in 14 ms on localhost (executor driver) (51/200)
2018-02-08 15:57:29,169 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 53.0 (TID 227)
2018-02-08 15:57:29,169 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 53.0 (TID 226). 4075 bytes result sent to driver
2018-02-08 15:57:29,170 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 53.0 (TID 228, localhost, executor driver, partition 62, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,170 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 53.0 (TID 226) in 14 ms on localhost (executor driver) (52/200)
2018-02-08 15:57:29,170 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 53.0 (TID 228)
2018-02-08 15:57:29,174 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,174 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,175 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,175 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,181 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 53.0 (TID 227). 4075 bytes result sent to driver
2018-02-08 15:57:29,182 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 53.0 (TID 229, localhost, executor driver, partition 63, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,183 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 53.0 (TID 227) in 14 ms on localhost (executor driver) (53/200)
2018-02-08 15:57:29,183 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 53.0 (TID 229)
2018-02-08 15:57:29,183 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 53.0 (TID 228). 4118 bytes result sent to driver
2018-02-08 15:57:29,183 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 53.0 (TID 230, localhost, executor driver, partition 64, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,184 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 53.0 (TID 230)
2018-02-08 15:57:29,184 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 53.0 (TID 228) in 15 ms on localhost (executor driver) (54/200)
2018-02-08 15:57:29,187 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,187 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,188 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,187 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,189 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,189 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,189 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,189 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,194 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 53.0 (TID 230). 4118 bytes result sent to driver
2018-02-08 15:57:29,196 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 53.0 (TID 231, localhost, executor driver, partition 65, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,197 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 53.0 (TID 229). 4118 bytes result sent to driver
2018-02-08 15:57:29,197 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 53.0 (TID 231)
2018-02-08 15:57:29,197 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 53.0 (TID 230) in 14 ms on localhost (executor driver) (55/200)
2018-02-08 15:57:29,198 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 53.0 (TID 232, localhost, executor driver, partition 67, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,198 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 53.0 (TID 229) in 16 ms on localhost (executor driver) (56/200)
2018-02-08 15:57:29,198 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 53.0 (TID 232)
2018-02-08 15:57:29,201 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,201 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,202 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,202 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,203 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,203 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,203 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,203 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,207 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 53.0 (TID 232). 4118 bytes result sent to driver
2018-02-08 15:57:29,208 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 53.0 (TID 233, localhost, executor driver, partition 68, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,208 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 53.0 (TID 231). 4118 bytes result sent to driver
2018-02-08 15:57:29,209 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 53.0 (TID 232) in 11 ms on localhost (executor driver) (57/200)
2018-02-08 15:57:29,209 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 53.0 (TID 233)
2018-02-08 15:57:29,211 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 53.0 (TID 234, localhost, executor driver, partition 70, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,212 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 53.0 (TID 231) in 16 ms on localhost (executor driver) (58/200)
2018-02-08 15:57:29,214 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 53.0 (TID 234)
2018-02-08 15:57:29,215 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,215 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,220 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,221 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,225 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,225 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,226 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,226 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,230 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 53.0 (TID 233). 4075 bytes result sent to driver
2018-02-08 15:57:29,231 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 53.0 (TID 235, localhost, executor driver, partition 71, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,231 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 53.0 (TID 235)
2018-02-08 15:57:29,231 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 53.0 (TID 233) in 23 ms on localhost (executor driver) (59/200)
2018-02-08 15:57:29,235 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,235 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,237 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,237 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,237 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 53.0 (TID 234). 4118 bytes result sent to driver
2018-02-08 15:57:29,238 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 53.0 (TID 236, localhost, executor driver, partition 72, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,238 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 53.0 (TID 236)
2018-02-08 15:57:29,238 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 53.0 (TID 234) in 28 ms on localhost (executor driver) (60/200)
2018-02-08 15:57:29,244 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,245 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,246 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,246 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,253 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 53.0 (TID 236). 4118 bytes result sent to driver
2018-02-08 15:57:29,253 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 53.0 (TID 237, localhost, executor driver, partition 73, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,254 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 53.0 (TID 237)
2018-02-08 15:57:29,254 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 53.0 (TID 236) in 16 ms on localhost (executor driver) (61/200)
2018-02-08 15:57:29,258 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,258 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,261 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,261 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,265 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 53.0 (TID 235). 4161 bytes result sent to driver
2018-02-08 15:57:29,266 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 53.0 (TID 238, localhost, executor driver, partition 74, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,267 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 53.0 (TID 235) in 36 ms on localhost (executor driver) (62/200)
2018-02-08 15:57:29,269 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 53.0 (TID 237). 4118 bytes result sent to driver
2018-02-08 15:57:29,270 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 53.0 (TID 238)
2018-02-08 15:57:29,270 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 53.0 (TID 239, localhost, executor driver, partition 75, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,271 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 53.0 (TID 237) in 18 ms on localhost (executor driver) (63/200)
2018-02-08 15:57:29,271 INFO[org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 53.0 (TID 239)
2018-02-08 15:57:29,274 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,275 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,275 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,275 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,276 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,276 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,277 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,277 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,283 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 53.0 (TID 238). 4118 bytes result sent to driver
2018-02-08 15:57:29,284 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 53.0 (TID 240, localhost, executor driver, partition 76, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,285 INFO[org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 53.0 (TID 239). 4075 bytes result sent to driver
2018-02-08 15:57:29,285 INFO[org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 53.0 (TID 240)
2018-02-08 15:57:29,285 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 53.0 (TID 238) in 20 ms on localhost (executor driver) (64/200)
2018-02-08 15:57:29,286 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 53.0 (TID 241, localhost, executor driver, partition 78, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,287 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 53.0 (TID 239) in 17 ms on localhost (executor driver) (65/200)
2018-02-08 15:57:29,288 INFO[org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 53.0 (TID 241)
2018-02-08 15:57:29,289 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,290 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,293 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,294 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,294 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,295 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,296 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,296 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,304 INFO[org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 53.0 (TID 241). 4118 bytes result sent to driver
2018-02-08 15:57:29,305 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 53.0 (TID 242, localhost, executor driver, partition 79, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,306 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 53.0 (TID 241) in 20 ms on localhost (executor driver) (66/200)
2018-02-08 15:57:29,306 INFO[org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 53.0 (TID 242)
2018-02-08 15:57:29,311 INFO[org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 53.0 (TID 240). 4075 bytes result sent to driver
2018-02-08 15:57:29,312 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,312 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,314 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 53.0 (TID 243, localhost, executor driver, partition 80, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,315 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,315 INFO[org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 53.0 (TID 243)
2018-02-08 15:57:29,315 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 53.0 (TID 240) in 31 ms on localhost (executor driver) (67/200)
2018-02-08 15:57:29,315 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,320 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,320 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,321 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,321 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,322 INFO[org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 53.0 (TID 242). 4118 bytes result sent to driver
2018-02-08 15:57:29,323 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 53.0 (TID 244, localhost, executor driver, partition 81, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,325 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 53.0 (TID 242) in 20 ms on localhost (executor driver) (68/200)
2018-02-08 15:57:29,325 INFO[org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 53.0 (TID 244)
2018-02-08 15:57:29,330 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,330 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,331 INFO[org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 53.0 (TID 243). 4118 bytes result sent to driver
2018-02-08 15:57:29,332 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 53.0 (TID 245, localhost, executor driver, partition 82, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,332 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,333 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,333 INFO[org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 53.0 (TID 245)
2018-02-08 15:57:29,333 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 53.0 (TID 243) in 19 ms on localhost (executor driver) (69/200)
2018-02-08 15:57:29,338 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,338 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,339 INFO[org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 53.0 (TID 244). 4118 bytes result sent to driver
2018-02-08 15:57:29,340 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,341 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,341 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 53.0 (TID 246, localhost, executor driver, partition 83, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,341 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 53.0 (TID 244) in 18 ms on localhost (executor driver) (70/200)
2018-02-08 15:57:29,341 INFO[org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 53.0 (TID 246)
2018-02-08 15:57:29,351 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,352 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,354 INFO[org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 53.0 (TID 245). 4118 bytes result sent to driver
2018-02-08 15:57:29,354 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,354 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,354 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 53.0 (TID 247, localhost, executor driver, partition 84, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,355 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 53.0 (TID 245) in 23 ms on localhost (executor driver) (71/200)
2018-02-08 15:57:29,355 INFO[org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 53.0 (TID 247)
2018-02-08 15:57:29,361 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,361 INFO[org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 53.0 (TID 246). 4161 bytes result sent to driver
2018-02-08 15:57:29,362 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,362 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 53.0 (TID 248, localhost, executor driver, partition 85, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,362 INFO[org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 53.0 (TID 248)
2018-02-08 15:57:29,362 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 53.0 (TID 246) in 22 ms on localhost (executor driver) (72/200)
2018-02-08 15:57:29,363 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,363 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,366 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,366 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,367 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,368 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,369 INFO[org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 53.0 (TID 247). 4118 bytes result sent to driver
2018-02-08 15:57:29,372 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 53.0 (TID 249, localhost, executor driver, partition 86, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,373 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 53.0 (TID 247) in 19 ms on localhost (executor driver) (73/200)
2018-02-08 15:57:29,374 INFO[org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 53.0 (TID 249)
2018-02-08 15:57:29,379 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,379 INFO[org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 53.0 (TID 248). 4075 bytes result sent to driver
2018-02-08 15:57:29,379 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,379 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 53.0 (TID 250, localhost, executor driver, partition 87, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,380 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 53.0 (TID 248) in 18 ms on localhost (executor driver) (74/200)
2018-02-08 15:57:29,380 INFO[org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 53.0 (TID 250)
2018-02-08 15:57:29,381 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,381 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,384 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,385 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,386 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,386 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,389 INFO[org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 53.0 (TID 249). 4118 bytes result sent to driver
2018-02-08 15:57:29,391 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 53.0 (TID 251, localhost, executor driver, partition 88, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,392 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 53.0 (TID 249) in 20 ms on localhost (executor driver) (75/200)
2018-02-08 15:57:29,392 INFO[org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 53.0 (TID 251)
2018-02-08 15:57:29,394 INFO[org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 53.0 (TID 250). 4118 bytes result sent to driver
2018-02-08 15:57:29,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 53.0 (TID 252, localhost, executor driver, partition 90, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 53.0 (TID 250) in 18 ms on localhost (executor driver) (76/200)
2018-02-08 15:57:29,398 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,398 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,398 INFO[org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 53.0 (TID 252)
2018-02-08 15:57:29,400 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,400 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,406 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,406 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,408 INFO[org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 53.0 (TID 251). 4118 bytes result sent to driver
2018-02-08 15:57:29,409 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,409 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,410 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 53.0 (TID 253, localhost, executor driver, partition 91, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,411 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 53.0 (TID 251) in 20 ms on localhost (executor driver) (77/200)
2018-02-08 15:57:29,412 INFO[org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 53.0 (TID 253)
2018-02-08 15:57:29,416 INFO[org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 53.0 (TID 252). 4118 bytes result sent to driver
2018-02-08 15:57:29,416 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 53.0 (TID 254, localhost, executor driver, partition 92, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,418 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,418 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,422 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,422 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,423 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 53.0 (TID 252) in 27 ms on localhost (executor driver) (78/200)
2018-02-08 15:57:29,424 INFO[org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 53.0 (TID 254)
2018-02-08 15:57:29,431 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,431 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,431 INFO[org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 53.0 (TID 253). 4075 bytes result sent to driver
2018-02-08 15:57:29,432 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 53.0 (TID 255, localhost, executor driver, partition 93, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,432 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 53.0 (TID 253) in 22 ms on localhost (executor driver) (79/200)
2018-02-08 15:57:29,432 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,433 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,433 INFO[org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 53.0 (TID 255)
2018-02-08 15:57:29,438 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,438 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,440 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,441 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,446 INFO[org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 53.0 (TID 255). 4118 bytes result sent to driver
2018-02-08 15:57:29,447 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 53.0 (TID 256, localhost, executor driver, partition 94, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,447 INFO[org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 53.0 (TID 256)
2018-02-08 15:57:29,447 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 53.0 (TID 255) in 16 ms on localhost (executor driver) (80/200)
2018-02-08 15:57:29,451 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,451 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,453 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,453 INFO[org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 53.0 (TID 254). 4118 bytes result sent to driver
2018-02-08 15:57:29,453 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,454 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 53.0 (TID 257, localhost, executor driver, partition 95, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,454 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 53.0 (TID 254) in 38 ms on localhost (executor driver) (81/200)
2018-02-08 15:57:29,454 INFO[org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 53.0 (TID 257)
2018-02-08 15:57:29,460 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,460 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,462 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,462 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,466 INFO[org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 53.0 (TID 257). 4075 bytes result sent to driver
2018-02-08 15:57:29,467 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 53.0 (TID 258, localhost, executor driver, partition 96, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,474 INFO[org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 53.0 (TID 256). 4118 bytes result sent to driver
2018-02-08 15:57:29,475 INFO[org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 53.0 (TID 258)
2018-02-08 15:57:29,475 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 53.0 (TID 257) in 22 ms on localhost (executor driver) (82/200)
2018-02-08 15:57:29,477 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 53.0 (TID 259, localhost, executor driver, partition 97, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,480 INFO[org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 53.0 (TID 259)
2018-02-08 15:57:29,480 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 53.0 (TID 256) in 34 ms on localhost (executor driver) (83/200)
2018-02-08 15:57:29,482 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,482 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,485 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,485 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,485 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,485 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,486 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,486 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,490 INFO[org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 53.0 (TID 258). 4118 bytes result sent to driver
2018-02-08 15:57:29,490 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 53.0 (TID 260, localhost, executor driver, partition 98, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,491 INFO[org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 53.0 (TID 260)
2018-02-08 15:57:29,491 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 53.0 (TID 258) in 24 ms on localhost (executor driver) (84/200)
2018-02-08 15:57:29,492 INFO[org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 53.0 (TID 259). 4118 bytes result sent to driver
2018-02-08 15:57:29,492 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 53.0 (TID 261, localhost, executor driver, partition 99, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,492 INFO[org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 53.0 (TID 261)
2018-02-08 15:57:29,492 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 53.0 (TID 259) in 15 ms on localhost (executor driver) (85/200)
2018-02-08 15:57:29,494 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,494 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,496 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,496 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,496 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,496 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,497 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,498 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,511 INFO[org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 53.0 (TID 261). 4118 bytes result sent to driver
2018-02-08 15:57:29,511 INFO[org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 53.0 (TID 260). 4075 bytes result sent to driver
2018-02-08 15:57:29,512 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 100.0 in stage 53.0 (TID 262, localhost, executor driver, partition 100, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,512 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 101.0 in stage 53.0 (TID 263, localhost, executor driver, partition 101, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,513 INFO[org.apache.spark.executor.Executor:54] - Running task 100.0 in stage 53.0 (TID 262)
2018-02-08 15:57:29,513 INFO[org.apache.spark.executor.Executor:54] - Running task 101.0 in stage 53.0 (TID 263)
2018-02-08 15:57:29,513 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 53.0 (TID 261) in 21 ms on localhost (executor driver) (86/200)
2018-02-08 15:57:29,514 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 53.0 (TID 260) in 24 ms on localhost (executor driver) (87/200)
2018-02-08 15:57:29,517 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,517 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,517 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,517 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,519 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,519 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,520 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,520 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,528 INFO[org.apache.spark.executor.Executor:54] - Finished task 100.0 in stage 53.0 (TID 262). 4118 bytes result sent to driver
2018-02-08 15:57:29,534 INFO[org.apache.spark.executor.Executor:54] - Finished task 101.0 in stage 53.0 (TID 263). 4118 bytes result sent to driver
2018-02-08 15:57:29,535 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 104.0 in stage 53.0 (TID 264, localhost, executor driver, partition 104, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,537 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 106.0 in stage 53.0 (TID 265, localhost, executor driver, partition 106, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,537 INFO[org.apache.spark.executor.Executor:54] - Running task 104.0 in stage 53.0 (TID 264)
2018-02-08 15:57:29,537 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 101.0 in stage 53.0 (TID 263) in 25 ms on localhost (executor driver) (88/200)
2018-02-08 15:57:29,537 INFO[org.apache.spark.executor.Executor:54] - Running task 106.0 in stage 53.0 (TID 265)
2018-02-08 15:57:29,537 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 100.0 in stage 53.0 (TID 262) in 25 ms on localhost (executor driver) (89/200)
2018-02-08 15:57:29,540 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,540 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,540 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,540 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,542 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,542 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,544 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,544 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,554 INFO[org.apache.spark.executor.Executor:54] - Finished task 104.0 in stage 53.0 (TID 264). 4118 bytes result sent to driver
2018-02-08 15:57:29,554 INFO[org.apache.spark.executor.Executor:54] - Finished task 106.0 in stage 53.0 (TID 265). 4118 bytes result sent to driver
2018-02-08 15:57:29,555 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 108.0 in stage 53.0 (TID 266, localhost, executor driver, partition 108, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,555 INFO[org.apache.spark.executor.Executor:54] - Running task 108.0 in stage 53.0 (TID 266)
2018-02-08 15:57:29,555 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 109.0 in stage 53.0 (TID 267, localhost, executor driver, partition 109, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 106.0 in stage 53.0 (TID 265) in 20 ms on localhost (executor driver) (90/200)
2018-02-08 15:57:29,556 INFO[org.apache.spark.executor.Executor:54] - Running task 109.0 in stage 53.0 (TID 267)
2018-02-08 15:57:29,558 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 104.0 in stage 53.0 (TID 264) in 23 ms on localhost (executor driver) (91/200)
2018-02-08 15:57:29,559 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,559 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,560 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,560 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,561 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,561 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,561 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,561 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,571 INFO[org.apache.spark.executor.Executor:54] - Finished task 108.0 in stage 53.0 (TID 266). 4118 bytes result sent to driver
2018-02-08 15:57:29,572 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 110.0 in stage 53.0 (TID 268, localhost, executor driver, partition 110, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,572 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 108.0 in stage 53.0 (TID 266) in 18 ms on localhost (executor driver) (92/200)
2018-02-08 15:57:29,572 INFO[org.apache.spark.executor.Executor:54] - Running task 110.0 in stage 53.0 (TID 268)
2018-02-08 15:57:29,576 INFO[org.apache.spark.executor.Executor:54] - Finished task 109.0 in stage 53.0 (TID 267). 4161 bytes result sent to driver
2018-02-08 15:57:29,576 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,576 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,576 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 111.0 in stage 53.0 (TID 269, localhost, executor driver, partition 111, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,576 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 109.0 in stage 53.0 (TID 267) in 21 ms on localhost (executor driver) (93/200)
2018-02-08 15:57:29,576 INFO[org.apache.spark.executor.Executor:54] - Running task 111.0 in stage 53.0 (TID 269)
2018-02-08 15:57:29,578 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,578 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,585 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,585 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,587 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,587 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,588 INFO[org.apache.spark.executor.Executor:54] - Finished task 110.0 in stage 53.0 (TID 268). 4118 bytes result sent to driver
2018-02-08 15:57:29,588 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 112.0 in stage 53.0 (TID 270, localhost, executor driver, partition 112, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,591 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 110.0 in stage 53.0 (TID 268) in 19 ms on localhost (executor driver) (94/200)
2018-02-08 15:57:29,591 INFO[org.apache.spark.executor.Executor:54] - Running task 112.0 in stage 53.0 (TID 270)
2018-02-08 15:57:29,594 INFO[org.apache.spark.executor.Executor:54] - Finished task 111.0 in stage 53.0 (TID 269). 4161 bytes result sent to driver
2018-02-08 15:57:29,596 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 113.0 in stage 53.0 (TID 271, localhost, executor driver, partition 113, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,599 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,599 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,600 INFO[org.apache.spark.executor.Executor:54] - Running task 113.0 in stage 53.0 (TID 271)
2018-02-08 15:57:29,600 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 111.0 in stage 53.0 (TID 269) in 24 ms on localhost (executor driver) (95/200)
2018-02-08 15:57:29,601 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,601 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,604 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,605 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,606 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,606 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,614 INFO[org.apache.spark.executor.Executor:54] - Finished task 113.0 in stage 53.0 (TID 271). 4118 bytes result sent to driver
2018-02-08 15:57:29,615 INFO[org.apache.spark.executor.Executor:54] - Finished task 112.0 in stage 53.0 (TID 270). 4161 bytes result sent to driver
2018-02-08 15:57:29,615 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 114.0 in stage 53.0 (TID 272, localhost, executor driver, partition 114, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,616 INFO[org.apache.spark.executor.Executor:54] - Running task 114.0 in stage 53.0 (TID 272)
2018-02-08 15:57:29,616 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 115.0 in stage 53.0 (TID 273, localhost, executor driver, partition 115, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,616 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 112.0 in stage 53.0 (TID 270) in 28 ms on localhost (executor driver) (96/200)
2018-02-08 15:57:29,616 INFO[org.apache.spark.executor.Executor:54] - Running task 115.0 in stage 53.0 (TID 273)
2018-02-08 15:57:29,617 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 113.0 in stage 53.0 (TID 271) in 21 ms on localhost (executor driver) (97/200)
2018-02-08 15:57:29,619 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,619 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,619 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,619 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,621 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,621 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,621 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,621 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,626 INFO[org.apache.spark.executor.Executor:54] - Finished task 114.0 in stage 53.0 (TID 272). 4118 bytes result sent to driver
2018-02-08 15:57:29,627 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 116.0 in stage 53.0 (TID 274, localhost, executor driver, partition 116, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,628 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 114.0 in stage 53.0 (TID 272) in 13 ms on localhost (executor driver) (98/200)
2018-02-08 15:57:29,628 INFO[org.apache.spark.executor.Executor:54] - Running task 116.0 in stage 53.0 (TID 274)
2018-02-08 15:57:29,632 INFO[org.apache.spark.executor.Executor:54] - Finished task 115.0 in stage 53.0 (TID 273). 4075 bytes result sent to driver
2018-02-08 15:57:29,632 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 117.0 in stage 53.0 (TID 275, localhost, executor driver, partition 117, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,633 INFO[org.apache.spark.executor.Executor:54] - Running task 117.0 in stage 53.0 (TID 275)
2018-02-08 15:57:29,633 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 115.0 in stage 53.0 (TID 273) in 17 ms on localhost (executor driver) (99/200)
2018-02-08 15:57:29,633 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,634 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,635 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,635 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,637 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,637 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,638 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,638 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,640 INFO[org.apache.spark.executor.Executor:54] - Finished task 116.0 in stage 53.0 (TID 274). 4075 bytes result sent to driver
2018-02-08 15:57:29,640 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 118.0 in stage 53.0 (TID 276, localhost, executor driver, partition 118, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,640 INFO[org.apache.spark.executor.Executor:54] - Running task 118.0 in stage 53.0 (TID 276)
2018-02-08 15:57:29,640 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 116.0 in stage 53.0 (TID 274) in 13 ms on localhost (executor driver) (100/200)
2018-02-08 15:57:29,644 INFO[org.apache.spark.executor.Executor:54] - Finished task 117.0 in stage 53.0 (TID 275). 4118 bytes result sent to driver
2018-02-08 15:57:29,645 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 119.0 in stage 53.0 (TID 277, localhost, executor driver, partition 119, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,645 INFO[org.apache.spark.executor.Executor:54] - Running task 119.0 in stage 53.0 (TID 277)
2018-02-08 15:57:29,645 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 117.0 in stage 53.0 (TID 275) in 13 ms on localhost (executor driver) (101/200)
2018-02-08 15:57:29,645 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,645 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,647 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,647 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,648 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,649 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,650 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,650 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,653 INFO[org.apache.spark.executor.Executor:54] - Finished task 118.0 in stage 53.0 (TID 276). 4075 bytes result sent to driver
2018-02-08 15:57:29,653 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 120.0 in stage 53.0 (TID 278, localhost, executor driver, partition 120, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,653 INFO[org.apache.spark.executor.Executor:54] - Running task 120.0 in stage 53.0 (TID 278)
2018-02-08 15:57:29,653 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 118.0 in stage 53.0 (TID 276) in 13 ms on localhost (executor driver) (102/200)
2018-02-08 15:57:29,654 INFO[org.apache.spark.executor.Executor:54] - Finished task 119.0 in stage 53.0 (TID 277). 4075 bytes result sent to driver
2018-02-08 15:57:29,654 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 121.0 in stage 53.0 (TID 279, localhost, executor driver, partition 121, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,654 INFO[org.apache.spark.executor.Executor:54] - Running task 121.0 in stage 53.0 (TID 279)
2018-02-08 15:57:29,654 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 119.0 in stage 53.0 (TID 277) in 9 ms on localhost (executor driver) (103/200)
2018-02-08 15:57:29,657 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,657 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,657 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,657 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,658 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,658 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,658 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,658 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,662 INFO[org.apache.spark.executor.Executor:54] - Finished task 121.0 in stage 53.0 (TID 279). 4118 bytes result sent to driver
2018-02-08 15:57:29,663 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 123.0 in stage 53.0 (TID 280, localhost, executor driver, partition 123, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,663 INFO[org.apache.spark.executor.Executor:54] - Running task 123.0 in stage 53.0 (TID 280)
2018-02-08 15:57:29,663 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 121.0 in stage 53.0 (TID 279) in 9 ms on localhost (executor driver) (104/200)
2018-02-08 15:57:29,663 INFO[org.apache.spark.executor.Executor:54] - Finished task 120.0 in stage 53.0 (TID 278). 4118 bytes result sent to driver
2018-02-08 15:57:29,663 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 124.0 in stage 53.0 (TID 281, localhost, executor driver, partition 124, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,664 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 120.0 in stage 53.0 (TID 278) in 11 ms on localhost (executor driver) (105/200)
2018-02-08 15:57:29,664 INFO[org.apache.spark.executor.Executor:54] - Running task 124.0 in stage 53.0 (TID 281)
2018-02-08 15:57:29,666 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,666 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,666 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,667 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,667 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,667 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,667 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,667 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,675 INFO[org.apache.spark.executor.Executor:54] - Finished task 124.0 in stage 53.0 (TID 281). 4118 bytes result sent to driver
2018-02-08 15:57:29,677 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 125.0 in stage 53.0 (TID 282, localhost, executor driver, partition 125, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,677 INFO[org.apache.spark.executor.Executor:54] - Running task 125.0 in stage 53.0 (TID 282)
2018-02-08 15:57:29,677 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 124.0 in stage 53.0 (TID 281) in 14 ms on localhost (executor driver) (106/200)
2018-02-08 15:57:29,681 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,681 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,682 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,682 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,683 INFO[org.apache.spark.executor.Executor:54] - Finished task 123.0 in stage 53.0 (TID 280). 4075 bytes result sent to driver
2018-02-08 15:57:29,684 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 126.0 in stage 53.0 (TID 283, localhost, executor driver, partition 126, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,684 INFO[org.apache.spark.executor.Executor:54] - Running task 126.0 in stage 53.0 (TID 283)
2018-02-08 15:57:29,684 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 123.0 in stage 53.0 (TID 280) in 22 ms on localhost (executor driver) (107/200)
2018-02-08 15:57:29,687 INFO[org.apache.spark.executor.Executor:54] - Finished task 125.0 in stage 53.0 (TID 282). 4118 bytes result sent to driver
2018-02-08 15:57:29,688 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 127.0 in stage 53.0 (TID 284, localhost, executor driver, partition 127, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,688 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,688 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 125.0 in stage 53.0 (TID 282) in 12 ms on localhost (executor driver) (108/200)
2018-02-08 15:57:29,688 INFO[org.apache.spark.executor.Executor:54] - Running task 127.0 in stage 53.0 (TID 284)
2018-02-08 15:57:29,688 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,689 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,689 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,693 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,693 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,695 INFO[org.apache.spark.executor.Executor:54] - Finished task 126.0 in stage 53.0 (TID 283). 4118 bytes result sent to driver
2018-02-08 15:57:29,695 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 128.0 in stage 53.0 (TID 285, localhost, executor driver, partition 128, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,695 INFO[org.apache.spark.executor.Executor:54] - Running task 128.0 in stage 53.0 (TID 285)
2018-02-08 15:57:29,695 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 126.0 in stage 53.0 (TID 283) in 11 ms on localhost (executor driver) (109/200)
2018-02-08 15:57:29,699 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,699 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,700 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,700 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,700 INFO[org.apache.spark.executor.Executor:54] - Finished task 127.0 in stage 53.0 (TID 284). 4075 bytes result sent to driver
2018-02-08 15:57:29,701 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 129.0 in stage 53.0 (TID 286, localhost, executor driver, partition 129, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,701 INFO[org.apache.spark.executor.Executor:54] - Running task 129.0 in stage 53.0 (TID 286)
2018-02-08 15:57:29,701 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 127.0 in stage 53.0 (TID 284) in 14 ms on localhost (executor driver) (110/200)
2018-02-08 15:57:29,704 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,705 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,705 INFO[org.apache.spark.executor.Executor:54] - Finished task 128.0 in stage 53.0 (TID 285). 4118 bytes result sent to driver
2018-02-08 15:57:29,705 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 130.0 in stage 53.0 (TID 287, localhost, executor driver, partition 130, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,705 INFO[org.apache.spark.executor.Executor:54] - Running task 130.0 in stage 53.0 (TID 287)
2018-02-08 15:57:29,706 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,706 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,705 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 128.0 in stage 53.0 (TID 285) in 10 ms on localhost (executor driver) (111/200)
2018-02-08 15:57:29,710 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,710 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,711 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,711 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,711 INFO[org.apache.spark.executor.Executor:54] - Finished task 129.0 in stage 53.0 (TID 286). 4118 bytes result sent to driver
2018-02-08 15:57:29,817 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 131.0 in stage 53.0 (TID 288, localhost, executor driver, partition 131, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,818 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 129.0 in stage 53.0 (TID 286) in 118 ms on localhost (executor driver) (112/200)
2018-02-08 15:57:29,830 INFO[org.apache.spark.executor.Executor:54] - Running task 131.0 in stage 53.0 (TID 288)
2018-02-08 15:57:29,834 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,835 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,837 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,838 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,843 INFO[org.apache.spark.executor.Executor:54] - Finished task 130.0 in stage 53.0 (TID 287). 4075 bytes result sent to driver
2018-02-08 15:57:29,844 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 133.0 in stage 53.0 (TID 289, localhost, executor driver, partition 133, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,844 INFO[org.apache.spark.executor.Executor:54] - Finished task 131.0 in stage 53.0 (TID 288). 4118 bytes result sent to driver
2018-02-08 15:57:29,844 INFO[org.apache.spark.executor.Executor:54] - Running task 133.0 in stage 53.0 (TID 289)
2018-02-08 15:57:29,844 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 130.0 in stage 53.0 (TID 287) in 139 ms on localhost (executor driver) (113/200)
2018-02-08 15:57:29,847 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 134.0 in stage 53.0 (TID 290, localhost, executor driver, partition 134, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,848 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 131.0 in stage 53.0 (TID 288) in 31 ms on localhost (executor driver) (114/200)
2018-02-08 15:57:29,848 INFO[org.apache.spark.executor.Executor:54] - Running task 134.0 in stage 53.0 (TID 290)
2018-02-08 15:57:29,851 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,852 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,855 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,855 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,861 INFO[org.apache.spark.executor.Executor:54] - Finished task 133.0 in stage 53.0 (TID 289). 4118 bytes result sent to driver
2018-02-08 15:57:29,862 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,862 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,864 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,864 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,870 INFO[org.apache.spark.executor.Executor:54] - Finished task 134.0 in stage 53.0 (TID 290). 4075 bytes result sent to driver
2018-02-08 15:57:29,871 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 136.0 in stage 53.0 (TID 291, localhost, executor driver, partition 136, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,871 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 137.0 in stage 53.0 (TID 292, localhost, executor driver, partition 137, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,874 INFO[org.apache.spark.executor.Executor:54] - Running task 136.0 in stage 53.0 (TID 291)
2018-02-08 15:57:29,875 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 133.0 in stage 53.0 (TID 289) in 31 ms on localhost (executor driver) (115/200)
2018-02-08 15:57:29,875 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 134.0 in stage 53.0 (TID 290) in 28 ms on localhost (executor driver) (116/200)
2018-02-08 15:57:29,880 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,880 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,881 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,882 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,884 INFO[org.apache.spark.executor.Executor:54] - Running task 137.0 in stage 53.0 (TID 292)
2018-02-08 15:57:29,890 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,890 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:57:29,892 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,892 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,904 INFO[org.apache.spark.executor.Executor:54] - Finished task 137.0 in stage 53.0 (TID 292). 4075 bytes result sent to driver
2018-02-08 15:57:29,904 INFO[org.apache.spark.executor.Executor:54] - Finished task 136.0 in stage 53.0 (TID 291). 4161 bytes result sent to driver
2018-02-08 15:57:29,905 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 138.0 in stage 53.0 (TID 293, localhost, executor driver, partition 138, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,905 INFO[org.apache.spark.executor.Executor:54] - Running task 138.0 in stage 53.0 (TID 293)
2018-02-08 15:57:29,905 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 139.0 in stage 53.0 (TID 294, localhost, executor driver, partition 139, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 136.0 in stage 53.0 (TID 291) in 34 ms on localhost (executor driver) (117/200)
2018-02-08 15:57:29,906 INFO[org.apache.spark.executor.Executor:54] - Running task 139.0 in stage 53.0 (TID 294)
2018-02-08 15:57:29,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 137.0 in stage 53.0 (TID 292) in 35 ms on localhost (executor driver) (118/200)
2018-02-08 15:57:29,908 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,908 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,909 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,909 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,910 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,910 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,910 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,910 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,914 INFO[org.apache.spark.executor.Executor:54] - Finished task 139.0 in stage 53.0 (TID 294). 4075 bytes result sent to driver
2018-02-08 15:57:29,915 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 140.0 in stage 53.0 (TID 295, localhost, executor driver, partition 140, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,915 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 139.0 in stage 53.0 (TID 294) in 10 ms on localhost (executor driver) (119/200)
2018-02-08 15:57:29,915 INFO[org.apache.spark.executor.Executor:54] - Running task 140.0 in stage 53.0 (TID 295)
2018-02-08 15:57:29,917 INFO[org.apache.spark.executor.Executor:54] - Finished task 138.0 in stage 53.0 (TID 293). 4075 bytes result sent to driver
2018-02-08 15:57:29,917 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 142.0 in stage 53.0 (TID 296, localhost, executor driver, partition 142, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,918 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 138.0 in stage 53.0 (TID 293) in 13 ms on localhost (executor driver) (120/200)
2018-02-08 15:57:29,918 INFO[org.apache.spark.executor.Executor:54] - Running task 142.0 in stage 53.0 (TID 296)
2018-02-08 15:57:29,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,923 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,924 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,924 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,924 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,925 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,925 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,930 INFO[org.apache.spark.executor.Executor:54] - Finished task 142.0 in stage 53.0 (TID 296). 4161 bytes result sent to driver
2018-02-08 15:57:29,933 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 144.0 in stage 53.0 (TID 297, localhost, executor driver, partition 144, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,934 INFO[org.apache.spark.executor.Executor:54] - Running task 144.0 in stage 53.0 (TID 297)
2018-02-08 15:57:29,934 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 142.0 in stage 53.0 (TID 296) in 17 ms on localhost (executor driver) (121/200)
2018-02-08 15:57:29,939 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,940 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,941 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,941 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,946 INFO[org.apache.spark.executor.Executor:54] - Finished task 140.0 in stage 53.0 (TID 295). 4118 bytes result sent to driver
2018-02-08 15:57:29,946 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 145.0 in stage 53.0 (TID 298, localhost, executor driver, partition 145, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,947 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 140.0 in stage 53.0 (TID 295) in 32 ms on localhost (executor driver) (122/200)
2018-02-08 15:57:29,947 INFO[org.apache.spark.executor.Executor:54] - Running task 145.0 in stage 53.0 (TID 298)
2018-02-08 15:57:29,949 INFO[org.apache.spark.executor.Executor:54] - Finished task 144.0 in stage 53.0 (TID 297). 4161 bytes result sent to driver
2018-02-08 15:57:29,950 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 146.0 in stage 53.0 (TID 299, localhost, executor driver, partition 146, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,950 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 144.0 in stage 53.0 (TID 297) in 18 ms on localhost (executor driver) (123/200)
2018-02-08 15:57:29,951 INFO[org.apache.spark.executor.Executor:54] - Running task 146.0 in stage 53.0 (TID 299)
2018-02-08 15:57:29,953 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,953 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,954 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,954 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,956 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:29,960 INFO[org.apache.spark.executor.Executor:54] - Finished task 145.0 in stage 53.0 (TID 298). 4161 bytes result sent to driver
2018-02-08 15:57:29,960 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 147.0 in stage 53.0 (TID 300, localhost, executor driver, partition 147, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,961 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 145.0 in stage 53.0 (TID 298) in 15 ms on localhost (executor driver) (124/200)
2018-02-08 15:57:29,961 INFO[org.apache.spark.executor.Executor:54] - Running task 147.0 in stage 53.0 (TID 300)
2018-02-08 15:57:29,962 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,962 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,968 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,968 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,970 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,970 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,977 INFO[org.apache.spark.executor.Executor:54] - Finished task 146.0 in stage 53.0 (TID 299). 4118 bytes result sent to driver
2018-02-08 15:57:29,983 INFO[org.apache.spark.executor.Executor:54] - Finished task 147.0 in stage 53.0 (TID 300). 4118 bytes result sent to driver
2018-02-08 15:57:29,986 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 148.0 in stage 53.0 (TID 301, localhost, executor driver, partition 148, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,987 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 147.0 in stage 53.0 (TID 300) in 27 ms on localhost (executor driver) (125/200)
2018-02-08 15:57:29,987 INFO[org.apache.spark.executor.Executor:54] - Running task 148.0 in stage 53.0 (TID 301)
2018-02-08 15:57:29,989 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 149.0 in stage 53.0 (TID 302, localhost, executor driver, partition 149, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:29,992 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:29,992 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:29,993 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:29,997 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 15:57:30,004 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 146.0 in stage 53.0 (TID 299) in 54 ms on localhost (executor driver) (126/200)
2018-02-08 15:57:30,004 INFO[org.apache.spark.executor.Executor:54] - Running task 149.0 in stage 53.0 (TID 302)
2018-02-08 15:57:30,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,012 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,013 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,018 INFO[org.apache.spark.executor.Executor:54] - Finished task 148.0 in stage 53.0 (TID 301). 4075 bytes result sent to driver
2018-02-08 15:57:30,019 INFO[org.apache.spark.executor.Executor:54] - Finished task 149.0 in stage 53.0 (TID 302). 4118 bytes result sent to driver
2018-02-08 15:57:30,019 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 150.0 in stage 53.0 (TID 303, localhost, executor driver, partition 150, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,020 INFO[org.apache.spark.executor.Executor:54] - Running task 150.0 in stage 53.0 (TID 303)
2018-02-08 15:57:30,020 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 151.0 in stage 53.0 (TID 304, localhost, executor driver, partition 151, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,021 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 149.0 in stage 53.0 (TID 302) in 32 ms on localhost (executor driver) (127/200)
2018-02-08 15:57:30,022 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 148.0 in stage 53.0 (TID 301) in 36 ms on localhost (executor driver) (128/200)
2018-02-08 15:57:30,022 INFO[org.apache.spark.executor.Executor:54] - Running task 151.0 in stage 53.0 (TID 304)
2018-02-08 15:57:30,025 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,025 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,027 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,028 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,029 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,030 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,032 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,032 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,036 INFO[org.apache.spark.executor.Executor:54] - Finished task 150.0 in stage 53.0 (TID 303). 4118 bytes result sent to driver
2018-02-08 15:57:30,037 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 152.0 in stage 53.0 (TID 305, localhost, executor driver, partition 152, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,038 INFO[org.apache.spark.executor.Executor:54] - Running task 152.0 in stage 53.0 (TID 305)
2018-02-08 15:57:30,038 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 150.0 in stage 53.0 (TID 303) in 19 ms on localhost (executor driver) (129/200)
2018-02-08 15:57:30,038 INFO[org.apache.spark.executor.Executor:54] - Finished task 151.0 in stage 53.0 (TID 304). 4118 bytes result sent to driver
2018-02-08 15:57:30,039 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 153.0 in stage 53.0 (TID 306, localhost, executor driver, partition 153, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,039 INFO[org.apache.spark.executor.Executor:54] - Running task 153.0 in stage 53.0 (TID 306)
2018-02-08 15:57:30,039 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 151.0 in stage 53.0 (TID 304) in 19 ms on localhost (executor driver) (130/200)
2018-02-08 15:57:30,042 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,042 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,042 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,042 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,045 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,050 INFO[org.apache.spark.executor.Executor:54] - Finished task 152.0 in stage 53.0 (TID 305). 4118 bytes result sent to driver
2018-02-08 15:57:30,051 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 154.0 in stage 53.0 (TID 307, localhost, executor driver, partition 154, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,051 INFO[org.apache.spark.executor.Executor:54] - Finished task 153.0 in stage 53.0 (TID 306). 4118 bytes result sent to driver
2018-02-08 15:57:30,051 INFO[org.apache.spark.executor.Executor:54] - Running task 154.0 in stage 53.0 (TID 307)
2018-02-08 15:57:30,051 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 152.0 in stage 53.0 (TID 305) in 14 ms on localhost (executor driver) (131/200)
2018-02-08 15:57:30,052 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 155.0 in stage 53.0 (TID 308, localhost, executor driver, partition 155, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,052 INFO[org.apache.spark.executor.Executor:54] - Running task 155.0 in stage 53.0 (TID 308)
2018-02-08 15:57:30,052 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 153.0 in stage 53.0 (TID 306) in 13 ms on localhost (executor driver) (132/200)
2018-02-08 15:57:30,055 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,055 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,055 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,055 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,056 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,056 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,056 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,056 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,060 INFO[org.apache.spark.executor.Executor:54] - Finished task 155.0 in stage 53.0 (TID 308). 4075 bytes result sent to driver
2018-02-08 15:57:30,060 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 156.0 in stage 53.0 (TID 309, localhost, executor driver, partition 156, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,061 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 155.0 in stage 53.0 (TID 308) in 9 ms on localhost (executor driver) (133/200)
2018-02-08 15:57:30,061 INFO[org.apache.spark.executor.Executor:54] - Finished task 154.0 in stage 53.0 (TID 307). 4118 bytes result sent to driver
2018-02-08 15:57:30,061 INFO[org.apache.spark.executor.Executor:54] - Running task 156.0 in stage 53.0 (TID 309)
2018-02-08 15:57:30,061 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 157.0 in stage 53.0 (TID 310, localhost, executor driver, partition 157, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,061 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 154.0 in stage 53.0 (TID 307) in 10 ms on localhost (executor driver) (134/200)
2018-02-08 15:57:30,061 INFO[org.apache.spark.executor.Executor:54] - Running task 157.0 in stage 53.0 (TID 310)
2018-02-08 15:57:30,064 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,064 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,064 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,065 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,065 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,065 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,066 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,066 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,069 INFO[org.apache.spark.executor.Executor:54] - Finished task 157.0 in stage 53.0 (TID 310). 4075 bytes result sent to driver
2018-02-08 15:57:30,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 158.0 in stage 53.0 (TID 311, localhost, executor driver, partition 158, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,070 INFO[org.apache.spark.executor.Executor:54] - Running task 158.0 in stage 53.0 (TID 311)
2018-02-08 15:57:30,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 157.0 in stage 53.0 (TID 310) in 9 ms on localhost (executor driver) (135/200)
2018-02-08 15:57:30,070 INFO[org.apache.spark.executor.Executor:54] - Finished task 156.0 in stage 53.0 (TID 309). 4075 bytes result sent to driver
2018-02-08 15:57:30,071 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 159.0 in stage 53.0 (TID 312, localhost, executor driver, partition 159, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,071 INFO[org.apache.spark.executor.Executor:54] - Running task 159.0 in stage 53.0 (TID 312)
2018-02-08 15:57:30,071 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 156.0 in stage 53.0 (TID 309) in 11 ms on localhost (executor driver) (136/200)
2018-02-08 15:57:30,073 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,073 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,073 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,073 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,074 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,074 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,074 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,074 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,078 INFO[org.apache.spark.executor.Executor:54] - Finished task 158.0 in stage 53.0 (TID 311). 4118 bytes result sent to driver
2018-02-08 15:57:30,078 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 160.0 in stage 53.0 (TID 313, localhost, executor driver, partition 160, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,079 INFO[org.apache.spark.executor.Executor:54] - Running task 160.0 in stage 53.0 (TID 313)
2018-02-08 15:57:30,079 INFO[org.apache.spark.executor.Executor:54] - Finished task 159.0 in stage 53.0 (TID 312). 4118 bytes result sent to driver
2018-02-08 15:57:30,079 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 158.0 in stage 53.0 (TID 311) in 9 ms on localhost (executor driver) (137/200)
2018-02-08 15:57:30,080 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 161.0 in stage 53.0 (TID 314, localhost, executor driver, partition 161, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,080 INFO[org.apache.spark.executor.Executor:54] - Running task 161.0 in stage 53.0 (TID 314)
2018-02-08 15:57:30,080 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 159.0 in stage 53.0 (TID 312) in 10 ms on localhost (executor driver) (138/200)
2018-02-08 15:57:30,083 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,083 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,083 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,083 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,084 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,084 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,084 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,084 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,088 INFO[org.apache.spark.executor.Executor:54] - Finished task 161.0 in stage 53.0 (TID 314). 4075 bytes result sent to driver
2018-02-08 15:57:30,088 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 162.0 in stage 53.0 (TID 315, localhost, executor driver, partition 162, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,088 INFO[org.apache.spark.executor.Executor:54] - Running task 162.0 in stage 53.0 (TID 315)
2018-02-08 15:57:30,088 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 161.0 in stage 53.0 (TID 314) in 9 ms on localhost (executor driver) (139/200)
2018-02-08 15:57:30,089 INFO[org.apache.spark.executor.Executor:54] - Finished task 160.0 in stage 53.0 (TID 313). 4075 bytes result sent to driver
2018-02-08 15:57:30,089 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 164.0 in stage 53.0 (TID 316, localhost, executor driver, partition 164, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,090 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 160.0 in stage 53.0 (TID 313) in 12 ms on localhost (executor driver) (140/200)
2018-02-08 15:57:30,090 INFO[org.apache.spark.executor.Executor:54] - Running task 164.0 in stage 53.0 (TID 316)
2018-02-08 15:57:30,092 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,092 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,094 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,094 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,094 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,094 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,095 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,095 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,099 INFO[org.apache.spark.executor.Executor:54] - Finished task 162.0 in stage 53.0 (TID 315). 4118 bytes result sent to driver
2018-02-08 15:57:30,100 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 165.0 in stage 53.0 (TID 317, localhost, executor driver, partition 165, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,100 INFO[org.apache.spark.executor.Executor:54] - Running task 165.0 in stage 53.0 (TID 317)
2018-02-08 15:57:30,100 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 162.0 in stage 53.0 (TID 315) in 12 ms on localhost (executor driver) (141/200)
2018-02-08 15:57:30,101 INFO[org.apache.spark.executor.Executor:54] - Finished task 164.0 in stage 53.0 (TID 316). 4118 bytes result sent to driver
2018-02-08 15:57:30,101 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 166.0 in stage 53.0 (TID 318, localhost, executor driver, partition 166, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,101 INFO[org.apache.spark.executor.Executor:54] - Running task 166.0 in stage 53.0 (TID 318)
2018-02-08 15:57:30,101 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 164.0 in stage 53.0 (TID 316) in 12 ms on localhost (executor driver) (142/200)
2018-02-08 15:57:30,103 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,105 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,105 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,105 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,105 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,111 INFO[org.apache.spark.executor.Executor:54] - Finished task 165.0 in stage 53.0 (TID 317). 4075 bytes result sent to driver
2018-02-08 15:57:30,112 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 167.0 in stage 53.0 (TID 319, localhost, executor driver, partition 167, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,112 INFO[org.apache.spark.executor.Executor:54] - Running task 167.0 in stage 53.0 (TID 319)
2018-02-08 15:57:30,112 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 165.0 in stage 53.0 (TID 317) in 12 ms on localhost (executor driver) (143/200)
2018-02-08 15:57:30,113 INFO[org.apache.spark.executor.Executor:54] - Finished task 166.0 in stage 53.0 (TID 318). 4075 bytes result sent to driver
2018-02-08 15:57:30,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 169.0 in stage 53.0 (TID 320, localhost, executor driver, partition 169, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 166.0 in stage 53.0 (TID 318) in 13 ms on localhost (executor driver) (144/200)
2018-02-08 15:57:30,114 INFO[org.apache.spark.executor.Executor:54] - Running task 169.0 in stage 53.0 (TID 320)
2018-02-08 15:57:30,116 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,116 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,118 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,118 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,121 INFO[org.apache.spark.executor.Executor:54] - Finished task 167.0 in stage 53.0 (TID 319). 4075 bytes result sent to driver
2018-02-08 15:57:30,122 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 170.0 in stage 53.0 (TID 321, localhost, executor driver, partition 170, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,122 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 167.0 in stage 53.0 (TID 319) in 10 ms on localhost (executor driver) (145/200)
2018-02-08 15:57:30,122 INFO[org.apache.spark.executor.Executor:54] - Running task 170.0 in stage 53.0 (TID 321)
2018-02-08 15:57:30,123 INFO[org.apache.spark.executor.Executor:54] - Finished task 169.0 in stage 53.0 (TID 320). 4075 bytes result sent to driver
2018-02-08 15:57:30,125 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 171.0 in stage 53.0 (TID 322, localhost, executor driver, partition 171, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,127 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 169.0 in stage 53.0 (TID 320) in 14 ms on localhost (executor driver) (146/200)
2018-02-08 15:57:30,127 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,128 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,127 INFO[org.apache.spark.executor.Executor:54] - Running task 171.0 in stage 53.0 (TID 322)
2018-02-08 15:57:30,131 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,131 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,134 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,134 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,135 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,138 INFO[org.apache.spark.executor.Executor:54] - Finished task 170.0 in stage 53.0 (TID 321). 4075 bytes result sent to driver
2018-02-08 15:57:30,138 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 15:57:30,139 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 172.0 in stage 53.0 (TID 323, localhost, executor driver, partition 172, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,139 INFO[org.apache.spark.executor.Executor:54] - Running task 172.0 in stage 53.0 (TID 323)
2018-02-08 15:57:30,139 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 170.0 in stage 53.0 (TID 321) in 18 ms on localhost (executor driver) (147/200)
2018-02-08 15:57:30,146 INFO[org.apache.spark.executor.Executor:54] - Finished task 171.0 in stage 53.0 (TID 322). 4118 bytes result sent to driver
2018-02-08 15:57:30,146 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 173.0 in stage 53.0 (TID 324, localhost, executor driver, partition 173, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,146 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,147 INFO[org.apache.spark.executor.Executor:54] - Running task 173.0 in stage 53.0 (TID 324)
2018-02-08 15:57:30,147 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 171.0 in stage 53.0 (TID 322) in 22 ms on localhost (executor driver) (148/200)
2018-02-08 15:57:30,147 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,148 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,148 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,150 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,150 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,151 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,151 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,153 INFO[org.apache.spark.executor.Executor:54] - Finished task 172.0 in stage 53.0 (TID 323). 4075 bytes result sent to driver
2018-02-08 15:57:30,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 175.0 in stage 53.0 (TID 325, localhost, executor driver, partition 175, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,154 INFO[org.apache.spark.executor.Executor:54] - Running task 175.0 in stage 53.0 (TID 325)
2018-02-08 15:57:30,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 172.0 in stage 53.0 (TID 323) in 16 ms on localhost (executor driver) (149/200)
2018-02-08 15:57:30,160 INFO[org.apache.spark.executor.Executor:54] - Finished task 173.0 in stage 53.0 (TID 324). 4118 bytes result sent to driver
2018-02-08 15:57:30,160 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 176.0 in stage 53.0 (TID 326, localhost, executor driver, partition 176, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,161 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,161 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,162 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 173.0 in stage 53.0 (TID 324) in 16 ms on localhost (executor driver) (150/200)
2018-02-08 15:57:30,162 INFO[org.apache.spark.executor.Executor:54] - Running task 176.0 in stage 53.0 (TID 326)
2018-02-08 15:57:30,162 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,162 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,166 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,168 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,168 INFO[org.apache.spark.executor.Executor:54] - Finished task 175.0 in stage 53.0 (TID 325). 4118 bytes result sent to driver
2018-02-08 15:57:30,168 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,169 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 177.0 in stage 53.0 (TID 327, localhost, executor driver, partition 177, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,169 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 175.0 in stage 53.0 (TID 325) in 16 ms on localhost (executor driver) (151/200)
2018-02-08 15:57:30,169 INFO[org.apache.spark.executor.Executor:54] - Running task 177.0 in stage 53.0 (TID 327)
2018-02-08 15:57:30,176 INFO[org.apache.spark.executor.Executor:54] - Finished task 176.0 in stage 53.0 (TID 326). 4118 bytes result sent to driver
2018-02-08 15:57:30,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,177 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,178 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 178.0 in stage 53.0 (TID 328, localhost, executor driver, partition 178, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,178 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,179 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,179 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 176.0 in stage 53.0 (TID 326) in 19 ms on localhost (executor driver) (152/200)
2018-02-08 15:57:30,179 INFO[org.apache.spark.executor.Executor:54] - Running task 178.0 in stage 53.0 (TID 328)
2018-02-08 15:57:30,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,185 INFO[org.apache.spark.executor.Executor:54] - Finished task 177.0 in stage 53.0 (TID 327). 4118 bytes result sent to driver
2018-02-08 15:57:30,186 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 179.0 in stage 53.0 (TID 329, localhost, executor driver, partition 179, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,187 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 177.0 in stage 53.0 (TID 327) in 18 ms on localhost (executor driver) (153/200)
2018-02-08 15:57:30,187 INFO[org.apache.spark.executor.Executor:54] - Running task 179.0 in stage 53.0 (TID 329)
2018-02-08 15:57:30,189 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,189 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,191 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,191 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,192 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,192 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,194 INFO[org.apache.spark.executor.Executor:54] - Finished task 178.0 in stage 53.0 (TID 328). 4118 bytes result sent to driver
2018-02-08 15:57:30,194 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 180.0 in stage 53.0 (TID 330, localhost, executor driver, partition 180, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,195 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 178.0 in stage 53.0 (TID 328) in 18 ms on localhost (executor driver) (154/200)
2018-02-08 15:57:30,195 INFO[org.apache.spark.executor.Executor:54] - Running task 180.0 in stage 53.0 (TID 330)
2018-02-08 15:57:30,196 INFO[org.apache.spark.executor.Executor:54] - Finished task 179.0 in stage 53.0 (TID 329). 4075 bytes result sent to driver
2018-02-08 15:57:30,197 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 181.0 in stage 53.0 (TID 331, localhost, executor driver, partition 181, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,197 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 179.0 in stage 53.0 (TID 329) in 11 ms on localhost (executor driver) (155/200)
2018-02-08 15:57:30,197 INFO[org.apache.spark.executor.Executor:54] - Running task 181.0 in stage 53.0 (TID 331)
2018-02-08 15:57:30,209 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,209 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,210 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,210 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,210 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,211 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,211 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,211 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,218 INFO[org.apache.spark.executor.Executor:54] - Finished task 181.0 in stage 53.0 (TID 331). 4075 bytes result sent to driver
2018-02-08 15:57:30,219 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 182.0 in stage 53.0 (TID 332, localhost, executor driver, partition 182, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,220 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 181.0 in stage 53.0 (TID 331) in 24 ms on localhost (executor driver) (156/200)
2018-02-08 15:57:30,221 INFO[org.apache.spark.executor.Executor:54] - Running task 182.0 in stage 53.0 (TID 332)
2018-02-08 15:57:30,222 INFO[org.apache.spark.executor.Executor:54] - Finished task 180.0 in stage 53.0 (TID 330). 4075 bytes result sent to driver
2018-02-08 15:57:30,222 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 183.0 in stage 53.0 (TID 333, localhost, executor driver, partition 183, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,223 INFO[org.apache.spark.executor.Executor:54] - Running task 183.0 in stage 53.0 (TID 333)
2018-02-08 15:57:30,223 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 180.0 in stage 53.0 (TID 330) in 29 ms on localhost (executor driver) (157/200)
2018-02-08 15:57:30,225 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,225 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,226 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,226 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,226 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,226 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,227 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,227 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,231 INFO[org.apache.spark.executor.Executor:54] - Finished task 182.0 in stage 53.0 (TID 332). 4075 bytes result sent to driver
2018-02-08 15:57:30,232 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 184.0 in stage 53.0 (TID 334, localhost, executor driver, partition 184, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,233 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 182.0 in stage 53.0 (TID 332) in 14 ms on localhost (executor driver) (158/200)
2018-02-08 15:57:30,233 INFO[org.apache.spark.executor.Executor:54] - Running task 184.0 in stage 53.0 (TID 334)
2018-02-08 15:57:30,234 INFO[org.apache.spark.executor.Executor:54] - Finished task 183.0 in stage 53.0 (TID 333). 4075 bytes result sent to driver
2018-02-08 15:57:30,234 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 185.0 in stage 53.0 (TID 335, localhost, executor driver, partition 185, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,235 INFO[org.apache.spark.executor.Executor:54] - Running task 185.0 in stage 53.0 (TID 335)
2018-02-08 15:57:30,235 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 183.0 in stage 53.0 (TID 333) in 13 ms on localhost (executor driver) (159/200)
2018-02-08 15:57:30,237 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,238 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,239 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,239 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,239 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,239 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,240 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,240 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,244 INFO[org.apache.spark.executor.Executor:54] - Finished task 184.0 in stage 53.0 (TID 334). 4075 bytes result sent to driver
2018-02-08 15:57:30,244 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 186.0 in stage 53.0 (TID 336, localhost, executor driver, partition 186, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,244 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 184.0 in stage 53.0 (TID 334) in 12 ms on localhost (executor driver) (160/200)
2018-02-08 15:57:30,244 INFO[org.apache.spark.executor.Executor:54] - Running task 186.0 in stage 53.0 (TID 336)
2018-02-08 15:57:30,248 INFO[org.apache.spark.executor.Executor:54] - Finished task 185.0 in stage 53.0 (TID 335). 4075 bytes result sent to driver
2018-02-08 15:57:30,248 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,249 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,249 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 187.0 in stage 53.0 (TID 337, localhost, executor driver, partition 187, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,250 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,251 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,251 INFO[org.apache.spark.executor.Executor:54] - Running task 187.0 in stage 53.0 (TID 337)
2018-02-08 15:57:30,251 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 185.0 in stage 53.0 (TID 335) in 17 ms on localhost (executor driver) (161/200)
2018-02-08 15:57:30,255 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,255 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,256 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,256 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,257 INFO[org.apache.spark.executor.Executor:54] - Finished task 186.0 in stage 53.0 (TID 336). 4118 bytes result sent to driver
2018-02-08 15:57:30,258 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 188.0 in stage 53.0 (TID 338, localhost, executor driver, partition 188, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,258 INFO[org.apache.spark.executor.Executor:54] - Running task 188.0 in stage 53.0 (TID 338)
2018-02-08 15:57:30,258 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 186.0 in stage 53.0 (TID 336) in 14 ms on localhost (executor driver) (162/200)
2018-02-08 15:57:30,263 INFO[org.apache.spark.executor.Executor:54] - Finished task 187.0 in stage 53.0 (TID 337). 4075 bytes result sent to driver
2018-02-08 15:57:30,264 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,264 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,264 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 189.0 in stage 53.0 (TID 339, localhost, executor driver, partition 189, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,265 INFO[org.apache.spark.executor.Executor:54] - Running task 189.0 in stage 53.0 (TID 339)
2018-02-08 15:57:30,265 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 187.0 in stage 53.0 (TID 337) in 16 ms on localhost (executor driver) (163/200)
2018-02-08 15:57:30,265 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,265 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,269 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,270 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,271 INFO[org.apache.spark.executor.Executor:54] - Finished task 188.0 in stage 53.0 (TID 338). 4118 bytes result sent to driver
2018-02-08 15:57:30,274 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,274 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,274 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 190.0 in stage 53.0 (TID 340, localhost, executor driver, partition 190, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,275 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 188.0 in stage 53.0 (TID 338) in 17 ms on localhost (executor driver) (164/200)
2018-02-08 15:57:30,275 INFO[org.apache.spark.executor.Executor:54] - Running task 190.0 in stage 53.0 (TID 340)
2018-02-08 15:57:30,279 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,279 INFO[org.apache.spark.executor.Executor:54] - Finished task 189.0 in stage 53.0 (TID 339). 4075 bytes result sent to driver
2018-02-08 15:57:30,279 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,280 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 193.0 in stage 53.0 (TID 341, localhost, executor driver, partition 193, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,280 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 189.0 in stage 53.0 (TID 339) in 16 ms on localhost (executor driver) (165/200)
2018-02-08 15:57:30,280 INFO[org.apache.spark.executor.Executor:54] - Running task 193.0 in stage 53.0 (TID 341)
2018-02-08 15:57:30,281 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,281 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,285 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,285 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,286 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,286 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,287 INFO[org.apache.spark.executor.Executor:54] - Finished task 190.0 in stage 53.0 (TID 340). 4118 bytes result sent to driver
2018-02-08 15:57:30,288 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 194.0 in stage 53.0 (TID 342, localhost, executor driver, partition 194, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,288 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 190.0 in stage 53.0 (TID 340) in 14 ms on localhost (executor driver) (166/200)
2018-02-08 15:57:30,288 INFO[org.apache.spark.executor.Executor:54] - Running task 194.0 in stage 53.0 (TID 342)
2018-02-08 15:57:30,292 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,292 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,292 INFO[org.apache.spark.executor.Executor:54] - Finished task 193.0 in stage 53.0 (TID 341). 4118 bytes result sent to driver
2018-02-08 15:57:30,293 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 195.0 in stage 53.0 (TID 343, localhost, executor driver, partition 195, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,293 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,293 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 193.0 in stage 53.0 (TID 341) in 13 ms on localhost (executor driver) (167/200)
2018-02-08 15:57:30,293 INFO[org.apache.spark.executor.Executor:54] - Running task 195.0 in stage 53.0 (TID 343)
2018-02-08 15:57:30,293 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,297 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,298 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,299 INFO[org.apache.spark.executor.Executor:54] - Finished task 194.0 in stage 53.0 (TID 342). 4118 bytes result sent to driver
2018-02-08 15:57:30,299 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,299 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,299 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 196.0 in stage 53.0 (TID 344, localhost, executor driver, partition 196, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,299 INFO[org.apache.spark.executor.Executor:54] - Running task 196.0 in stage 53.0 (TID 344)
2018-02-08 15:57:30,299 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 194.0 in stage 53.0 (TID 342) in 12 ms on localhost (executor driver) (168/200)
2018-02-08 15:57:30,304 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,304 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,305 INFO[org.apache.spark.executor.Executor:54] - Finished task 195.0 in stage 53.0 (TID 343). 4118 bytes result sent to driver
2018-02-08 15:57:30,305 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 197.0 in stage 53.0 (TID 345, localhost, executor driver, partition 197, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,305 INFO[org.apache.spark.executor.Executor:54] - Running task 197.0 in stage 53.0 (TID 345)
2018-02-08 15:57:30,305 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 195.0 in stage 53.0 (TID 343) in 12 ms on localhost (executor driver) (169/200)
2018-02-08 15:57:30,306 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,306 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,310 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,310 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,310 INFO[org.apache.spark.executor.Executor:54] - Finished task 196.0 in stage 53.0 (TID 344). 4075 bytes result sent to driver
2018-02-08 15:57:30,311 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,311 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,311 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 198.0 in stage 53.0 (TID 346, localhost, executor driver, partition 198, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,312 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 196.0 in stage 53.0 (TID 344) in 13 ms on localhost (executor driver) (170/200)
2018-02-08 15:57:30,312 INFO[org.apache.spark.executor.Executor:54] - Running task 198.0 in stage 53.0 (TID 346)
2018-02-08 15:57:30,317 INFO[org.apache.spark.executor.Executor:54] - Finished task 197.0 in stage 53.0 (TID 345). 4118 bytes result sent to driver
2018-02-08 15:57:30,317 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,317 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,317 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 199.0 in stage 53.0 (TID 347, localhost, executor driver, partition 199, PROCESS_LOCAL, 5043 bytes)
2018-02-08 15:57:30,318 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 197.0 in stage 53.0 (TID 345) in 13 ms on localhost (executor driver) (171/200)
2018-02-08 15:57:30,319 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,320 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,321 INFO[org.apache.spark.executor.Executor:54] - Running task 199.0 in stage 53.0 (TID 347)
2018-02-08 15:57:30,325 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,325 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,327 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,327 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,333 INFO[org.apache.spark.executor.Executor:54] - Finished task 198.0 in stage 53.0 (TID 346). 4075 bytes result sent to driver
2018-02-08 15:57:30,334 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 53.0 (TID 348, localhost, executor driver, partition 14, ANY, 5043 bytes)
2018-02-08 15:57:30,334 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 53.0 (TID 348)
2018-02-08 15:57:30,334 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 198.0 in stage 53.0 (TID 346) in 23 ms on localhost (executor driver) (172/200)
2018-02-08 15:57:30,339 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,339 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,340 INFO[org.apache.spark.executor.Executor:54] - Finished task 199.0 in stage 53.0 (TID 347). 4118 bytes result sent to driver
2018-02-08 15:57:30,341 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,341 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,342 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 53.0 (TID 349, localhost, executor driver, partition 19, ANY, 5043 bytes)
2018-02-08 15:57:30,343 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 199.0 in stage 53.0 (TID 347) in 25 ms on localhost (executor driver) (173/200)
2018-02-08 15:57:30,343 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 53.0 (TID 349)
2018-02-08 15:57:30,373 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,374 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,375 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,375 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,429 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 53.0 (TID 348). 4290 bytes result sent to driver
2018-02-08 15:57:30,430 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 53.0 (TID 350, localhost, executor driver, partition 24, ANY, 5043 bytes)
2018-02-08 15:57:30,430 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 53.0 (TID 348) in 97 ms on localhost (executor driver) (174/200)
2018-02-08 15:57:30,430 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 53.0 (TID 350)
2018-02-08 15:57:30,434 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,434 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,436 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,436 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,447 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 53.0 (TID 349). 4290 bytes result sent to driver
2018-02-08 15:57:30,448 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 53.0 (TID 351, localhost, executor driver, partition 30, ANY, 5043 bytes)
2018-02-08 15:57:30,448 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 53.0 (TID 351)
2018-02-08 15:57:30,448 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 53.0 (TID 349) in 107 ms on localhost (executor driver) (175/200)
2018-02-08 15:57:30,452 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,453 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,454 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,455 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,478 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 53.0 (TID 350). 4247 bytes result sent to driver
2018-02-08 15:57:30,479 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 53.0 (TID 352, localhost, executor driver, partition 43, ANY, 5043 bytes)
2018-02-08 15:57:30,479 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 53.0 (TID 352)
2018-02-08 15:57:30,479 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 53.0 (TID 350) in 49 ms on localhost (executor driver) (176/200)
2018-02-08 15:57:30,483 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,483 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,484 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,484 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,498 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 53.0 (TID 351). 4290 bytes result sent to driver
2018-02-08 15:57:30,498 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 53.0 (TID 353, localhost, executor driver, partition 48, ANY, 5043 bytes)
2018-02-08 15:57:30,499 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 53.0 (TID 353)
2018-02-08 15:57:30,499 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 53.0 (TID 351) in 51 ms on localhost (executor driver) (177/200)
2018-02-08 15:57:30,503 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,503 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,505 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,505 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,532 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 53.0 (TID 352). 4247 bytes result sent to driver
2018-02-08 15:57:30,533 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 53.0 (TID 354, localhost, executor driver, partition 49, ANY, 5043 bytes)
2018-02-08 15:57:30,533 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 53.0 (TID 354)
2018-02-08 15:57:30,533 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 53.0 (TID 352) in 54 ms on localhost (executor driver) (178/200)
2018-02-08 15:57:30,537 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,537 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,539 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,539 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,553 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 53.0 (TID 353). 4247 bytes result sent to driver
2018-02-08 15:57:30,554 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 53.0 (TID 355, localhost, executor driver, partition 51, ANY, 5043 bytes)
2018-02-08 15:57:30,555 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 53.0 (TID 353) in 57 ms on localhost (executor driver) (179/200)
2018-02-08 15:57:30,555 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 53.0 (TID 355)
2018-02-08 15:57:30,560 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,560 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,562 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,562 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,603 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 53.0 (TID 355). 4247 bytes result sent to driver
2018-02-08 15:57:30,604 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 53.0 (TID 356, localhost, executor driver, partition 53, ANY, 5043 bytes)
2018-02-08 15:57:30,604 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 53.0 (TID 355) in 50 ms on localhost (executor driver) (180/200)
2018-02-08 15:57:30,607 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 53.0 (TID 356)
2018-02-08 15:57:30,612 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,612 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,614 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,615 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,655 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 53.0 (TID 354). 4247 bytes result sent to driver
2018-02-08 15:57:30,656 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 53.0 (TID 357, localhost, executor driver, partition 66, ANY, 5043 bytes)
2018-02-08 15:57:30,657 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 53.0 (TID 354) in 124 ms on localhost (executor driver) (181/200)
2018-02-08 15:57:30,657 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 53.0 (TID 357)
2018-02-08 15:57:30,661 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,662 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,663 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,663 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,674 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 53.0 (TID 356). 4290 bytes result sent to driver
2018-02-08 15:57:30,675 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 53.0 (TID 358, localhost, executor driver, partition 69, ANY, 5043 bytes)
2018-02-08 15:57:30,675 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 53.0 (TID 358)
2018-02-08 15:57:30,675 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 53.0 (TID 356) in 72 ms on localhost (executor driver) (182/200)
2018-02-08 15:57:30,679 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,679 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,680 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,680 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,711 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 53.0 (TID 357). 4247 bytes result sent to driver
2018-02-08 15:57:30,712 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 53.0 (TID 359, localhost, executor driver, partition 77, ANY, 5043 bytes)
2018-02-08 15:57:30,713 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 53.0 (TID 357) in 57 ms on localhost (executor driver) (183/200)
2018-02-08 15:57:30,713 INFO[org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 53.0 (TID 359)
2018-02-08 15:57:30,718 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,718 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,721 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,721 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,725 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 53.0 (TID 358). 4247 bytes result sent to driver
2018-02-08 15:57:30,726 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 53.0 (TID 360, localhost, executor driver, partition 89, ANY, 5043 bytes)
2018-02-08 15:57:30,726 INFO[org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 53.0 (TID 360)
2018-02-08 15:57:30,726 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 53.0 (TID 358) in 51 ms on localhost (executor driver) (184/200)
2018-02-08 15:57:30,729 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,729 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,731 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,731 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,758 INFO[org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 53.0 (TID 359). 4247 bytes result sent to driver
2018-02-08 15:57:30,758 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 102.0 in stage 53.0 (TID 361, localhost, executor driver, partition 102, ANY, 5043 bytes)
2018-02-08 15:57:30,759 INFO[org.apache.spark.executor.Executor:54] - Running task 102.0 in stage 53.0 (TID 361)
2018-02-08 15:57:30,759 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 53.0 (TID 359) in 47 ms on localhost (executor driver) (185/200)
2018-02-08 15:57:30,763 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,763 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,764 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,765 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,774 INFO[org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 53.0 (TID 360). 4247 bytes result sent to driver
2018-02-08 15:57:30,775 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 103.0 in stage 53.0 (TID 362, localhost, executor driver, partition 103, ANY, 5043 bytes)
2018-02-08 15:57:30,775 INFO[org.apache.spark.executor.Executor:54] - Running task 103.0 in stage 53.0 (TID 362)
2018-02-08 15:57:30,775 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 53.0 (TID 360) in 49 ms on localhost (executor driver) (186/200)
2018-02-08 15:57:30,779 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,779 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,781 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,781 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,809 INFO[org.apache.spark.executor.Executor:54] - Finished task 102.0 in stage 53.0 (TID 361). 4247 bytes result sent to driver
2018-02-08 15:57:30,810 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 105.0 in stage 53.0 (TID 363, localhost, executor driver, partition 105, ANY, 5043 bytes)
2018-02-08 15:57:30,810 INFO[org.apache.spark.executor.Executor:54] - Running task 105.0 in stage 53.0 (TID 363)
2018-02-08 15:57:30,810 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 102.0 in stage 53.0 (TID 361) in 52 ms on localhost (executor driver) (187/200)
2018-02-08 15:57:30,812 INFO[org.apache.spark.executor.Executor:54] - Finished task 103.0 in stage 53.0 (TID 362). 4247 bytes result sent to driver
2018-02-08 15:57:30,813 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 107.0 in stage 53.0 (TID 364, localhost, executor driver, partition 107, ANY, 5043 bytes)
2018-02-08 15:57:30,813 INFO[org.apache.spark.executor.Executor:54] - Running task 107.0 in stage 53.0 (TID 364)
2018-02-08 15:57:30,813 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 103.0 in stage 53.0 (TID 362) in 38 ms on localhost (executor driver) (188/200)
2018-02-08 15:57:30,815 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,815 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,816 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,817 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,818 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,818 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,819 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,820 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,874 INFO[org.apache.spark.executor.Executor:54] - Finished task 107.0 in stage 53.0 (TID 364). 4247 bytes result sent to driver
2018-02-08 15:57:30,874 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 122.0 in stage 53.0 (TID 365, localhost, executor driver, partition 122, ANY, 5043 bytes)
2018-02-08 15:57:30,874 INFO[org.apache.spark.executor.Executor:54] - Running task 122.0 in stage 53.0 (TID 365)
2018-02-08 15:57:30,874 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 107.0 in stage 53.0 (TID 364) in 61 ms on localhost (executor driver) (189/200)
2018-02-08 15:57:30,877 INFO[org.apache.spark.executor.Executor:54] - Finished task 105.0 in stage 53.0 (TID 363). 4290 bytes result sent to driver
2018-02-08 15:57:30,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 132.0 in stage 53.0 (TID 366, localhost, executor driver, partition 132, ANY, 5043 bytes)
2018-02-08 15:57:30,879 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 105.0 in stage 53.0 (TID 363) in 69 ms on localhost (executor driver) (190/200)
2018-02-08 15:57:30,879 INFO[org.apache.spark.executor.Executor:54] - Running task 132.0 in stage 53.0 (TID 366)
2018-02-08 15:57:30,883 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,883 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,885 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,885 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,885 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,885 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,886 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,887 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,923 INFO[org.apache.spark.executor.Executor:54] - Finished task 132.0 in stage 53.0 (TID 366). 4247 bytes result sent to driver
2018-02-08 15:57:30,924 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 135.0 in stage 53.0 (TID 367, localhost, executor driver, partition 135, ANY, 5043 bytes)
2018-02-08 15:57:30,924 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 132.0 in stage 53.0 (TID 366) in 46 ms on localhost (executor driver) (191/200)
2018-02-08 15:57:30,925 INFO[org.apache.spark.executor.Executor:54] - Running task 135.0 in stage 53.0 (TID 367)
2018-02-08 15:57:30,927 INFO[org.apache.spark.executor.Executor:54] - Finished task 122.0 in stage 53.0 (TID 365). 4247 bytes result sent to driver
2018-02-08 15:57:30,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 141.0 in stage 53.0 (TID 368, localhost, executor driver, partition 141, ANY, 5043 bytes)
2018-02-08 15:57:30,928 INFO[org.apache.spark.executor.Executor:54] - Running task 141.0 in stage 53.0 (TID 368)
2018-02-08 15:57:30,928 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 122.0 in stage 53.0 (TID 365) in 54 ms on localhost (executor driver) (192/200)
2018-02-08 15:57:30,930 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,930 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,932 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,932 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,932 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,932 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,933 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,934 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,970 INFO[org.apache.spark.executor.Executor:54] - Finished task 141.0 in stage 53.0 (TID 368). 4290 bytes result sent to driver
2018-02-08 15:57:30,971 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 143.0 in stage 53.0 (TID 369, localhost, executor driver, partition 143, ANY, 5043 bytes)
2018-02-08 15:57:30,971 INFO[org.apache.spark.executor.Executor:54] - Running task 143.0 in stage 53.0 (TID 369)
2018-02-08 15:57:30,971 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 141.0 in stage 53.0 (TID 368) in 43 ms on localhost (executor driver) (193/200)
2018-02-08 15:57:30,974 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,975 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:30,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,988 INFO[org.apache.spark.executor.Executor:54] - Finished task 135.0 in stage 53.0 (TID 367). 4247 bytes result sent to driver
2018-02-08 15:57:30,988 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 163.0 in stage 53.0 (TID 370, localhost, executor driver, partition 163, ANY, 5043 bytes)
2018-02-08 15:57:30,989 INFO[org.apache.spark.executor.Executor:54] - Running task 163.0 in stage 53.0 (TID 370)
2018-02-08 15:57:30,990 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 135.0 in stage 53.0 (TID 367) in 67 ms on localhost (executor driver) (194/200)
2018-02-08 15:57:30,996 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:30,996 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:30,997 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:30,997 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,041 INFO[org.apache.spark.executor.Executor:54] - Finished task 143.0 in stage 53.0 (TID 369). 4247 bytes result sent to driver
2018-02-08 15:57:31,042 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 168.0 in stage 53.0 (TID 371, localhost, executor driver, partition 168, ANY, 5043 bytes)
2018-02-08 15:57:31,042 INFO[org.apache.spark.executor.Executor:54] - Running task 168.0 in stage 53.0 (TID 371)
2018-02-08 15:57:31,043 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 143.0 in stage 53.0 (TID 369) in 71 ms on localhost (executor driver) (195/200)
2018-02-08 15:57:31,047 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:31,047 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,048 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,048 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,072 INFO[org.apache.spark.executor.Executor:54] - Finished task 163.0 in stage 53.0 (TID 370). 4247 bytes result sent to driver
2018-02-08 15:57:31,073 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 174.0 in stage 53.0 (TID 372, localhost, executor driver, partition 174, ANY, 5043 bytes)
2018-02-08 15:57:31,073 INFO[org.apache.spark.executor.Executor:54] - Running task 174.0 in stage 53.0 (TID 372)
2018-02-08 15:57:31,073 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 163.0 in stage 53.0 (TID 370) in 85 ms on localhost (executor driver) (196/200)
2018-02-08 15:57:31,076 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:31,077 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,078 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,079 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,110 INFO[org.apache.spark.executor.Executor:54] - Finished task 168.0 in stage 53.0 (TID 371). 4290 bytes result sent to driver
2018-02-08 15:57:31,110 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 191.0 in stage 53.0 (TID 373, localhost, executor driver, partition 191, ANY, 5043 bytes)
2018-02-08 15:57:31,111 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 168.0 in stage 53.0 (TID 371) in 69 ms on localhost (executor driver) (197/200)
2018-02-08 15:57:31,111 INFO[org.apache.spark.executor.Executor:54] - Running task 191.0 in stage 53.0 (TID 373)
2018-02-08 15:57:31,114 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:31,115 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,116 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,117 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,139 INFO[org.apache.spark.executor.Executor:54] - Finished task 174.0 in stage 53.0 (TID 372). 4247 bytes result sent to driver
2018-02-08 15:57:31,140 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 192.0 in stage 53.0 (TID 374, localhost, executor driver, partition 192, ANY, 5043 bytes)
2018-02-08 15:57:31,141 INFO[org.apache.spark.executor.Executor:54] - Running task 192.0 in stage 53.0 (TID 374)
2018-02-08 15:57:31,141 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 174.0 in stage 53.0 (TID 372) in 69 ms on localhost (executor driver) (198/200)
2018-02-08 15:57:31,146 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:57:31,146 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,147 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,147 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,161 INFO[org.apache.spark.executor.Executor:54] - Finished task 191.0 in stage 53.0 (TID 373). 4247 bytes result sent to driver
2018-02-08 15:57:31,161 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 191.0 in stage 53.0 (TID 373) in 51 ms on localhost (executor driver) (199/200)
2018-02-08 15:57:31,182 INFO[org.apache.spark.executor.Executor:54] - Finished task 192.0 in stage 53.0 (TID 374). 4247 bytes result sent to driver
2018-02-08 15:57:31,183 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 192.0 in stage 53.0 (TID 374) in 43 ms on localhost (executor driver) (200/200)
2018-02-08 15:57:31,183 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2018-02-08 15:57:31,183 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 53 (rdd at RegressionEvaluator.scala:82) finished in 2.872 s
2018-02-08 15:57:31,183 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:57:31,183 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:57:31,183 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 54)
2018-02-08 15:57:31,183 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:57:31,184 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 54 (MapPartitionsRDD[150] at map at RegressionMetrics.scala:55), which has no missing parents
2018-02-08 15:57:31,192 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24 stored as values in memory (estimated size 73.9 KB, free 631.2 MB)
2018-02-08 15:57:31,194 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 29.7 KB, free 631.2 MB)
2018-02-08 15:57:31,194 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_24_piece0 in memory on 192.168.11.26:62834 (size: 29.7 KB, free: 631.7 MB)
2018-02-08 15:57:31,195 INFO[org.apache.spark.SparkContext:54] - Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:57:31,196 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 200 missing tasks from ResultStage 54 (MapPartitionsRDD[150] at map at RegressionMetrics.scala:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-02-08 15:57:31,196 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 54.0 with 200 tasks
2018-02-08 15:57:31,198 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 54.0 (TID 375, localhost, executor driver, partition 0, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,198 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 54.0 (TID 376, localhost, executor driver, partition 1, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,198 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 54.0 (TID 375)
2018-02-08 15:57:31,198 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 54.0 (TID 376)
2018-02-08 15:57:31,202 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,202 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,202 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,202 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,214 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.969924 ms
2018-02-08 15:57:31,226 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 10.466563 ms
2018-02-08 15:57:31,228 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,228 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,228 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,228 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,238 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.461763 ms
2018-02-08 15:57:31,252 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.286403 ms
2018-02-08 15:57:31,261 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 4.822081 ms
2018-02-08 15:57:31,263 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 54.0 (TID 376). 5343 bytes result sent to driver
2018-02-08 15:57:31,263 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 54.0 (TID 375). 5343 bytes result sent to driver
2018-02-08 15:57:31,264 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 54.0 (TID 377, localhost, executor driver, partition 6, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,264 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 54.0 (TID 378, localhost, executor driver, partition 8, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,264 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 54.0 (TID 377)
2018-02-08 15:57:31,265 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 54.0 (TID 375) in 68 ms on localhost (executor driver) (1/200)
2018-02-08 15:57:31,265 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 54.0 (TID 376) in 67 ms on localhost (executor driver) (2/200)
2018-02-08 15:57:31,266 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 54.0 (TID 378)
2018-02-08 15:57:31,269 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,270 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:57:31,271 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,271 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,271 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,271 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,274 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 54.0 (TID 377). 5300 bytes result sent to driver
2018-02-08 15:57:31,275 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 54.0 (TID 379, localhost, executor driver, partition 9, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,275 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 54.0 (TID 377) in 11 ms on localhost (executor driver) (3/200)
2018-02-08 15:57:31,275 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 54.0 (TID 379)
2018-02-08 15:57:31,283 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,284 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,285 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,285 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,287 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 54.0 (TID 379). 5343 bytes result sent to driver
2018-02-08 15:57:31,288 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 54.0 (TID 380, localhost, executor driver, partition 10, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,288 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 54.0 (TID 379) in 13 ms on localhost (executor driver) (4/200)
2018-02-08 15:57:31,288 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 54.0 (TID 380)
2018-02-08 15:57:31,297 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,297 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,298 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,298 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,300 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 54.0 (TID 378). 5300 bytes result sent to driver
2018-02-08 15:57:31,300 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 54.0 (TID 381, localhost, executor driver, partition 12, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,301 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 54.0 (TID 378) in 37 ms on localhost (executor driver) (5/200)
2018-02-08 15:57:31,301 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 54.0 (TID 381)
2018-02-08 15:57:31,315 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,315 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,317 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,317 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,318 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,318 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,321 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 54.0 (TID 381). 5343 bytes result sent to driver
2018-02-08 15:57:31,322 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 54.0 (TID 382, localhost, executor driver, partition 15, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,322 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 54.0 (TID 381) in 22 ms on localhost (executor driver) (6/200)
2018-02-08 15:57:31,322 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 54.0 (TID 382)
2018-02-08 15:57:31,323 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 54.0 (TID 380). 5343 bytes result sent to driver
2018-02-08 15:57:31,323 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 54.0 (TID 383, localhost, executor driver, partition 16, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,331 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 54.0 (TID 380) in 43 ms on localhost (executor driver) (7/200)
2018-02-08 15:57:31,333 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 54.0 (TID 383)
2018-02-08 15:57:31,333 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,338 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 5 ms
2018-02-08 15:57:31,338 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,338 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,339 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,339 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,339 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,339 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,345 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 54.0 (TID 382). 5300 bytes result sent to driver
2018-02-08 15:57:31,345 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 54.0 (TID 384, localhost, executor driver, partition 17, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,346 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 54.0 (TID 382) in 25 ms on localhost (executor driver) (8/200)
2018-02-08 15:57:31,346 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 54.0 (TID 384)
2018-02-08 15:57:31,347 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 54.0 (TID 383). 5300 bytes result sent to driver
2018-02-08 15:57:31,348 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 54.0 (TID 385, localhost, executor driver, partition 20, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,348 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 54.0 (TID 385)
2018-02-08 15:57:31,348 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 54.0 (TID 383) in 25 ms on localhost (executor driver) (9/200)
2018-02-08 15:57:31,352 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,353 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,354 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,354 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,355 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,355 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 15:57:31,356 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,356 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,360 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 54.0 (TID 385). 5300 bytes result sent to driver
2018-02-08 15:57:31,361 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 54.0 (TID 386, localhost, executor driver, partition 22, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,361 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 54.0 (TID 385) in 14 ms on localhost (executor driver) (10/200)
2018-02-08 15:57:31,361 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 54.0 (TID 386)
2018-02-08 15:57:31,362 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 54.0 (TID 384). 5343 bytes result sent to driver
2018-02-08 15:57:31,362 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 54.0 (TID 387, localhost, executor driver, partition 23, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,365 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 54.0 (TID 384) in 20 ms on localhost (executor driver) (11/200)
2018-02-08 15:57:31,366 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 54.0 (TID 387)
2018-02-08 15:57:31,367 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,368 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,369 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,369 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,370 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,370 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,371 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 54.0 (TID 386). 5300 bytes result sent to driver
2018-02-08 15:57:31,371 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 54.0 (TID 388, localhost, executor driver, partition 25, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,371 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,371 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 54.0 (TID 386) in 10 ms on localhost (executor driver) (12/200)
2018-02-08 15:57:31,371 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 54.0 (TID 388)
2018-02-08 15:57:31,371 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,375 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 54.0 (TID 387). 5343 bytes result sent to driver
2018-02-08 15:57:31,376 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 54.0 (TID 389, localhost, executor driver, partition 26, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,376 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 54.0 (TID 389)
2018-02-08 15:57:31,376 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 54.0 (TID 387) in 14 ms on localhost (executor driver) (13/200)
2018-02-08 15:57:31,377 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,377 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,379 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,379 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,380 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,380 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,381 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,381 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,382 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 54.0 (TID 388). 5343 bytes result sent to driver
2018-02-08 15:57:31,382 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 54.0 (TID 390, localhost, executor driver, partition 28, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,383 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 54.0 (TID 388) in 12 ms on localhost (executor driver) (14/200)
2018-02-08 15:57:31,383 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 54.0 (TID 390)
2018-02-08 15:57:31,383 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 54.0 (TID 389). 5300 bytes result sent to driver
2018-02-08 15:57:31,383 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 54.0 (TID 391, localhost, executor driver, partition 29, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,384 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 54.0 (TID 389) in 9 ms on localhost (executor driver) (15/200)
2018-02-08 15:57:31,384 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 54.0 (TID 391)
2018-02-08 15:57:31,387 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,387 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,388 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,388 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,388 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,388 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,389 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,389 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,390 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 54.0 (TID 390). 5300 bytes result sent to driver
2018-02-08 15:57:31,390 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 54.0 (TID 392, localhost, executor driver, partition 31, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,390 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 54.0 (TID 391). 5343 bytes result sent to driver
2018-02-08 15:57:31,390 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 54.0 (TID 392)
2018-02-08 15:57:31,390 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 54.0 (TID 390) in 8 ms on localhost (executor driver) (16/200)
2018-02-08 15:57:31,390 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 54.0 (TID 393, localhost, executor driver, partition 33, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,391 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 54.0 (TID 393)
2018-02-08 15:57:31,391 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 54.0 (TID 391) in 8 ms on localhost (executor driver) (17/200)
2018-02-08 15:57:31,394 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,394 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,394 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,394 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,395 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,395 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,395 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,395 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,396 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 54.0 (TID 393). 5300 bytes result sent to driver
2018-02-08 15:57:31,396 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 54.0 (TID 392). 5300 bytes result sent to driver
2018-02-08 15:57:31,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 54.0 (TID 394, localhost, executor driver, partition 34, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,397 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 54.0 (TID 394)
2018-02-08 15:57:31,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 54.0 (TID 395, localhost, executor driver, partition 36, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,397 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 54.0 (TID 395)
2018-02-08 15:57:31,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 54.0 (TID 392) in 7 ms on localhost (executor driver) (18/200)
2018-02-08 15:57:31,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 54.0 (TID 393) in 7 ms on localhost (executor driver) (19/200)
2018-02-08 15:57:31,400 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,400 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,400 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,400 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,401 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,401 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,401 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,401 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,403 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 54.0 (TID 395). 5300 bytes result sent to driver
2018-02-08 15:57:31,403 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 54.0 (TID 394). 5300 bytes result sent to driver
2018-02-08 15:57:31,403 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 54.0 (TID 396, localhost, executor driver, partition 37, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,403 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 54.0 (TID 396)
2018-02-08 15:57:31,403 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 54.0 (TID 397, localhost, executor driver, partition 38, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,403 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 54.0 (TID 395) in 6 ms on localhost (executor driver) (20/200)
2018-02-08 15:57:31,403 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 54.0 (TID 397)
2018-02-08 15:57:31,404 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 54.0 (TID 394) in 7 ms on localhost (executor driver) (21/200)
2018-02-08 15:57:31,407 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,407 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,408 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,408 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,409 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,409 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,409 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,409 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,411 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 54.0 (TID 397). 5343 bytes result sent to driver
2018-02-08 15:57:31,411 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 54.0 (TID 396). 5343 bytes result sent to driver
2018-02-08 15:57:31,411 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 54.0 (TID 398, localhost, executor driver, partition 39, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,411 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 54.0 (TID 398)
2018-02-08 15:57:31,411 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 54.0 (TID 399, localhost, executor driver, partition 40, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,411 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 54.0 (TID 396) in 8 ms on localhost (executor driver) (22/200)
2018-02-08 15:57:31,412 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 54.0 (TID 397) in 9 ms on localhost (executor driver) (23/200)
2018-02-08 15:57:31,411 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 54.0 (TID 399)
2018-02-08 15:57:31,415 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,415 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,415 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,415 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,416 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,416 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,416 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,417 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,418 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 54.0 (TID 398). 5300 bytes result sent to driver
2018-02-08 15:57:31,419 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 54.0 (TID 400, localhost, executor driver, partition 41, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,419 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 54.0 (TID 399). 5300 bytes result sent to driver
2018-02-08 15:57:31,419 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 54.0 (TID 400)
2018-02-08 15:57:31,419 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 54.0 (TID 398) in 8 ms on localhost (executor driver) (24/200)
2018-02-08 15:57:31,420 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 54.0 (TID 401, localhost, executor driver, partition 42, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,422 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 54.0 (TID 399) in 11 ms on localhost (executor driver) (25/200)
2018-02-08 15:57:31,423 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 54.0 (TID 401)
2018-02-08 15:57:31,424 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,424 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,425 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,425 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,427 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,427 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,428 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 54.0 (TID 400). 5343 bytes result sent to driver
2018-02-08 15:57:31,429 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,429 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,429 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 54.0 (TID 402, localhost, executor driver, partition 45, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,430 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 54.0 (TID 402)
2018-02-08 15:57:31,430 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 54.0 (TID 400) in 11 ms on localhost (executor driver) (26/200)
2018-02-08 15:57:31,432 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 54.0 (TID 401). 5300 bytes result sent to driver
2018-02-08 15:57:31,432 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 54.0 (TID 403, localhost, executor driver, partition 46, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,432 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 54.0 (TID 403)
2018-02-08 15:57:31,432 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 54.0 (TID 401) in 12 ms on localhost (executor driver) (27/200)
2018-02-08 15:57:31,434 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,434 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,435 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,435 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,436 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,436 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,437 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 54.0 (TID 402). 5300 bytes result sent to driver
2018-02-08 15:57:31,437 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,438 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 54.0 (TID 404, localhost, executor driver, partition 47, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,438 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,438 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 54.0 (TID 402) in 9 ms on localhost (executor driver) (28/200)
2018-02-08 15:57:31,438 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 54.0 (TID 404)
2018-02-08 15:57:31,439 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 54.0 (TID 403). 5343 bytes result sent to driver
2018-02-08 15:57:31,440 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 54.0 (TID 405, localhost, executor driver, partition 50, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,440 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 54.0 (TID 405)
2018-02-08 15:57:31,440 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 54.0 (TID 403) in 8 ms on localhost (executor driver) (29/200)
2018-02-08 15:57:31,441 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,441 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,442 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,442 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,443 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,443 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,444 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,444 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,444 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 54.0 (TID 404). 5300 bytes result sent to driver
2018-02-08 15:57:31,444 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 54.0 (TID 406, localhost, executor driver, partition 52, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,444 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 54.0 (TID 406)
2018-02-08 15:57:31,444 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 54.0 (TID 404) in 7 ms on localhost (executor driver) (30/200)
2018-02-08 15:57:31,445 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 54.0 (TID 405). 5300 bytes result sent to driver
2018-02-08 15:57:31,446 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 54.0 (TID 407, localhost, executor driver, partition 54, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,446 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 54.0 (TID 407)
2018-02-08 15:57:31,446 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 54.0 (TID 405) in 6 ms on localhost (executor driver) (31/200)
2018-02-08 15:57:31,448 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,448 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,449 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,449 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,449 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,449 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,450 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,450 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,451 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 54.0 (TID 406). 5300 bytes result sent to driver
2018-02-08 15:57:31,451 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 54.0 (TID 407). 5300 bytes result sent to driver
2018-02-08 15:57:31,451 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 54.0 (TID 408, localhost, executor driver, partition 55, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,452 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 54.0 (TID 408)
2018-02-08 15:57:31,452 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 54.0 (TID 409, localhost, executor driver, partition 56, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,452 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 54.0 (TID 409)
2018-02-08 15:57:31,452 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 54.0 (TID 407) in 7 ms on localhost (executor driver) (32/200)
2018-02-08 15:57:31,452 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 54.0 (TID 406) in 8 ms on localhost (executor driver) (33/200)
2018-02-08 15:57:31,455 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,455 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,456 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,456 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,457 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,457 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,457 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,457 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,458 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 54.0 (TID 409). 5343 bytes result sent to driver
2018-02-08 15:57:31,458 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 54.0 (TID 408). 5343 bytes result sent to driver
2018-02-08 15:57:31,459 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 54.0 (TID 410, localhost, executor driver, partition 59, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,459 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 54.0 (TID 410)
2018-02-08 15:57:31,459 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 54.0 (TID 411, localhost, executor driver, partition 60, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,459 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 54.0 (TID 411)
2018-02-08 15:57:31,459 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 54.0 (TID 408) in 8 ms on localhost (executor driver) (34/200)
2018-02-08 15:57:31,459 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 54.0 (TID 409) in 7 ms on localhost (executor driver) (35/200)
2018-02-08 15:57:31,462 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,462 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,462 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,463 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,463 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,463 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,463 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,463 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,465 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 54.0 (TID 410). 5300 bytes result sent to driver
2018-02-08 15:57:31,467 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 54.0 (TID 411). 5300 bytes result sent to driver
2018-02-08 15:57:31,467 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 54.0 (TID 412, localhost, executor driver, partition 62, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,468 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 54.0 (TID 413, localhost, executor driver, partition 64, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,469 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 54.0 (TID 412)
2018-02-08 15:57:31,469 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 54.0 (TID 413)
2018-02-08 15:57:31,474 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,474 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,474 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,474 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,476 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,476 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,477 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,477 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,478 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 54.0 (TID 412). 5300 bytes result sent to driver
2018-02-08 15:57:31,479 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 54.0 (TID 413). 5300 bytes result sent to driver
2018-02-08 15:57:31,469 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 54.0 (TID 410) in 10 ms on localhost (executor driver) (36/200)
2018-02-08 15:57:31,480 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 54.0 (TID 414, localhost, executor driver, partition 67, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,480 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 54.0 (TID 415, localhost, executor driver, partition 68, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,480 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 54.0 (TID 414)
2018-02-08 15:57:31,480 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 54.0 (TID 413) in 12 ms on localhost (executor driver) (37/200)
2018-02-08 15:57:31,481 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 54.0 (TID 412) in 14 ms on localhost (executor driver) (38/200)
2018-02-08 15:57:31,481 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 54.0 (TID 415)
2018-02-08 15:57:31,485 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,486 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,487 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,487 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,489 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,490 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,490 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 54.0 (TID 415). 5343 bytes result sent to driver
2018-02-08 15:57:31,490 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 54.0 (TID 416, localhost, executor driver, partition 71, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,490 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,491 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,491 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 54.0 (TID 411) in 32 ms on localhost (executor driver) (39/200)
2018-02-08 15:57:31,491 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 54.0 (TID 415) in 11 ms on localhost (executor driver) (40/200)
2018-02-08 15:57:31,492 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 54.0 (TID 416)
2018-02-08 15:57:31,493 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 54.0 (TID 414). 5343 bytes result sent to driver
2018-02-08 15:57:31,493 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 54.0 (TID 417, localhost, executor driver, partition 72, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,494 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 54.0 (TID 414) in 14 ms on localhost (executor driver) (41/200)
2018-02-08 15:57:31,495 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 54.0 (TID 417)
2018-02-08 15:57:31,497 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,497 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,499 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,499 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,506 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,506 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,507 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,507 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,510 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 54.0 (TID 417). 5300 bytes result sent to driver
2018-02-08 15:57:31,511 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 54.0 (TID 418, localhost, executor driver, partition 74, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,512 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 54.0 (TID 417) in 19 ms on localhost (executor driver) (42/200)
2018-02-08 15:57:31,512 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 54.0 (TID 418)
2018-02-08 15:57:31,524 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 54.0 (TID 416). 5343 bytes result sent to driver
2018-02-08 15:57:31,524 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 54.0 (TID 419, localhost, executor driver, partition 76, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,525 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 54.0 (TID 416) in 35 ms on localhost (executor driver) (43/200)
2018-02-08 15:57:31,525 INFO[org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 54.0 (TID 419)
2018-02-08 15:57:31,528 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,528 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,529 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,529 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,529 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,529 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,539 INFO[org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 54.0 (TID 419). 5343 bytes result sent to driver
2018-02-08 15:57:31,540 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 54.0 (TID 420, localhost, executor driver, partition 78, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,540 INFO[org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 54.0 (TID 420)
2018-02-08 15:57:31,540 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 54.0 (TID 419) in 16 ms on localhost (executor driver) (44/200)
2018-02-08 15:57:31,542 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 54.0 (TID 418). 5386 bytes result sent to driver
2018-02-08 15:57:31,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 54.0 (TID 421, localhost, executor driver, partition 79, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,543 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 54.0 (TID 418) in 32 ms on localhost (executor driver) (45/200)
2018-02-08 15:57:31,543 INFO[org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 54.0 (TID 421)
2018-02-08 15:57:31,544 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,546 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:57:31,547 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,547 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,551 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,551 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,551 INFO[org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 54.0 (TID 420). 5300 bytes result sent to driver
2018-02-08 15:57:31,551 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 54.0 (TID 422, localhost, executor driver, partition 80, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,552 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,552 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,554 INFO[org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 54.0 (TID 421). 5343 bytes result sent to driver
2018-02-08 15:57:31,555 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 54.0 (TID 423, localhost, executor driver, partition 81, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,556 INFO[org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 54.0 (TID 422)
2018-02-08 15:57:31,556 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 54.0 (TID 420) in 16 ms on localhost (executor driver) (46/200)
2018-02-08 15:57:31,560 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 54.0 (TID 421) in 17 ms on localhost (executor driver) (47/200)
2018-02-08 15:57:31,560 INFO[org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 54.0 (TID 423)
2018-02-08 15:57:31,561 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,561 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,563 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,564 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,564 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,565 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,567 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,568 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,568 INFO[org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 54.0 (TID 422). 5343 bytes result sent to driver
2018-02-08 15:57:31,568 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 54.0 (TID 424, localhost, executor driver, partition 82, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,569 INFO[org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 54.0 (TID 424)
2018-02-08 15:57:31,569 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 54.0 (TID 422) in 18 ms on localhost (executor driver) (48/200)
2018-02-08 15:57:31,569 INFO[org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 54.0 (TID 423). 5343 bytes result sent to driver
2018-02-08 15:57:31,569 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 54.0 (TID 425, localhost, executor driver, partition 83, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,570 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 54.0 (TID 423) in 15 ms on localhost (executor driver) (49/200)
2018-02-08 15:57:31,570 INFO[org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 54.0 (TID 425)
2018-02-08 15:57:31,573 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,574 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,575 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,575 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,575 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,575 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,576 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,576 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,577 INFO[org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 54.0 (TID 424). 5300 bytes result sent to driver
2018-02-08 15:57:31,577 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 54.0 (TID 426, localhost, executor driver, partition 87, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,578 INFO[org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 54.0 (TID 425). 5300 bytes result sent to driver
2018-02-08 15:57:31,578 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 54.0 (TID 424) in 10 ms on localhost (executor driver) (50/200)
2018-02-08 15:57:31,578 INFO[org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 54.0 (TID 426)
2018-02-08 15:57:31,578 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 54.0 (TID 427, localhost, executor driver, partition 88, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,579 INFO[org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 54.0 (TID 427)
2018-02-08 15:57:31,579 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 54.0 (TID 425) in 10 ms on localhost (executor driver) (51/200)
2018-02-08 15:57:31,584 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,584 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,584 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,584 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,585 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,585 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,585 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,585 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,587 INFO[org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 54.0 (TID 427). 5300 bytes result sent to driver
2018-02-08 15:57:31,587 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 54.0 (TID 428, localhost, executor driver, partition 90, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,588 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 54.0 (TID 427) in 10 ms on localhost (executor driver) (52/200)
2018-02-08 15:57:31,588 INFO[org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 54.0 (TID 426). 5300 bytes result sent to driver
2018-02-08 15:57:31,588 INFO[org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 54.0 (TID 428)
2018-02-08 15:57:31,589 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 54.0 (TID 429, localhost, executor driver, partition 92, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,589 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 54.0 (TID 426) in 12 ms on localhost (executor driver) (53/200)
2018-02-08 15:57:31,589 INFO[org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 54.0 (TID 429)
2018-02-08 15:57:31,592 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,593 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,593 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,593 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,594 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,594 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,594 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,594 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,596 INFO[org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 54.0 (TID 429). 5343 bytes result sent to driver
2018-02-08 15:57:31,596 INFO[org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 54.0 (TID 428). 5343 bytes result sent to driver
2018-02-08 15:57:31,597 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 54.0 (TID 430, localhost, executor driver, partition 93, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,599 INFO[org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 54.0 (TID 430)
2018-02-08 15:57:31,599 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 54.0 (TID 431, localhost, executor driver, partition 94, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,599 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 54.0 (TID 429) in 11 ms on localhost (executor driver) (54/200)
2018-02-08 15:57:31,599 INFO[org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 54.0 (TID 431)
2018-02-08 15:57:31,599 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 54.0 (TID 428) in 12 ms on localhost (executor driver) (55/200)
2018-02-08 15:57:31,602 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,603 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,603 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,604 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,604 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,604 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,604 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,604 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,606 INFO[org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 54.0 (TID 430). 5300 bytes result sent to driver
2018-02-08 15:57:31,606 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 54.0 (TID 432, localhost, executor driver, partition 96, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,607 INFO[org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 54.0 (TID 431). 5300 bytes result sent to driver
2018-02-08 15:57:31,607 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 54.0 (TID 430) in 11 ms on localhost (executor driver) (56/200)
2018-02-08 15:57:31,607 INFO[org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 54.0 (TID 432)
2018-02-08 15:57:31,607 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 54.0 (TID 433, localhost, executor driver, partition 97, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,608 INFO[org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 54.0 (TID 433)
2018-02-08 15:57:31,608 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 54.0 (TID 431) in 11 ms on localhost (executor driver) (57/200)
2018-02-08 15:57:31,611 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,611 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,611 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,611 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,612 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,612 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,612 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,612 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,614 INFO[org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 54.0 (TID 432). 5343 bytes result sent to driver
2018-02-08 15:57:31,614 INFO[org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 54.0 (TID 433). 5343 bytes result sent to driver
2018-02-08 15:57:31,615 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 54.0 (TID 434, localhost, executor driver, partition 98, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,615 INFO[org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 54.0 (TID 434)
2018-02-08 15:57:31,615 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 54.0 (TID 435, localhost, executor driver, partition 99, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,616 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 54.0 (TID 432) in 10 ms on localhost (executor driver) (58/200)
2018-02-08 15:57:31,616 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 54.0 (TID 433) in 9 ms on localhost (executor driver) (59/200)
2018-02-08 15:57:31,616 INFO[org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 54.0 (TID 435)
2018-02-08 15:57:31,619 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,619 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,619 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,619 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,620 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,620 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,620 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,620 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,622 INFO[org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 54.0 (TID 435). 5300 bytes result sent to driver
2018-02-08 15:57:31,622 INFO[org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 54.0 (TID 434). 5300 bytes result sent to driver
2018-02-08 15:57:31,622 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 100.0 in stage 54.0 (TID 436, localhost, executor driver, partition 100, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,623 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 101.0 in stage 54.0 (TID 437, localhost, executor driver, partition 101, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,623 INFO[org.apache.spark.executor.Executor:54] - Running task 100.0 in stage 54.0 (TID 436)
2018-02-08 15:57:31,623 INFO[org.apache.spark.executor.Executor:54] - Running task 101.0 in stage 54.0 (TID 437)
2018-02-08 15:57:31,623 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 54.0 (TID 434) in 8 ms on localhost (executor driver) (60/200)
2018-02-08 15:57:31,624 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 54.0 (TID 435) in 9 ms on localhost (executor driver) (61/200)
2018-02-08 15:57:31,627 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,627 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,627 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,627 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,628 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,628 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,628 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,628 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,630 INFO[org.apache.spark.executor.Executor:54] - Finished task 100.0 in stage 54.0 (TID 436). 5343 bytes result sent to driver
2018-02-08 15:57:31,630 INFO[org.apache.spark.executor.Executor:54] - Finished task 101.0 in stage 54.0 (TID 437). 5343 bytes result sent to driver
2018-02-08 15:57:31,630 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 104.0 in stage 54.0 (TID 438, localhost, executor driver, partition 104, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,630 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 100.0 in stage 54.0 (TID 436) in 8 ms on localhost (executor driver) (62/200)
2018-02-08 15:57:31,630 INFO[org.apache.spark.executor.Executor:54] - Running task 104.0 in stage 54.0 (TID 438)
2018-02-08 15:57:31,631 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 108.0 in stage 54.0 (TID 439, localhost, executor driver, partition 108, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,631 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 101.0 in stage 54.0 (TID 437) in 8 ms on localhost (executor driver) (63/200)
2018-02-08 15:57:31,631 INFO[org.apache.spark.executor.Executor:54] - Running task 108.0 in stage 54.0 (TID 439)
2018-02-08 15:57:31,634 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,634 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,634 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,635 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,635 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,635 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,636 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,636 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,637 INFO[org.apache.spark.executor.Executor:54] - Finished task 104.0 in stage 54.0 (TID 438). 5300 bytes result sent to driver
2018-02-08 15:57:31,637 INFO[org.apache.spark.executor.Executor:54] - Finished task 108.0 in stage 54.0 (TID 439). 5300 bytes result sent to driver
2018-02-08 15:57:31,638 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 110.0 in stage 54.0 (TID 440, localhost, executor driver, partition 110, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,638 INFO[org.apache.spark.executor.Executor:54] - Running task 110.0 in stage 54.0 (TID 440)
2018-02-08 15:57:31,638 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 112.0 in stage 54.0 (TID 441, localhost, executor driver, partition 112, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,638 INFO[org.apache.spark.executor.Executor:54] - Running task 112.0 in stage 54.0 (TID 441)
2018-02-08 15:57:31,638 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 104.0 in stage 54.0 (TID 438) in 8 ms on localhost (executor driver) (64/200)
2018-02-08 15:57:31,638 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 108.0 in stage 54.0 (TID 439) in 7 ms on localhost (executor driver) (65/200)
2018-02-08 15:57:31,641 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,641 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,641 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,641 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,642 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,642 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,642 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,642 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,644 INFO[org.apache.spark.executor.Executor:54] - Finished task 112.0 in stage 54.0 (TID 441). 5343 bytes result sent to driver
2018-02-08 15:57:31,644 INFO[org.apache.spark.executor.Executor:54] - Finished task 110.0 in stage 54.0 (TID 440). 5343 bytes result sent to driver
2018-02-08 15:57:31,644 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 114.0 in stage 54.0 (TID 442, localhost, executor driver, partition 114, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,644 INFO[org.apache.spark.executor.Executor:54] - Running task 114.0 in stage 54.0 (TID 442)
2018-02-08 15:57:31,644 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 117.0 in stage 54.0 (TID 443, localhost, executor driver, partition 117, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,645 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 110.0 in stage 54.0 (TID 440) in 8 ms on localhost (executor driver) (66/200)
2018-02-08 15:57:31,645 INFO[org.apache.spark.executor.Executor:54] - Running task 117.0 in stage 54.0 (TID 443)
2018-02-08 15:57:31,645 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 112.0 in stage 54.0 (TID 441) in 7 ms on localhost (executor driver) (67/200)
2018-02-08 15:57:31,647 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,647 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,648 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,648 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,648 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,648 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,648 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,649 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,650 INFO[org.apache.spark.executor.Executor:54] - Finished task 114.0 in stage 54.0 (TID 442). 5300 bytes result sent to driver
2018-02-08 15:57:31,650 INFO[org.apache.spark.executor.Executor:54] - Finished task 117.0 in stage 54.0 (TID 443). 5300 bytes result sent to driver
2018-02-08 15:57:31,650 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 118.0 in stage 54.0 (TID 444, localhost, executor driver, partition 118, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,651 INFO[org.apache.spark.executor.Executor:54] - Running task 118.0 in stage 54.0 (TID 444)
2018-02-08 15:57:31,651 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 120.0 in stage 54.0 (TID 445, localhost, executor driver, partition 120, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,651 INFO[org.apache.spark.executor.Executor:54] - Running task 120.0 in stage 54.0 (TID 445)
2018-02-08 15:57:31,651 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 117.0 in stage 54.0 (TID 443) in 7 ms on localhost (executor driver) (68/200)
2018-02-08 15:57:31,651 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 114.0 in stage 54.0 (TID 442) in 7 ms on localhost (executor driver) (69/200)
2018-02-08 15:57:31,654 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,654 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,654 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,654 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,655 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,655 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,655 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,655 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,658 INFO[org.apache.spark.executor.Executor:54] - Finished task 118.0 in stage 54.0 (TID 444). 5343 bytes result sent to driver
2018-02-08 15:57:31,658 INFO[org.apache.spark.executor.Executor:54] - Finished task 120.0 in stage 54.0 (TID 445). 5343 bytes result sent to driver
2018-02-08 15:57:31,658 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 121.0 in stage 54.0 (TID 446, localhost, executor driver, partition 121, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,658 INFO[org.apache.spark.executor.Executor:54] - Running task 121.0 in stage 54.0 (TID 446)
2018-02-08 15:57:31,659 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 123.0 in stage 54.0 (TID 447, localhost, executor driver, partition 123, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,659 INFO[org.apache.spark.executor.Executor:54] - Running task 123.0 in stage 54.0 (TID 447)
2018-02-08 15:57:31,659 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 118.0 in stage 54.0 (TID 444) in 9 ms on localhost (executor driver) (70/200)
2018-02-08 15:57:31,659 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 120.0 in stage 54.0 (TID 445) in 8 ms on localhost (executor driver) (71/200)
2018-02-08 15:57:31,662 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,662 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,663 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,663 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,663 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,663 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,664 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,664 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,665 INFO[org.apache.spark.executor.Executor:54] - Finished task 121.0 in stage 54.0 (TID 446). 5300 bytes result sent to driver
2018-02-08 15:57:31,665 INFO[org.apache.spark.executor.Executor:54] - Finished task 123.0 in stage 54.0 (TID 447). 5300 bytes result sent to driver
2018-02-08 15:57:31,665 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 125.0 in stage 54.0 (TID 448, localhost, executor driver, partition 125, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,666 INFO[org.apache.spark.executor.Executor:54] - Running task 125.0 in stage 54.0 (TID 448)
2018-02-08 15:57:31,666 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 127.0 in stage 54.0 (TID 449, localhost, executor driver, partition 127, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,666 INFO[org.apache.spark.executor.Executor:54] - Running task 127.0 in stage 54.0 (TID 449)
2018-02-08 15:57:31,666 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 121.0 in stage 54.0 (TID 446) in 8 ms on localhost (executor driver) (72/200)
2018-02-08 15:57:31,666 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 123.0 in stage 54.0 (TID 447) in 8 ms on localhost (executor driver) (73/200)
2018-02-08 15:57:31,669 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,669 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,669 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,669 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,670 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,670 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,670 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,670 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,672 INFO[org.apache.spark.executor.Executor:54] - Finished task 127.0 in stage 54.0 (TID 449). 5343 bytes result sent to driver
2018-02-08 15:57:31,672 INFO[org.apache.spark.executor.Executor:54] - Finished task 125.0 in stage 54.0 (TID 448). 5343 bytes result sent to driver
2018-02-08 15:57:31,673 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 130.0 in stage 54.0 (TID 450, localhost, executor driver, partition 130, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,673 INFO[org.apache.spark.executor.Executor:54] - Running task 130.0 in stage 54.0 (TID 450)
2018-02-08 15:57:31,673 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 133.0 in stage 54.0 (TID 451, localhost, executor driver, partition 133, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,673 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 127.0 in stage 54.0 (TID 449) in 7 ms on localhost (executor driver) (74/200)
2018-02-08 15:57:31,673 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 125.0 in stage 54.0 (TID 448) in 8 ms on localhost (executor driver) (75/200)
2018-02-08 15:57:31,673 INFO[org.apache.spark.executor.Executor:54] - Running task 133.0 in stage 54.0 (TID 451)
2018-02-08 15:57:31,676 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,676 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,676 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,676 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,677 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,677 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,678 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,678 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,680 INFO[org.apache.spark.executor.Executor:54] - Finished task 133.0 in stage 54.0 (TID 451). 5300 bytes result sent to driver
2018-02-08 15:57:31,680 INFO[org.apache.spark.executor.Executor:54] - Finished task 130.0 in stage 54.0 (TID 450). 5300 bytes result sent to driver
2018-02-08 15:57:31,680 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 134.0 in stage 54.0 (TID 452, localhost, executor driver, partition 134, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,681 INFO[org.apache.spark.executor.Executor:54] - Running task 134.0 in stage 54.0 (TID 452)
2018-02-08 15:57:31,681 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 138.0 in stage 54.0 (TID 453, localhost, executor driver, partition 138, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,681 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 133.0 in stage 54.0 (TID 451) in 8 ms on localhost (executor driver) (76/200)
2018-02-08 15:57:31,681 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 130.0 in stage 54.0 (TID 450) in 9 ms on localhost (executor driver) (77/200)
2018-02-08 15:57:31,681 INFO[org.apache.spark.executor.Executor:54] - Running task 138.0 in stage 54.0 (TID 453)
2018-02-08 15:57:31,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,687 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,687 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,687 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,687 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,690 INFO[org.apache.spark.executor.Executor:54] - Finished task 138.0 in stage 54.0 (TID 453). 5343 bytes result sent to driver
2018-02-08 15:57:31,690 INFO[org.apache.spark.executor.Executor:54] - Finished task 134.0 in stage 54.0 (TID 452). 5343 bytes result sent to driver
2018-02-08 15:57:31,690 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 139.0 in stage 54.0 (TID 454, localhost, executor driver, partition 139, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,690 INFO[org.apache.spark.executor.Executor:54] - Running task 139.0 in stage 54.0 (TID 454)
2018-02-08 15:57:31,690 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 142.0 in stage 54.0 (TID 455, localhost, executor driver, partition 142, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,690 INFO[org.apache.spark.executor.Executor:54] - Running task 142.0 in stage 54.0 (TID 455)
2018-02-08 15:57:31,690 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 134.0 in stage 54.0 (TID 452) in 10 ms on localhost (executor driver) (78/200)
2018-02-08 15:57:31,690 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 138.0 in stage 54.0 (TID 453) in 9 ms on localhost (executor driver) (79/200)
2018-02-08 15:57:31,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,694 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,695 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,698 INFO[org.apache.spark.executor.Executor:54] - Finished task 139.0 in stage 54.0 (TID 454). 5343 bytes result sent to driver
2018-02-08 15:57:31,698 INFO[org.apache.spark.executor.Executor:54] - Finished task 142.0 in stage 54.0 (TID 455). 5300 bytes result sent to driver
2018-02-08 15:57:31,698 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 144.0 in stage 54.0 (TID 456, localhost, executor driver, partition 144, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,698 INFO[org.apache.spark.executor.Executor:54] - Running task 144.0 in stage 54.0 (TID 456)
2018-02-08 15:57:31,699 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 145.0 in stage 54.0 (TID 457, localhost, executor driver, partition 145, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,699 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 142.0 in stage 54.0 (TID 455) in 9 ms on localhost (executor driver) (80/200)
2018-02-08 15:57:31,699 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 139.0 in stage 54.0 (TID 454) in 9 ms on localhost (executor driver) (81/200)
2018-02-08 15:57:31,700 INFO[org.apache.spark.executor.Executor:54] - Running task 145.0 in stage 54.0 (TID 457)
2018-02-08 15:57:31,703 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,703 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,703 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,704 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,704 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,704 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,704 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,704 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,706 INFO[org.apache.spark.executor.Executor:54] - Finished task 145.0 in stage 54.0 (TID 457). 5343 bytes result sent to driver
2018-02-08 15:57:31,706 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 147.0 in stage 54.0 (TID 458, localhost, executor driver, partition 147, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,707 INFO[org.apache.spark.executor.Executor:54] - Running task 147.0 in stage 54.0 (TID 458)
2018-02-08 15:57:31,707 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 145.0 in stage 54.0 (TID 457) in 8 ms on localhost (executor driver) (82/200)
2018-02-08 15:57:31,707 INFO[org.apache.spark.executor.Executor:54] - Finished task 144.0 in stage 54.0 (TID 456). 5343 bytes result sent to driver
2018-02-08 15:57:31,707 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 148.0 in stage 54.0 (TID 459, localhost, executor driver, partition 148, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,707 INFO[org.apache.spark.executor.Executor:54] - Running task 148.0 in stage 54.0 (TID 459)
2018-02-08 15:57:31,707 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 144.0 in stage 54.0 (TID 456) in 9 ms on localhost (executor driver) (83/200)
2018-02-08 15:57:31,714 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,714 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,714 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,714 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:57:31,715 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,715 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,715 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,715 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,717 INFO[org.apache.spark.executor.Executor:54] - Finished task 148.0 in stage 54.0 (TID 459). 5300 bytes result sent to driver
2018-02-08 15:57:31,717 INFO[org.apache.spark.executor.Executor:54] - Finished task 147.0 in stage 54.0 (TID 458). 5300 bytes result sent to driver
2018-02-08 15:57:31,717 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 149.0 in stage 54.0 (TID 460, localhost, executor driver, partition 149, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,718 INFO[org.apache.spark.executor.Executor:54] - Running task 149.0 in stage 54.0 (TID 460)
2018-02-08 15:57:31,718 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 152.0 in stage 54.0 (TID 461, localhost, executor driver, partition 152, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,718 INFO[org.apache.spark.executor.Executor:54] - Running task 152.0 in stage 54.0 (TID 461)
2018-02-08 15:57:31,718 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 148.0 in stage 54.0 (TID 459) in 11 ms on localhost (executor driver) (84/200)
2018-02-08 15:57:31,719 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 147.0 in stage 54.0 (TID 458) in 13 ms on localhost (executor driver) (85/200)
2018-02-08 15:57:31,722 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,722 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,723 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,723 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,724 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,724 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,724 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,724 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,728 INFO[org.apache.spark.executor.Executor:54] - Finished task 152.0 in stage 54.0 (TID 461). 5300 bytes result sent to driver
2018-02-08 15:57:31,729 INFO[org.apache.spark.executor.Executor:54] - Finished task 149.0 in stage 54.0 (TID 460). 5300 bytes result sent to driver
2018-02-08 15:57:31,729 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 153.0 in stage 54.0 (TID 462, localhost, executor driver, partition 153, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,729 INFO[org.apache.spark.executor.Executor:54] - Running task 153.0 in stage 54.0 (TID 462)
2018-02-08 15:57:31,729 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 154.0 in stage 54.0 (TID 463, localhost, executor driver, partition 154, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,730 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 149.0 in stage 54.0 (TID 460) in 13 ms on localhost (executor driver) (86/200)
2018-02-08 15:57:31,730 INFO[org.apache.spark.executor.Executor:54] - Running task 154.0 in stage 54.0 (TID 463)
2018-02-08 15:57:31,731 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 152.0 in stage 54.0 (TID 461) in 13 ms on localhost (executor driver) (87/200)
2018-02-08 15:57:31,733 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,733 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,733 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,734 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,735 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,735 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,735 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,738 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 15:57:31,738 INFO[org.apache.spark.executor.Executor:54] - Finished task 154.0 in stage 54.0 (TID 463). 5343 bytes result sent to driver
2018-02-08 15:57:31,739 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 155.0 in stage 54.0 (TID 464, localhost, executor driver, partition 155, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,739 INFO[org.apache.spark.executor.Executor:54] - Running task 155.0 in stage 54.0 (TID 464)
2018-02-08 15:57:31,739 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 154.0 in stage 54.0 (TID 463) in 10 ms on localhost (executor driver) (88/200)
2018-02-08 15:57:31,740 INFO[org.apache.spark.executor.Executor:54] - Finished task 153.0 in stage 54.0 (TID 462). 5343 bytes result sent to driver
2018-02-08 15:57:31,740 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 157.0 in stage 54.0 (TID 465, localhost, executor driver, partition 157, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,740 INFO[org.apache.spark.executor.Executor:54] - Running task 157.0 in stage 54.0 (TID 465)
2018-02-08 15:57:31,740 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 153.0 in stage 54.0 (TID 462) in 11 ms on localhost (executor driver) (89/200)
2018-02-08 15:57:31,744 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,745 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,745 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,745 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,746 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,746 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,746 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,747 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,749 INFO[org.apache.spark.executor.Executor:54] - Finished task 157.0 in stage 54.0 (TID 465). 5300 bytes result sent to driver
2018-02-08 15:57:31,750 INFO[org.apache.spark.executor.Executor:54] - Finished task 155.0 in stage 54.0 (TID 464). 5300 bytes result sent to driver
2018-02-08 15:57:31,750 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 158.0 in stage 54.0 (TID 466, localhost, executor driver, partition 158, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,750 INFO[org.apache.spark.executor.Executor:54] - Running task 158.0 in stage 54.0 (TID 466)
2018-02-08 15:57:31,750 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 159.0 in stage 54.0 (TID 467, localhost, executor driver, partition 159, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,750 INFO[org.apache.spark.executor.Executor:54] - Running task 159.0 in stage 54.0 (TID 467)
2018-02-08 15:57:31,750 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 155.0 in stage 54.0 (TID 464) in 11 ms on localhost (executor driver) (90/200)
2018-02-08 15:57:31,751 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 157.0 in stage 54.0 (TID 465) in 11 ms on localhost (executor driver) (91/200)
2018-02-08 15:57:31,753 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,753 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,753 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,754 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,754 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,754 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,755 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,754 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,756 INFO[org.apache.spark.executor.Executor:54] - Finished task 158.0 in stage 54.0 (TID 466). 5300 bytes result sent to driver
2018-02-08 15:57:31,760 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 160.0 in stage 54.0 (TID 468, localhost, executor driver, partition 160, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,760 INFO[org.apache.spark.executor.Executor:54] - Finished task 159.0 in stage 54.0 (TID 467). 5300 bytes result sent to driver
2018-02-08 15:57:31,760 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 158.0 in stage 54.0 (TID 466) in 10 ms on localhost (executor driver) (92/200)
2018-02-08 15:57:31,760 INFO[org.apache.spark.executor.Executor:54] - Running task 160.0 in stage 54.0 (TID 468)
2018-02-08 15:57:31,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 161.0 in stage 54.0 (TID 469, localhost, executor driver, partition 161, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 159.0 in stage 54.0 (TID 467) in 11 ms on localhost (executor driver) (93/200)
2018-02-08 15:57:31,761 INFO[org.apache.spark.executor.Executor:54] - Running task 161.0 in stage 54.0 (TID 469)
2018-02-08 15:57:31,764 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,764 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,765 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,765 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,765 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,765 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,765 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,766 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,767 INFO[org.apache.spark.executor.Executor:54] - Finished task 161.0 in stage 54.0 (TID 469). 5343 bytes result sent to driver
2018-02-08 15:57:31,767 INFO[org.apache.spark.executor.Executor:54] - Finished task 160.0 in stage 54.0 (TID 468). 5343 bytes result sent to driver
2018-02-08 15:57:31,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 166.0 in stage 54.0 (TID 470, localhost, executor driver, partition 166, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,768 INFO[org.apache.spark.executor.Executor:54] - Running task 166.0 in stage 54.0 (TID 470)
2018-02-08 15:57:31,768 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 167.0 in stage 54.0 (TID 471, localhost, executor driver, partition 167, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,768 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 160.0 in stage 54.0 (TID 468) in 9 ms on localhost (executor driver) (94/200)
2018-02-08 15:57:31,768 INFO[org.apache.spark.executor.Executor:54] - Running task 167.0 in stage 54.0 (TID 471)
2018-02-08 15:57:31,768 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 161.0 in stage 54.0 (TID 469) in 8 ms on localhost (executor driver) (95/200)
2018-02-08 15:57:31,772 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,772 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,773 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,773 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,775 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,775 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,775 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,775 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,777 INFO[org.apache.spark.executor.Executor:54] - Finished task 167.0 in stage 54.0 (TID 471). 5343 bytes result sent to driver
2018-02-08 15:57:31,777 INFO[org.apache.spark.executor.Executor:54] - Finished task 166.0 in stage 54.0 (TID 470). 5343 bytes result sent to driver
2018-02-08 15:57:31,777 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 169.0 in stage 54.0 (TID 472, localhost, executor driver, partition 169, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,777 INFO[org.apache.spark.executor.Executor:54] - Running task 169.0 in stage 54.0 (TID 472)
2018-02-08 15:57:31,777 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 170.0 in stage 54.0 (TID 473, localhost, executor driver, partition 170, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,777 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 167.0 in stage 54.0 (TID 471) in 9 ms on localhost (executor driver) (96/200)
2018-02-08 15:57:31,777 INFO[org.apache.spark.executor.Executor:54] - Running task 170.0 in stage 54.0 (TID 473)
2018-02-08 15:57:31,778 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 166.0 in stage 54.0 (TID 470) in 10 ms on localhost (executor driver) (97/200)
2018-02-08 15:57:31,780 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,780 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,781 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,780 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,783 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,783 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,783 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,783 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,785 INFO[org.apache.spark.executor.Executor:54] - Finished task 169.0 in stage 54.0 (TID 472). 5343 bytes result sent to driver
2018-02-08 15:57:31,785 INFO[org.apache.spark.executor.Executor:54] - Finished task 170.0 in stage 54.0 (TID 473). 5300 bytes result sent to driver
2018-02-08 15:57:31,785 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 171.0 in stage 54.0 (TID 474, localhost, executor driver, partition 171, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,785 INFO[org.apache.spark.executor.Executor:54] - Running task 171.0 in stage 54.0 (TID 474)
2018-02-08 15:57:31,785 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 172.0 in stage 54.0 (TID 475, localhost, executor driver, partition 172, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,786 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 169.0 in stage 54.0 (TID 472) in 9 ms on localhost (executor driver) (98/200)
2018-02-08 15:57:31,786 INFO[org.apache.spark.executor.Executor:54] - Running task 172.0 in stage 54.0 (TID 475)
2018-02-08 15:57:31,786 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 170.0 in stage 54.0 (TID 473) in 9 ms on localhost (executor driver) (99/200)
2018-02-08 15:57:31,789 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,789 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,790 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,791 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,792 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,792 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,792 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,792 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,794 INFO[org.apache.spark.executor.Executor:54] - Finished task 171.0 in stage 54.0 (TID 474). 5300 bytes result sent to driver
2018-02-08 15:57:31,794 INFO[org.apache.spark.executor.Executor:54] - Finished task 172.0 in stage 54.0 (TID 475). 5300 bytes result sent to driver
2018-02-08 15:57:31,794 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 175.0 in stage 54.0 (TID 476, localhost, executor driver, partition 175, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,794 INFO[org.apache.spark.executor.Executor:54] - Running task 175.0 in stage 54.0 (TID 476)
2018-02-08 15:57:31,794 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 176.0 in stage 54.0 (TID 477, localhost, executor driver, partition 176, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,794 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 172.0 in stage 54.0 (TID 475) in 9 ms on localhost (executor driver) (100/200)
2018-02-08 15:57:31,795 INFO[org.apache.spark.executor.Executor:54] - Running task 176.0 in stage 54.0 (TID 477)
2018-02-08 15:57:31,795 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 171.0 in stage 54.0 (TID 474) in 10 ms on localhost (executor driver) (101/200)
2018-02-08 15:57:31,798 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,798 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,798 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,798 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,799 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,799 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,799 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,800 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,801 INFO[org.apache.spark.executor.Executor:54] - Finished task 175.0 in stage 54.0 (TID 476). 5343 bytes result sent to driver
2018-02-08 15:57:31,801 INFO[org.apache.spark.executor.Executor:54] - Finished task 176.0 in stage 54.0 (TID 477). 5343 bytes result sent to driver
2018-02-08 15:57:31,802 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 177.0 in stage 54.0 (TID 478, localhost, executor driver, partition 177, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,802 INFO[org.apache.spark.executor.Executor:54] - Running task 177.0 in stage 54.0 (TID 478)
2018-02-08 15:57:31,802 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 178.0 in stage 54.0 (TID 479, localhost, executor driver, partition 178, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,802 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 175.0 in stage 54.0 (TID 476) in 8 ms on localhost (executor driver) (102/200)
2018-02-08 15:57:31,802 INFO[org.apache.spark.executor.Executor:54] - Running task 178.0 in stage 54.0 (TID 479)
2018-02-08 15:57:31,802 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 176.0 in stage 54.0 (TID 477) in 8 ms on localhost (executor driver) (103/200)
2018-02-08 15:57:31,807 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,807 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,807 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,807 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,808 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,808 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,808 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,808 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,810 INFO[org.apache.spark.executor.Executor:54] - Finished task 177.0 in stage 54.0 (TID 478). 5300 bytes result sent to driver
2018-02-08 15:57:31,810 INFO[org.apache.spark.executor.Executor:54] - Finished task 178.0 in stage 54.0 (TID 479). 5300 bytes result sent to driver
2018-02-08 15:57:31,810 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 179.0 in stage 54.0 (TID 480, localhost, executor driver, partition 179, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,811 INFO[org.apache.spark.executor.Executor:54] - Running task 179.0 in stage 54.0 (TID 480)
2018-02-08 15:57:31,811 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 180.0 in stage 54.0 (TID 481, localhost, executor driver, partition 180, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,811 INFO[org.apache.spark.executor.Executor:54] - Running task 180.0 in stage 54.0 (TID 481)
2018-02-08 15:57:31,811 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 178.0 in stage 54.0 (TID 479) in 9 ms on localhost (executor driver) (104/200)
2018-02-08 15:57:31,811 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 177.0 in stage 54.0 (TID 478) in 10 ms on localhost (executor driver) (105/200)
2018-02-08 15:57:31,814 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,814 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,814 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,815 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,816 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,816 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,816 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,816 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,817 INFO[org.apache.spark.executor.Executor:54] - Finished task 179.0 in stage 54.0 (TID 480). 5343 bytes result sent to driver
2018-02-08 15:57:31,817 INFO[org.apache.spark.executor.Executor:54] - Finished task 180.0 in stage 54.0 (TID 481). 5343 bytes result sent to driver
2018-02-08 15:57:31,818 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 182.0 in stage 54.0 (TID 482, localhost, executor driver, partition 182, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,818 INFO[org.apache.spark.executor.Executor:54] - Running task 182.0 in stage 54.0 (TID 482)
2018-02-08 15:57:31,818 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 185.0 in stage 54.0 (TID 483, localhost, executor driver, partition 185, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,818 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 179.0 in stage 54.0 (TID 480) in 8 ms on localhost (executor driver) (106/200)
2018-02-08 15:57:31,818 INFO[org.apache.spark.executor.Executor:54] - Running task 185.0 in stage 54.0 (TID 483)
2018-02-08 15:57:31,818 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 180.0 in stage 54.0 (TID 481) in 7 ms on localhost (executor driver) (107/200)
2018-02-08 15:57:31,821 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,821 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,821 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,821 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,822 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,822 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,822 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,822 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,824 INFO[org.apache.spark.executor.Executor:54] - Finished task 182.0 in stage 54.0 (TID 482). 5300 bytes result sent to driver
2018-02-08 15:57:31,824 INFO[org.apache.spark.executor.Executor:54] - Finished task 185.0 in stage 54.0 (TID 483). 5300 bytes result sent to driver
2018-02-08 15:57:31,824 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 186.0 in stage 54.0 (TID 484, localhost, executor driver, partition 186, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,824 INFO[org.apache.spark.executor.Executor:54] - Running task 186.0 in stage 54.0 (TID 484)
2018-02-08 15:57:31,825 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 187.0 in stage 54.0 (TID 485, localhost, executor driver, partition 187, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,825 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 182.0 in stage 54.0 (TID 482) in 7 ms on localhost (executor driver) (108/200)
2018-02-08 15:57:31,825 INFO[org.apache.spark.executor.Executor:54] - Running task 187.0 in stage 54.0 (TID 485)
2018-02-08 15:57:31,825 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 185.0 in stage 54.0 (TID 483) in 7 ms on localhost (executor driver) (109/200)
2018-02-08 15:57:31,828 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,828 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,828 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,828 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,829 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,829 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,829 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,829 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,831 INFO[org.apache.spark.executor.Executor:54] - Finished task 187.0 in stage 54.0 (TID 485). 5343 bytes result sent to driver
2018-02-08 15:57:31,831 INFO[org.apache.spark.executor.Executor:54] - Finished task 186.0 in stage 54.0 (TID 484). 5343 bytes result sent to driver
2018-02-08 15:57:31,832 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 188.0 in stage 54.0 (TID 486, localhost, executor driver, partition 188, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,832 INFO[org.apache.spark.executor.Executor:54] - Running task 188.0 in stage 54.0 (TID 486)
2018-02-08 15:57:31,832 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 189.0 in stage 54.0 (TID 487, localhost, executor driver, partition 189, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,832 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 187.0 in stage 54.0 (TID 485) in 7 ms on localhost (executor driver) (110/200)
2018-02-08 15:57:31,832 INFO[org.apache.spark.executor.Executor:54] - Running task 189.0 in stage 54.0 (TID 487)
2018-02-08 15:57:31,832 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 186.0 in stage 54.0 (TID 484) in 8 ms on localhost (executor driver) (111/200)
2018-02-08 15:57:31,835 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,835 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,835 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,835 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,836 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,836 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,836 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,836 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,838 INFO[org.apache.spark.executor.Executor:54] - Finished task 188.0 in stage 54.0 (TID 486). 5300 bytes result sent to driver
2018-02-08 15:57:31,838 INFO[org.apache.spark.executor.Executor:54] - Finished task 189.0 in stage 54.0 (TID 487). 5300 bytes result sent to driver
2018-02-08 15:57:31,839 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 190.0 in stage 54.0 (TID 488, localhost, executor driver, partition 190, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,839 INFO[org.apache.spark.executor.Executor:54] - Running task 190.0 in stage 54.0 (TID 488)
2018-02-08 15:57:31,839 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 194.0 in stage 54.0 (TID 489, localhost, executor driver, partition 194, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,840 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 189.0 in stage 54.0 (TID 487) in 8 ms on localhost (executor driver) (112/200)
2018-02-08 15:57:31,840 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 188.0 in stage 54.0 (TID 486) in 9 ms on localhost (executor driver) (113/200)
2018-02-08 15:57:31,841 INFO[org.apache.spark.executor.Executor:54] - Running task 194.0 in stage 54.0 (TID 489)
2018-02-08 15:57:31,844 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,845 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,845 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,846 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,846 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,846 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,847 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,847 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,849 INFO[org.apache.spark.executor.Executor:54] - Finished task 194.0 in stage 54.0 (TID 489). 5343 bytes result sent to driver
2018-02-08 15:57:31,849 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 195.0 in stage 54.0 (TID 490, localhost, executor driver, partition 195, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,849 INFO[org.apache.spark.executor.Executor:54] - Finished task 190.0 in stage 54.0 (TID 488). 5300 bytes result sent to driver
2018-02-08 15:57:31,850 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 194.0 in stage 54.0 (TID 489) in 11 ms on localhost (executor driver) (114/200)
2018-02-08 15:57:31,850 INFO[org.apache.spark.executor.Executor:54] - Running task 195.0 in stage 54.0 (TID 490)
2018-02-08 15:57:31,850 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 196.0 in stage 54.0 (TID 491, localhost, executor driver, partition 196, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,851 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 190.0 in stage 54.0 (TID 488) in 12 ms on localhost (executor driver) (115/200)
2018-02-08 15:57:31,851 INFO[org.apache.spark.executor.Executor:54] - Running task 196.0 in stage 54.0 (TID 491)
2018-02-08 15:57:31,854 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,854 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,855 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,855 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,855 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,864 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 9 ms
2018-02-08 15:57:31,864 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,865 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,866 INFO[org.apache.spark.executor.Executor:54] - Finished task 195.0 in stage 54.0 (TID 490). 5343 bytes result sent to driver
2018-02-08 15:57:31,867 INFO[org.apache.spark.executor.Executor:54] - Finished task 196.0 in stage 54.0 (TID 491). 5343 bytes result sent to driver
2018-02-08 15:57:31,867 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 197.0 in stage 54.0 (TID 492, localhost, executor driver, partition 197, PROCESS_LOCAL, 5054 bytes)
2018-02-08 15:57:31,867 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 54.0 (TID 493, localhost, executor driver, partition 2, ANY, 5054 bytes)
2018-02-08 15:57:31,868 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 195.0 in stage 54.0 (TID 490) in 19 ms on localhost (executor driver) (116/200)
2018-02-08 15:57:31,868 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_23_piece0 on 192.168.11.26:62834 in memory (size: 24.8 KB, free: 631.7 MB)
2018-02-08 15:57:31,868 INFO[org.apache.spark.executor.Executor:54] - Running task 197.0 in stage 54.0 (TID 492)
2018-02-08 15:57:31,868 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 54.0 (TID 493)
2018-02-08 15:57:31,873 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,873 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,873 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 7 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,873 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,874 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,874 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,868 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 196.0 in stage 54.0 (TID 491) in 18 ms on localhost (executor driver) (117/200)
2018-02-08 15:57:31,876 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,876 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,877 INFO[org.apache.spark.executor.Executor:54] - Finished task 197.0 in stage 54.0 (TID 492). 5343 bytes result sent to driver
2018-02-08 15:57:31,877 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 54.0 (TID 494, localhost, executor driver, partition 3, ANY, 5054 bytes)
2018-02-08 15:57:31,878 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 54.0 (TID 494)
2018-02-08 15:57:31,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 197.0 in stage 54.0 (TID 492) in 11 ms on localhost (executor driver) (118/200)
2018-02-08 15:57:31,885 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,885 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,886 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,886 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,903 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 54.0 (TID 493). 5569 bytes result sent to driver
2018-02-08 15:57:31,903 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 54.0 (TID 494). 5569 bytes result sent to driver
2018-02-08 15:57:31,904 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 54.0 (TID 495, localhost, executor driver, partition 4, ANY, 5054 bytes)
2018-02-08 15:57:31,904 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 54.0 (TID 496, localhost, executor driver, partition 5, ANY, 5054 bytes)
2018-02-08 15:57:31,904 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 54.0 (TID 495)
2018-02-08 15:57:31,904 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 54.0 (TID 493) in 37 ms on localhost (executor driver) (119/200)
2018-02-08 15:57:31,905 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 54.0 (TID 496)
2018-02-08 15:57:31,905 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 54.0 (TID 494) in 28 ms on localhost (executor driver) (120/200)
2018-02-08 15:57:31,908 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,908 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,908 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,908 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,909 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,909 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,910 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,910 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,914 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 54.0 (TID 495). 5569 bytes result sent to driver
2018-02-08 15:57:31,914 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 54.0 (TID 497, localhost, executor driver, partition 7, ANY, 5054 bytes)
2018-02-08 15:57:31,914 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 54.0 (TID 497)
2018-02-08 15:57:31,915 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 54.0 (TID 495) in 11 ms on localhost (executor driver) (121/200)
2018-02-08 15:57:31,916 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 54.0 (TID 496). 5526 bytes result sent to driver
2018-02-08 15:57:31,916 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 54.0 (TID 498, localhost, executor driver, partition 11, ANY, 5054 bytes)
2018-02-08 15:57:31,917 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 54.0 (TID 498)
2018-02-08 15:57:31,917 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 54.0 (TID 496) in 13 ms on localhost (executor driver) (122/200)
2018-02-08 15:57:31,919 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,920 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,921 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,921 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,921 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,921 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,926 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 54.0 (TID 497). 5569 bytes result sent to driver
2018-02-08 15:57:31,926 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 54.0 (TID 499, localhost, executor driver, partition 13, ANY, 5054 bytes)
2018-02-08 15:57:31,926 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 54.0 (TID 499)
2018-02-08 15:57:31,926 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 54.0 (TID 497) in 12 ms on localhost (executor driver) (123/200)
2018-02-08 15:57:31,929 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 54.0 (TID 498). 5569 bytes result sent to driver
2018-02-08 15:57:31,929 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 54.0 (TID 500, localhost, executor driver, partition 14, ANY, 5054 bytes)
2018-02-08 15:57:31,929 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 54.0 (TID 500)
2018-02-08 15:57:31,929 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 54.0 (TID 498) in 13 ms on localhost (executor driver) (124/200)
2018-02-08 15:57:31,930 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,930 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,932 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,932 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,932 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,932 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,935 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,935 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,937 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 54.0 (TID 499). 5526 bytes result sent to driver
2018-02-08 15:57:31,938 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 54.0 (TID 501, localhost, executor driver, partition 18, ANY, 5054 bytes)
2018-02-08 15:57:31,939 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 54.0 (TID 499) in 13 ms on localhost (executor driver) (125/200)
2018-02-08 15:57:31,939 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 54.0 (TID 501)
2018-02-08 15:57:31,939 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 54.0 (TID 500). 5569 bytes result sent to driver
2018-02-08 15:57:31,940 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 54.0 (TID 502, localhost, executor driver, partition 19, ANY, 5054 bytes)
2018-02-08 15:57:31,940 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 54.0 (TID 502)
2018-02-08 15:57:31,940 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 54.0 (TID 500) in 11 ms on localhost (executor driver) (126/200)
2018-02-08 15:57:31,943 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,943 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,943 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,943 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,946 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 54.0 (TID 501). 5526 bytes result sent to driver
2018-02-08 15:57:31,947 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 54.0 (TID 503, localhost, executor driver, partition 21, ANY, 5054 bytes)
2018-02-08 15:57:31,947 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 54.0 (TID 503)
2018-02-08 15:57:31,947 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 54.0 (TID 501) in 9 ms on localhost (executor driver) (127/200)
2018-02-08 15:57:31,947 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 54.0 (TID 502). 5526 bytes result sent to driver
2018-02-08 15:57:31,948 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 54.0 (TID 504, localhost, executor driver, partition 24, ANY, 5054 bytes)
2018-02-08 15:57:31,948 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 54.0 (TID 504)
2018-02-08 15:57:31,948 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 54.0 (TID 502) in 9 ms on localhost (executor driver) (128/200)
2018-02-08 15:57:31,953 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,953 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,954 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,954 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,955 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,958 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 54.0 (TID 503). 5569 bytes result sent to driver
2018-02-08 15:57:31,959 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 54.0 (TID 504). 5569 bytes result sent to driver
2018-02-08 15:57:31,959 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 54.0 (TID 505, localhost, executor driver, partition 27, ANY, 5054 bytes)
2018-02-08 15:57:31,960 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 54.0 (TID 506, localhost, executor driver, partition 30, ANY, 5054 bytes)
2018-02-08 15:57:31,960 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 54.0 (TID 503) in 13 ms on localhost (executor driver) (129/200)
2018-02-08 15:57:31,960 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 54.0 (TID 504) in 12 ms on localhost (executor driver) (130/200)
2018-02-08 15:57:31,960 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 54.0 (TID 505)
2018-02-08 15:57:31,967 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 54.0 (TID 506)
2018-02-08 15:57:31,971 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 6 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,971 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,971 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,971 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,973 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,973 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,974 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,973 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,979 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 54.0 (TID 506). 5569 bytes result sent to driver
2018-02-08 15:57:31,980 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 54.0 (TID 507, localhost, executor driver, partition 32, ANY, 5054 bytes)
2018-02-08 15:57:31,980 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 54.0 (TID 507)
2018-02-08 15:57:31,980 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 54.0 (TID 506) in 20 ms on localhost (executor driver) (131/200)
2018-02-08 15:57:31,981 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 54.0 (TID 505). 5526 bytes result sent to driver
2018-02-08 15:57:31,983 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 54.0 (TID 508, localhost, executor driver, partition 35, ANY, 5054 bytes)
2018-02-08 15:57:31,984 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 54.0 (TID 505) in 25 ms on localhost (executor driver) (132/200)
2018-02-08 15:57:31,984 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 54.0 (TID 508)
2018-02-08 15:57:31,989 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,989 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,989 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:31,990 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,990 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,990 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:31,990 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:31,991 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:31,994 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 54.0 (TID 508). 5526 bytes result sent to driver
2018-02-08 15:57:31,995 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 54.0 (TID 509, localhost, executor driver, partition 43, ANY, 5054 bytes)
2018-02-08 15:57:31,995 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 54.0 (TID 509)
2018-02-08 15:57:31,995 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 54.0 (TID 508) in 12 ms on localhost (executor driver) (133/200)
2018-02-08 15:57:31,996 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 54.0 (TID 507). 5569 bytes result sent to driver
2018-02-08 15:57:31,997 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 54.0 (TID 510, localhost, executor driver, partition 44, ANY, 5054 bytes)
2018-02-08 15:57:32,003 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 54.0 (TID 507) in 23 ms on localhost (executor driver) (134/200)
2018-02-08 15:57:32,004 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 54.0 (TID 510)
2018-02-08 15:57:32,005 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,005 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,006 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,006 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,008 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,008 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,010 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 54.0 (TID 509). 5526 bytes result sent to driver
2018-02-08 15:57:32,010 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 54.0 (TID 511, localhost, executor driver, partition 48, ANY, 5054 bytes)
2018-02-08 15:57:32,010 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 54.0 (TID 509) in 15 ms on localhost (executor driver) (135/200)
2018-02-08 15:57:32,011 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 54.0 (TID 511)
2018-02-08 15:57:32,014 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 54.0 (TID 510). 5526 bytes result sent to driver
2018-02-08 15:57:32,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 54.0 (TID 512, localhost, executor driver, partition 49, ANY, 5054 bytes)
2018-02-08 15:57:32,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 54.0 (TID 510) in 21 ms on localhost (executor driver) (136/200)
2018-02-08 15:57:32,017 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 54.0 (TID 512)
2018-02-08 15:57:32,018 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,018 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,019 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,019 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,021 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 7 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,021 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,022 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,023 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,023 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 54.0 (TID 511). 5569 bytes result sent to driver
2018-02-08 15:57:32,023 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 54.0 (TID 513, localhost, executor driver, partition 51, ANY, 5054 bytes)
2018-02-08 15:57:32,024 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 54.0 (TID 511) in 14 ms on localhost (executor driver) (137/200)
2018-02-08 15:57:32,024 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 54.0 (TID 513)
2018-02-08 15:57:32,028 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 54.0 (TID 512). 5526 bytes result sent to driver
2018-02-08 15:57:32,028 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 54.0 (TID 514, localhost, executor driver, partition 53, ANY, 5054 bytes)
2018-02-08 15:57:32,028 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 54.0 (TID 512) in 11 ms on localhost (executor driver) (138/200)
2018-02-08 15:57:32,031 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 54.0 (TID 514)
2018-02-08 15:57:32,031 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,032 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,033 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,034 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,036 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,036 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,037 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,037 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,038 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 54.0 (TID 513). 5569 bytes result sent to driver
2018-02-08 15:57:32,038 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 54.0 (TID 515, localhost, executor driver, partition 57, ANY, 5054 bytes)
2018-02-08 15:57:32,038 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 54.0 (TID 515)
2018-02-08 15:57:32,038 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 54.0 (TID 513) in 15 ms on localhost (executor driver) (139/200)
2018-02-08 15:57:32,041 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 54.0 (TID 514). 5526 bytes result sent to driver
2018-02-08 15:57:32,042 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 54.0 (TID 516, localhost, executor driver, partition 58, ANY, 5054 bytes)
2018-02-08 15:57:32,042 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 54.0 (TID 516)
2018-02-08 15:57:32,042 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 54.0 (TID 514) in 14 ms on localhost (executor driver) (140/200)
2018-02-08 15:57:32,042 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,042 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,043 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,043 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,045 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,045 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,046 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,046 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,047 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 54.0 (TID 515). 5569 bytes result sent to driver
2018-02-08 15:57:32,047 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 54.0 (TID 517, localhost, executor driver, partition 61, ANY, 5054 bytes)
2018-02-08 15:57:32,047 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 54.0 (TID 517)
2018-02-08 15:57:32,047 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 54.0 (TID 515) in 9 ms on localhost (executor driver) (141/200)
2018-02-08 15:57:32,049 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 54.0 (TID 516). 5343 bytes result sent to driver
2018-02-08 15:57:32,049 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 54.0 (TID 518, localhost, executor driver, partition 63, ANY, 5054 bytes)
2018-02-08 15:57:32,049 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 54.0 (TID 518)
2018-02-08 15:57:32,049 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 54.0 (TID 516) in 8 ms on localhost (executor driver) (142/200)
2018-02-08 15:57:32,051 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,051 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,052 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,052 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,052 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 6 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,052 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,053 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,053 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,055 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 54.0 (TID 517). 5526 bytes result sent to driver
2018-02-08 15:57:32,055 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 54.0 (TID 519, localhost, executor driver, partition 65, ANY, 5054 bytes)
2018-02-08 15:57:32,056 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 54.0 (TID 517) in 9 ms on localhost (executor driver) (143/200)
2018-02-08 15:57:32,056 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 54.0 (TID 519)
2018-02-08 15:57:32,057 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 54.0 (TID 518). 5526 bytes result sent to driver
2018-02-08 15:57:32,057 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 54.0 (TID 520, localhost, executor driver, partition 66, ANY, 5054 bytes)
2018-02-08 15:57:32,057 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 54.0 (TID 520)
2018-02-08 15:57:32,057 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 54.0 (TID 518) in 8 ms on localhost (executor driver) (144/200)
2018-02-08 15:57:32,059 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,059 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,060 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,060 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,060 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,060 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,061 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,061 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,063 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 54.0 (TID 520). 5569 bytes result sent to driver
2018-02-08 15:57:32,064 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 54.0 (TID 521, localhost, executor driver, partition 69, ANY, 5054 bytes)
2018-02-08 15:57:32,064 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 54.0 (TID 521)
2018-02-08 15:57:32,064 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 54.0 (TID 520) in 7 ms on localhost (executor driver) (145/200)
2018-02-08 15:57:32,064 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 54.0 (TID 519). 5569 bytes result sent to driver
2018-02-08 15:57:32,064 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 54.0 (TID 522, localhost, executor driver, partition 70, ANY, 5054 bytes)
2018-02-08 15:57:32,064 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 54.0 (TID 522)
2018-02-08 15:57:32,064 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 54.0 (TID 519) in 9 ms on localhost (executor driver) (146/200)
2018-02-08 15:57:32,067 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,067 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,067 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,068 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,069 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,069 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,069 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,069 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,071 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 54.0 (TID 521). 5526 bytes result sent to driver
2018-02-08 15:57:32,072 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 54.0 (TID 522). 5526 bytes result sent to driver
2018-02-08 15:57:32,072 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 54.0 (TID 523, localhost, executor driver, partition 73, ANY, 5054 bytes)
2018-02-08 15:57:32,072 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 54.0 (TID 523)
2018-02-08 15:57:32,072 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 54.0 (TID 524, localhost, executor driver, partition 75, ANY, 5054 bytes)
2018-02-08 15:57:32,072 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 54.0 (TID 521) in 9 ms on localhost (executor driver) (147/200)
2018-02-08 15:57:32,072 INFO[org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 54.0 (TID 524)
2018-02-08 15:57:32,072 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 54.0 (TID 522) in 8 ms on localhost (executor driver) (148/200)
2018-02-08 15:57:32,075 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,075 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,075 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,075 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,076 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,076 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,077 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,076 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,079 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 54.0 (TID 523). 5343 bytes result sent to driver
2018-02-08 15:57:32,079 INFO[org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 54.0 (TID 524). 5569 bytes result sent to driver
2018-02-08 15:57:32,080 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 54.0 (TID 525, localhost, executor driver, partition 77, ANY, 5054 bytes)
2018-02-08 15:57:32,080 INFO[org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 54.0 (TID 525)
2018-02-08 15:57:32,080 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 54.0 (TID 526, localhost, executor driver, partition 84, ANY, 5054 bytes)
2018-02-08 15:57:32,080 INFO[org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 54.0 (TID 526)
2018-02-08 15:57:32,080 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 54.0 (TID 524) in 8 ms on localhost (executor driver) (149/200)
2018-02-08 15:57:32,081 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 54.0 (TID 523) in 9 ms on localhost (executor driver) (150/200)
2018-02-08 15:57:32,083 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 6 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,083 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,084 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,084 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,085 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,085 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,085 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,085 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,089 INFO[org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 54.0 (TID 526). 5569 bytes result sent to driver
2018-02-08 15:57:32,090 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 54.0 (TID 527, localhost, executor driver, partition 85, ANY, 5054 bytes)
2018-02-08 15:57:32,092 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 54.0 (TID 526) in 11 ms on localhost (executor driver) (151/200)
2018-02-08 15:57:32,092 INFO[org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 54.0 (TID 527)
2018-02-08 15:57:32,094 INFO[org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 54.0 (TID 525). 5569 bytes result sent to driver
2018-02-08 15:57:32,095 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 54.0 (TID 528, localhost, executor driver, partition 86, ANY, 5054 bytes)
2018-02-08 15:57:32,096 INFO[org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 54.0 (TID 528)
2018-02-08 15:57:32,096 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 54.0 (TID 525) in 17 ms on localhost (executor driver) (152/200)
2018-02-08 15:57:32,099 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,099 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,099 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,099 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,100 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,100 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,101 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,101 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,104 INFO[org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 54.0 (TID 527). 5569 bytes result sent to driver
2018-02-08 15:57:32,104 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 54.0 (TID 529, localhost, executor driver, partition 89, ANY, 5054 bytes)
2018-02-08 15:57:32,105 INFO[org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 54.0 (TID 528). 5526 bytes result sent to driver
2018-02-08 15:57:32,105 INFO[org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 54.0 (TID 529)
2018-02-08 15:57:32,105 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 54.0 (TID 527) in 15 ms on localhost (executor driver) (153/200)
2018-02-08 15:57:32,105 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 54.0 (TID 530, localhost, executor driver, partition 91, ANY, 5054 bytes)
2018-02-08 15:57:32,106 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 54.0 (TID 528) in 11 ms on localhost (executor driver) (154/200)
2018-02-08 15:57:32,106 INFO[org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 54.0 (TID 530)
2018-02-08 15:57:32,110 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 6 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,110 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,110 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,111 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,112 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,112 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,112 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,112 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,116 INFO[org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 54.0 (TID 530). 5612 bytes result sent to driver
2018-02-08 15:57:32,116 INFO[org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 54.0 (TID 529). 5569 bytes result sent to driver
2018-02-08 15:57:32,116 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 54.0 (TID 531, localhost, executor driver, partition 95, ANY, 5054 bytes)
2018-02-08 15:57:32,116 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 102.0 in stage 54.0 (TID 532, localhost, executor driver, partition 102, ANY, 5054 bytes)
2018-02-08 15:57:32,117 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 54.0 (TID 530) in 12 ms on localhost (executor driver) (155/200)
2018-02-08 15:57:32,116 INFO[org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 54.0 (TID 531)
2018-02-08 15:57:32,117 INFO[org.apache.spark.executor.Executor:54] - Running task 102.0 in stage 54.0 (TID 532)
2018-02-08 15:57:32,117 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 54.0 (TID 529) in 13 ms on localhost (executor driver) (156/200)
2018-02-08 15:57:32,120 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,120 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,120 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,120 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,121 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,121 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,122 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,122 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,124 INFO[org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 54.0 (TID 531). 5569 bytes result sent to driver
2018-02-08 15:57:32,125 INFO[org.apache.spark.executor.Executor:54] - Finished task 102.0 in stage 54.0 (TID 532). 5569 bytes result sent to driver
2018-02-08 15:57:32,125 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 103.0 in stage 54.0 (TID 533, localhost, executor driver, partition 103, ANY, 5054 bytes)
2018-02-08 15:57:32,125 INFO[org.apache.spark.executor.Executor:54] - Running task 103.0 in stage 54.0 (TID 533)
2018-02-08 15:57:32,125 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 105.0 in stage 54.0 (TID 534, localhost, executor driver, partition 105, ANY, 5054 bytes)
2018-02-08 15:57:32,126 INFO[org.apache.spark.executor.Executor:54] - Running task 105.0 in stage 54.0 (TID 534)
2018-02-08 15:57:32,127 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 102.0 in stage 54.0 (TID 532) in 11 ms on localhost (executor driver) (157/200)
2018-02-08 15:57:32,128 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 54.0 (TID 531) in 12 ms on localhost (executor driver) (158/200)
2018-02-08 15:57:32,130 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,130 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,130 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,131 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,132 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,132 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,132 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,132 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,134 INFO[org.apache.spark.executor.Executor:54] - Finished task 103.0 in stage 54.0 (TID 533). 5526 bytes result sent to driver
2018-02-08 15:57:32,134 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 106.0 in stage 54.0 (TID 535, localhost, executor driver, partition 106, ANY, 5054 bytes)
2018-02-08 15:57:32,135 INFO[org.apache.spark.executor.Executor:54] - Finished task 105.0 in stage 54.0 (TID 534). 5526 bytes result sent to driver
2018-02-08 15:57:32,135 INFO[org.apache.spark.executor.Executor:54] - Running task 106.0 in stage 54.0 (TID 535)
2018-02-08 15:57:32,135 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 103.0 in stage 54.0 (TID 533) in 10 ms on localhost (executor driver) (159/200)
2018-02-08 15:57:32,135 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 107.0 in stage 54.0 (TID 536, localhost, executor driver, partition 107, ANY, 5054 bytes)
2018-02-08 15:57:32,136 INFO[org.apache.spark.executor.Executor:54] - Running task 107.0 in stage 54.0 (TID 536)
2018-02-08 15:57:32,136 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 105.0 in stage 54.0 (TID 534) in 11 ms on localhost (executor driver) (160/200)
2018-02-08 15:57:32,138 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,138 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,139 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,139 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,140 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,140 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,140 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,140 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,145 INFO[org.apache.spark.executor.Executor:54] - Finished task 107.0 in stage 54.0 (TID 536). 5569 bytes result sent to driver
2018-02-08 15:57:32,145 INFO[org.apache.spark.executor.Executor:54] - Finished task 106.0 in stage 54.0 (TID 535). 5569 bytes result sent to driver
2018-02-08 15:57:32,145 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 109.0 in stage 54.0 (TID 537, localhost, executor driver, partition 109, ANY, 5054 bytes)
2018-02-08 15:57:32,146 INFO[org.apache.spark.executor.Executor:54] - Running task 109.0 in stage 54.0 (TID 537)
2018-02-08 15:57:32,146 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 111.0 in stage 54.0 (TID 538, localhost, executor driver, partition 111, ANY, 5054 bytes)
2018-02-08 15:57:32,146 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 107.0 in stage 54.0 (TID 536) in 11 ms on localhost (executor driver) (161/200)
2018-02-08 15:57:32,146 INFO[org.apache.spark.executor.Executor:54] - Running task 111.0 in stage 54.0 (TID 538)
2018-02-08 15:57:32,146 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 106.0 in stage 54.0 (TID 535) in 12 ms on localhost (executor driver) (162/200)
2018-02-08 15:57:32,149 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,149 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,149 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,149 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,150 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,150 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,150 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,150 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,154 INFO[org.apache.spark.executor.Executor:54] - Finished task 111.0 in stage 54.0 (TID 538). 5526 bytes result sent to driver
2018-02-08 15:57:32,154 INFO[org.apache.spark.executor.Executor:54] - Finished task 109.0 in stage 54.0 (TID 537). 5526 bytes result sent to driver
2018-02-08 15:57:32,155 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 113.0 in stage 54.0 (TID 539, localhost, executor driver, partition 113, ANY, 5054 bytes)
2018-02-08 15:57:32,156 INFO[org.apache.spark.executor.Executor:54] - Running task 113.0 in stage 54.0 (TID 539)
2018-02-08 15:57:32,156 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 115.0 in stage 54.0 (TID 540, localhost, executor driver, partition 115, ANY, 5054 bytes)
2018-02-08 15:57:32,156 INFO[org.apache.spark.executor.Executor:54] - Running task 115.0 in stage 54.0 (TID 540)
2018-02-08 15:57:32,156 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 109.0 in stage 54.0 (TID 537) in 11 ms on localhost (executor driver) (163/200)
2018-02-08 15:57:32,156 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 111.0 in stage 54.0 (TID 538) in 10 ms on localhost (executor driver) (164/200)
2018-02-08 15:57:32,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 7 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,160 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,161 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,161 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,166 INFO[org.apache.spark.executor.Executor:54] - Finished task 115.0 in stage 54.0 (TID 540). 5526 bytes result sent to driver
2018-02-08 15:57:32,167 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 116.0 in stage 54.0 (TID 541, localhost, executor driver, partition 116, ANY, 5054 bytes)
2018-02-08 15:57:32,167 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 115.0 in stage 54.0 (TID 540) in 11 ms on localhost (executor driver) (165/200)
2018-02-08 15:57:32,168 INFO[org.apache.spark.executor.Executor:54] - Running task 116.0 in stage 54.0 (TID 541)
2018-02-08 15:57:32,169 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,169 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
2018-02-08 15:57:32,173 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,174 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,177 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,177 INFO[org.apache.spark.executor.Executor:54] - Finished task 113.0 in stage 54.0 (TID 539). 5569 bytes result sent to driver
2018-02-08 15:57:32,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 119.0 in stage 54.0 (TID 542, localhost, executor driver, partition 119, ANY, 5054 bytes)
2018-02-08 15:57:32,178 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 113.0 in stage 54.0 (TID 539) in 24 ms on localhost (executor driver) (166/200)
2018-02-08 15:57:32,179 INFO[org.apache.spark.executor.Executor:54] - Running task 119.0 in stage 54.0 (TID 542)
2018-02-08 15:57:32,182 INFO[org.apache.spark.executor.Executor:54] - Finished task 116.0 in stage 54.0 (TID 541). 5569 bytes result sent to driver
2018-02-08 15:57:32,182 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 122.0 in stage 54.0 (TID 543, localhost, executor driver, partition 122, ANY, 5054 bytes)
2018-02-08 15:57:32,182 INFO[org.apache.spark.executor.Executor:54] - Running task 122.0 in stage 54.0 (TID 543)
2018-02-08 15:57:32,182 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 116.0 in stage 54.0 (TID 541) in 15 ms on localhost (executor driver) (167/200)
2018-02-08 15:57:32,183 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,184 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,186 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,186 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,186 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,188 INFO[org.apache.spark.executor.Executor:54] - Finished task 119.0 in stage 54.0 (TID 542). 5569 bytes result sent to driver
2018-02-08 15:57:32,190 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 124.0 in stage 54.0 (TID 544, localhost, executor driver, partition 124, ANY, 5054 bytes)
2018-02-08 15:57:32,191 INFO[org.apache.spark.executor.Executor:54] - Running task 124.0 in stage 54.0 (TID 544)
2018-02-08 15:57:32,191 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 119.0 in stage 54.0 (TID 542) in 14 ms on localhost (executor driver) (168/200)
2018-02-08 15:57:32,193 INFO[org.apache.spark.executor.Executor:54] - Finished task 122.0 in stage 54.0 (TID 543). 5569 bytes result sent to driver
2018-02-08 15:57:32,194 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 126.0 in stage 54.0 (TID 545, localhost, executor driver, partition 126, ANY, 5054 bytes)
2018-02-08 15:57:32,194 INFO[org.apache.spark.executor.Executor:54] - Running task 126.0 in stage 54.0 (TID 545)
2018-02-08 15:57:32,194 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 122.0 in stage 54.0 (TID 543) in 12 ms on localhost (executor driver) (169/200)
2018-02-08 15:57:32,196 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,196 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,197 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,197 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,197 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,198 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,198 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,198 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,200 INFO[org.apache.spark.executor.Executor:54] - Finished task 124.0 in stage 54.0 (TID 544). 5526 bytes result sent to driver
2018-02-08 15:57:32,200 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 128.0 in stage 54.0 (TID 546, localhost, executor driver, partition 128, ANY, 5054 bytes)
2018-02-08 15:57:32,201 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 124.0 in stage 54.0 (TID 544) in 12 ms on localhost (executor driver) (170/200)
2018-02-08 15:57:32,201 INFO[org.apache.spark.executor.Executor:54] - Running task 128.0 in stage 54.0 (TID 546)
2018-02-08 15:57:32,202 INFO[org.apache.spark.executor.Executor:54] - Finished task 126.0 in stage 54.0 (TID 545). 5569 bytes result sent to driver
2018-02-08 15:57:32,203 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 129.0 in stage 54.0 (TID 547, localhost, executor driver, partition 129, ANY, 5054 bytes)
2018-02-08 15:57:32,203 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 126.0 in stage 54.0 (TID 545) in 9 ms on localhost (executor driver) (171/200)
2018-02-08 15:57:32,204 INFO[org.apache.spark.executor.Executor:54] - Running task 129.0 in stage 54.0 (TID 547)
2018-02-08 15:57:32,207 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,207 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,208 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,208 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,209 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,209 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,209 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,210 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,212 INFO[org.apache.spark.executor.Executor:54] - Finished task 128.0 in stage 54.0 (TID 546). 5569 bytes result sent to driver
2018-02-08 15:57:32,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 131.0 in stage 54.0 (TID 548, localhost, executor driver, partition 131, ANY, 5054 bytes)
2018-02-08 15:57:32,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 128.0 in stage 54.0 (TID 546) in 13 ms on localhost (executor driver) (172/200)
2018-02-08 15:57:32,213 INFO[org.apache.spark.executor.Executor:54] - Finished task 129.0 in stage 54.0 (TID 547). 5526 bytes result sent to driver
2018-02-08 15:57:32,213 INFO[org.apache.spark.executor.Executor:54] - Running task 131.0 in stage 54.0 (TID 548)
2018-02-08 15:57:32,214 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 132.0 in stage 54.0 (TID 549, localhost, executor driver, partition 132, ANY, 5054 bytes)
2018-02-08 15:57:32,214 INFO[org.apache.spark.executor.Executor:54] - Running task 132.0 in stage 54.0 (TID 549)
2018-02-08 15:57:32,214 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 129.0 in stage 54.0 (TID 547) in 11 ms on localhost (executor driver) (173/200)
2018-02-08 15:57:32,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 6 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,218 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,218 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,219 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,219 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,224 INFO[org.apache.spark.executor.Executor:54] - Finished task 131.0 in stage 54.0 (TID 548). 5569 bytes result sent to driver
2018-02-08 15:57:32,224 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 135.0 in stage 54.0 (TID 550, localhost, executor driver, partition 135, ANY, 5054 bytes)
2018-02-08 15:57:32,224 INFO[org.apache.spark.executor.Executor:54] - Running task 135.0 in stage 54.0 (TID 550)
2018-02-08 15:57:32,224 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 131.0 in stage 54.0 (TID 548) in 11 ms on localhost (executor driver) (174/200)
2018-02-08 15:57:32,225 INFO[org.apache.spark.executor.Executor:54] - Finished task 132.0 in stage 54.0 (TID 549). 5612 bytes result sent to driver
2018-02-08 15:57:32,225 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 136.0 in stage 54.0 (TID 551, localhost, executor driver, partition 136, ANY, 5054 bytes)
2018-02-08 15:57:32,226 INFO[org.apache.spark.executor.Executor:54] - Running task 136.0 in stage 54.0 (TID 551)
2018-02-08 15:57:32,226 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 132.0 in stage 54.0 (TID 549) in 12 ms on localhost (executor driver) (175/200)
2018-02-08 15:57:32,228 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,228 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,229 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,229 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,230 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,230 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,230 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,230 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,233 INFO[org.apache.spark.executor.Executor:54] - Finished task 136.0 in stage 54.0 (TID 551). 5569 bytes result sent to driver
2018-02-08 15:57:32,233 INFO[org.apache.spark.executor.Executor:54] - Finished task 135.0 in stage 54.0 (TID 550). 5569 bytes result sent to driver
2018-02-08 15:57:32,233 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 137.0 in stage 54.0 (TID 552, localhost, executor driver, partition 137, ANY, 5054 bytes)
2018-02-08 15:57:32,233 INFO[org.apache.spark.executor.Executor:54] - Running task 137.0 in stage 54.0 (TID 552)
2018-02-08 15:57:32,233 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 140.0 in stage 54.0 (TID 553, localhost, executor driver, partition 140, ANY, 5054 bytes)
2018-02-08 15:57:32,234 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 136.0 in stage 54.0 (TID 551) in 9 ms on localhost (executor driver) (176/200)
2018-02-08 15:57:32,234 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 135.0 in stage 54.0 (TID 550) in 10 ms on localhost (executor driver) (177/200)
2018-02-08 15:57:32,235 INFO[org.apache.spark.executor.Executor:54] - Running task 140.0 in stage 54.0 (TID 553)
2018-02-08 15:57:32,238 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,239 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,239 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,239 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,240 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,240 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,240 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,240 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,243 INFO[org.apache.spark.executor.Executor:54] - Finished task 140.0 in stage 54.0 (TID 553). 5526 bytes result sent to driver
2018-02-08 15:57:32,243 INFO[org.apache.spark.executor.Executor:54] - Finished task 137.0 in stage 54.0 (TID 552). 5526 bytes result sent to driver
2018-02-08 15:57:32,243 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 141.0 in stage 54.0 (TID 554, localhost, executor driver, partition 141, ANY, 5054 bytes)
2018-02-08 15:57:32,243 INFO[org.apache.spark.executor.Executor:54] - Running task 141.0 in stage 54.0 (TID 554)
2018-02-08 15:57:32,243 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 143.0 in stage 54.0 (TID 555, localhost, executor driver, partition 143, ANY, 5054 bytes)
2018-02-08 15:57:32,244 INFO[org.apache.spark.executor.Executor:54] - Running task 143.0 in stage 54.0 (TID 555)
2018-02-08 15:57:32,244 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 137.0 in stage 54.0 (TID 552) in 11 ms on localhost (executor driver) (178/200)
2018-02-08 15:57:32,244 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 140.0 in stage 54.0 (TID 553) in 11 ms on localhost (executor driver) (179/200)
2018-02-08 15:57:32,247 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,247 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,247 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,247 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,248 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,248 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,248 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,248 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,252 INFO[org.apache.spark.executor.Executor:54] - Finished task 143.0 in stage 54.0 (TID 555). 5569 bytes result sent to driver
2018-02-08 15:57:32,252 INFO[org.apache.spark.executor.Executor:54] - Finished task 141.0 in stage 54.0 (TID 554). 5526 bytes result sent to driver
2018-02-08 15:57:32,252 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 146.0 in stage 54.0 (TID 556, localhost, executor driver, partition 146, ANY, 5054 bytes)
2018-02-08 15:57:32,253 INFO[org.apache.spark.executor.Executor:54] - Running task 146.0 in stage 54.0 (TID 556)
2018-02-08 15:57:32,253 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 150.0 in stage 54.0 (TID 557, localhost, executor driver, partition 150, ANY, 5054 bytes)
2018-02-08 15:57:32,253 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 143.0 in stage 54.0 (TID 555) in 10 ms on localhost (executor driver) (180/200)
2018-02-08 15:57:32,253 INFO[org.apache.spark.executor.Executor:54] - Running task 150.0 in stage 54.0 (TID 557)
2018-02-08 15:57:32,255 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 141.0 in stage 54.0 (TID 554) in 12 ms on localhost (executor driver) (181/200)
2018-02-08 15:57:32,256 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 5 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,256 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,257 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 9 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,257 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,258 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,258 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,258 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,258 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,261 INFO[org.apache.spark.executor.Executor:54] - Finished task 146.0 in stage 54.0 (TID 556). 5526 bytes result sent to driver
2018-02-08 15:57:32,262 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 151.0 in stage 54.0 (TID 558, localhost, executor driver, partition 151, ANY, 5054 bytes)
2018-02-08 15:57:32,262 INFO[org.apache.spark.executor.Executor:54] - Finished task 150.0 in stage 54.0 (TID 557). 5569 bytes result sent to driver
2018-02-08 15:57:32,262 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 146.0 in stage 54.0 (TID 556) in 10 ms on localhost (executor driver) (182/200)
2018-02-08 15:57:32,262 INFO[org.apache.spark.executor.Executor:54] - Running task 151.0 in stage 54.0 (TID 558)
2018-02-08 15:57:32,262 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 156.0 in stage 54.0 (TID 559, localhost, executor driver, partition 156, ANY, 5054 bytes)
2018-02-08 15:57:32,263 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 150.0 in stage 54.0 (TID 557) in 11 ms on localhost (executor driver) (183/200)
2018-02-08 15:57:32,263 INFO[org.apache.spark.executor.Executor:54] - Running task 156.0 in stage 54.0 (TID 559)
2018-02-08 15:57:32,265 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 4 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,265 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,266 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,266 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,267 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,267 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,267 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,267 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,271 INFO[org.apache.spark.executor.Executor:54] - Finished task 156.0 in stage 54.0 (TID 559). 5569 bytes result sent to driver
2018-02-08 15:57:32,271 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 162.0 in stage 54.0 (TID 560, localhost, executor driver, partition 162, ANY, 5054 bytes)
2018-02-08 15:57:32,272 INFO[org.apache.spark.executor.Executor:54] - Running task 162.0 in stage 54.0 (TID 560)
2018-02-08 15:57:32,272 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 156.0 in stage 54.0 (TID 559) in 10 ms on localhost (executor driver) (184/200)
2018-02-08 15:57:32,272 INFO[org.apache.spark.executor.Executor:54] - Finished task 151.0 in stage 54.0 (TID 558). 5569 bytes result sent to driver
2018-02-08 15:57:32,272 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 163.0 in stage 54.0 (TID 561, localhost, executor driver, partition 163, ANY, 5054 bytes)
2018-02-08 15:57:32,272 INFO[org.apache.spark.executor.Executor:54] - Running task 163.0 in stage 54.0 (TID 561)
2018-02-08 15:57:32,272 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 151.0 in stage 54.0 (TID 558) in 10 ms on localhost (executor driver) (185/200)
2018-02-08 15:57:32,275 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,275 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,275 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,275 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,276 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,276 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,276 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,276 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,279 INFO[org.apache.spark.executor.Executor:54] - Finished task 163.0 in stage 54.0 (TID 561). 5526 bytes result sent to driver
2018-02-08 15:57:32,279 INFO[org.apache.spark.executor.Executor:54] - Finished task 162.0 in stage 54.0 (TID 560). 5526 bytes result sent to driver
2018-02-08 15:57:32,279 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 164.0 in stage 54.0 (TID 562, localhost, executor driver, partition 164, ANY, 5054 bytes)
2018-02-08 15:57:32,280 INFO[org.apache.spark.executor.Executor:54] - Running task 164.0 in stage 54.0 (TID 562)
2018-02-08 15:57:32,280 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 165.0 in stage 54.0 (TID 563, localhost, executor driver, partition 165, ANY, 5054 bytes)
2018-02-08 15:57:32,280 INFO[org.apache.spark.executor.Executor:54] - Running task 165.0 in stage 54.0 (TID 563)
2018-02-08 15:57:32,280 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 162.0 in stage 54.0 (TID 560) in 9 ms on localhost (executor driver) (186/200)
2018-02-08 15:57:32,281 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 163.0 in stage 54.0 (TID 561) in 9 ms on localhost (executor driver) (187/200)
2018-02-08 15:57:32,283 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,283 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 7 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,283 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,284 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,285 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,285 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,285 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,285 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,289 INFO[org.apache.spark.executor.Executor:54] - Finished task 165.0 in stage 54.0 (TID 563). 5526 bytes result sent to driver
2018-02-08 15:57:32,290 INFO[org.apache.spark.executor.Executor:54] - Finished task 164.0 in stage 54.0 (TID 562). 5526 bytes result sent to driver
2018-02-08 15:57:32,290 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 168.0 in stage 54.0 (TID 564, localhost, executor driver, partition 168, ANY, 5054 bytes)
2018-02-08 15:57:32,291 INFO[org.apache.spark.executor.Executor:54] - Running task 168.0 in stage 54.0 (TID 564)
2018-02-08 15:57:32,291 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 173.0 in stage 54.0 (TID 565, localhost, executor driver, partition 173, ANY, 5054 bytes)
2018-02-08 15:57:32,291 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 164.0 in stage 54.0 (TID 562) in 12 ms on localhost (executor driver) (188/200)
2018-02-08 15:57:32,291 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 165.0 in stage 54.0 (TID 563) in 12 ms on localhost (executor driver) (189/200)
2018-02-08 15:57:32,292 INFO[org.apache.spark.executor.Executor:54] - Running task 173.0 in stage 54.0 (TID 565)
2018-02-08 15:57:32,294 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,294 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,295 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,295 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,295 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,296 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,296 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,296 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,299 INFO[org.apache.spark.executor.Executor:54] - Finished task 168.0 in stage 54.0 (TID 564). 5569 bytes result sent to driver
2018-02-08 15:57:32,299 INFO[org.apache.spark.executor.Executor:54] - Finished task 173.0 in stage 54.0 (TID 565). 5612 bytes result sent to driver
2018-02-08 15:57:32,299 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 174.0 in stage 54.0 (TID 566, localhost, executor driver, partition 174, ANY, 5054 bytes)
2018-02-08 15:57:32,299 INFO[org.apache.spark.executor.Executor:54] - Running task 174.0 in stage 54.0 (TID 566)
2018-02-08 15:57:32,300 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 181.0 in stage 54.0 (TID 567, localhost, executor driver, partition 181, ANY, 5054 bytes)
2018-02-08 15:57:32,301 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 173.0 in stage 54.0 (TID 565) in 11 ms on localhost (executor driver) (190/200)
2018-02-08 15:57:32,302 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 168.0 in stage 54.0 (TID 564) in 12 ms on localhost (executor driver) (191/200)
2018-02-08 15:57:32,303 INFO[org.apache.spark.executor.Executor:54] - Running task 181.0 in stage 54.0 (TID 567)
2018-02-08 15:57:32,304 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 7 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,305 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,306 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,306 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,306 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,306 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,307 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,307 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,310 INFO[org.apache.spark.executor.Executor:54] - Finished task 174.0 in stage 54.0 (TID 566). 5526 bytes result sent to driver
2018-02-08 15:57:32,310 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 183.0 in stage 54.0 (TID 568, localhost, executor driver, partition 183, ANY, 5054 bytes)
2018-02-08 15:57:32,311 INFO[org.apache.spark.executor.Executor:54] - Running task 183.0 in stage 54.0 (TID 568)
2018-02-08 15:57:32,311 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 174.0 in stage 54.0 (TID 566) in 11 ms on localhost (executor driver) (192/200)
2018-02-08 15:57:32,312 INFO[org.apache.spark.executor.Executor:54] - Finished task 181.0 in stage 54.0 (TID 567). 5569 bytes result sent to driver
2018-02-08 15:57:32,313 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 184.0 in stage 54.0 (TID 569, localhost, executor driver, partition 184, ANY, 5054 bytes)
2018-02-08 15:57:32,313 INFO[org.apache.spark.executor.Executor:54] - Running task 184.0 in stage 54.0 (TID 569)
2018-02-08 15:57:32,313 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 181.0 in stage 54.0 (TID 567) in 14 ms on localhost (executor driver) (193/200)
2018-02-08 15:57:32,315 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 6 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,315 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,316 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,317 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,318 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,318 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,318 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,319 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,322 INFO[org.apache.spark.executor.Executor:54] - Finished task 183.0 in stage 54.0 (TID 568). 5569 bytes result sent to driver
2018-02-08 15:57:32,323 INFO[org.apache.spark.executor.Executor:54] - Finished task 184.0 in stage 54.0 (TID 569). 5526 bytes result sent to driver
2018-02-08 15:57:32,323 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 191.0 in stage 54.0 (TID 570, localhost, executor driver, partition 191, ANY, 5054 bytes)
2018-02-08 15:57:32,324 INFO[org.apache.spark.executor.Executor:54] - Running task 191.0 in stage 54.0 (TID 570)
2018-02-08 15:57:32,324 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 192.0 in stage 54.0 (TID 571, localhost, executor driver, partition 192, ANY, 5054 bytes)
2018-02-08 15:57:32,324 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 183.0 in stage 54.0 (TID 568) in 14 ms on localhost (executor driver) (194/200)
2018-02-08 15:57:32,324 INFO[org.apache.spark.executor.Executor:54] - Running task 192.0 in stage 54.0 (TID 571)
2018-02-08 15:57:32,325 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 184.0 in stage 54.0 (TID 569) in 12 ms on localhost (executor driver) (195/200)
2018-02-08 15:57:32,328 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,328 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,328 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,329 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,330 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,330 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,332 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,332 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,336 INFO[org.apache.spark.executor.Executor:54] - Finished task 191.0 in stage 54.0 (TID 570). 5569 bytes result sent to driver
2018-02-08 15:57:32,336 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 193.0 in stage 54.0 (TID 572, localhost, executor driver, partition 193, ANY, 5054 bytes)
2018-02-08 15:57:32,337 INFO[org.apache.spark.executor.Executor:54] - Finished task 192.0 in stage 54.0 (TID 571). 5569 bytes result sent to driver
2018-02-08 15:57:32,337 INFO[org.apache.spark.executor.Executor:54] - Running task 193.0 in stage 54.0 (TID 572)
2018-02-08 15:57:32,337 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 191.0 in stage 54.0 (TID 570) in 14 ms on localhost (executor driver) (196/200)
2018-02-08 15:57:32,337 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 198.0 in stage 54.0 (TID 573, localhost, executor driver, partition 198, ANY, 5054 bytes)
2018-02-08 15:57:32,337 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 192.0 in stage 54.0 (TID 571) in 13 ms on localhost (executor driver) (197/200)
2018-02-08 15:57:32,337 INFO[org.apache.spark.executor.Executor:54] - Running task 198.0 in stage 54.0 (TID 573)
2018-02-08 15:57:32,341 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,341 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,343 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 3 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,343 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,343 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,343 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,344 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,344 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,347 INFO[org.apache.spark.executor.Executor:54] - Finished task 193.0 in stage 54.0 (TID 572). 5569 bytes result sent to driver
2018-02-08 15:57:32,348 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 199.0 in stage 54.0 (TID 574, localhost, executor driver, partition 199, ANY, 5054 bytes)
2018-02-08 15:57:32,348 INFO[org.apache.spark.executor.Executor:54] - Running task 199.0 in stage 54.0 (TID 574)
2018-02-08 15:57:32,348 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 193.0 in stage 54.0 (TID 572) in 12 ms on localhost (executor driver) (198/200)
2018-02-08 15:57:32,348 INFO[org.apache.spark.executor.Executor:54] - Finished task 198.0 in stage 54.0 (TID 573). 5569 bytes result sent to driver
2018-02-08 15:57:32,349 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 198.0 in stage 54.0 (TID 573) in 12 ms on localhost (executor driver) (199/200)
2018-02-08 15:57:32,354 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 200 blocks
2018-02-08 15:57:32,354 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:57:32,355 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:57:32,355 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:57:32,358 INFO[org.apache.spark.executor.Executor:54] - Finished task 199.0 in stage 54.0 (TID 574). 5526 bytes result sent to driver
2018-02-08 15:57:32,358 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 199.0 in stage 54.0 (TID 574) in 10 ms on localhost (executor driver) (200/200)
2018-02-08 15:57:32,359 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2018-02-08 15:57:32,359 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 54 (aggregate at RegressionMetrics.scala:57) finished in 1.162 s
2018-02-08 15:57:32,360 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: aggregate at RegressionMetrics.scala:57, took 4.848472 s
2018-02-08 15:57:32,369 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:57:32,375 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@34a1d21f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:57:32,379 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:57:32,389 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:57:32,990 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:57:32,990 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:57:32,992 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:57:32,994 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:57:32,996 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:57:32,997 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:57:32,997 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-94e6a2db-4c5b-4444-ad8d-ae78c07ef9a2
2018-02-08 15:59:02,893 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 15:59:03,425 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 15:59:03,444 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 15:59:03,445 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 15:59:03,445 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 15:59:03,446 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 15:59:03,446 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 15:59:03,770 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 62874.
2018-02-08 15:59:03,786 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 15:59:03,827 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 15:59:03,830 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 15:59:03,830 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 15:59:03,838 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-5af0b282-5574-4523-aa82-ad0887c9e94f
2018-02-08 15:59:03,857 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 15:59:03,901 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 15:59:03,968 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2593ms
2018-02-08 15:59:04,033 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 15:59:04,045 INFO[org.spark_project.jetty.server.Server:403] - Started @2672ms
2018-02-08 15:59:04,063 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@44785b6f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:59:04,064 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 15:59:04,087 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2488b073{/jobs,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,088 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a48e6e2{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,089 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a94964{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,090 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@631e06ab{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,090 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@34a75079{/stages,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,092 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@107ed6fc{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,092 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@186978a6{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,093 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@132ddbab{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,097 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@acb0951{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,098 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,099 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/storage,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,100 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3efe7086{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,100 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@741b3bc3{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,101 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@63648ee9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,102 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45be7cd5{/environment,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,103 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3185fa6b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,104 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b58ed3c{/executors,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,104 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a320ade{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,105 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7813cb11{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,106 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@21005f6c{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,112 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@545de5a4{/static,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,112 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@305f031{/,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,114 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d1f7216{/api,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,114 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4ebea12c{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,115 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6256ac4f{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,117 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 15:59:04,187 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 15:59:04,211 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62887.
2018-02-08 15:59:04,212 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:62887
2018-02-08 15:59:04,213 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 15:59:04,215 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 62887, None)
2018-02-08 15:59:04,219 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:62887 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 62887, None)
2018-02-08 15:59:04,222 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 62887, None)
2018-02-08 15:59:04,232 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 62887, None)
2018-02-08 15:59:04,421 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5a6d5a8f{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,511 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 15:59:04,511 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 15:59:04,517 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@46b695ec{/SQL,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,517 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@325f7fa9{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,518 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3af9aa66{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,519 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@91c4a3f{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 15:59:04,521 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d269ed7{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 15:59:05,466 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 15:59:07,217 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Pruning directories with: 
2018-02-08 15:59:07,220 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Post-Scan Filters: 
2018-02-08 15:59:07,223 INFO[org.apache.spark.sql.execution.datasources.FileSourceStrategy:54] - Output Data Schema: struct<value: string>
2018-02-08 15:59:07,231 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Pushed Filters: 
2018-02-08 15:59:07,672 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 165.011573 ms
2018-02-08 15:59:07,719 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 322.9 KB, free 631.5 MB)
2018-02-08 15:59:07,875 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.6 KB, free 631.5 MB)
2018-02-08 15:59:07,879 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:62887 (size: 27.6 KB, free: 631.8 MB)
2018-02-08 15:59:07,883 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from javaRDD at MachineLeaningFiltering.java:27
2018-02-08 15:59:07,894 INFO[org.apache.spark.sql.execution.FileSourceScanExec:54] - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2018-02-08 15:59:08,251 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 27.039369 ms
2018-02-08 15:59:08,292 INFO[org.apache.spark.ml.util.Instrumentation:54] - ALS-als_35f73d3adf4b-981876983-1: training: numPartitions=1 storageLevel=StorageLevel(1 replicas)
2018-02-08 15:59:08,314 INFO[org.apache.spark.ml.util.Instrumentation:54] - ALS-als_35f73d3adf4b-981876983-1: {"ratingCol":"rating","itemCol":"movieId","userCol":"userId","regParam":0.01,"maxIter":5}
2018-02-08 15:59:08,380 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at ALS.scala:843
2018-02-08 15:59:08,398 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (isEmpty at ALS.scala:843) with 1 output partitions
2018-02-08 15:59:08,399 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (isEmpty at ALS.scala:843)
2018-02-08 15:59:08,399 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 15:59:08,400 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:59:08,407 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[10] at map at ALS.scala:613), which has no missing parents
2018-02-08 15:59:08,428 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 24.0 KB, free 631.4 MB)
2018-02-08 15:59:08,432 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 11.1 KB, free 631.4 MB)
2018-02-08 15:59:08,432 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:62887 (size: 11.1 KB, free: 631.8 MB)
2018-02-08 15:59:08,433 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:08,442 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[10] at map at ALS.scala:613) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:59:08,443 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
2018-02-08 15:59:08,474 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5324 bytes)
2018-02-08 15:59:08,485 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 15:59:08,583 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.999042 ms
2018-02-08 15:59:08,605 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.434564 ms
2018-02-08 15:59:08,620 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.071043 ms
2018-02-08 15:59:08,622 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/als/sample_movielens_ratings.txt, range: 0-32363, partition values: [empty row]
2018-02-08 15:59:08,631 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.199682 ms
2018-02-08 15:59:08,669 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1841 bytes result sent to driver
2018-02-08 15:59:08,675 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 209 ms on localhost (executor driver) (1/1)
2018-02-08 15:59:08,677 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 15:59:08,681 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (isEmpty at ALS.scala:843) finished in 0.225 s
2018-02-08 15:59:08,687 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: isEmpty at ALS.scala:843, took 0.307042 s
2018-02-08 15:59:08,778 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:857
2018-02-08 15:59:08,784 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 11 (mapPartitions at ALS.scala:1101)
2018-02-08 15:59:08,785 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 14 (map at ALS.scala:1344)
2018-02-08 15:59:08,785 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (count at ALS.scala:857) with 10 output partitions
2018-02-08 15:59:08,785 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (count at ALS.scala:857)
2018-02-08 15:59:08,785 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 2)
2018-02-08 15:59:08,789 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 2)
2018-02-08 15:59:08,791 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at mapPartitions at ALS.scala:1101), which has no missing parents
2018-02-08 15:59:08,798 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 26.1 KB, free 631.4 MB)
2018-02-08 15:59:08,800 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 12.0 KB, free 631.4 MB)
2018-02-08 15:59:08,803 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:62887 (size: 12.0 KB, free: 631.8 MB)
2018-02-08 15:59:08,803 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:08,806 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at mapPartitions at ALS.scala:1101) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:59:08,806 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 15:59:08,808 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5313 bytes)
2018-02-08 15:59:08,808 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
2018-02-08 15:59:08,830 INFO[org.apache.spark.sql.execution.datasources.FileScanRDD:54] - Reading File path: file:///E:/IntelliJWorkspaceMumu/mumu-spark/data/mllib/als/sample_movielens_ratings.txt, range: 0-32363, partition values: [empty row]
2018-02-08 15:59:08,979 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1777 bytes result sent to driver
2018-02-08 15:59:08,981 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 174 ms on localhost (executor driver) (1/1)
2018-02-08 15:59:08,981 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 15:59:08,983 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 1 (mapPartitions at ALS.scala:1101) finished in 0.176 s
2018-02-08 15:59:08,984 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:08,984 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:08,985 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 2, ResultStage 3)
2018-02-08 15:59:08,985 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:08,990 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at map at ALS.scala:1344), which has no missing parents
2018-02-08 15:59:09,000 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 27.4 KB, free 631.4 MB)
2018-02-08 15:59:09,004 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 12.5 KB, free 631.3 MB)
2018-02-08 15:59:09,007 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:62887 (size: 12.5 KB, free: 631.7 MB)
2018-02-08 15:59:09,008 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:09,009 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:59:09,010 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 1 tasks
2018-02-08 15:59:09,015 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4610 bytes)
2018-02-08 15:59:09,015 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 2)
2018-02-08 15:59:09,039 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,040 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 15:59:09,114 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_13_0 stored as values in memory (estimated size 31.1 KB, free 631.3 MB)
2018-02-08 15:59:09,116 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_13_0 in memory on 192.168.11.26:62887 (size: 31.1 KB, free: 631.7 MB)
2018-02-08 15:59:09,209 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.11.26:62887 in memory (size: 12.0 KB, free: 631.7 MB)
2018-02-08 15:59:09,232 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:62887 in memory (size: 11.1 KB, free: 631.7 MB)
2018-02-08 15:59:09,377 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 2). 2768 bytes result sent to driver
2018-02-08 15:59:09,378 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 2) in 364 ms on localhost (executor driver) (1/1)
2018-02-08 15:59:09,379 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 15:59:09,379 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 2 (map at ALS.scala:1344) finished in 0.365 s
2018-02-08 15:59:09,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:09,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:09,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 3)
2018-02-08 15:59:09,380 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:09,381 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (userOutBlocks MapPartitionsRDD[17] at mapValues at ALS.scala:1381), which has no missing parents
2018-02-08 15:59:09,383 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 28.0 KB, free 631.4 MB)
2018-02-08 15:59:09,387 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.7 KB, free 631.3 MB)
2018-02-08 15:59:09,389 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:62887 (size: 12.7 KB, free: 631.7 MB)
2018-02-08 15:59:09,390 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:09,391 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 3 (userOutBlocks MapPartitionsRDD[17] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:09,391 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 10 tasks
2018-02-08 15:59:09,392 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:59:09,392 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, ANY, 4621 bytes)
2018-02-08 15:59:09,392 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 3)
2018-02-08 15:59:09,395 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 3.0 (TID 4)
2018-02-08 15:59:09,403 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,403 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:09,407 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,407 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:09,429 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_1 stored as values in memory (estimated size 1424.0 B, free 631.3 MB)
2018-02-08 15:59:09,432 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_0 stored as values in memory (estimated size 1312.0 B, free 631.3 MB)
2018-02-08 15:59:09,439 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_1 in memory on 192.168.11.26:62887 (size: 1424.0 B, free: 631.7 MB)
2018-02-08 15:59:09,440 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_1 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:59:09,442 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_0 in memory on 192.168.11.26:62887 (size: 1312.0 B, free: 631.7 MB)
2018-02-08 15:59:09,447 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_0 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:59:09,448 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_1 in memory on 192.168.11.26:62887 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:59:09,448 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_0 in memory on 192.168.11.26:62887 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:59:09,450 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 3.0 (TID 4). 2527 bytes result sent to driver
2018-02-08 15:59:09,451 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 3.0 (TID 5, localhost, executor driver, partition 2, ANY, 4621 bytes)
2018-02-08 15:59:09,453 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 3.0 (TID 5)
2018-02-08 15:59:09,453 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 3). 2613 bytes result sent to driver
2018-02-08 15:59:09,454 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 3.0 (TID 6, localhost, executor driver, partition 3, ANY, 4621 bytes)
2018-02-08 15:59:09,455 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 3) in 64 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:09,459 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 3.0 (TID 6)
2018-02-08 15:59:09,474 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,474 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:09,475 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,476 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:09,479 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_3 stored as values in memory (estimated size 1376.0 B, free 631.3 MB)
2018-02-08 15:59:09,480 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_2 stored as values in memory (estimated size 1456.0 B, free 631.3 MB)
2018-02-08 15:59:09,481 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_3 in memory on 192.168.11.26:62887 (size: 1376.0 B, free: 631.7 MB)
2018-02-08 15:59:09,486 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_2 in memory on 192.168.11.26:62887 (size: 1456.0 B, free: 631.7 MB)
2018-02-08 15:59:09,488 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_3 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:59:09,490 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_2 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:59:09,490 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_3 in memory on 192.168.11.26:62887 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:59:09,494 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 3.0 (TID 6). 2527 bytes result sent to driver
2018-02-08 15:59:09,495 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_2 in memory on 192.168.11.26:62887 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:59:09,497 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 3.0 (TID 7, localhost, executor driver, partition 4, ANY, 4621 bytes)
2018-02-08 15:59:09,503 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 3.0 (TID 5). 2527 bytes result sent to driver
2018-02-08 15:59:09,504 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 3.0 (TID 6) in 50 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:09,507 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 3.0 (TID 7)
2018-02-08 15:59:09,509 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 3.0 (TID 8, localhost, executor driver, partition 5, ANY, 4621 bytes)
2018-02-08 15:59:09,510 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 3.0 (TID 8)
2018-02-08 15:59:09,513 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 3.0 (TID 5) in 62 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:09,524 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,524 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:09,533 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_5 stored as values in memory (estimated size 1344.0 B, free 631.3 MB)
2018-02-08 15:59:09,534 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_5 in memory on 192.168.11.26:62887 (size: 1344.0 B, free: 631.7 MB)
2018-02-08 15:59:09,535 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_5 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:59:09,538 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_5 in memory on 192.168.11.26:62887 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:59:09,540 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 3.0 (TID 8). 2613 bytes result sent to driver
2018-02-08 15:59:09,540 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 3.0 (TID 9, localhost, executor driver, partition 6, ANY, 4621 bytes)
2018-02-08 15:59:09,541 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 3.0 (TID 8) in 33 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:09,541 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 3.0 (TID 9)
2018-02-08 15:59:09,547 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,548 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 4 ms
2018-02-08 15:59:09,548 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,549 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:09,551 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_6 stored as values in memory (estimated size 1408.0 B, free 631.3 MB)
2018-02-08 15:59:09,552 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_6 in memory on 192.168.11.26:62887 (size: 1408.0 B, free: 631.7 MB)
2018-02-08 15:59:09,554 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_4 stored as values in memory (estimated size 1504.0 B, free 631.3 MB)
2018-02-08 15:59:09,554 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_6 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:59:09,556 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_4 in memory on 192.168.11.26:62887 (size: 1504.0 B, free: 631.7 MB)
2018-02-08 15:59:09,556 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_6 in memory on 192.168.11.26:62887 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:59:09,559 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 3.0 (TID 9). 2570 bytes result sent to driver
2018-02-08 15:59:09,559 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 3.0 (TID 10, localhost, executor driver, partition 7, ANY, 4621 bytes)
2018-02-08 15:59:09,560 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_4 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:59:09,565 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 3.0 (TID 10)
2018-02-08 15:59:09,565 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 3.0 (TID 9) in 25 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:09,570 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 3.0 (TID 4) in 178 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:09,570 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_4 in memory on 192.168.11.26:62887 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:59:09,573 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 3.0 (TID 7). 2570 bytes result sent to driver
2018-02-08 15:59:09,573 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,573 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:09,574 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 3.0 (TID 11, localhost, executor driver, partition 8, ANY, 4621 bytes)
2018-02-08 15:59:09,576 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_7 stored as values in memory (estimated size 1360.0 B, free 631.3 MB)
2018-02-08 15:59:09,577 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 3.0 (TID 7) in 81 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:09,578 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_7 in memory on 192.168.11.26:62887 (size: 1360.0 B, free: 631.7 MB)
2018-02-08 15:59:09,577 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 3.0 (TID 11)
2018-02-08 15:59:09,580 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_7 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:59:09,584 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_7 in memory on 192.168.11.26:62887 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:59:09,586 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 3.0 (TID 10). 2527 bytes result sent to driver
2018-02-08 15:59:09,587 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 3.0 (TID 12, localhost, executor driver, partition 9, ANY, 4621 bytes)
2018-02-08 15:59:09,587 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 3.0 (TID 10) in 28 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:09,588 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 3.0 (TID 12)
2018-02-08 15:59:09,588 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,590 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 2 ms
2018-02-08 15:59:09,595 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_8 stored as values in memory (estimated size 1408.0 B, free 631.3 MB)
2018-02-08 15:59:09,596 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_8 in memory on 192.168.11.26:62887 (size: 1408.0 B, free: 631.7 MB)
2018-02-08 15:59:09,597 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_8 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:59:09,600 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_8 in memory on 192.168.11.26:62887 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:59:09,603 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 3.0 (TID 11). 2570 bytes result sent to driver
2018-02-08 15:59:09,605 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 3.0 (TID 11) in 32 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:09,606 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,606 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:09,610 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_16_9 stored as values in memory (estimated size 1376.0 B, free 631.3 MB)
2018-02-08 15:59:09,611 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_16_9 in memory on 192.168.11.26:62887 (size: 1376.0 B, free: 631.7 MB)
2018-02-08 15:59:09,612 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_17_9 stored as values in memory (estimated size 440.0 B, free 631.3 MB)
2018-02-08 15:59:09,613 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_17_9 in memory on 192.168.11.26:62887 (size: 440.0 B, free: 631.7 MB)
2018-02-08 15:59:09,615 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 3.0 (TID 12). 2527 bytes result sent to driver
2018-02-08 15:59:09,619 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 3.0 (TID 12) in 32 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:09,620 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 15:59:09,624 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (count at ALS.scala:857) finished in 0.232 s
2018-02-08 15:59:09,627 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: count at ALS.scala:857, took 0.847955 s
2018-02-08 15:59:09,667 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:865
2018-02-08 15:59:09,671 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:59:09,679 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 19 (map at ALS.scala:1344)
2018-02-08 15:59:09,679 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (count at ALS.scala:865) with 10 output partitions
2018-02-08 15:59:09,679 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (count at ALS.scala:865)
2018-02-08 15:59:09,679 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 5)
2018-02-08 15:59:09,680 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 5)
2018-02-08 15:59:09,682 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 5 (MapPartitionsRDD[19] at map at ALS.scala:1344), which has no missing parents
2018-02-08 15:59:09,685 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 27.6 KB, free 631.3 MB)
2018-02-08 15:59:09,690 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 12.6 KB, free 631.3 MB)
2018-02-08 15:59:09,692 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:62887 (size: 12.6 KB, free: 631.7 MB)
2018-02-08 15:59:09,693 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:09,694 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[19] at map at ALS.scala:1344) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:59:09,695 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 1 tasks
2018-02-08 15:59:09,699 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:59:09,700 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 13)
2018-02-08 15:59:09,704 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_13_0 locally
2018-02-08 15:59:09,787 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_4_piece0 on 192.168.11.26:62887 in memory (size: 12.7 KB, free: 631.7 MB)
2018-02-08 15:59:09,922 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 13). 1786 bytes result sent to driver
2018-02-08 15:59:09,923 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 13) in 225 ms on localhost (executor driver) (1/1)
2018-02-08 15:59:09,923 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 15:59:09,924 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 5 (map at ALS.scala:1344) finished in 0.226 s
2018-02-08 15:59:09,924 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:09,924 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:09,924 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 6)
2018-02-08 15:59:09,924 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:09,925 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (itemOutBlocks MapPartitionsRDD[22] at mapValues at ALS.scala:1381), which has no missing parents
2018-02-08 15:59:09,930 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 28.1 KB, free 631.3 MB)
2018-02-08 15:59:09,935 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 12.8 KB, free 631.3 MB)
2018-02-08 15:59:09,936 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:62887 (size: 12.8 KB, free: 631.7 MB)
2018-02-08 15:59:09,937 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:09,938 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 6 (itemOutBlocks MapPartitionsRDD[22] at mapValues at ALS.scala:1381) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:09,939 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 10 tasks
2018-02-08 15:59:09,940 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 14, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 15:59:09,940 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 6.0 (TID 15, localhost, executor driver, partition 1, ANY, 4621 bytes)
2018-02-08 15:59:09,940 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 14)
2018-02-08 15:59:09,940 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 6.0 (TID 15)
2018-02-08 15:59:09,950 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,950 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:09,951 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,951 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:09,956 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_1 stored as values in memory (estimated size 1432.0 B, free 631.3 MB)
2018-02-08 15:59:09,957 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_0 stored as values in memory (estimated size 1464.0 B, free 631.3 MB)
2018-02-08 15:59:09,958 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_1 in memory on 192.168.11.26:62887 (size: 1432.0 B, free: 631.7 MB)
2018-02-08 15:59:09,959 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_0 in memory on 192.168.11.26:62887 (size: 1464.0 B, free: 631.7 MB)
2018-02-08 15:59:09,960 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_1 stored as values in memory (estimated size 648.0 B, free 631.3 MB)
2018-02-08 15:59:09,965 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_0 stored as values in memory (estimated size 664.0 B, free 631.3 MB)
2018-02-08 15:59:09,966 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_1 in memory on 192.168.11.26:62887 (size: 648.0 B, free: 631.7 MB)
2018-02-08 15:59:09,967 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_0 in memory on 192.168.11.26:62887 (size: 664.0 B, free: 631.7 MB)
2018-02-08 15:59:09,968 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 6.0 (TID 15). 2570 bytes result sent to driver
2018-02-08 15:59:09,969 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 6.0 (TID 16, localhost, executor driver, partition 2, ANY, 4621 bytes)
2018-02-08 15:59:09,971 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 14). 2527 bytes result sent to driver
2018-02-08 15:59:09,971 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 6.0 (TID 16)
2018-02-08 15:59:09,971 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 6.0 (TID 15) in 31 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:09,972 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 6.0 (TID 17, localhost, executor driver, partition 3, ANY, 4621 bytes)
2018-02-08 15:59:09,975 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 14) in 35 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:09,975 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 6.0 (TID 17)
2018-02-08 15:59:09,981 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:09,981 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:09,990 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_2 stored as values in memory (estimated size 1480.0 B, free 631.3 MB)
2018-02-08 15:59:09,991 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_2 in memory on 192.168.11.26:62887 (size: 1480.0 B, free: 631.7 MB)
2018-02-08 15:59:09,996 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_2 stored as values in memory (estimated size 640.0 B, free 631.3 MB)
2018-02-08 15:59:09,998 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_2 in memory on 192.168.11.26:62887 (size: 640.0 B, free: 631.7 MB)
2018-02-08 15:59:10,004 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 6.0 (TID 16). 2570 bytes result sent to driver
2018-02-08 15:59:10,005 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:10,005 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:10,008 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 6.0 (TID 18, localhost, executor driver, partition 4, ANY, 4621 bytes)
2018-02-08 15:59:10,009 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_3 stored as values in memory (estimated size 1368.0 B, free 631.3 MB)
2018-02-08 15:59:10,010 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 6.0 (TID 16) in 41 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:10,012 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 6.0 (TID 18)
2018-02-08 15:59:10,014 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_3 in memory on 192.168.11.26:62887 (size: 1368.0 B, free: 631.7 MB)
2018-02-08 15:59:10,016 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_3 stored as values in memory (estimated size 648.0 B, free 631.3 MB)
2018-02-08 15:59:10,017 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_3 in memory on 192.168.11.26:62887 (size: 648.0 B, free: 631.7 MB)
2018-02-08 15:59:10,019 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 6.0 (TID 17). 2527 bytes result sent to driver
2018-02-08 15:59:10,020 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:10,020 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:10,020 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 6.0 (TID 19, localhost, executor driver, partition 5, ANY, 4621 bytes)
2018-02-08 15:59:10,022 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_4 stored as values in memory (estimated size 1496.0 B, free 631.3 MB)
2018-02-08 15:59:10,023 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 6.0 (TID 17) in 51 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:10,023 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 6.0 (TID 19)
2018-02-08 15:59:10,023 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_4 in memory on 192.168.11.26:62887 (size: 1496.0 B, free: 631.7 MB)
2018-02-08 15:59:10,028 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_4 stored as values in memory (estimated size 664.0 B, free 631.3 MB)
2018-02-08 15:59:10,030 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:10,031 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:10,036 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_5 stored as values in memory (estimated size 1496.0 B, free 631.3 MB)
2018-02-08 15:59:10,037 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_4 in memory on 192.168.11.26:62887 (size: 664.0 B, free: 631.7 MB)
2018-02-08 15:59:10,037 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_5 in memory on 192.168.11.26:62887 (size: 1496.0 B, free: 631.7 MB)
2018-02-08 15:59:10,038 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 6.0 (TID 18). 2570 bytes result sent to driver
2018-02-08 15:59:10,044 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 6.0 (TID 20, localhost, executor driver, partition 6, ANY, 4621 bytes)
2018-02-08 15:59:10,044 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_5 stored as values in memory (estimated size 648.0 B, free 631.3 MB)
2018-02-08 15:59:10,045 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 6.0 (TID 20)
2018-02-08 15:59:10,045 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 6.0 (TID 18) in 40 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:10,046 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_5 in memory on 192.168.11.26:62887 (size: 648.0 B, free: 631.7 MB)
2018-02-08 15:59:10,049 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 6.0 (TID 19). 2570 bytes result sent to driver
2018-02-08 15:59:10,051 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 6.0 (TID 21, localhost, executor driver, partition 7, ANY, 4621 bytes)
2018-02-08 15:59:10,051 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 6.0 (TID 21)
2018-02-08 15:59:10,051 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 6.0 (TID 19) in 31 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:10,053 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:10,053 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:10,057 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:10,057 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:10,058 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_6 stored as values in memory (estimated size 1448.0 B, free 631.3 MB)
2018-02-08 15:59:10,058 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_6 in memory on 192.168.11.26:62887 (size: 1448.0 B, free: 631.7 MB)
2018-02-08 15:59:10,060 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_7 stored as values in memory (estimated size 1432.0 B, free 631.3 MB)
2018-02-08 15:59:10,062 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_7 in memory on 192.168.11.26:62887 (size: 1432.0 B, free: 631.7 MB)
2018-02-08 15:59:10,062 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_6 stored as values in memory (estimated size 672.0 B, free 631.3 MB)
2018-02-08 15:59:10,063 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_7 stored as values in memory (estimated size 656.0 B, free 631.3 MB)
2018-02-08 15:59:10,064 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_6 in memory on 192.168.11.26:62887 (size: 672.0 B, free: 631.7 MB)
2018-02-08 15:59:10,065 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 6.0 (TID 20). 2613 bytes result sent to driver
2018-02-08 15:59:10,066 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_7 in memory on 192.168.11.26:62887 (size: 656.0 B, free: 631.7 MB)
2018-02-08 15:59:10,067 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 6.0 (TID 22, localhost, executor driver, partition 8, ANY, 4621 bytes)
2018-02-08 15:59:10,067 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 6.0 (TID 20) in 24 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:10,068 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 6.0 (TID 22)
2018-02-08 15:59:10,068 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 6.0 (TID 21). 2570 bytes result sent to driver
2018-02-08 15:59:10,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 6.0 (TID 23, localhost, executor driver, partition 9, ANY, 4621 bytes)
2018-02-08 15:59:10,072 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 6.0 (TID 21) in 21 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:10,072 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 6.0 (TID 23)
2018-02-08 15:59:10,074 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:10,075 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:10,078 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_8 stored as values in memory (estimated size 1448.0 B, free 631.3 MB)
2018-02-08 15:59:10,078 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 1 blocks
2018-02-08 15:59:10,079 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:10,079 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_8 in memory on 192.168.11.26:62887 (size: 1448.0 B, free: 631.7 MB)
2018-02-08 15:59:10,080 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_8 stored as values in memory (estimated size 632.0 B, free 631.3 MB)
2018-02-08 15:59:10,083 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_8 in memory on 192.168.11.26:62887 (size: 632.0 B, free: 631.7 MB)
2018-02-08 15:59:10,084 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 6.0 (TID 22). 2570 bytes result sent to driver
2018-02-08 15:59:10,084 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 6.0 (TID 22) in 18 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:10,087 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_21_9 stored as values in memory (estimated size 1464.0 B, free 631.3 MB)
2018-02-08 15:59:10,087 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_21_9 in memory on 192.168.11.26:62887 (size: 1464.0 B, free: 631.7 MB)
2018-02-08 15:59:10,090 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_22_9 stored as values in memory (estimated size 664.0 B, free 631.3 MB)
2018-02-08 15:59:10,092 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_22_9 in memory on 192.168.11.26:62887 (size: 664.0 B, free: 631.7 MB)
2018-02-08 15:59:10,094 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 6.0 (TID 23). 2570 bytes result sent to driver
2018-02-08 15:59:10,094 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 6.0 (TID 23) in 24 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:10,095 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 15:59:10,096 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (count at ALS.scala:865) finished in 0.155 s
2018-02-08 15:59:10,098 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: count at ALS.scala:865, took 0.430356 s
2018-02-08 15:59:10,342 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_6_piece0 on 192.168.11.26:62887 in memory (size: 12.8 KB, free: 631.7 MB)
2018-02-08 15:59:10,431 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:944
2018-02-08 15:59:10,432 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:59:10,433 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 155 bytes
2018-02-08 15:59:10,435 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 23 (map at ALS.scala:1017)
2018-02-08 15:59:10,436 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 28 (flatMap at ALS.scala:1433)
2018-02-08 15:59:10,436 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 2 is 156 bytes
2018-02-08 15:59:10,437 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 37 (flatMap at ALS.scala:1433)
2018-02-08 15:59:10,437 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 46 (flatMap at ALS.scala:1433)
2018-02-08 15:59:10,437 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 55 (flatMap at ALS.scala:1433)
2018-02-08 15:59:10,437 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 64 (flatMap at ALS.scala:1433)
2018-02-08 15:59:10,439 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 73 (flatMap at ALS.scala:1433)
2018-02-08 15:59:10,439 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 82 (flatMap at ALS.scala:1433)
2018-02-08 15:59:10,440 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 91 (flatMap at ALS.scala:1433)
2018-02-08 15:59:10,440 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 100 (flatMap at ALS.scala:1433)
2018-02-08 15:59:10,440 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 109 (flatMap at ALS.scala:1433)
2018-02-08 15:59:10,441 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (count at ALS.scala:944) with 10 output partitions
2018-02-08 15:59:10,441 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 21 (count at ALS.scala:944)
2018-02-08 15:59:10,441 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 20, ShuffleMapStage 8)
2018-02-08 15:59:10,442 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 20)
2018-02-08 15:59:10,451 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 9 (MapPartitionsRDD[23] at map at ALS.scala:1017), which has no missing parents
2018-02-08 15:59:10,453 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7 stored as values in memory (estimated size 28.0 KB, free 631.3 MB)
2018-02-08 15:59:10,455 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_7_piece0 stored as bytes in memory (estimated size 12.7 KB, free 631.3 MB)
2018-02-08 15:59:10,456 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_7_piece0 in memory on 192.168.11.26:62887 (size: 12.7 KB, free: 631.7 MB)
2018-02-08 15:59:10,456 INFO[org.apache.spark.SparkContext:54] - Created broadcast 7 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:10,457 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[23] at map at ALS.scala:1017) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:10,457 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 9.0 with 10 tasks
2018-02-08 15:59:10,458 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 9.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:59:10,459 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 9.0 (TID 25, localhost, executor driver, partition 1, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:59:10,459 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 9.0 (TID 24)
2018-02-08 15:59:10,459 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 9.0 (TID 25)
2018-02-08 15:59:10,464 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:59:10,466 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:59:10,471 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 15:59:10,471 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 15:59:10,488 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 9.0 (TID 24). 1700 bytes result sent to driver
2018-02-08 15:59:10,490 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 9.0 (TID 26, localhost, executor driver, partition 2, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:59:10,491 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 9.0 (TID 25). 1700 bytes result sent to driver
2018-02-08 15:59:10,492 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 9.0 (TID 24) in 34 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:10,492 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 9.0 (TID 26)
2018-02-08 15:59:10,494 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 9.0 (TID 27, localhost, executor driver, partition 3, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:59:10,496 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 9.0 (TID 25) in 37 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:10,496 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:59:10,496 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 9.0 (TID 27)
2018-02-08 15:59:10,500 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:59:10,510 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 9.0 (TID 27). 1700 bytes result sent to driver
2018-02-08 15:59:10,511 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 9.0 (TID 28, localhost, executor driver, partition 4, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:59:10,511 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 9.0 (TID 27) in 18 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:10,511 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 9.0 (TID 28)
2018-02-08 15:59:10,515 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:59:10,523 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 9.0 (TID 26). 1700 bytes result sent to driver
2018-02-08 15:59:10,525 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 9.0 (TID 29, localhost, executor driver, partition 5, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:59:10,526 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 9.0 (TID 26) in 36 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:10,526 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 9.0 (TID 29)
2018-02-08 15:59:10,529 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:59:10,544 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 9.0 (TID 29). 1700 bytes result sent to driver
2018-02-08 15:59:10,549 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 9.0 (TID 28). 1743 bytes result sent to driver
2018-02-08 15:59:10,551 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 9.0 (TID 30, localhost, executor driver, partition 6, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:59:10,552 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 9.0 (TID 28) in 41 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:10,553 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 9.0 (TID 30)
2018-02-08 15:59:10,557 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:59:10,571 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 9.0 (TID 31, localhost, executor driver, partition 7, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:59:10,574 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 9.0 (TID 29) in 49 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:10,576 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 9.0 (TID 30). 1700 bytes result sent to driver
2018-02-08 15:59:10,582 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 9.0 (TID 32, localhost, executor driver, partition 8, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:59:10,583 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 9.0 (TID 30) in 32 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:10,583 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 9.0 (TID 32)
2018-02-08 15:59:10,587 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:59:10,629 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 9.0 (TID 32). 1657 bytes result sent to driver
2018-02-08 15:59:10,631 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 9.0 (TID 33, localhost, executor driver, partition 9, PROCESS_LOCAL, 4610 bytes)
2018-02-08 15:59:10,632 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 9.0 (TID 32) in 51 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:10,632 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 9.0 (TID 33)
2018-02-08 15:59:10,640 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:59:10,661 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 9.0 (TID 31)
2018-02-08 15:59:10,664 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:59:10,670 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 9.0 (TID 33). 1700 bytes result sent to driver
2018-02-08 15:59:10,671 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 9.0 (TID 33) in 41 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:10,677 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 9.0 (TID 31). 1700 bytes result sent to driver
2018-02-08 15:59:10,678 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 9.0 (TID 31) in 112 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:10,678 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2018-02-08 15:59:10,679 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 9 (map at ALS.scala:1017) finished in 0.222 s
2018-02-08 15:59:10,679 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:10,679 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:10,680 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 10, ShuffleMapStage 14)
2018-02-08 15:59:10,680 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:10,681 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 10 (MapPartitionsRDD[28] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:59:10,684 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8 stored as values in memory (estimated size 29.1 KB, free 631.2 MB)
2018-02-08 15:59:10,686 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.0 KB, free 631.2 MB)
2018-02-08 15:59:10,687 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_8_piece0 in memory on 192.168.11.26:62887 (size: 13.0 KB, free: 631.7 MB)
2018-02-08 15:59:10,687 INFO[org.apache.spark.SparkContext:54] - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:10,688 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[28] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:10,688 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 10.0 with 10 tasks
2018-02-08 15:59:10,691 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 10.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:59:10,691 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 10.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:59:10,691 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 10.0 (TID 34)
2018-02-08 15:59:10,691 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 10.0 (TID 35)
2018-02-08 15:59:10,695 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:59:10,695 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:59:10,696 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,696 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,696 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:10,696 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:10,743 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 10.0 (TID 35). 2087 bytes result sent to driver
2018-02-08 15:59:10,744 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 10.0 (TID 36, localhost, executor driver, partition 2, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:59:10,746 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 10.0 (TID 35) in 55 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:10,747 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 10.0 (TID 36)
2018-02-08 15:59:10,752 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 10.0 (TID 34). 2087 bytes result sent to driver
2018-02-08 15:59:10,753 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:59:10,753 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,753 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:10,756 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 10.0 (TID 37, localhost, executor driver, partition 3, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:59:10,775 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 10.0 (TID 34) in 86 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:10,780 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 10.0 (TID 37)
2018-02-08 15:59:10,785 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:59:10,786 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,786 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:10,823 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 10.0 (TID 36). 2130 bytes result sent to driver
2018-02-08 15:59:10,825 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 10.0 (TID 38, localhost, executor driver, partition 4, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:59:10,826 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 10.0 (TID 38)
2018-02-08 15:59:10,826 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 10.0 (TID 36) in 83 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:10,829 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:59:10,830 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,830 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:10,853 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 10.0 (TID 37). 2130 bytes result sent to driver
2018-02-08 15:59:10,854 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 10.0 (TID 39, localhost, executor driver, partition 5, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:59:10,854 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 10.0 (TID 39)
2018-02-08 15:59:10,854 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 10.0 (TID 37) in 99 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:10,857 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:59:10,858 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,859 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:10,871 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 10.0 (TID 38). 2130 bytes result sent to driver
2018-02-08 15:59:10,872 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 10.0 (TID 40, localhost, executor driver, partition 6, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:59:10,872 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 10.0 (TID 40)
2018-02-08 15:59:10,872 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 10.0 (TID 38) in 48 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:10,876 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:59:10,878 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,878 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:10,897 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 10.0 (TID 39). 2087 bytes result sent to driver
2018-02-08 15:59:10,899 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 10.0 (TID 41, localhost, executor driver, partition 7, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:59:10,899 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 10.0 (TID 39) in 46 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:10,899 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 10.0 (TID 41)
2018-02-08 15:59:10,902 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:59:10,902 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,903 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:10,910 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 10.0 (TID 40). 2130 bytes result sent to driver
2018-02-08 15:59:10,910 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 10.0 (TID 42, localhost, executor driver, partition 8, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:59:10,911 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 10.0 (TID 40) in 39 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:10,912 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 10.0 (TID 42)
2018-02-08 15:59:10,918 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:59:10,918 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,919 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:10,934 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 10.0 (TID 41). 2087 bytes result sent to driver
2018-02-08 15:59:10,935 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 10.0 (TID 43, localhost, executor driver, partition 9, PROCESS_LOCAL, 4827 bytes)
2018-02-08 15:59:10,935 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 10.0 (TID 43)
2018-02-08 15:59:10,935 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 10.0 (TID 41) in 37 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:10,939 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:59:10,940 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 1 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,940 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:10,946 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 10.0 (TID 42). 2087 bytes result sent to driver
2018-02-08 15:59:10,947 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 10.0 (TID 42) in 37 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:10,964 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 10.0 (TID 43). 2130 bytes result sent to driver
2018-02-08 15:59:10,965 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 10.0 (TID 43) in 30 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:10,965 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 10.0, whose tasks have all completed, from pool 
2018-02-08 15:59:10,965 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 10 (flatMap at ALS.scala:1433) finished in 0.276 s
2018-02-08 15:59:10,965 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:10,965 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:10,965 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 12, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 14)
2018-02-08 15:59:10,965 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:10,966 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 12 (MapPartitionsRDD[37] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:59:10,969 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9 stored as values in memory (estimated size 31.3 KB, free 631.2 MB)
2018-02-08 15:59:10,971 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_9_piece0 stored as bytes in memory (estimated size 13.8 KB, free 631.2 MB)
2018-02-08 15:59:10,973 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_9_piece0 in memory on 192.168.11.26:62887 (size: 13.8 KB, free: 631.6 MB)
2018-02-08 15:59:10,974 INFO[org.apache.spark.SparkContext:54] - Created broadcast 9 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:10,974 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[37] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:10,975 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 12.0 with 10 tasks
2018-02-08 15:59:10,976 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 12.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:10,976 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 12.0 (TID 45, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:10,977 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 12.0 (TID 44)
2018-02-08 15:59:10,977 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 12.0 (TID 45)
2018-02-08 15:59:10,981 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:59:10,982 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:59:10,982 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,982 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:10,981 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:59:10,985 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:59:10,986 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:10,986 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,001 WARN[com.github.fommil.netlib.LAPACK:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
2018-02-08 15:59:11,001 WARN[com.github.fommil.netlib.LAPACK:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
2018-02-08 15:59:11,078 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 12.0 (TID 45). 2087 bytes result sent to driver
2018-02-08 15:59:11,079 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 12.0 (TID 46, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,079 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 12.0 (TID 46)
2018-02-08 15:59:11,081 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 12.0 (TID 44). 2087 bytes result sent to driver
2018-02-08 15:59:11,081 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 12.0 (TID 45) in 105 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:11,082 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 12.0 (TID 47, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,082 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 12.0 (TID 47)
2018-02-08 15:59:11,083 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 12.0 (TID 44) in 108 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:11,083 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:59:11,084 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:59:11,085 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,085 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,085 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:59:11,085 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:59:11,086 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,086 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,121 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 12.0 (TID 46). 2087 bytes result sent to driver
2018-02-08 15:59:11,122 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 12.0 (TID 48, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,122 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 12.0 (TID 48)
2018-02-08 15:59:11,122 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 12.0 (TID 46) in 43 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:11,123 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 12.0 (TID 47). 2087 bytes result sent to driver
2018-02-08 15:59:11,124 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 12.0 (TID 49, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,124 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 12.0 (TID 47) in 42 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:11,125 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 12.0 (TID 49)
2018-02-08 15:59:11,126 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:59:11,127 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:59:11,127 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,127 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,128 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:59:11,128 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:59:11,128 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,128 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,157 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 12.0 (TID 49). 2087 bytes result sent to driver
2018-02-08 15:59:11,157 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 12.0 (TID 50, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,158 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 12.0 (TID 49) in 34 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:11,158 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 12.0 (TID 50)
2018-02-08 15:59:11,161 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:59:11,161 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:59:11,161 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,161 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,179 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 12.0 (TID 48). 2130 bytes result sent to driver
2018-02-08 15:59:11,180 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 12.0 (TID 51, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,181 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 12.0 (TID 51)
2018-02-08 15:59:11,181 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 12.0 (TID 48) in 59 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:11,185 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:59:11,185 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:59:11,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,185 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,226 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 12.0 (TID 50). 2087 bytes result sent to driver
2018-02-08 15:59:11,227 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 12.0 (TID 52, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,227 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 12.0 (TID 50) in 70 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:11,227 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 12.0 (TID 52)
2018-02-08 15:59:11,232 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:59:11,233 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:59:11,233 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,234 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,247 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 12.0 (TID 51). 2087 bytes result sent to driver
2018-02-08 15:59:11,248 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 12.0 (TID 53, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,248 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 12.0 (TID 53)
2018-02-08 15:59:11,248 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 12.0 (TID 51) in 69 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:11,252 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:59:11,252 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:59:11,252 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,253 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,286 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 12.0 (TID 52). 2087 bytes result sent to driver
2018-02-08 15:59:11,287 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 12.0 (TID 52) in 61 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:11,295 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 12.0 (TID 53). 2087 bytes result sent to driver
2018-02-08 15:59:11,295 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 12.0 (TID 53) in 48 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:11,295 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2018-02-08 15:59:11,296 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 12 (flatMap at ALS.scala:1433) finished in 0.321 s
2018-02-08 15:59:11,296 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:11,297 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:11,298 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 13, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 14)
2018-02-08 15:59:11,298 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:11,299 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 13 (MapPartitionsRDD[46] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:59:11,306 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10 stored as values in memory (estimated size 32.3 KB, free 631.2 MB)
2018-02-08 15:59:11,309 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_10_piece0 stored as bytes in memory (estimated size 14.2 KB, free 631.1 MB)
2018-02-08 15:59:11,310 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_10_piece0 in memory on 192.168.11.26:62887 (size: 14.2 KB, free: 631.6 MB)
2018-02-08 15:59:11,314 INFO[org.apache.spark.SparkContext:54] - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:11,316 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[46] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:11,316 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 13.0 with 10 tasks
2018-02-08 15:59:11,317 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 13.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,318 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 13.0 (TID 55, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,318 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 13.0 (TID 54)
2018-02-08 15:59:11,318 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 13.0 (TID 55)
2018-02-08 15:59:11,321 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:59:11,321 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:59:11,322 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,322 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,326 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:59:11,326 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:59:11,326 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,327 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,364 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 13.0 (TID 55). 2087 bytes result sent to driver
2018-02-08 15:59:11,365 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 13.0 (TID 56, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,365 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 13.0 (TID 55) in 47 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:11,367 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 13.0 (TID 56)
2018-02-08 15:59:11,368 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 13.0 (TID 54). 2087 bytes result sent to driver
2018-02-08 15:59:11,368 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 13.0 (TID 57, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,369 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 13.0 (TID 57)
2018-02-08 15:59:11,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 13.0 (TID 54) in 52 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:11,371 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:59:11,371 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:59:11,371 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,371 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,371 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:59:11,372 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:59:11,372 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,372 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,410 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 13.0 (TID 56). 2087 bytes result sent to driver
2018-02-08 15:59:11,412 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 13.0 (TID 58, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,412 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 13.0 (TID 58)
2018-02-08 15:59:11,412 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 13.0 (TID 56) in 47 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:11,415 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:59:11,415 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:59:11,416 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,416 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,435 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 13.0 (TID 57). 2087 bytes result sent to driver
2018-02-08 15:59:11,436 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 13.0 (TID 59, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,437 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 13.0 (TID 57) in 69 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:11,439 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 13.0 (TID 59)
2018-02-08 15:59:11,442 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:59:11,442 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:59:11,443 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,443 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,460 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 13.0 (TID 58). 2087 bytes result sent to driver
2018-02-08 15:59:11,461 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 13.0 (TID 60, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,461 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 13.0 (TID 58) in 50 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:11,461 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 13.0 (TID 60)
2018-02-08 15:59:11,464 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:59:11,465 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:59:11,465 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,465 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,483 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 13.0 (TID 59). 2087 bytes result sent to driver
2018-02-08 15:59:11,484 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 13.0 (TID 61, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,484 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 13.0 (TID 59) in 48 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:11,484 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 13.0 (TID 61)
2018-02-08 15:59:11,489 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:59:11,489 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:59:11,489 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,490 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,504 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 13.0 (TID 60). 2087 bytes result sent to driver
2018-02-08 15:59:11,504 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 13.0 (TID 62, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,504 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 13.0 (TID 60) in 44 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:11,505 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 13.0 (TID 62)
2018-02-08 15:59:11,507 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:59:11,508 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:59:11,508 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,508 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,524 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 13.0 (TID 61). 2087 bytes result sent to driver
2018-02-08 15:59:11,525 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 13.0 (TID 63, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,525 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 13.0 (TID 61) in 42 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:11,526 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 13.0 (TID 63)
2018-02-08 15:59:11,529 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:59:11,530 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:59:11,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,530 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,540 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 13.0 (TID 62). 2087 bytes result sent to driver
2018-02-08 15:59:11,541 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 13.0 (TID 62) in 37 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:11,562 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 13.0 (TID 63). 2087 bytes result sent to driver
2018-02-08 15:59:11,562 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 13.0 (TID 63) in 37 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:11,562 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2018-02-08 15:59:11,563 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 13 (flatMap at ALS.scala:1433) finished in 0.246 s
2018-02-08 15:59:11,563 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:11,563 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:11,563 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18, ShuffleMapStage 14)
2018-02-08 15:59:11,563 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:11,564 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 14 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:59:11,567 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11 stored as values in memory (estimated size 33.2 KB, free 631.1 MB)
2018-02-08 15:59:11,569 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.5 KB, free 631.1 MB)
2018-02-08 15:59:11,569 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_11_piece0 in memory on 192.168.11.26:62887 (size: 14.5 KB, free: 631.6 MB)
2018-02-08 15:59:11,570 INFO[org.apache.spark.SparkContext:54] - Created broadcast 11 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:11,571 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[55] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:11,571 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 14.0 with 10 tasks
2018-02-08 15:59:11,571 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 14.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,572 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 14.0 (TID 65, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,572 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 14.0 (TID 64)
2018-02-08 15:59:11,572 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 14.0 (TID 65)
2018-02-08 15:59:11,574 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:59:11,574 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:59:11,575 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,575 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:59:11,575 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,575 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:59:11,575 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,576 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,635 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 14.0 (TID 65). 2087 bytes result sent to driver
2018-02-08 15:59:11,635 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 14.0 (TID 66, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,636 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 14.0 (TID 65) in 65 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:11,636 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 14.0 (TID 66)
2018-02-08 15:59:11,639 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:59:11,640 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:59:11,640 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,641 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,653 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 14.0 (TID 64). 2087 bytes result sent to driver
2018-02-08 15:59:11,653 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 14.0 (TID 67, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,654 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 14.0 (TID 64) in 83 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:11,654 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 14.0 (TID 67)
2018-02-08 15:59:11,657 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:59:11,657 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:59:11,657 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,658 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,681 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 14.0 (TID 66). 2087 bytes result sent to driver
2018-02-08 15:59:11,682 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 14.0 (TID 68, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,682 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 14.0 (TID 68)
2018-02-08 15:59:11,682 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 14.0 (TID 66) in 47 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:11,685 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:59:11,685 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:59:11,685 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,686 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,702 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 14.0 (TID 67). 2130 bytes result sent to driver
2018-02-08 15:59:11,703 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 14.0 (TID 69, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,703 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 14.0 (TID 67) in 50 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:11,703 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 14.0 (TID 69)
2018-02-08 15:59:11,706 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:59:11,706 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:59:11,707 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,707 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,733 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 14.0 (TID 68). 2087 bytes result sent to driver
2018-02-08 15:59:11,734 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 14.0 (TID 70, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,735 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 14.0 (TID 68) in 54 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:11,735 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 14.0 (TID 70)
2018-02-08 15:59:11,738 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:59:11,738 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:59:11,739 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,739 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,761 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 14.0 (TID 69). 2087 bytes result sent to driver
2018-02-08 15:59:11,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 14.0 (TID 71, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,762 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 14.0 (TID 69) in 59 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:11,762 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 14.0 (TID 71)
2018-02-08 15:59:11,766 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:59:11,766 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:59:11,767 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,767 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,776 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 14.0 (TID 70). 2087 bytes result sent to driver
2018-02-08 15:59:11,777 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 14.0 (TID 72, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,777 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 14.0 (TID 70) in 43 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:11,777 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 14.0 (TID 72)
2018-02-08 15:59:11,780 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:59:11,781 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:59:11,781 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,782 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,799 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 14.0 (TID 71). 2130 bytes result sent to driver
2018-02-08 15:59:11,800 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 14.0 (TID 73, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,800 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 14.0 (TID 73)
2018-02-08 15:59:11,800 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 14.0 (TID 71) in 39 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:11,803 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:59:11,803 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:59:11,804 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,804 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,815 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 14.0 (TID 72). 2087 bytes result sent to driver
2018-02-08 15:59:11,815 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 14.0 (TID 72) in 39 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:11,832 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 14.0 (TID 73). 2087 bytes result sent to driver
2018-02-08 15:59:11,833 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 14.0 (TID 73) in 33 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:11,833 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2018-02-08 15:59:11,833 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 14 (flatMap at ALS.scala:1433) finished in 0.262 s
2018-02-08 15:59:11,833 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:11,833 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:11,833 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 15, ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:59:11,834 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:11,834 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 15 (MapPartitionsRDD[64] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:59:11,837 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12 stored as values in memory (estimated size 34.1 KB, free 631.1 MB)
2018-02-08 15:59:11,839 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.7 KB, free 631.0 MB)
2018-02-08 15:59:11,839 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_12_piece0 in memory on 192.168.11.26:62887 (size: 14.7 KB, free: 631.6 MB)
2018-02-08 15:59:11,840 INFO[org.apache.spark.SparkContext:54] - Created broadcast 12 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:11,840 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[64] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:11,840 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 15.0 with 10 tasks
2018-02-08 15:59:11,841 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 15.0 (TID 74, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,841 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 15.0 (TID 75, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,841 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 15.0 (TID 75)
2018-02-08 15:59:11,841 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 15.0 (TID 74)
2018-02-08 15:59:11,844 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:59:11,844 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:59:11,844 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:59:11,844 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:59:11,844 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,844 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,845 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,845 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,879 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 15.0 (TID 75). 2130 bytes result sent to driver
2018-02-08 15:59:11,880 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 15.0 (TID 76, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,880 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 15.0 (TID 75) in 39 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:11,880 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 15.0 (TID 76)
2018-02-08 15:59:11,883 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:59:11,883 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:59:11,884 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,884 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,888 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 15.0 (TID 74). 2130 bytes result sent to driver
2018-02-08 15:59:11,889 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 15.0 (TID 77, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,891 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 15.0 (TID 74) in 50 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:11,894 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 15.0 (TID 77)
2018-02-08 15:59:11,898 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:59:11,898 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:59:11,899 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,899 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:11,945 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 15.0 (TID 76). 2087 bytes result sent to driver
2018-02-08 15:59:11,946 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 15.0 (TID 78, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,946 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 15.0 (TID 78)
2018-02-08 15:59:11,946 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 15.0 (TID 76) in 66 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:11,951 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:59:11,951 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:59:11,952 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,953 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:11,957 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 15.0 (TID 77). 2087 bytes result sent to driver
2018-02-08 15:59:11,958 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 15.0 (TID 79, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:11,958 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 15.0 (TID 77) in 69 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:11,958 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 15.0 (TID 79)
2018-02-08 15:59:11,961 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:59:11,962 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:59:11,962 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:11,962 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,000 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 15.0 (TID 78). 2087 bytes result sent to driver
2018-02-08 15:59:12,001 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 15.0 (TID 80, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,001 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 15.0 (TID 78) in 56 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:12,001 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 15.0 (TID 80)
2018-02-08 15:59:12,005 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 15.0 (TID 79). 2087 bytes result sent to driver
2018-02-08 15:59:12,005 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:59:12,005 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:59:12,005 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 15.0 (TID 81, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,005 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,006 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 15.0 (TID 81)
2018-02-08 15:59:12,006 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 15.0 (TID 79) in 48 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:12,006 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:12,008 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:59:12,008 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:59:12,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,034 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 15.0 (TID 80). 2087 bytes result sent to driver
2018-02-08 15:59:12,035 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 15.0 (TID 82, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,035 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 15.0 (TID 80) in 34 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:12,035 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 15.0 (TID 82)
2018-02-08 15:59:12,036 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 15.0 (TID 81). 2087 bytes result sent to driver
2018-02-08 15:59:12,037 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 15.0 (TID 83, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,038 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:59:12,039 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:59:12,039 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 15.0 (TID 81) in 34 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:12,039 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,039 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,040 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 15.0 (TID 83)
2018-02-08 15:59:12,043 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:59:12,043 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:59:12,043 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:12,072 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 15.0 (TID 82). 2087 bytes result sent to driver
2018-02-08 15:59:12,074 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 15.0 (TID 82) in 39 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:12,079 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 15.0 (TID 83). 2087 bytes result sent to driver
2018-02-08 15:59:12,079 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 15.0 (TID 83) in 42 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:12,080 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 15.0, whose tasks have all completed, from pool 
2018-02-08 15:59:12,080 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 15 (flatMap at ALS.scala:1433) finished in 0.240 s
2018-02-08 15:59:12,080 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:12,080 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:12,080 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 16, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:59:12,080 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:12,081 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 16 (MapPartitionsRDD[73] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:59:12,084 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13 stored as values in memory (estimated size 35.0 KB, free 631.0 MB)
2018-02-08 15:59:12,087 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_13_piece0 stored as bytes in memory (estimated size 15.0 KB, free 631.0 MB)
2018-02-08 15:59:12,088 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_13_piece0 in memory on 192.168.11.26:62887 (size: 15.0 KB, free: 631.6 MB)
2018-02-08 15:59:12,088 INFO[org.apache.spark.SparkContext:54] - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:12,089 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[73] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:12,089 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 16.0 with 10 tasks
2018-02-08 15:59:12,090 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 16.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,090 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 16.0 (TID 85, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,090 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 16.0 (TID 85)
2018-02-08 15:59:12,090 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 16.0 (TID 84)
2018-02-08 15:59:12,093 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:59:12,093 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:59:12,093 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:59:12,094 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:59:12,095 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,095 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:12,095 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,095 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,130 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 16.0 (TID 84). 2130 bytes result sent to driver
2018-02-08 15:59:12,131 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 16.0 (TID 86, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,131 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 16.0 (TID 84) in 42 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:12,132 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 16.0 (TID 86)
2018-02-08 15:59:12,135 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:59:12,136 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:59:12,136 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,136 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,137 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 16.0 (TID 85). 2130 bytes result sent to driver
2018-02-08 15:59:12,138 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 16.0 (TID 87, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,138 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 16.0 (TID 87)
2018-02-08 15:59:12,138 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 16.0 (TID 85) in 48 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:12,143 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:59:12,143 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:59:12,144 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,144 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,172 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 16.0 (TID 86). 2087 bytes result sent to driver
2018-02-08 15:59:12,173 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 16.0 (TID 88, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,173 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 16.0 (TID 86) in 42 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:12,174 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 16.0 (TID 88)
2018-02-08 15:59:12,175 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 16.0 (TID 87). 2130 bytes result sent to driver
2018-02-08 15:59:12,176 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 16.0 (TID 89, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 16.0 (TID 87) in 39 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:12,177 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 16.0 (TID 89)
2018-02-08 15:59:12,177 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:59:12,177 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:59:12,178 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,178 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,180 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:59:12,180 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:59:12,181 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,181 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,212 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 16.0 (TID 89). 2130 bytes result sent to driver
2018-02-08 15:59:12,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 16.0 (TID 90, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,213 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 16.0 (TID 89) in 37 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:12,213 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 16.0 (TID 90)
2018-02-08 15:59:12,216 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 16.0 (TID 88). 2044 bytes result sent to driver
2018-02-08 15:59:12,216 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:59:12,216 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 16.0 (TID 91, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,216 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:59:12,217 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 16.0 (TID 91)
2018-02-08 15:59:12,217 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 16.0 (TID 88) in 45 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:12,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,217 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,220 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:59:12,220 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:59:12,221 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,221 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,245 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 16.0 (TID 90). 2087 bytes result sent to driver
2018-02-08 15:59:12,245 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 16.0 (TID 92, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,246 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 16.0 (TID 92)
2018-02-08 15:59:12,246 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 16.0 (TID 90) in 34 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:12,247 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 16.0 (TID 91). 2130 bytes result sent to driver
2018-02-08 15:59:12,247 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 16.0 (TID 93, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,247 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 16.0 (TID 91) in 31 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:12,247 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 16.0 (TID 93)
2018-02-08 15:59:12,249 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:59:12,249 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:59:12,249 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,250 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:12,250 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:59:12,250 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:59:12,250 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,250 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,288 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 16.0 (TID 93). 2130 bytes result sent to driver
2018-02-08 15:59:12,289 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 16.0 (TID 93) in 42 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:12,290 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 16.0 (TID 92). 2087 bytes result sent to driver
2018-02-08 15:59:12,291 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 16.0 (TID 92) in 46 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:12,291 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 16.0, whose tasks have all completed, from pool 
2018-02-08 15:59:12,291 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 16 (flatMap at ALS.scala:1433) finished in 0.202 s
2018-02-08 15:59:12,291 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:12,291 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:12,291 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 17, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:59:12,292 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:12,293 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 17 (MapPartitionsRDD[82] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:59:12,295 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14 stored as values in memory (estimated size 35.9 KB, free 631.0 MB)
2018-02-08 15:59:12,301 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_14_piece0 stored as bytes in memory (estimated size 15.2 KB, free 630.9 MB)
2018-02-08 15:59:12,303 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_14_piece0 in memory on 192.168.11.26:62887 (size: 15.2 KB, free: 631.6 MB)
2018-02-08 15:59:12,303 INFO[org.apache.spark.SparkContext:54] - Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:12,304 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[82] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:12,304 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 17.0 with 10 tasks
2018-02-08 15:59:12,305 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 17.0 (TID 94, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,305 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 17.0 (TID 95, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,305 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 17.0 (TID 95)
2018-02-08 15:59:12,305 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 17.0 (TID 94)
2018-02-08 15:59:12,309 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:59:12,309 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:59:12,309 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,310 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:12,310 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:59:12,310 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:59:12,310 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,310 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,345 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 17.0 (TID 94). 2087 bytes result sent to driver
2018-02-08 15:59:12,346 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 17.0 (TID 96, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,346 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 17.0 (TID 94) in 41 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:12,348 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 17.0 (TID 96)
2018-02-08 15:59:12,349 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 17.0 (TID 95). 2087 bytes result sent to driver
2018-02-08 15:59:12,350 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 17.0 (TID 97, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,351 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 17.0 (TID 95) in 46 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:12,354 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:59:12,355 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:59:12,355 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 17.0 (TID 97)
2018-02-08 15:59:12,355 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,355 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,359 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:59:12,360 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:59:12,360 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,360 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,388 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 17.0 (TID 97). 2173 bytes result sent to driver
2018-02-08 15:59:12,388 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 17.0 (TID 98, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,389 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 17.0 (TID 97) in 39 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:12,389 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 17.0 (TID 98)
2018-02-08 15:59:12,390 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 17.0 (TID 96). 2087 bytes result sent to driver
2018-02-08 15:59:12,390 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 17.0 (TID 99, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,390 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 17.0 (TID 99)
2018-02-08 15:59:12,390 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 17.0 (TID 96) in 44 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:12,392 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:59:12,392 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:59:12,393 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,393 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,394 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:59:12,394 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:59:12,394 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,394 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,422 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 17.0 (TID 98). 2087 bytes result sent to driver
2018-02-08 15:59:12,424 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 17.0 (TID 100, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,424 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 17.0 (TID 98) in 36 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:12,425 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 17.0 (TID 100)
2018-02-08 15:59:12,425 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 17.0 (TID 99). 2087 bytes result sent to driver
2018-02-08 15:59:12,426 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 17.0 (TID 101, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,427 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 17.0 (TID 99) in 37 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:12,428 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 17.0 (TID 101)
2018-02-08 15:59:12,429 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:59:12,429 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:59:12,431 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,431 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,434 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:59:12,434 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:59:12,435 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,435 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,459 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 17.0 (TID 100). 2087 bytes result sent to driver
2018-02-08 15:59:12,460 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 17.0 (TID 102, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,460 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 17.0 (TID 102)
2018-02-08 15:59:12,461 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 17.0 (TID 100) in 38 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:12,463 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 17.0 (TID 101). 2087 bytes result sent to driver
2018-02-08 15:59:12,463 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 17.0 (TID 103, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,463 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:59:12,464 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 17.0 (TID 103)
2018-02-08 15:59:12,464 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:59:12,464 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 17.0 (TID 101) in 38 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:12,464 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,464 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,466 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:59:12,466 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:59:12,467 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,467 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,491 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 17.0 (TID 102). 2087 bytes result sent to driver
2018-02-08 15:59:12,492 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 17.0 (TID 102) in 32 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:12,493 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 17.0 (TID 103). 2087 bytes result sent to driver
2018-02-08 15:59:12,493 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 17.0 (TID 103) in 30 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:12,493 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2018-02-08 15:59:12,494 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 17 (flatMap at ALS.scala:1433) finished in 0.188 s
2018-02-08 15:59:12,494 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:12,495 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:12,495 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 20, ResultStage 21, ShuffleMapStage 18)
2018-02-08 15:59:12,495 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:12,495 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 18 (MapPartitionsRDD[91] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:59:12,502 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15 stored as values in memory (estimated size 36.8 KB, free 630.9 MB)
2018-02-08 15:59:12,505 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_15_piece0 stored as bytes in memory (estimated size 15.4 KB, free 630.9 MB)
2018-02-08 15:59:12,505 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_15_piece0 in memory on 192.168.11.26:62887 (size: 15.4 KB, free: 631.6 MB)
2018-02-08 15:59:12,506 INFO[org.apache.spark.SparkContext:54] - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:12,507 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[91] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:12,507 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 18.0 with 10 tasks
2018-02-08 15:59:12,508 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 18.0 (TID 104, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,508 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 18.0 (TID 105, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,509 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 18.0 (TID 104)
2018-02-08 15:59:12,509 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 18.0 (TID 105)
2018-02-08 15:59:12,513 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:59:12,514 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:59:12,515 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,515 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:12,533 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:59:12,533 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:59:12,534 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,534 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,577 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 18.0 (TID 104). 2087 bytes result sent to driver
2018-02-08 15:59:12,579 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 18.0 (TID 106, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,579 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 18.0 (TID 104) in 71 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:12,580 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 18.0 (TID 106)
2018-02-08 15:59:12,583 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:59:12,583 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:59:12,584 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,584 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,594 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 18.0 (TID 105). 2087 bytes result sent to driver
2018-02-08 15:59:12,595 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 18.0 (TID 107, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,596 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 18.0 (TID 105) in 88 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:12,596 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 18.0 (TID 107)
2018-02-08 15:59:12,611 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:59:12,611 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:59:12,613 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,613 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,642 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 18.0 (TID 106). 2087 bytes result sent to driver
2018-02-08 15:59:12,643 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 18.0 (TID 108, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,647 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 18.0 (TID 106) in 70 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:12,647 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 18.0 (TID 108)
2018-02-08 15:59:12,650 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:59:12,651 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:59:12,651 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,651 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,654 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 18.0 (TID 107). 2087 bytes result sent to driver
2018-02-08 15:59:12,656 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 18.0 (TID 109, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,657 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 18.0 (TID 107) in 62 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:12,663 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 18.0 (TID 109)
2018-02-08 15:59:12,666 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:59:12,666 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:59:12,666 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,667 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:12,686 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 18.0 (TID 108). 2087 bytes result sent to driver
2018-02-08 15:59:12,686 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 18.0 (TID 110, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,687 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 18.0 (TID 110)
2018-02-08 15:59:12,687 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 18.0 (TID 108) in 44 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:12,689 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:59:12,690 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:59:12,690 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,690 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,714 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 18.0 (TID 109). 2087 bytes result sent to driver
2018-02-08 15:59:12,715 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 18.0 (TID 111, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,715 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 18.0 (TID 109) in 60 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:12,715 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 18.0 (TID 111)
2018-02-08 15:59:12,721 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:59:12,721 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:59:12,722 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,722 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,746 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 18.0 (TID 110). 2087 bytes result sent to driver
2018-02-08 15:59:12,747 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 18.0 (TID 112, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,747 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 18.0 (TID 110) in 61 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:12,748 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 18.0 (TID 112)
2018-02-08 15:59:12,753 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:59:12,753 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:59:12,753 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,753 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,760 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 18.0 (TID 111). 2130 bytes result sent to driver
2018-02-08 15:59:12,760 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 18.0 (TID 113, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 18.0 (TID 111) in 47 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:12,761 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 18.0 (TID 113)
2018-02-08 15:59:12,763 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:59:12,764 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:59:12,764 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,764 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,801 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 18.0 (TID 113). 2087 bytes result sent to driver
2018-02-08 15:59:12,807 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 18.0 (TID 112). 2087 bytes result sent to driver
2018-02-08 15:59:12,807 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 18.0 (TID 112) in 60 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:12,807 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 18.0 (TID 113) in 47 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:12,807 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2018-02-08 15:59:12,808 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 18 (flatMap at ALS.scala:1433) finished in 0.300 s
2018-02-08 15:59:12,808 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:12,808 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:12,808 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 19, ShuffleMapStage 20, ResultStage 21)
2018-02-08 15:59:12,808 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:12,809 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 19 (MapPartitionsRDD[100] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:59:12,812 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16 stored as values in memory (estimated size 37.8 KB, free 630.9 MB)
2018-02-08 15:59:12,817 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_16_piece0 stored as bytes in memory (estimated size 15.6 KB, free 630.8 MB)
2018-02-08 15:59:12,818 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_16_piece0 in memory on 192.168.11.26:62887 (size: 15.6 KB, free: 631.5 MB)
2018-02-08 15:59:12,819 INFO[org.apache.spark.SparkContext:54] - Created broadcast 16 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:12,820 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[100] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:12,820 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 19.0 with 10 tasks
2018-02-08 15:59:12,821 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 19.0 (TID 114, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,821 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 19.0 (TID 115, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,828 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 19.0 (TID 114)
2018-02-08 15:59:12,828 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 19.0 (TID 115)
2018-02-08 15:59:12,832 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_0 locally
2018-02-08 15:59:12,833 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_1 locally
2018-02-08 15:59:12,833 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:59:12,833 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:59:12,833 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,833 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,833 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,833 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,860 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 19.0 (TID 115). 2087 bytes result sent to driver
2018-02-08 15:59:12,860 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 19.0 (TID 116, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,861 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 19.0 (TID 115) in 40 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:12,861 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 19.0 (TID 116)
2018-02-08 15:59:12,862 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 19.0 (TID 114). 2087 bytes result sent to driver
2018-02-08 15:59:12,863 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 19.0 (TID 117, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,863 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 19.0 (TID 114) in 42 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:12,863 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 19.0 (TID 117)
2018-02-08 15:59:12,864 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_2 locally
2018-02-08 15:59:12,865 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:59:12,865 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,866 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:12,866 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_3 locally
2018-02-08 15:59:12,866 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:59:12,867 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,867 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:12,893 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 19.0 (TID 116). 2087 bytes result sent to driver
2018-02-08 15:59:12,893 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 19.0 (TID 118, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,894 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 19.0 (TID 116) in 34 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:12,894 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 19.0 (TID 118)
2018-02-08 15:59:12,898 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_4 locally
2018-02-08 15:59:12,898 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:59:12,898 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,898 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,909 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 19.0 (TID 117). 2087 bytes result sent to driver
2018-02-08 15:59:12,909 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 19.0 (TID 119, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,909 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 19.0 (TID 119)
2018-02-08 15:59:12,909 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 19.0 (TID 117) in 46 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:12,912 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_5 locally
2018-02-08 15:59:12,912 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:59:12,913 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,913 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:12,946 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 19.0 (TID 118). 2087 bytes result sent to driver
2018-02-08 15:59:12,953 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 19.0 (TID 120, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,953 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 19.0 (TID 118) in 60 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:12,955 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 19.0 (TID 120)
2018-02-08 15:59:12,961 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 19.0 (TID 119). 2087 bytes result sent to driver
2018-02-08 15:59:12,961 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_6 locally
2018-02-08 15:59:12,961 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:59:12,962 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 19.0 (TID 121, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:12,962 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,962 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 19.0 (TID 121)
2018-02-08 15:59:12,962 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 19.0 (TID 119) in 53 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:12,962 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:12,965 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_7 locally
2018-02-08 15:59:12,965 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:59:12,965 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:12,966 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:12,999 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 19.0 (TID 120). 2087 bytes result sent to driver
2018-02-08 15:59:13,000 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 19.0 (TID 122, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,000 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 19.0 (TID 120) in 53 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:13,000 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 19.0 (TID 122)
2018-02-08 15:59:13,002 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 19.0 (TID 121). 2087 bytes result sent to driver
2018-02-08 15:59:13,003 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 19.0 (TID 123, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,004 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 19.0 (TID 123)
2018-02-08 15:59:13,004 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 19.0 (TID 121) in 43 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:13,005 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_8 locally
2018-02-08 15:59:13,006 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:59:13,008 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,008 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:13,008 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_17_9 locally
2018-02-08 15:59:13,008 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:59:13,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,037 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 19.0 (TID 123). 2087 bytes result sent to driver
2018-02-08 15:59:13,038 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 19.0 (TID 123) in 36 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:13,042 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 19.0 (TID 122). 2087 bytes result sent to driver
2018-02-08 15:59:13,042 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 19.0 (TID 122) in 43 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:13,042 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 19.0, whose tasks have all completed, from pool 
2018-02-08 15:59:13,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 19 (flatMap at ALS.scala:1433) finished in 0.223 s
2018-02-08 15:59:13,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:13,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:13,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ShuffleMapStage 20, ResultStage 21)
2018-02-08 15:59:13,043 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:13,044 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 20 (MapPartitionsRDD[109] at flatMap at ALS.scala:1433), which has no missing parents
2018-02-08 15:59:13,047 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17 stored as values in memory (estimated size 38.7 KB, free 630.8 MB)
2018-02-08 15:59:13,049 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_17_piece0 stored as bytes in memory (estimated size 15.9 KB, free 630.8 MB)
2018-02-08 15:59:13,050 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_17_piece0 in memory on 192.168.11.26:62887 (size: 15.9 KB, free: 631.5 MB)
2018-02-08 15:59:13,050 INFO[org.apache.spark.SparkContext:54] - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:13,051 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[109] at flatMap at ALS.scala:1433) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:13,051 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 20.0 with 10 tasks
2018-02-08 15:59:13,051 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 20.0 (TID 124, localhost, executor driver, partition 0, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,052 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 20.0 (TID 125, localhost, executor driver, partition 1, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,052 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 20.0 (TID 124)
2018-02-08 15:59:13,052 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 20.0 (TID 125)
2018-02-08 15:59:13,055 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_0 locally
2018-02-08 15:59:13,055 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_1 locally
2018-02-08 15:59:13,056 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:59:13,056 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:59:13,056 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,056 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,056 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,056 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,080 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 20.0 (TID 124). 2087 bytes result sent to driver
2018-02-08 15:59:13,080 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 20.0 (TID 126, localhost, executor driver, partition 2, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,081 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 20.0 (TID 124) in 30 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:13,081 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 20.0 (TID 126)
2018-02-08 15:59:13,083 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 20.0 (TID 125). 2087 bytes result sent to driver
2018-02-08 15:59:13,083 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 20.0 (TID 127, localhost, executor driver, partition 3, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,083 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 20.0 (TID 125) in 31 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:13,084 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 20.0 (TID 127)
2018-02-08 15:59:13,084 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_2 locally
2018-02-08 15:59:13,084 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:59:13,085 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,085 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,087 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_3 locally
2018-02-08 15:59:13,087 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:59:13,087 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,087 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,111 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 20.0 (TID 126). 2087 bytes result sent to driver
2018-02-08 15:59:13,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 20.0 (TID 128, localhost, executor driver, partition 4, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,114 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 20.0 (TID 128)
2018-02-08 15:59:13,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 20.0 (TID 126) in 34 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:13,117 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_4 locally
2018-02-08 15:59:13,118 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:59:13,118 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,118 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,119 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 20.0 (TID 127). 2087 bytes result sent to driver
2018-02-08 15:59:13,119 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 20.0 (TID 129, localhost, executor driver, partition 5, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,120 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 20.0 (TID 127) in 37 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:13,120 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 20.0 (TID 129)
2018-02-08 15:59:13,123 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_5 locally
2018-02-08 15:59:13,123 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:59:13,132 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,132 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 8 ms
2018-02-08 15:59:13,139 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_13_piece0 on 192.168.11.26:62887 in memory (size: 15.0 KB, free: 631.5 MB)
2018-02-08 15:59:13,149 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_9_piece0 on 192.168.11.26:62887 in memory (size: 13.8 KB, free: 631.6 MB)
2018-02-08 15:59:13,167 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_11_piece0 on 192.168.11.26:62887 in memory (size: 14.5 KB, free: 631.6 MB)
2018-02-08 15:59:13,169 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_12_piece0 on 192.168.11.26:62887 in memory (size: 14.7 KB, free: 631.6 MB)
2018-02-08 15:59:13,170 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_15_piece0 on 192.168.11.26:62887 in memory (size: 15.4 KB, free: 631.6 MB)
2018-02-08 15:59:13,170 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_14_piece0 on 192.168.11.26:62887 in memory (size: 15.2 KB, free: 631.6 MB)
2018-02-08 15:59:13,172 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_8_piece0 on 192.168.11.26:62887 in memory (size: 13.0 KB, free: 631.6 MB)
2018-02-08 15:59:13,173 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_16_piece0 on 192.168.11.26:62887 in memory (size: 15.6 KB, free: 631.6 MB)
2018-02-08 15:59:13,174 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_10_piece0 on 192.168.11.26:62887 in memory (size: 14.2 KB, free: 631.7 MB)
2018-02-08 15:59:13,176 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_7_piece0 on 192.168.11.26:62887 in memory (size: 12.7 KB, free: 631.7 MB)
2018-02-08 15:59:13,185 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 20.0 (TID 129). 2130 bytes result sent to driver
2018-02-08 15:59:13,185 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 20.0 (TID 130, localhost, executor driver, partition 6, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,185 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 20.0 (TID 130)
2018-02-08 15:59:13,185 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 20.0 (TID 129) in 66 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:13,189 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 20.0 (TID 128). 2130 bytes result sent to driver
2018-02-08 15:59:13,189 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 20.0 (TID 131, localhost, executor driver, partition 7, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,190 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_6 locally
2018-02-08 15:59:13,190 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 20.0 (TID 131)
2018-02-08 15:59:13,190 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 20.0 (TID 128) in 76 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:13,190 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:59:13,190 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,191 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:13,192 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_7 locally
2018-02-08 15:59:13,193 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:59:13,193 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,193 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,224 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 20.0 (TID 131). 2087 bytes result sent to driver
2018-02-08 15:59:13,224 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 20.0 (TID 132, localhost, executor driver, partition 8, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,225 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 20.0 (TID 131) in 36 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:13,226 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 20.0 (TID 130). 2130 bytes result sent to driver
2018-02-08 15:59:13,226 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 20.0 (TID 132)
2018-02-08 15:59:13,228 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 20.0 (TID 133, localhost, executor driver, partition 9, PROCESS_LOCAL, 4900 bytes)
2018-02-08 15:59:13,228 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 20.0 (TID 133)
2018-02-08 15:59:13,228 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 20.0 (TID 130) in 43 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:13,230 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_8 locally
2018-02-08 15:59:13,230 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:59:13,231 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,231 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,231 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_22_9 locally
2018-02-08 15:59:13,231 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:59:13,233 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,233 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,267 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 20.0 (TID 133). 2130 bytes result sent to driver
2018-02-08 15:59:13,267 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 20.0 (TID 133) in 40 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:13,276 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 20.0 (TID 132). 2087 bytes result sent to driver
2018-02-08 15:59:13,276 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 20.0 (TID 132) in 52 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:13,276 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2018-02-08 15:59:13,277 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 20 (flatMap at ALS.scala:1433) finished in 0.226 s
2018-02-08 15:59:13,277 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:13,277 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:13,277 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 21)
2018-02-08 15:59:13,277 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:13,278 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 21 (userFactors MapPartitionsRDD[119] at mapPartitions at ALS.scala:924), which has no missing parents
2018-02-08 15:59:13,281 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18 stored as values in memory (estimated size 39.8 KB, free 631.2 MB)
2018-02-08 15:59:13,283 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_18_piece0 stored as bytes in memory (estimated size 16.1 KB, free 631.2 MB)
2018-02-08 15:59:13,284 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_18_piece0 in memory on 192.168.11.26:62887 (size: 16.1 KB, free: 631.6 MB)
2018-02-08 15:59:13,284 INFO[org.apache.spark.SparkContext:54] - Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:13,284 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 21 (userFactors MapPartitionsRDD[119] at mapPartitions at ALS.scala:924) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:13,285 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 21.0 with 10 tasks
2018-02-08 15:59:13,285 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 21.0 (TID 134, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,285 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 21.0 (TID 135, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,286 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 21.0 (TID 135)
2018-02-08 15:59:13,286 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 21.0 (TID 134)
2018-02-08 15:59:13,288 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:59:13,288 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:59:13,289 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_0 locally
2018-02-08 15:59:13,289 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_1 locally
2018-02-08 15:59:13,289 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,289 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,289 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,289 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,293 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_0 stored as values in memory (estimated size 320.0 B, free 631.2 MB)
2018-02-08 15:59:13,293 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_1 stored as values in memory (estimated size 320.0 B, free 631.2 MB)
2018-02-08 15:59:13,293 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_0 in memory on 192.168.11.26:62887 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:59:13,293 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_1 in memory on 192.168.11.26:62887 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:59:13,295 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 21.0 (TID 135). 2566 bytes result sent to driver
2018-02-08 15:59:13,295 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 21.0 (TID 134). 2566 bytes result sent to driver
2018-02-08 15:59:13,295 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 21.0 (TID 136, localhost, executor driver, partition 2, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,295 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 21.0 (TID 136)
2018-02-08 15:59:13,295 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 21.0 (TID 137, localhost, executor driver, partition 3, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,296 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 21.0 (TID 137)
2018-02-08 15:59:13,296 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 21.0 (TID 134) in 11 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:13,296 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 21.0 (TID 135) in 11 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:13,298 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:59:13,298 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:59:13,298 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_2 locally
2018-02-08 15:59:13,299 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_3 locally
2018-02-08 15:59:13,299 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,299 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,299 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,299 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,302 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_2 stored as values in memory (estimated size 320.0 B, free 631.2 MB)
2018-02-08 15:59:13,303 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_2 in memory on 192.168.11.26:62887 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:59:13,303 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_3 stored as values in memory (estimated size 320.0 B, free 631.2 MB)
2018-02-08 15:59:13,303 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_3 in memory on 192.168.11.26:62887 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:59:13,303 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 21.0 (TID 136). 2609 bytes result sent to driver
2018-02-08 15:59:13,304 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 21.0 (TID 137). 2566 bytes result sent to driver
2018-02-08 15:59:13,304 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 21.0 (TID 138, localhost, executor driver, partition 4, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,304 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 21.0 (TID 138)
2018-02-08 15:59:13,304 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 21.0 (TID 139, localhost, executor driver, partition 5, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,305 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 21.0 (TID 137) in 10 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:13,305 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 21.0 (TID 136) in 10 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:13,305 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 21.0 (TID 139)
2018-02-08 15:59:13,308 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:59:13,308 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:59:13,308 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_4 locally
2018-02-08 15:59:13,308 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_5 locally
2018-02-08 15:59:13,308 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,308 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,309 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:13,309 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:13,313 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_5 stored as values in memory (estimated size 320.0 B, free 631.2 MB)
2018-02-08 15:59:13,313 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_4 stored as values in memory (estimated size 320.0 B, free 631.2 MB)
2018-02-08 15:59:13,313 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_5 in memory on 192.168.11.26:62887 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:59:13,313 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_4 in memory on 192.168.11.26:62887 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:59:13,314 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 21.0 (TID 139). 2609 bytes result sent to driver
2018-02-08 15:59:13,314 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 21.0 (TID 138). 2609 bytes result sent to driver
2018-02-08 15:59:13,315 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 21.0 (TID 140, localhost, executor driver, partition 6, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,315 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 21.0 (TID 140)
2018-02-08 15:59:13,315 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 21.0 (TID 141, localhost, executor driver, partition 7, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,316 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 21.0 (TID 139) in 12 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:13,316 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 21.0 (TID 141)
2018-02-08 15:59:13,318 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 21.0 (TID 138) in 14 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:13,318 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:59:13,319 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_6 locally
2018-02-08 15:59:13,319 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:59:13,319 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_7 locally
2018-02-08 15:59:13,319 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,320 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:13,319 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,320 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:13,325 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_6 stored as values in memory (estimated size 320.0 B, free 631.2 MB)
2018-02-08 15:59:13,325 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_7 stored as values in memory (estimated size 320.0 B, free 631.2 MB)
2018-02-08 15:59:13,325 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_6 in memory on 192.168.11.26:62887 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:59:13,325 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_7 in memory on 192.168.11.26:62887 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:59:13,328 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 21.0 (TID 140). 2566 bytes result sent to driver
2018-02-08 15:59:13,328 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 21.0 (TID 141). 2566 bytes result sent to driver
2018-02-08 15:59:13,328 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 21.0 (TID 142, localhost, executor driver, partition 8, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,328 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 21.0 (TID 142)
2018-02-08 15:59:13,330 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 21.0 (TID 143, localhost, executor driver, partition 9, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,330 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 21.0 (TID 140) in 16 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:13,331 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 21.0 (TID 141) in 16 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:13,331 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 21.0 (TID 143)
2018-02-08 15:59:13,332 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:59:13,332 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_8 locally
2018-02-08 15:59:13,333 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,333 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,333 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:59:13,333 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_16_9 locally
2018-02-08 15:59:13,334 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,334 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:13,336 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_9 stored as values in memory (estimated size 320.0 B, free 631.2 MB)
2018-02-08 15:59:13,336 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_119_8 stored as values in memory (estimated size 320.0 B, free 631.2 MB)
2018-02-08 15:59:13,337 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_9 in memory on 192.168.11.26:62887 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:59:13,337 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_119_8 in memory on 192.168.11.26:62887 (size: 320.0 B, free: 631.6 MB)
2018-02-08 15:59:13,337 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 21.0 (TID 143). 2566 bytes result sent to driver
2018-02-08 15:59:13,337 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 21.0 (TID 142). 2566 bytes result sent to driver
2018-02-08 15:59:13,338 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 21.0 (TID 143) in 10 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:13,338 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 21.0 (TID 142) in 10 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:13,338 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 21.0, whose tasks have all completed, from pool 
2018-02-08 15:59:13,338 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 21 (count at ALS.scala:944) finished in 0.053 s
2018-02-08 15:59:13,338 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: count at ALS.scala:944, took 2.908267 s
2018-02-08 15:59:13,345 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 105 from persistence list
2018-02-08 15:59:13,348 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 105
2018-02-08 15:59:13,351 INFO[org.apache.spark.SparkContext:54] - Starting job: count at ALS.scala:946
2018-02-08 15:59:13,352 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:59:13,352 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 155 bytes
2018-02-08 15:59:13,352 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 13 is 197 bytes
2018-02-08 15:59:13,353 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 12 is 161 bytes
2018-02-08 15:59:13,353 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 2 is 156 bytes
2018-02-08 15:59:13,354 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 11 is 238 bytes
2018-02-08 15:59:13,354 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 10 is 161 bytes
2018-02-08 15:59:13,354 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 9 is 240 bytes
2018-02-08 15:59:13,355 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 8 is 161 bytes
2018-02-08 15:59:13,356 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 7 is 238 bytes
2018-02-08 15:59:13,356 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 6 is 161 bytes
2018-02-08 15:59:13,357 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 5 is 240 bytes
2018-02-08 15:59:13,357 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 4 is 161 bytes
2018-02-08 15:59:13,359 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 4 (count at ALS.scala:946) with 10 output partitions
2018-02-08 15:59:13,359 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 35 (count at ALS.scala:946)
2018-02-08 15:59:13,359 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 34, ShuffleMapStage 26)
2018-02-08 15:59:13,359 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:59:13,360 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 35 (itemFactors MapPartitionsRDD[124] at mapPartitions at ALS.scala:936), which has no missing parents
2018-02-08 15:59:13,363 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19 stored as values in memory (estimated size 38.9 KB, free 631.2 MB)
2018-02-08 15:59:13,366 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_19_piece0 stored as bytes in memory (estimated size 16.0 KB, free 631.1 MB)
2018-02-08 15:59:13,367 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_19_piece0 in memory on 192.168.11.26:62887 (size: 16.0 KB, free: 631.6 MB)
2018-02-08 15:59:13,367 INFO[org.apache.spark.SparkContext:54] - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:13,368 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 10 missing tasks from ResultStage 35 (itemFactors MapPartitionsRDD[124] at mapPartitions at ALS.scala:936) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
2018-02-08 15:59:13,368 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 35.0 with 10 tasks
2018-02-08 15:59:13,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 35.0 (TID 144, localhost, executor driver, partition 0, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 35.0 (TID 145, localhost, executor driver, partition 1, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,369 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 35.0 (TID 145)
2018-02-08 15:59:13,369 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 35.0 (TID 144)
2018-02-08 15:59:13,373 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:59:13,373 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:59:13,373 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_1 locally
2018-02-08 15:59:13,373 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_0 locally
2018-02-08 15:59:13,375 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,375 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,375 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,376 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:13,379 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_1 stored as values in memory (estimated size 1016.0 B, free 631.1 MB)
2018-02-08 15:59:13,379 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_0 stored as values in memory (estimated size 1016.0 B, free 631.1 MB)
2018-02-08 15:59:13,379 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_1 in memory on 192.168.11.26:62887 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:59:13,380 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_0 in memory on 192.168.11.26:62887 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:59:13,380 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 35.0 (TID 145). 2609 bytes result sent to driver
2018-02-08 15:59:13,380 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 35.0 (TID 146, localhost, executor driver, partition 2, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,381 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 35.0 (TID 144). 2609 bytes result sent to driver
2018-02-08 15:59:13,381 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 35.0 (TID 146)
2018-02-08 15:59:13,381 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 35.0 (TID 145) in 12 ms on localhost (executor driver) (1/10)
2018-02-08 15:59:13,381 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 35.0 (TID 147, localhost, executor driver, partition 3, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,382 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 35.0 (TID 144) in 13 ms on localhost (executor driver) (2/10)
2018-02-08 15:59:13,382 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 35.0 (TID 147)
2018-02-08 15:59:13,383 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:59:13,384 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_2 locally
2018-02-08 15:59:13,384 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,384 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,385 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:59:13,385 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_3 locally
2018-02-08 15:59:13,386 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,386 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,388 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_2 stored as values in memory (estimated size 1016.0 B, free 631.1 MB)
2018-02-08 15:59:13,389 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_2 in memory on 192.168.11.26:62887 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:59:13,389 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_3 stored as values in memory (estimated size 1016.0 B, free 631.1 MB)
2018-02-08 15:59:13,390 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 35.0 (TID 146). 2652 bytes result sent to driver
2018-02-08 15:59:13,393 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_3 in memory on 192.168.11.26:62887 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:59:13,393 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 35.0 (TID 148, localhost, executor driver, partition 4, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,394 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 35.0 (TID 147). 2609 bytes result sent to driver
2018-02-08 15:59:13,394 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 35.0 (TID 146) in 14 ms on localhost (executor driver) (3/10)
2018-02-08 15:59:13,394 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 35.0 (TID 149, localhost, executor driver, partition 5, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,394 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 35.0 (TID 148)
2018-02-08 15:59:13,396 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 35.0 (TID 147) in 15 ms on localhost (executor driver) (4/10)
2018-02-08 15:59:13,396 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 35.0 (TID 149)
2018-02-08 15:59:13,399 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:59:13,399 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_4 locally
2018-02-08 15:59:13,400 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,400 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,401 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:59:13,401 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_5 locally
2018-02-08 15:59:13,402 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,402 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,404 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_4 stored as values in memory (estimated size 1016.0 B, free 631.1 MB)
2018-02-08 15:59:13,404 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_4 in memory on 192.168.11.26:62887 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:59:13,408 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_5 stored as values in memory (estimated size 1016.0 B, free 631.1 MB)
2018-02-08 15:59:13,408 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 35.0 (TID 148). 2566 bytes result sent to driver
2018-02-08 15:59:13,408 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_5 in memory on 192.168.11.26:62887 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:59:13,409 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 35.0 (TID 150, localhost, executor driver, partition 6, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,410 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 35.0 (TID 148) in 17 ms on localhost (executor driver) (5/10)
2018-02-08 15:59:13,410 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 35.0 (TID 149). 2609 bytes result sent to driver
2018-02-08 15:59:13,410 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 35.0 (TID 150)
2018-02-08 15:59:13,411 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 35.0 (TID 151, localhost, executor driver, partition 7, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,411 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 35.0 (TID 149) in 17 ms on localhost (executor driver) (6/10)
2018-02-08 15:59:13,413 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 35.0 (TID 151)
2018-02-08 15:59:13,414 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:59:13,414 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_6 locally
2018-02-08 15:59:13,414 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,415 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:13,416 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:59:13,416 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_7 locally
2018-02-08 15:59:13,416 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,417 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:13,419 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_6 stored as values in memory (estimated size 1016.0 B, free 631.1 MB)
2018-02-08 15:59:13,419 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_6 in memory on 192.168.11.26:62887 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:59:13,420 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_7 stored as values in memory (estimated size 1016.0 B, free 631.1 MB)
2018-02-08 15:59:13,420 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_7 in memory on 192.168.11.26:62887 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:59:13,425 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 35.0 (TID 150). 2609 bytes result sent to driver
2018-02-08 15:59:13,426 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 35.0 (TID 152, localhost, executor driver, partition 8, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,426 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 35.0 (TID 150) in 17 ms on localhost (executor driver) (7/10)
2018-02-08 15:59:13,426 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 35.0 (TID 152)
2018-02-08 15:59:13,427 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 35.0 (TID 151). 2566 bytes result sent to driver
2018-02-08 15:59:13,428 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 35.0 (TID 153, localhost, executor driver, partition 9, PROCESS_LOCAL, 4911 bytes)
2018-02-08 15:59:13,428 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 35.0 (TID 151) in 17 ms on localhost (executor driver) (8/10)
2018-02-08 15:59:13,428 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 35.0 (TID 153)
2018-02-08 15:59:13,431 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:59:13,431 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_8 locally
2018-02-08 15:59:13,431 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:59:13,431 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_21_9 locally
2018-02-08 15:59:13,431 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,432 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:13,432 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 10 blocks
2018-02-08 15:59:13,432 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:13,435 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_9 stored as values in memory (estimated size 1016.0 B, free 631.1 MB)
2018-02-08 15:59:13,436 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_124_8 stored as values in memory (estimated size 1016.0 B, free 631.1 MB)
2018-02-08 15:59:13,437 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_9 in memory on 192.168.11.26:62887 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:59:13,437 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_124_8 in memory on 192.168.11.26:62887 (size: 1016.0 B, free: 631.6 MB)
2018-02-08 15:59:13,438 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 35.0 (TID 153). 2609 bytes result sent to driver
2018-02-08 15:59:13,438 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 35.0 (TID 152). 2609 bytes result sent to driver
2018-02-08 15:59:13,440 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 35.0 (TID 153) in 12 ms on localhost (executor driver) (9/10)
2018-02-08 15:59:13,440 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 35.0 (TID 152) in 14 ms on localhost (executor driver) (10/10)
2018-02-08 15:59:13,440 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2018-02-08 15:59:13,440 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 35 (count at ALS.scala:946) finished in 0.072 s
2018-02-08 15:59:13,441 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 4 finished: count at ALS.scala:946, took 0.090129 s
2018-02-08 15:59:13,442 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 16 from persistence list
2018-02-08 15:59:13,443 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 16
2018-02-08 15:59:13,444 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 17 from persistence list
2018-02-08 15:59:13,446 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 17
2018-02-08 15:59:13,448 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 21 from persistence list
2018-02-08 15:59:13,449 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 21
2018-02-08 15:59:13,451 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 22 from persistence list
2018-02-08 15:59:13,451 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 22
2018-02-08 15:59:13,452 INFO[org.apache.spark.rdd.MapPartitionsRDD:54] - Removing RDD 13 from persistence list
2018-02-08 15:59:13,453 INFO[org.apache.spark.storage.BlockManager:54] - Removing RDD 13
2018-02-08 15:59:13,595 INFO[org.apache.spark.ml.util.Instrumentation:54] - ALS-als_35f73d3adf4b-981876983-1: training finished
2018-02-08 15:59:14,301 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 30.20577 ms
2018-02-08 15:59:14,333 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 27.295688 ms
2018-02-08 15:59:14,380 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 30.222409 ms
2018-02-08 15:59:14,410 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:42
2018-02-08 15:59:14,414 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 3 is 240 bytes
2018-02-08 15:59:14,414 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 141 (show at MachineLeaningFiltering.java:42)
2018-02-08 15:59:14,415 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 5 (show at MachineLeaningFiltering.java:42) with 1 output partitions
2018-02-08 15:59:14,415 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 51 (show at MachineLeaningFiltering.java:42)
2018-02-08 15:59:14,415 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 50)
2018-02-08 15:59:14,415 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 50)
2018-02-08 15:59:14,423 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 50 (MapPartitionsRDD[141] at show at MachineLeaningFiltering.java:42), which has no missing parents
2018-02-08 15:59:14,486 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20 stored as values in memory (estimated size 91.3 KB, free 631.1 MB)
2018-02-08 15:59:14,488 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_20_piece0 stored as bytes in memory (estimated size 32.6 KB, free 631.1 MB)
2018-02-08 15:59:14,488 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_20_piece0 in memory on 192.168.11.26:62887 (size: 32.6 KB, free: 631.7 MB)
2018-02-08 15:59:14,488 INFO[org.apache.spark.SparkContext:54] - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:14,490 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 100 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[141] at show at MachineLeaningFiltering.java:42) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-02-08 15:59:14,490 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 50.0 with 100 tasks
2018-02-08 15:59:14,493 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 50.0 (TID 154, localhost, executor driver, partition 0, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:14,493 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 50.0 (TID 155, localhost, executor driver, partition 1, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:14,494 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 50.0 (TID 154)
2018-02-08 15:59:14,494 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 50.0 (TID 155)
2018-02-08 15:59:14,538 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:14,539 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:14,565 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.893764 ms
2018-02-08 15:59:14,571 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:14,571 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:14,596 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 13.295044 ms
2018-02-08 15:59:14,633 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 28.162569 ms
2018-02-08 15:59:14,652 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.591365 ms
2018-02-08 15:59:14,662 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.268163 ms
2018-02-08 15:59:14,671 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 5.958402 ms
2018-02-08 15:59:14,700 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 4.913282 ms
2018-02-08 15:59:14,713 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 5.984002 ms
2018-02-08 15:59:14,723 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.949762 ms
2018-02-08 15:59:14,733 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 5.432642 ms
2018-02-08 15:59:14,745 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.158082 ms
2018-02-08 15:59:14,773 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 20.446087 ms
2018-02-08 15:59:14,836 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 32.62625 ms
2018-02-08 15:59:15,021 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 50.0 (TID 154). 2637 bytes result sent to driver
2018-02-08 15:59:15,022 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 50.0 (TID 156, localhost, executor driver, partition 2, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,022 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 50.0 (TID 154) in 531 ms on localhost (executor driver) (1/100)
2018-02-08 15:59:15,023 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 50.0 (TID 156)
2018-02-08 15:59:15,028 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:15,031 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:15,042 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 50.0 (TID 155). 2637 bytes result sent to driver
2018-02-08 15:59:15,044 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 50.0 (TID 157, localhost, executor driver, partition 3, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,044 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 50.0 (TID 155) in 551 ms on localhost (executor driver) (2/100)
2018-02-08 15:59:15,045 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 50.0 (TID 157)
2018-02-08 15:59:15,050 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:15,051 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:15,092 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 50.0 (TID 157). 2637 bytes result sent to driver
2018-02-08 15:59:15,094 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 50.0 (TID 158, localhost, executor driver, partition 4, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,094 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 50.0 (TID 157) in 51 ms on localhost (executor driver) (3/100)
2018-02-08 15:59:15,095 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 50.0 (TID 158)
2018-02-08 15:59:15,099 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:15,101 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:15,111 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 50.0 (TID 156). 2594 bytes result sent to driver
2018-02-08 15:59:15,112 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 50.0 (TID 159, localhost, executor driver, partition 5, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,113 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 50.0 (TID 156) in 91 ms on localhost (executor driver) (4/100)
2018-02-08 15:59:15,116 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 50.0 (TID 159)
2018-02-08 15:59:15,121 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:15,122 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:15,160 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 50.0 (TID 158). 2594 bytes result sent to driver
2018-02-08 15:59:15,161 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 50.0 (TID 160, localhost, executor driver, partition 6, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,161 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 50.0 (TID 158) in 67 ms on localhost (executor driver) (5/100)
2018-02-08 15:59:15,161 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 50.0 (TID 160)
2018-02-08 15:59:15,166 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:15,168 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:15,202 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 50.0 (TID 159). 2594 bytes result sent to driver
2018-02-08 15:59:15,203 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 50.0 (TID 161, localhost, executor driver, partition 7, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,203 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 50.0 (TID 159) in 91 ms on localhost (executor driver) (6/100)
2018-02-08 15:59:15,203 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 50.0 (TID 161)
2018-02-08 15:59:15,208 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:15,209 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:15,211 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 50.0 (TID 160). 2594 bytes result sent to driver
2018-02-08 15:59:15,212 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 50.0 (TID 162, localhost, executor driver, partition 8, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,212 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 50.0 (TID 162)
2018-02-08 15:59:15,212 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 50.0 (TID 160) in 51 ms on localhost (executor driver) (7/100)
2018-02-08 15:59:15,216 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:15,217 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:15,263 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 50.0 (TID 161). 2594 bytes result sent to driver
2018-02-08 15:59:15,264 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 50.0 (TID 163, localhost, executor driver, partition 9, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,266 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 50.0 (TID 161) in 63 ms on localhost (executor driver) (8/100)
2018-02-08 15:59:15,266 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 50.0 (TID 163)
2018-02-08 15:59:15,274 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:15,275 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:15,307 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 50.0 (TID 162). 2594 bytes result sent to driver
2018-02-08 15:59:15,310 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 50.0 (TID 164, localhost, executor driver, partition 10, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,333 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 50.0 (TID 162) in 121 ms on localhost (executor driver) (9/100)
2018-02-08 15:59:15,333 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 50.0 (TID 164)
2018-02-08 15:59:15,338 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:15,339 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:15,381 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 50.0 (TID 164). 2594 bytes result sent to driver
2018-02-08 15:59:15,382 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 50.0 (TID 165, localhost, executor driver, partition 11, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,382 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 50.0 (TID 164) in 72 ms on localhost (executor driver) (10/100)
2018-02-08 15:59:15,382 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 50.0 (TID 165)
2018-02-08 15:59:15,386 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:15,387 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:15,400 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 50.0 (TID 163). 2594 bytes result sent to driver
2018-02-08 15:59:15,400 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 50.0 (TID 166, localhost, executor driver, partition 12, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,400 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 50.0 (TID 163) in 136 ms on localhost (executor driver) (11/100)
2018-02-08 15:59:15,401 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 50.0 (TID 166)
2018-02-08 15:59:15,405 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:15,407 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:15,438 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 50.0 (TID 165). 2594 bytes result sent to driver
2018-02-08 15:59:15,438 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 50.0 (TID 167, localhost, executor driver, partition 13, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,438 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 50.0 (TID 167)
2018-02-08 15:59:15,438 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 50.0 (TID 165) in 57 ms on localhost (executor driver) (12/100)
2018-02-08 15:59:15,442 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:15,443 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 50.0 (TID 166). 2637 bytes result sent to driver
2018-02-08 15:59:15,443 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:15,443 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 50.0 (TID 168, localhost, executor driver, partition 14, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,444 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 50.0 (TID 166) in 44 ms on localhost (executor driver) (13/100)
2018-02-08 15:59:15,444 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 50.0 (TID 168)
2018-02-08 15:59:15,447 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:15,448 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:15,481 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 50.0 (TID 168). 2594 bytes result sent to driver
2018-02-08 15:59:15,483 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 50.0 (TID 169, localhost, executor driver, partition 15, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,483 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 50.0 (TID 169)
2018-02-08 15:59:15,483 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 50.0 (TID 168) in 40 ms on localhost (executor driver) (14/100)
2018-02-08 15:59:15,483 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 50.0 (TID 167). 2594 bytes result sent to driver
2018-02-08 15:59:15,484 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 50.0 (TID 170, localhost, executor driver, partition 16, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,484 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 50.0 (TID 170)
2018-02-08 15:59:15,484 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 50.0 (TID 167) in 46 ms on localhost (executor driver) (15/100)
2018-02-08 15:59:15,487 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:15,487 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:15,490 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:15,493 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:15,525 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 50.0 (TID 169). 2594 bytes result sent to driver
2018-02-08 15:59:15,526 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 50.0 (TID 171, localhost, executor driver, partition 17, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,527 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 50.0 (TID 169) in 45 ms on localhost (executor driver) (16/100)
2018-02-08 15:59:15,527 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 50.0 (TID 171)
2018-02-08 15:59:15,532 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:15,533 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:15,571 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 50.0 (TID 170). 2594 bytes result sent to driver
2018-02-08 15:59:15,572 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 50.0 (TID 172, localhost, executor driver, partition 18, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,574 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 50.0 (TID 170) in 91 ms on localhost (executor driver) (17/100)
2018-02-08 15:59:15,574 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 50.0 (TID 172)
2018-02-08 15:59:15,583 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:15,586 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:15,602 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 50.0 (TID 171). 2637 bytes result sent to driver
2018-02-08 15:59:15,603 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 50.0 (TID 173, localhost, executor driver, partition 19, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,603 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 50.0 (TID 171) in 77 ms on localhost (executor driver) (18/100)
2018-02-08 15:59:15,603 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 50.0 (TID 173)
2018-02-08 15:59:15,607 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:15,608 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:15,622 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 50.0 (TID 172). 2594 bytes result sent to driver
2018-02-08 15:59:15,623 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 50.0 (TID 174, localhost, executor driver, partition 20, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,623 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 50.0 (TID 172) in 51 ms on localhost (executor driver) (19/100)
2018-02-08 15:59:15,623 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 50.0 (TID 174)
2018-02-08 15:59:15,628 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:15,628 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:15,643 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 50.0 (TID 173). 2637 bytes result sent to driver
2018-02-08 15:59:15,643 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 50.0 (TID 175, localhost, executor driver, partition 21, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,644 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 50.0 (TID 173) in 42 ms on localhost (executor driver) (20/100)
2018-02-08 15:59:15,644 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 50.0 (TID 175)
2018-02-08 15:59:15,647 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:15,648 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:15,671 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 50.0 (TID 174). 2637 bytes result sent to driver
2018-02-08 15:59:15,671 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 50.0 (TID 176, localhost, executor driver, partition 22, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,672 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 50.0 (TID 174) in 50 ms on localhost (executor driver) (21/100)
2018-02-08 15:59:15,672 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 50.0 (TID 176)
2018-02-08 15:59:15,676 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:15,676 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 50.0 (TID 175). 2594 bytes result sent to driver
2018-02-08 15:59:15,677 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 50.0 (TID 177, localhost, executor driver, partition 23, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,677 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:15,677 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 50.0 (TID 175) in 34 ms on localhost (executor driver) (22/100)
2018-02-08 15:59:15,677 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 50.0 (TID 177)
2018-02-08 15:59:15,682 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:15,683 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:15,711 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 50.0 (TID 176). 2594 bytes result sent to driver
2018-02-08 15:59:15,712 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 50.0 (TID 178, localhost, executor driver, partition 24, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,712 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 50.0 (TID 176) in 41 ms on localhost (executor driver) (23/100)
2018-02-08 15:59:15,713 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 50.0 (TID 178)
2018-02-08 15:59:15,715 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 50.0 (TID 177). 2594 bytes result sent to driver
2018-02-08 15:59:15,715 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 50.0 (TID 179, localhost, executor driver, partition 25, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,715 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 50.0 (TID 179)
2018-02-08 15:59:15,715 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 50.0 (TID 177) in 38 ms on localhost (executor driver) (24/100)
2018-02-08 15:59:15,718 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:15,721 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:15,722 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:15,723 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:15,758 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 50.0 (TID 179). 2637 bytes result sent to driver
2018-02-08 15:59:15,759 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 50.0 (TID 180, localhost, executor driver, partition 26, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,759 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 50.0 (TID 180)
2018-02-08 15:59:15,759 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 50.0 (TID 179) in 44 ms on localhost (executor driver) (25/100)
2018-02-08 15:59:15,764 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:15,765 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:15,777 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 50.0 (TID 178). 2637 bytes result sent to driver
2018-02-08 15:59:15,779 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 50.0 (TID 181, localhost, executor driver, partition 27, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,780 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 50.0 (TID 178) in 68 ms on localhost (executor driver) (26/100)
2018-02-08 15:59:15,780 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 50.0 (TID 181)
2018-02-08 15:59:15,787 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:15,788 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:15,802 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 50.0 (TID 180). 2594 bytes result sent to driver
2018-02-08 15:59:15,802 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 50.0 (TID 182, localhost, executor driver, partition 28, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,803 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 50.0 (TID 182)
2018-02-08 15:59:15,803 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 50.0 (TID 180) in 45 ms on localhost (executor driver) (27/100)
2018-02-08 15:59:15,806 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:15,807 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:15,835 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 50.0 (TID 182). 2594 bytes result sent to driver
2018-02-08 15:59:15,835 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 50.0 (TID 183, localhost, executor driver, partition 29, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,836 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 50.0 (TID 183)
2018-02-08 15:59:15,836 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 50.0 (TID 182) in 34 ms on localhost (executor driver) (28/100)
2018-02-08 15:59:15,839 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:15,840 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:15,842 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 50.0 (TID 181). 2594 bytes result sent to driver
2018-02-08 15:59:15,843 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 50.0 (TID 184, localhost, executor driver, partition 30, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,843 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 50.0 (TID 184)
2018-02-08 15:59:15,843 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 50.0 (TID 181) in 64 ms on localhost (executor driver) (29/100)
2018-02-08 15:59:15,847 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:15,848 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:15,865 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 50.0 (TID 183). 2594 bytes result sent to driver
2018-02-08 15:59:15,866 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 50.0 (TID 185, localhost, executor driver, partition 31, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,866 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 50.0 (TID 183) in 31 ms on localhost (executor driver) (30/100)
2018-02-08 15:59:15,866 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 50.0 (TID 185)
2018-02-08 15:59:15,873 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:15,874 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:15,879 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 50.0 (TID 184). 2594 bytes result sent to driver
2018-02-08 15:59:15,880 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 50.0 (TID 186, localhost, executor driver, partition 32, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,880 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 50.0 (TID 186)
2018-02-08 15:59:15,880 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 50.0 (TID 184) in 37 ms on localhost (executor driver) (31/100)
2018-02-08 15:59:15,883 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:15,884 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:15,912 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 50.0 (TID 185). 2594 bytes result sent to driver
2018-02-08 15:59:15,913 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 50.0 (TID 187, localhost, executor driver, partition 33, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,913 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 50.0 (TID 185) in 47 ms on localhost (executor driver) (32/100)
2018-02-08 15:59:15,916 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 50.0 (TID 187)
2018-02-08 15:59:15,918 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 50.0 (TID 186). 2594 bytes result sent to driver
2018-02-08 15:59:15,919 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 50.0 (TID 188, localhost, executor driver, partition 34, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,919 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 50.0 (TID 188)
2018-02-08 15:59:15,919 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 50.0 (TID 186) in 40 ms on localhost (executor driver) (33/100)
2018-02-08 15:59:15,923 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:15,925 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:15,925 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:15,926 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:15,965 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 50.0 (TID 187). 2637 bytes result sent to driver
2018-02-08 15:59:15,966 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 50.0 (TID 189, localhost, executor driver, partition 35, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,967 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 50.0 (TID 187) in 54 ms on localhost (executor driver) (34/100)
2018-02-08 15:59:15,967 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 50.0 (TID 189)
2018-02-08 15:59:15,974 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 50.0 (TID 188). 2637 bytes result sent to driver
2018-02-08 15:59:15,975 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:15,975 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 50.0 (TID 190, localhost, executor driver, partition 36, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:15,976 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 50.0 (TID 188) in 57 ms on localhost (executor driver) (35/100)
2018-02-08 15:59:15,976 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:15,976 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 50.0 (TID 190)
2018-02-08 15:59:15,980 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:15,981 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:16,021 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 50.0 (TID 190). 2594 bytes result sent to driver
2018-02-08 15:59:16,022 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 50.0 (TID 191, localhost, executor driver, partition 37, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,023 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 50.0 (TID 190) in 48 ms on localhost (executor driver) (36/100)
2018-02-08 15:59:16,023 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 50.0 (TID 191)
2018-02-08 15:59:16,027 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:16,028 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:16,033 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 50.0 (TID 189). 2637 bytes result sent to driver
2018-02-08 15:59:16,033 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 50.0 (TID 192, localhost, executor driver, partition 38, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,034 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 50.0 (TID 192)
2018-02-08 15:59:16,034 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 50.0 (TID 189) in 68 ms on localhost (executor driver) (37/100)
2018-02-08 15:59:16,037 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:16,038 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:16,064 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 50.0 (TID 191). 2594 bytes result sent to driver
2018-02-08 15:59:16,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 50.0 (TID 193, localhost, executor driver, partition 39, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,070 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 50.0 (TID 193)
2018-02-08 15:59:16,072 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 50.0 (TID 191) in 50 ms on localhost (executor driver) (38/100)
2018-02-08 15:59:16,075 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:16,076 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:16,077 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 50.0 (TID 192). 2637 bytes result sent to driver
2018-02-08 15:59:16,077 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 50.0 (TID 194, localhost, executor driver, partition 40, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,078 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 50.0 (TID 192) in 45 ms on localhost (executor driver) (39/100)
2018-02-08 15:59:16,078 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 50.0 (TID 194)
2018-02-08 15:59:16,085 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:16,086 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:16,113 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 50.0 (TID 193). 2594 bytes result sent to driver
2018-02-08 15:59:16,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 50.0 (TID 195, localhost, executor driver, partition 41, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 50.0 (TID 193) in 45 ms on localhost (executor driver) (40/100)
2018-02-08 15:59:16,114 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 50.0 (TID 195)
2018-02-08 15:59:16,119 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:16,120 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:16,121 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 50.0 (TID 194). 2594 bytes result sent to driver
2018-02-08 15:59:16,122 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 50.0 (TID 196, localhost, executor driver, partition 42, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,122 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 50.0 (TID 194) in 45 ms on localhost (executor driver) (41/100)
2018-02-08 15:59:16,122 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 50.0 (TID 196)
2018-02-08 15:59:16,133 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:16,133 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:16,156 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_18_piece0 on 192.168.11.26:62887 in memory (size: 16.1 KB, free: 631.7 MB)
2018-02-08 15:59:16,170 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_17_piece0 on 192.168.11.26:62887 in memory (size: 15.9 KB, free: 631.7 MB)
2018-02-08 15:59:16,176 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 487
2018-02-08 15:59:16,180 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_19_piece0 on 192.168.11.26:62887 in memory (size: 16.0 KB, free: 631.7 MB)
2018-02-08 15:59:16,180 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 50.0 (TID 195). 2637 bytes result sent to driver
2018-02-08 15:59:16,181 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 50.0 (TID 197, localhost, executor driver, partition 43, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,182 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 50.0 (TID 195) in 68 ms on localhost (executor driver) (42/100)
2018-02-08 15:59:16,182 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 50.0 (TID 197)
2018-02-08 15:59:16,187 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:16,188 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:16,191 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 50.0 (TID 196). 2637 bytes result sent to driver
2018-02-08 15:59:16,191 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 50.0 (TID 198, localhost, executor driver, partition 44, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,191 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 50.0 (TID 196) in 69 ms on localhost (executor driver) (43/100)
2018-02-08 15:59:16,191 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 50.0 (TID 198)
2018-02-08 15:59:16,196 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:16,197 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:16,237 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 50.0 (TID 198). 2594 bytes result sent to driver
2018-02-08 15:59:16,237 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 50.0 (TID 199, localhost, executor driver, partition 45, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,238 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 50.0 (TID 198) in 47 ms on localhost (executor driver) (44/100)
2018-02-08 15:59:16,238 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 50.0 (TID 199)
2018-02-08 15:59:16,243 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:16,244 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:16,252 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 50.0 (TID 197). 2594 bytes result sent to driver
2018-02-08 15:59:16,252 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 50.0 (TID 200, localhost, executor driver, partition 46, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,252 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 50.0 (TID 197) in 71 ms on localhost (executor driver) (45/100)
2018-02-08 15:59:16,252 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 50.0 (TID 200)
2018-02-08 15:59:16,256 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:16,258 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:16,273 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 50.0 (TID 199). 2594 bytes result sent to driver
2018-02-08 15:59:16,274 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 50.0 (TID 201, localhost, executor driver, partition 47, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,274 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 50.0 (TID 199) in 37 ms on localhost (executor driver) (46/100)
2018-02-08 15:59:16,275 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 50.0 (TID 201)
2018-02-08 15:59:16,279 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:16,280 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:16,316 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 50.0 (TID 200). 2594 bytes result sent to driver
2018-02-08 15:59:16,323 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 50.0 (TID 202, localhost, executor driver, partition 48, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,324 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 50.0 (TID 200) in 72 ms on localhost (executor driver) (47/100)
2018-02-08 15:59:16,328 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 50.0 (TID 202)
2018-02-08 15:59:16,328 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 50.0 (TID 201). 2594 bytes result sent to driver
2018-02-08 15:59:16,332 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 50.0 (TID 203, localhost, executor driver, partition 49, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,332 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 50.0 (TID 201) in 58 ms on localhost (executor driver) (48/100)
2018-02-08 15:59:16,332 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 50.0 (TID 203)
2018-02-08 15:59:16,332 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:16,333 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:16,343 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:16,344 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:16,383 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 50.0 (TID 202). 2594 bytes result sent to driver
2018-02-08 15:59:16,384 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 50.0 (TID 204, localhost, executor driver, partition 50, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,384 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 50.0 (TID 202) in 62 ms on localhost (executor driver) (49/100)
2018-02-08 15:59:16,385 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 50.0 (TID 204)
2018-02-08 15:59:16,393 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:16,394 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:16,411 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 50.0 (TID 203). 2594 bytes result sent to driver
2018-02-08 15:59:16,412 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 50.0 (TID 205, localhost, executor driver, partition 51, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,412 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 50.0 (TID 205)
2018-02-08 15:59:16,412 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 50.0 (TID 203) in 80 ms on localhost (executor driver) (50/100)
2018-02-08 15:59:16,419 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:16,420 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:16,447 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 50.0 (TID 204). 2637 bytes result sent to driver
2018-02-08 15:59:16,448 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 50.0 (TID 206, localhost, executor driver, partition 52, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,448 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 50.0 (TID 204) in 65 ms on localhost (executor driver) (51/100)
2018-02-08 15:59:16,448 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 50.0 (TID 206)
2018-02-08 15:59:16,455 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:16,456 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:16,480 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 50.0 (TID 205). 2594 bytes result sent to driver
2018-02-08 15:59:16,480 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 50.0 (TID 207, localhost, executor driver, partition 53, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,481 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 50.0 (TID 207)
2018-02-08 15:59:16,481 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 50.0 (TID 205) in 69 ms on localhost (executor driver) (52/100)
2018-02-08 15:59:16,486 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:16,487 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:16,514 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 50.0 (TID 206). 2637 bytes result sent to driver
2018-02-08 15:59:16,515 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 50.0 (TID 208, localhost, executor driver, partition 54, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,515 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 50.0 (TID 206) in 67 ms on localhost (executor driver) (53/100)
2018-02-08 15:59:16,515 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 50.0 (TID 208)
2018-02-08 15:59:16,519 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:16,520 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:16,550 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 50.0 (TID 207). 2637 bytes result sent to driver
2018-02-08 15:59:16,551 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 50.0 (TID 209, localhost, executor driver, partition 55, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,551 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 50.0 (TID 209)
2018-02-08 15:59:16,551 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 50.0 (TID 207) in 71 ms on localhost (executor driver) (54/100)
2018-02-08 15:59:16,555 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:16,556 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:16,576 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 50.0 (TID 208). 2594 bytes result sent to driver
2018-02-08 15:59:16,578 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 50.0 (TID 210, localhost, executor driver, partition 56, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,578 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 50.0 (TID 208) in 64 ms on localhost (executor driver) (55/100)
2018-02-08 15:59:16,578 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 50.0 (TID 210)
2018-02-08 15:59:16,584 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:16,586 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:16,612 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 50.0 (TID 209). 2594 bytes result sent to driver
2018-02-08 15:59:16,612 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 50.0 (TID 211, localhost, executor driver, partition 57, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,613 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 50.0 (TID 209) in 62 ms on localhost (executor driver) (56/100)
2018-02-08 15:59:16,613 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 50.0 (TID 211)
2018-02-08 15:59:16,617 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:16,617 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:16,662 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 50.0 (TID 210). 2594 bytes result sent to driver
2018-02-08 15:59:16,663 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 50.0 (TID 212, localhost, executor driver, partition 58, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,663 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 50.0 (TID 212)
2018-02-08 15:59:16,663 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 50.0 (TID 210) in 85 ms on localhost (executor driver) (57/100)
2018-02-08 15:59:16,667 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:16,668 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:16,684 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 50.0 (TID 211). 2594 bytes result sent to driver
2018-02-08 15:59:16,684 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 50.0 (TID 213, localhost, executor driver, partition 59, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,685 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 50.0 (TID 213)
2018-02-08 15:59:16,685 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 50.0 (TID 211) in 73 ms on localhost (executor driver) (58/100)
2018-02-08 15:59:16,689 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:16,689 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:16,710 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 50.0 (TID 212). 2594 bytes result sent to driver
2018-02-08 15:59:16,711 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 50.0 (TID 214, localhost, executor driver, partition 60, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,711 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 50.0 (TID 212) in 48 ms on localhost (executor driver) (59/100)
2018-02-08 15:59:16,711 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 50.0 (TID 214)
2018-02-08 15:59:16,715 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:16,716 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:16,732 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 50.0 (TID 213). 2637 bytes result sent to driver
2018-02-08 15:59:16,733 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 50.0 (TID 215, localhost, executor driver, partition 61, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,733 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 50.0 (TID 213) in 49 ms on localhost (executor driver) (60/100)
2018-02-08 15:59:16,733 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 50.0 (TID 215)
2018-02-08 15:59:16,738 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:16,739 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:16,753 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 50.0 (TID 214). 2594 bytes result sent to driver
2018-02-08 15:59:16,753 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 50.0 (TID 216, localhost, executor driver, partition 62, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,754 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 50.0 (TID 214) in 43 ms on localhost (executor driver) (61/100)
2018-02-08 15:59:16,754 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 50.0 (TID 216)
2018-02-08 15:59:16,759 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:16,760 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:16,784 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 50.0 (TID 215). 2594 bytes result sent to driver
2018-02-08 15:59:16,785 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 50.0 (TID 217, localhost, executor driver, partition 63, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,785 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 50.0 (TID 215) in 53 ms on localhost (executor driver) (62/100)
2018-02-08 15:59:16,785 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 50.0 (TID 217)
2018-02-08 15:59:16,793 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:16,794 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:16,814 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 50.0 (TID 216). 2594 bytes result sent to driver
2018-02-08 15:59:16,815 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 50.0 (TID 218, localhost, executor driver, partition 64, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,815 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 50.0 (TID 216) in 62 ms on localhost (executor driver) (63/100)
2018-02-08 15:59:16,815 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 50.0 (TID 218)
2018-02-08 15:59:16,821 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:16,822 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:16,843 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 50.0 (TID 217). 2594 bytes result sent to driver
2018-02-08 15:59:16,844 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 50.0 (TID 219, localhost, executor driver, partition 65, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,844 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 50.0 (TID 219)
2018-02-08 15:59:16,844 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 50.0 (TID 217) in 59 ms on localhost (executor driver) (64/100)
2018-02-08 15:59:16,849 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:16,851 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:16,870 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 50.0 (TID 218). 2594 bytes result sent to driver
2018-02-08 15:59:16,871 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 50.0 (TID 220, localhost, executor driver, partition 66, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,871 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 50.0 (TID 220)
2018-02-08 15:59:16,871 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 50.0 (TID 218) in 56 ms on localhost (executor driver) (65/100)
2018-02-08 15:59:16,874 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:16,876 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:16,896 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 50.0 (TID 219). 2594 bytes result sent to driver
2018-02-08 15:59:16,896 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 50.0 (TID 221, localhost, executor driver, partition 67, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,897 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 50.0 (TID 219) in 53 ms on localhost (executor driver) (66/100)
2018-02-08 15:59:16,897 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 50.0 (TID 221)
2018-02-08 15:59:16,901 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:16,902 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:16,913 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 50.0 (TID 220). 2637 bytes result sent to driver
2018-02-08 15:59:16,914 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 50.0 (TID 222, localhost, executor driver, partition 68, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,914 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 50.0 (TID 222)
2018-02-08 15:59:16,914 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 50.0 (TID 220) in 44 ms on localhost (executor driver) (67/100)
2018-02-08 15:59:16,918 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:16,919 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:16,939 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 50.0 (TID 221). 2594 bytes result sent to driver
2018-02-08 15:59:16,939 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 50.0 (TID 223, localhost, executor driver, partition 69, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,940 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 50.0 (TID 221) in 44 ms on localhost (executor driver) (68/100)
2018-02-08 15:59:16,940 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 50.0 (TID 223)
2018-02-08 15:59:16,944 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:16,945 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:16,963 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 50.0 (TID 222). 2594 bytes result sent to driver
2018-02-08 15:59:16,965 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 50.0 (TID 224, localhost, executor driver, partition 70, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:16,967 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 50.0 (TID 222) in 53 ms on localhost (executor driver) (69/100)
2018-02-08 15:59:16,967 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 50.0 (TID 224)
2018-02-08 15:59:16,975 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:16,976 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:17,002 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 50.0 (TID 223). 2594 bytes result sent to driver
2018-02-08 15:59:17,005 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 50.0 (TID 225, localhost, executor driver, partition 71, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,006 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 50.0 (TID 223) in 67 ms on localhost (executor driver) (70/100)
2018-02-08 15:59:17,007 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 50.0 (TID 225)
2018-02-08 15:59:17,016 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:17,016 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:17,066 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 50.0 (TID 224). 2637 bytes result sent to driver
2018-02-08 15:59:17,067 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 50.0 (TID 226, localhost, executor driver, partition 72, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,069 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 50.0 (TID 224) in 105 ms on localhost (executor driver) (71/100)
2018-02-08 15:59:17,072 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 50.0 (TID 225). 2637 bytes result sent to driver
2018-02-08 15:59:17,073 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 50.0 (TID 226)
2018-02-08 15:59:17,076 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 50.0 (TID 227, localhost, executor driver, partition 73, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,077 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 50.0 (TID 225) in 72 ms on localhost (executor driver) (72/100)
2018-02-08 15:59:17,077 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 50.0 (TID 227)
2018-02-08 15:59:17,078 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:17,079 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:17,082 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:17,083 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:17,107 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 50.0 (TID 227). 2594 bytes result sent to driver
2018-02-08 15:59:17,107 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 50.0 (TID 228, localhost, executor driver, partition 74, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,108 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 50.0 (TID 228)
2018-02-08 15:59:17,108 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 50.0 (TID 227) in 32 ms on localhost (executor driver) (73/100)
2018-02-08 15:59:17,109 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 50.0 (TID 226). 2637 bytes result sent to driver
2018-02-08 15:59:17,110 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 50.0 (TID 229, localhost, executor driver, partition 75, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,110 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 50.0 (TID 226) in 43 ms on localhost (executor driver) (74/100)
2018-02-08 15:59:17,111 INFO[org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 50.0 (TID 229)
2018-02-08 15:59:17,112 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:17,112 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:17,114 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:17,114 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:17,135 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 50.0 (TID 228). 2637 bytes result sent to driver
2018-02-08 15:59:17,136 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 50.0 (TID 230, localhost, executor driver, partition 76, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,136 INFO[org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 50.0 (TID 230)
2018-02-08 15:59:17,136 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 50.0 (TID 228) in 29 ms on localhost (executor driver) (75/100)
2018-02-08 15:59:17,137 INFO[org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 50.0 (TID 229). 2594 bytes result sent to driver
2018-02-08 15:59:17,138 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 50.0 (TID 231, localhost, executor driver, partition 77, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,138 INFO[org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 50.0 (TID 231)
2018-02-08 15:59:17,138 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 50.0 (TID 229) in 28 ms on localhost (executor driver) (76/100)
2018-02-08 15:59:17,140 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:17,141 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:17,141 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:17,141 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:17,163 INFO[org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 50.0 (TID 231). 2637 bytes result sent to driver
2018-02-08 15:59:17,164 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 50.0 (TID 232, localhost, executor driver, partition 78, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,164 INFO[org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 50.0 (TID 232)
2018-02-08 15:59:17,164 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 50.0 (TID 231) in 27 ms on localhost (executor driver) (77/100)
2018-02-08 15:59:17,165 INFO[org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 50.0 (TID 230). 2637 bytes result sent to driver
2018-02-08 15:59:17,165 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 50.0 (TID 233, localhost, executor driver, partition 79, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,166 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 50.0 (TID 230) in 30 ms on localhost (executor driver) (78/100)
2018-02-08 15:59:17,166 INFO[org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 50.0 (TID 233)
2018-02-08 15:59:17,168 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:17,169 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:17,169 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:17,170 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:17,199 INFO[org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 50.0 (TID 233). 2594 bytes result sent to driver
2018-02-08 15:59:17,199 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 50.0 (TID 234, localhost, executor driver, partition 80, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,200 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 50.0 (TID 233) in 35 ms on localhost (executor driver) (79/100)
2018-02-08 15:59:17,200 INFO[org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 50.0 (TID 234)
2018-02-08 15:59:17,204 INFO[org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 50.0 (TID 232). 2594 bytes result sent to driver
2018-02-08 15:59:17,205 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 50.0 (TID 235, localhost, executor driver, partition 81, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,206 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 50.0 (TID 232) in 42 ms on localhost (executor driver) (80/100)
2018-02-08 15:59:17,206 INFO[org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 50.0 (TID 235)
2018-02-08 15:59:17,206 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:17,207 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:17,211 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:17,211 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:17,238 INFO[org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 50.0 (TID 234). 2637 bytes result sent to driver
2018-02-08 15:59:17,239 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 50.0 (TID 236, localhost, executor driver, partition 82, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,239 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 50.0 (TID 234) in 40 ms on localhost (executor driver) (81/100)
2018-02-08 15:59:17,240 INFO[org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 50.0 (TID 236)
2018-02-08 15:59:17,244 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:17,245 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:17,252 INFO[org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 50.0 (TID 235). 2594 bytes result sent to driver
2018-02-08 15:59:17,254 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 50.0 (TID 237, localhost, executor driver, partition 83, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,255 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 50.0 (TID 235) in 50 ms on localhost (executor driver) (82/100)
2018-02-08 15:59:17,256 INFO[org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 50.0 (TID 237)
2018-02-08 15:59:17,260 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:17,261 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:17,278 INFO[org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 50.0 (TID 236). 2594 bytes result sent to driver
2018-02-08 15:59:17,278 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 50.0 (TID 238, localhost, executor driver, partition 84, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,278 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 50.0 (TID 236) in 39 ms on localhost (executor driver) (83/100)
2018-02-08 15:59:17,278 INFO[org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 50.0 (TID 238)
2018-02-08 15:59:17,285 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:17,286 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:17,295 INFO[org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 50.0 (TID 237). 2594 bytes result sent to driver
2018-02-08 15:59:17,296 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 50.0 (TID 239, localhost, executor driver, partition 85, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,297 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 50.0 (TID 237) in 43 ms on localhost (executor driver) (84/100)
2018-02-08 15:59:17,297 INFO[org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 50.0 (TID 239)
2018-02-08 15:59:17,303 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:17,303 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:17,324 INFO[org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 50.0 (TID 238). 2637 bytes result sent to driver
2018-02-08 15:59:17,324 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 50.0 (TID 240, localhost, executor driver, partition 86, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,324 INFO[org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 50.0 (TID 240)
2018-02-08 15:59:17,324 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 50.0 (TID 238) in 46 ms on localhost (executor driver) (85/100)
2018-02-08 15:59:17,328 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:17,328 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:17,331 INFO[org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 50.0 (TID 239). 2594 bytes result sent to driver
2018-02-08 15:59:17,332 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 50.0 (TID 241, localhost, executor driver, partition 87, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,332 INFO[org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 50.0 (TID 241)
2018-02-08 15:59:17,332 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 50.0 (TID 239) in 36 ms on localhost (executor driver) (86/100)
2018-02-08 15:59:17,336 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:17,336 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:17,355 INFO[org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 50.0 (TID 240). 2637 bytes result sent to driver
2018-02-08 15:59:17,355 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 50.0 (TID 242, localhost, executor driver, partition 88, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,356 INFO[org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 50.0 (TID 242)
2018-02-08 15:59:17,356 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 50.0 (TID 240) in 32 ms on localhost (executor driver) (87/100)
2018-02-08 15:59:17,360 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:17,361 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:17,365 INFO[org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 50.0 (TID 241). 2594 bytes result sent to driver
2018-02-08 15:59:17,366 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 50.0 (TID 243, localhost, executor driver, partition 89, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,366 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 50.0 (TID 241) in 35 ms on localhost (executor driver) (88/100)
2018-02-08 15:59:17,366 INFO[org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 50.0 (TID 243)
2018-02-08 15:59:17,370 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:17,370 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:17,387 INFO[org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 50.0 (TID 242). 2594 bytes result sent to driver
2018-02-08 15:59:17,388 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 50.0 (TID 244, localhost, executor driver, partition 90, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,389 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 50.0 (TID 242) in 34 ms on localhost (executor driver) (89/100)
2018-02-08 15:59:17,389 INFO[org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 50.0 (TID 244)
2018-02-08 15:59:17,393 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:17,394 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:17,408 INFO[org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 50.0 (TID 243). 2594 bytes result sent to driver
2018-02-08 15:59:17,409 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 50.0 (TID 245, localhost, executor driver, partition 91, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,409 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 50.0 (TID 243) in 43 ms on localhost (executor driver) (90/100)
2018-02-08 15:59:17,409 INFO[org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 50.0 (TID 245)
2018-02-08 15:59:17,414 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:17,415 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:17,437 INFO[org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 50.0 (TID 244). 2594 bytes result sent to driver
2018-02-08 15:59:17,438 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 50.0 (TID 246, localhost, executor driver, partition 92, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,438 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 50.0 (TID 244) in 50 ms on localhost (executor driver) (91/100)
2018-02-08 15:59:17,439 INFO[org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 50.0 (TID 246)
2018-02-08 15:59:17,450 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:17,451 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:17,455 INFO[org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 50.0 (TID 245). 2594 bytes result sent to driver
2018-02-08 15:59:17,456 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 50.0 (TID 247, localhost, executor driver, partition 93, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,456 INFO[org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 50.0 (TID 247)
2018-02-08 15:59:17,456 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 50.0 (TID 245) in 47 ms on localhost (executor driver) (92/100)
2018-02-08 15:59:17,461 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:17,462 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:17,484 INFO[org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 50.0 (TID 246). 2594 bytes result sent to driver
2018-02-08 15:59:17,485 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 50.0 (TID 248, localhost, executor driver, partition 94, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,486 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 50.0 (TID 246) in 48 ms on localhost (executor driver) (93/100)
2018-02-08 15:59:17,486 INFO[org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 50.0 (TID 248)
2018-02-08 15:59:17,493 INFO[org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 50.0 (TID 247). 2594 bytes result sent to driver
2018-02-08 15:59:17,493 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:17,494 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:17,495 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 50.0 (TID 249, localhost, executor driver, partition 95, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,495 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 50.0 (TID 247) in 40 ms on localhost (executor driver) (94/100)
2018-02-08 15:59:17,495 INFO[org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 50.0 (TID 249)
2018-02-08 15:59:17,499 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:17,500 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:17,522 INFO[org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 50.0 (TID 248). 2594 bytes result sent to driver
2018-02-08 15:59:17,523 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 50.0 (TID 250, localhost, executor driver, partition 96, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,523 INFO[org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 50.0 (TID 250)
2018-02-08 15:59:17,523 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 50.0 (TID 248) in 38 ms on localhost (executor driver) (95/100)
2018-02-08 15:59:17,528 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:17,529 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:17,531 INFO[org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 50.0 (TID 249). 2637 bytes result sent to driver
2018-02-08 15:59:17,534 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 50.0 (TID 251, localhost, executor driver, partition 97, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,535 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 50.0 (TID 249) in 40 ms on localhost (executor driver) (96/100)
2018-02-08 15:59:17,536 INFO[org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 50.0 (TID 251)
2018-02-08 15:59:17,539 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:17,540 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:17,564 INFO[org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 50.0 (TID 250). 2594 bytes result sent to driver
2018-02-08 15:59:17,564 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 50.0 (TID 252, localhost, executor driver, partition 98, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,565 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 50.0 (TID 250) in 42 ms on localhost (executor driver) (97/100)
2018-02-08 15:59:17,565 INFO[org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 50.0 (TID 252)
2018-02-08 15:59:17,567 INFO[org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 50.0 (TID 251). 2594 bytes result sent to driver
2018-02-08 15:59:17,568 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 50.0 (TID 253, localhost, executor driver, partition 99, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:17,569 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 50.0 (TID 251) in 34 ms on localhost (executor driver) (98/100)
2018-02-08 15:59:17,569 INFO[org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 50.0 (TID 253)
2018-02-08 15:59:17,569 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:17,570 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:17,573 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:17,574 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:17,612 INFO[org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 50.0 (TID 253). 2594 bytes result sent to driver
2018-02-08 15:59:17,612 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 50.0 (TID 253) in 44 ms on localhost (executor driver) (99/100)
2018-02-08 15:59:17,634 INFO[org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 50.0 (TID 252). 2637 bytes result sent to driver
2018-02-08 15:59:17,634 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 50.0 (TID 252) in 70 ms on localhost (executor driver) (100/100)
2018-02-08 15:59:17,635 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2018-02-08 15:59:17,635 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 50 (show at MachineLeaningFiltering.java:42) finished in 3.145 s
2018-02-08 15:59:17,636 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:17,637 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:17,637 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 51)
2018-02-08 15:59:17,637 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:17,638 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 51 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42), which has no missing parents
2018-02-08 15:59:17,658 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21 stored as values in memory (estimated size 59.6 KB, free 631.2 MB)
2018-02-08 15:59:17,660 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.7 KB, free 631.2 MB)
2018-02-08 15:59:17,660 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_21_piece0 in memory on 192.168.11.26:62887 (size: 24.7 KB, free: 631.7 MB)
2018-02-08 15:59:17,661 INFO[org.apache.spark.SparkContext:54] - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:17,661 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:59:17,662 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 51.0 with 1 tasks
2018-02-08 15:59:17,663 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 51.0 (TID 254, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,663 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 51.0 (TID 254)
2018-02-08 15:59:17,673 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,673 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,674 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 51.0 (TID 254). 2467 bytes result sent to driver
2018-02-08 15:59:17,675 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 51.0 (TID 254) in 13 ms on localhost (executor driver) (1/1)
2018-02-08 15:59:17,675 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2018-02-08 15:59:17,676 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 51 (show at MachineLeaningFiltering.java:42) finished in 0.013 s
2018-02-08 15:59:17,680 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 5 finished: show at MachineLeaningFiltering.java:42, took 3.268626 s
2018-02-08 15:59:17,689 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:42
2018-02-08 15:59:17,690 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:59:17,691 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 155 bytes
2018-02-08 15:59:17,692 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 13 is 197 bytes
2018-02-08 15:59:17,692 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 12 is 161 bytes
2018-02-08 15:59:17,693 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 2 is 156 bytes
2018-02-08 15:59:17,693 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 11 is 238 bytes
2018-02-08 15:59:17,694 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 10 is 161 bytes
2018-02-08 15:59:17,695 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 9 is 240 bytes
2018-02-08 15:59:17,695 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 8 is 161 bytes
2018-02-08 15:59:17,696 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 7 is 238 bytes
2018-02-08 15:59:17,697 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 6 is 161 bytes
2018-02-08 15:59:17,697 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 5 is 240 bytes
2018-02-08 15:59:17,698 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 4 is 161 bytes
2018-02-08 15:59:17,698 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 3 is 240 bytes
2018-02-08 15:59:17,701 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 14 is 439 bytes
2018-02-08 15:59:17,701 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 6 (show at MachineLeaningFiltering.java:42) with 4 output partitions
2018-02-08 15:59:17,702 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 67 (show at MachineLeaningFiltering.java:42)
2018-02-08 15:59:17,702 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 66)
2018-02-08 15:59:17,702 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:59:17,702 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 67 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42), which has no missing parents
2018-02-08 15:59:17,706 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22 stored as values in memory (estimated size 59.6 KB, free 631.1 MB)
2018-02-08 15:59:17,708 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.7 KB, free 631.1 MB)
2018-02-08 15:59:17,711 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_22_piece0 in memory on 192.168.11.26:62887 (size: 24.7 KB, free: 631.7 MB)
2018-02-08 15:59:17,712 INFO[org.apache.spark.SparkContext:54] - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:17,712 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 4 missing tasks from ResultStage 67 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2018-02-08 15:59:17,712 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 67.0 with 4 tasks
2018-02-08 15:59:17,713 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 67.0 (TID 255, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,713 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 67.0 (TID 256, localhost, executor driver, partition 2, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,714 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 67.0 (TID 256)
2018-02-08 15:59:17,714 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 67.0 (TID 255)
2018-02-08 15:59:17,718 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,718 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,718 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,718 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,719 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 67.0 (TID 256). 2467 bytes result sent to driver
2018-02-08 15:59:17,719 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 67.0 (TID 255). 2467 bytes result sent to driver
2018-02-08 15:59:17,719 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 67.0 (TID 257, localhost, executor driver, partition 3, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,719 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 67.0 (TID 258, localhost, executor driver, partition 4, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,720 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 67.0 (TID 256) in 7 ms on localhost (executor driver) (1/4)
2018-02-08 15:59:17,720 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 67.0 (TID 258)
2018-02-08 15:59:17,720 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 67.0 (TID 255) in 7 ms on localhost (executor driver) (2/4)
2018-02-08 15:59:17,720 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 67.0 (TID 257)
2018-02-08 15:59:17,724 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,724 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,724 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:17,724 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:17,724 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 67.0 (TID 258). 2424 bytes result sent to driver
2018-02-08 15:59:17,724 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 67.0 (TID 257). 2424 bytes result sent to driver
2018-02-08 15:59:17,725 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 67.0 (TID 258) in 6 ms on localhost (executor driver) (3/4)
2018-02-08 15:59:17,725 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 67.0 (TID 257) in 6 ms on localhost (executor driver) (4/4)
2018-02-08 15:59:17,725 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2018-02-08 15:59:17,725 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 67 (show at MachineLeaningFiltering.java:42) finished in 0.012 s
2018-02-08 15:59:17,725 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 6 finished: show at MachineLeaningFiltering.java:42, took 0.036461 s
2018-02-08 15:59:17,727 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:42
2018-02-08 15:59:17,730 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 7 (show at MachineLeaningFiltering.java:42) with 20 output partitions
2018-02-08 15:59:17,730 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 83 (show at MachineLeaningFiltering.java:42)
2018-02-08 15:59:17,730 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 82)
2018-02-08 15:59:17,730 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:59:17,730 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 83 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42), which has no missing parents
2018-02-08 15:59:17,734 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23 stored as values in memory (estimated size 59.6 KB, free 631.0 MB)
2018-02-08 15:59:17,736 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_23_piece0 stored as bytes in memory (estimated size 24.7 KB, free 631.0 MB)
2018-02-08 15:59:17,736 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_23_piece0 in memory on 192.168.11.26:62887 (size: 24.7 KB, free: 631.6 MB)
2018-02-08 15:59:17,737 INFO[org.apache.spark.SparkContext:54] - Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:17,737 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 20 missing tasks from ResultStage 83 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19))
2018-02-08 15:59:17,737 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 83.0 with 20 tasks
2018-02-08 15:59:17,737 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 83.0 (TID 259, localhost, executor driver, partition 5, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,738 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 83.0 (TID 260, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,738 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 83.0 (TID 259)
2018-02-08 15:59:17,738 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 83.0 (TID 260)
2018-02-08 15:59:17,741 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,741 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,741 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,741 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,742 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 83.0 (TID 259). 2381 bytes result sent to driver
2018-02-08 15:59:17,742 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 83.0 (TID 260). 2381 bytes result sent to driver
2018-02-08 15:59:17,742 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 83.0 (TID 261, localhost, executor driver, partition 7, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,742 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 83.0 (TID 259) in 5 ms on localhost (executor driver) (1/20)
2018-02-08 15:59:17,742 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 83.0 (TID 261)
2018-02-08 15:59:17,742 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 83.0 (TID 260) in 4 ms on localhost (executor driver) (2/20)
2018-02-08 15:59:17,743 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 83.0 (TID 262, localhost, executor driver, partition 8, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,743 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 83.0 (TID 262)
2018-02-08 15:59:17,745 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,746 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:17,746 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 83.0 (TID 261). 2424 bytes result sent to driver
2018-02-08 15:59:17,746 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,746 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,746 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 83.0 (TID 263, localhost, executor driver, partition 9, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,747 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 83.0 (TID 261) in 5 ms on localhost (executor driver) (3/20)
2018-02-08 15:59:17,747 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 83.0 (TID 263)
2018-02-08 15:59:17,747 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 83.0 (TID 262). 2424 bytes result sent to driver
2018-02-08 15:59:17,747 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 83.0 (TID 264, localhost, executor driver, partition 10, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,747 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 83.0 (TID 262) in 4 ms on localhost (executor driver) (4/20)
2018-02-08 15:59:17,747 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 83.0 (TID 264)
2018-02-08 15:59:17,750 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,750 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,750 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,750 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,751 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 83.0 (TID 264). 2510 bytes result sent to driver
2018-02-08 15:59:17,751 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 83.0 (TID 263). 2510 bytes result sent to driver
2018-02-08 15:59:17,751 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 83.0 (TID 265, localhost, executor driver, partition 11, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,751 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 83.0 (TID 266, localhost, executor driver, partition 12, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,751 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 83.0 (TID 265)
2018-02-08 15:59:17,751 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 83.0 (TID 263) in 5 ms on localhost (executor driver) (5/20)
2018-02-08 15:59:17,752 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 83.0 (TID 264) in 5 ms on localhost (executor driver) (6/20)
2018-02-08 15:59:17,752 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 83.0 (TID 266)
2018-02-08 15:59:17,755 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,755 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,755 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 83.0 (TID 265). 2424 bytes result sent to driver
2018-02-08 15:59:17,756 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,756 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,756 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 83.0 (TID 267, localhost, executor driver, partition 13, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,756 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 83.0 (TID 266). 2381 bytes result sent to driver
2018-02-08 15:59:17,757 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 83.0 (TID 268, localhost, executor driver, partition 15, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,757 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 83.0 (TID 266) in 6 ms on localhost (executor driver) (7/20)
2018-02-08 15:59:17,757 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 83.0 (TID 267)
2018-02-08 15:59:17,757 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 83.0 (TID 265) in 6 ms on localhost (executor driver) (8/20)
2018-02-08 15:59:17,757 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 83.0 (TID 268)
2018-02-08 15:59:17,760 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,760 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,761 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 83.0 (TID 268). 2424 bytes result sent to driver
2018-02-08 15:59:17,761 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,761 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,761 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 83.0 (TID 267). 2424 bytes result sent to driver
2018-02-08 15:59:17,762 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 83.0 (TID 269, localhost, executor driver, partition 16, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,762 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 83.0 (TID 270, localhost, executor driver, partition 17, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,762 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 83.0 (TID 268) in 6 ms on localhost (executor driver) (9/20)
2018-02-08 15:59:17,762 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 83.0 (TID 267) in 6 ms on localhost (executor driver) (10/20)
2018-02-08 15:59:17,762 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 83.0 (TID 269)
2018-02-08 15:59:17,762 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 83.0 (TID 270)
2018-02-08 15:59:17,766 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,766 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:17,766 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,766 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,766 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 83.0 (TID 269). 2467 bytes result sent to driver
2018-02-08 15:59:17,766 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 83.0 (TID 270). 2424 bytes result sent to driver
2018-02-08 15:59:17,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 83.0 (TID 271, localhost, executor driver, partition 18, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 83.0 (TID 272, localhost, executor driver, partition 20, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,767 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 83.0 (TID 271)
2018-02-08 15:59:17,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 83.0 (TID 270) in 5 ms on localhost (executor driver) (11/20)
2018-02-08 15:59:17,767 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 83.0 (TID 269) in 6 ms on localhost (executor driver) (12/20)
2018-02-08 15:59:17,767 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 83.0 (TID 272)
2018-02-08 15:59:17,772 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,772 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,774 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 83.0 (TID 271). 2381 bytes result sent to driver
2018-02-08 15:59:17,775 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 83.0 (TID 273, localhost, executor driver, partition 21, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,775 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 83.0 (TID 271) in 9 ms on localhost (executor driver) (13/20)
2018-02-08 15:59:17,775 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 83.0 (TID 273)
2018-02-08 15:59:17,776 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,776 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,777 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 83.0 (TID 272). 2424 bytes result sent to driver
2018-02-08 15:59:17,779 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 83.0 (TID 274, localhost, executor driver, partition 22, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,780 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 83.0 (TID 272) in 13 ms on localhost (executor driver) (14/20)
2018-02-08 15:59:17,780 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,780 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,781 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 83.0 (TID 273). 2467 bytes result sent to driver
2018-02-08 15:59:17,782 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 83.0 (TID 275, localhost, executor driver, partition 23, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,782 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 83.0 (TID 273) in 7 ms on localhost (executor driver) (15/20)
2018-02-08 15:59:17,782 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 83.0 (TID 275)
2018-02-08 15:59:17,783 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 83.0 (TID 274)
2018-02-08 15:59:17,785 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,785 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,786 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:17,786 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:17,786 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 83.0 (TID 274). 2424 bytes result sent to driver
2018-02-08 15:59:17,786 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 83.0 (TID 275). 2424 bytes result sent to driver
2018-02-08 15:59:17,786 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 83.0 (TID 276, localhost, executor driver, partition 14, ANY, 4726 bytes)
2018-02-08 15:59:17,787 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 83.0 (TID 276)
2018-02-08 15:59:17,787 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 83.0 (TID 274) in 10 ms on localhost (executor driver) (16/20)
2018-02-08 15:59:17,787 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 83.0 (TID 277, localhost, executor driver, partition 19, ANY, 4726 bytes)
2018-02-08 15:59:17,787 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 83.0 (TID 275) in 6 ms on localhost (executor driver) (17/20)
2018-02-08 15:59:17,787 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 83.0 (TID 277)
2018-02-08 15:59:17,790 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,790 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 20 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,790 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:17,790 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:17,808 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.286723 ms
2018-02-08 15:59:17,816 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 6.773762 ms
2018-02-08 15:59:17,830 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 11.233603 ms
2018-02-08 15:59:17,911 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 40.413453 ms
2018-02-08 15:59:17,915 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 83.0 (TID 277). 2780 bytes result sent to driver
2018-02-08 15:59:17,916 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 83.0 (TID 278, localhost, executor driver, partition 24, ANY, 4726 bytes)
2018-02-08 15:59:17,916 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 83.0 (TID 277) in 129 ms on localhost (executor driver) (18/20)
2018-02-08 15:59:17,918 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 83.0 (TID 278)
2018-02-08 15:59:17,919 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 83.0 (TID 276). 2652 bytes result sent to driver
2018-02-08 15:59:17,920 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 83.0 (TID 276) in 134 ms on localhost (executor driver) (19/20)
2018-02-08 15:59:17,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,922 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,941 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 83.0 (TID 278). 2715 bytes result sent to driver
2018-02-08 15:59:17,941 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 83.0 (TID 278) in 26 ms on localhost (executor driver) (20/20)
2018-02-08 15:59:17,942 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 83.0, whose tasks have all completed, from pool 
2018-02-08 15:59:17,942 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 83 (show at MachineLeaningFiltering.java:42) finished in 0.205 s
2018-02-08 15:59:17,942 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 7 finished: show at MachineLeaningFiltering.java:42, took 0.215355 s
2018-02-08 15:59:17,945 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:42
2018-02-08 15:59:17,949 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 8 (show at MachineLeaningFiltering.java:42) with 100 output partitions
2018-02-08 15:59:17,949 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 99 (show at MachineLeaningFiltering.java:42)
2018-02-08 15:59:17,949 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 98)
2018-02-08 15:59:17,949 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:59:17,949 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 99 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42), which has no missing parents
2018-02-08 15:59:17,954 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24 stored as values in memory (estimated size 59.6 KB, free 630.9 MB)
2018-02-08 15:59:17,958 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_24_piece0 stored as bytes in memory (estimated size 24.7 KB, free 630.9 MB)
2018-02-08 15:59:17,958 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_24_piece0 in memory on 192.168.11.26:62887 (size: 24.7 KB, free: 631.6 MB)
2018-02-08 15:59:17,958 INFO[org.apache.spark.SparkContext:54] - Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:17,959 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 100 missing tasks from ResultStage 99 (MapPartitionsRDD[144] at show at MachineLeaningFiltering.java:42) (first 15 tasks are for partitions Vector(25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39))
2018-02-08 15:59:17,959 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 99.0 with 100 tasks
2018-02-08 15:59:17,959 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 99.0 (TID 279, localhost, executor driver, partition 25, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,959 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 99.0 (TID 280, localhost, executor driver, partition 26, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,960 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 99.0 (TID 279)
2018-02-08 15:59:17,960 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 99.0 (TID 280)
2018-02-08 15:59:17,963 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,963 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,963 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,963 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,963 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 99.0 (TID 280). 2424 bytes result sent to driver
2018-02-08 15:59:17,963 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 99.0 (TID 279). 2424 bytes result sent to driver
2018-02-08 15:59:17,964 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 99.0 (TID 281, localhost, executor driver, partition 27, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,964 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 99.0 (TID 281)
2018-02-08 15:59:17,964 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 99.0 (TID 280) in 5 ms on localhost (executor driver) (1/100)
2018-02-08 15:59:17,964 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 99.0 (TID 282, localhost, executor driver, partition 28, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,964 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 99.0 (TID 279) in 5 ms on localhost (executor driver) (2/100)
2018-02-08 15:59:17,964 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 99.0 (TID 282)
2018-02-08 15:59:17,967 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,967 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,967 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,967 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,968 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 99.0 (TID 281). 2381 bytes result sent to driver
2018-02-08 15:59:17,968 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 99.0 (TID 282). 2424 bytes result sent to driver
2018-02-08 15:59:17,968 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 99.0 (TID 283, localhost, executor driver, partition 29, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,968 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 99.0 (TID 281) in 4 ms on localhost (executor driver) (3/100)
2018-02-08 15:59:17,968 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 99.0 (TID 283)
2018-02-08 15:59:17,968 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 99.0 (TID 284, localhost, executor driver, partition 31, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,968 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 99.0 (TID 284)
2018-02-08 15:59:17,968 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 99.0 (TID 282) in 4 ms on localhost (executor driver) (4/100)
2018-02-08 15:59:17,971 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,971 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,971 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,972 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:17,972 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 99.0 (TID 283). 2424 bytes result sent to driver
2018-02-08 15:59:17,972 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 99.0 (TID 284). 2424 bytes result sent to driver
2018-02-08 15:59:17,972 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 99.0 (TID 285, localhost, executor driver, partition 32, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,973 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 99.0 (TID 285)
2018-02-08 15:59:17,973 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 99.0 (TID 283) in 5 ms on localhost (executor driver) (5/100)
2018-02-08 15:59:17,973 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 99.0 (TID 284) in 5 ms on localhost (executor driver) (6/100)
2018-02-08 15:59:17,973 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 99.0 (TID 286, localhost, executor driver, partition 33, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,973 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 99.0 (TID 286)
2018-02-08 15:59:17,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,976 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 99.0 (TID 285). 2424 bytes result sent to driver
2018-02-08 15:59:17,976 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 99.0 (TID 286). 2424 bytes result sent to driver
2018-02-08 15:59:17,977 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 99.0 (TID 287, localhost, executor driver, partition 34, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,977 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 99.0 (TID 285) in 5 ms on localhost (executor driver) (7/100)
2018-02-08 15:59:17,977 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 99.0 (TID 287)
2018-02-08 15:59:17,977 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 99.0 (TID 286) in 4 ms on localhost (executor driver) (8/100)
2018-02-08 15:59:17,977 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 99.0 (TID 288, localhost, executor driver, partition 35, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,977 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 99.0 (TID 288)
2018-02-08 15:59:17,980 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,980 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,980 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,980 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,981 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 99.0 (TID 288). 2381 bytes result sent to driver
2018-02-08 15:59:17,981 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 99.0 (TID 287). 2381 bytes result sent to driver
2018-02-08 15:59:17,981 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 99.0 (TID 289, localhost, executor driver, partition 36, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,981 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 99.0 (TID 288) in 4 ms on localhost (executor driver) (9/100)
2018-02-08 15:59:17,981 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 99.0 (TID 289)
2018-02-08 15:59:17,981 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 99.0 (TID 287) in 5 ms on localhost (executor driver) (10/100)
2018-02-08 15:59:17,982 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 99.0 (TID 290, localhost, executor driver, partition 37, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,982 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 99.0 (TID 290)
2018-02-08 15:59:17,985 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,985 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,985 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,985 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,986 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 99.0 (TID 290). 2424 bytes result sent to driver
2018-02-08 15:59:17,986 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 99.0 (TID 289). 2467 bytes result sent to driver
2018-02-08 15:59:17,986 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 99.0 (TID 291, localhost, executor driver, partition 38, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,986 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 99.0 (TID 290) in 5 ms on localhost (executor driver) (11/100)
2018-02-08 15:59:17,986 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 99.0 (TID 291)
2018-02-08 15:59:17,986 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 99.0 (TID 289) in 5 ms on localhost (executor driver) (12/100)
2018-02-08 15:59:17,986 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 99.0 (TID 292, localhost, executor driver, partition 39, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,987 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 99.0 (TID 292)
2018-02-08 15:59:17,989 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,989 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,989 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,989 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,990 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 99.0 (TID 291). 2424 bytes result sent to driver
2018-02-08 15:59:17,990 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 99.0 (TID 292). 2424 bytes result sent to driver
2018-02-08 15:59:17,990 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 99.0 (TID 293, localhost, executor driver, partition 40, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,991 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 99.0 (TID 294, localhost, executor driver, partition 41, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,991 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 99.0 (TID 293)
2018-02-08 15:59:17,991 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 99.0 (TID 292) in 5 ms on localhost (executor driver) (13/100)
2018-02-08 15:59:17,991 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 99.0 (TID 291) in 5 ms on localhost (executor driver) (14/100)
2018-02-08 15:59:17,991 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 99.0 (TID 294)
2018-02-08 15:59:17,994 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,994 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,994 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,995 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:17,995 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 99.0 (TID 294). 2424 bytes result sent to driver
2018-02-08 15:59:17,995 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 99.0 (TID 293). 2424 bytes result sent to driver
2018-02-08 15:59:17,995 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 99.0 (TID 295, localhost, executor driver, partition 42, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,995 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 99.0 (TID 294) in 4 ms on localhost (executor driver) (15/100)
2018-02-08 15:59:17,995 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 99.0 (TID 295)
2018-02-08 15:59:17,996 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 99.0 (TID 293) in 6 ms on localhost (executor driver) (16/100)
2018-02-08 15:59:17,996 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 99.0 (TID 296, localhost, executor driver, partition 44, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:17,996 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 99.0 (TID 296)
2018-02-08 15:59:17,999 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:17,999 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:17,999 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,000 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,000 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 99.0 (TID 296). 2467 bytes result sent to driver
2018-02-08 15:59:18,000 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 99.0 (TID 295). 2467 bytes result sent to driver
2018-02-08 15:59:18,000 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 99.0 (TID 297, localhost, executor driver, partition 45, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,000 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 99.0 (TID 298, localhost, executor driver, partition 46, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,001 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 99.0 (TID 297)
2018-02-08 15:59:18,001 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 99.0 (TID 295) in 6 ms on localhost (executor driver) (17/100)
2018-02-08 15:59:18,001 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 99.0 (TID 296) in 5 ms on localhost (executor driver) (18/100)
2018-02-08 15:59:18,001 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 99.0 (TID 298)
2018-02-08 15:59:18,004 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,004 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,004 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,004 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,004 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 99.0 (TID 297). 2381 bytes result sent to driver
2018-02-08 15:59:18,005 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 99.0 (TID 298). 2381 bytes result sent to driver
2018-02-08 15:59:18,005 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 99.0 (TID 299, localhost, executor driver, partition 47, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,005 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 99.0 (TID 297) in 5 ms on localhost (executor driver) (19/100)
2018-02-08 15:59:18,005 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 99.0 (TID 299)
2018-02-08 15:59:18,005 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 99.0 (TID 298) in 5 ms on localhost (executor driver) (20/100)
2018-02-08 15:59:18,008 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 99.0 (TID 300, localhost, executor driver, partition 50, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,008 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 99.0 (TID 300)
2018-02-08 15:59:18,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,009 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,010 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 99.0 (TID 299). 2381 bytes result sent to driver
2018-02-08 15:59:18,010 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 99.0 (TID 301, localhost, executor driver, partition 52, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,010 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 99.0 (TID 299) in 5 ms on localhost (executor driver) (21/100)
2018-02-08 15:59:18,011 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 99.0 (TID 301)
2018-02-08 15:59:18,012 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,012 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,012 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 99.0 (TID 300). 2424 bytes result sent to driver
2018-02-08 15:59:18,013 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 99.0 (TID 302, localhost, executor driver, partition 54, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,014 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,014 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,014 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 99.0 (TID 302)
2018-02-08 15:59:18,014 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 99.0 (TID 301). 2424 bytes result sent to driver
2018-02-08 15:59:18,014 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 99.0 (TID 300) in 7 ms on localhost (executor driver) (22/100)
2018-02-08 15:59:18,014 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 99.0 (TID 303, localhost, executor driver, partition 55, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,015 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 99.0 (TID 301) in 5 ms on localhost (executor driver) (23/100)
2018-02-08 15:59:18,015 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 99.0 (TID 303)
2018-02-08 15:59:18,017 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,017 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,018 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 99.0 (TID 302). 2467 bytes result sent to driver
2018-02-08 15:59:18,018 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,018 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,018 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 99.0 (TID 304, localhost, executor driver, partition 56, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,019 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 99.0 (TID 303). 2381 bytes result sent to driver
2018-02-08 15:59:18,020 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 99.0 (TID 305, localhost, executor driver, partition 57, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,020 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 99.0 (TID 304)
2018-02-08 15:59:18,020 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 99.0 (TID 303) in 6 ms on localhost (executor driver) (24/100)
2018-02-08 15:59:18,021 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 99.0 (TID 302) in 8 ms on localhost (executor driver) (25/100)
2018-02-08 15:59:18,021 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 99.0 (TID 305)
2018-02-08 15:59:18,024 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,024 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,024 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,025 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,025 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 99.0 (TID 305). 2424 bytes result sent to driver
2018-02-08 15:59:18,025 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 99.0 (TID 304). 2424 bytes result sent to driver
2018-02-08 15:59:18,026 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 99.0 (TID 306, localhost, executor driver, partition 58, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,026 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 99.0 (TID 307, localhost, executor driver, partition 59, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,026 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 99.0 (TID 306)
2018-02-08 15:59:18,026 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 99.0 (TID 304) in 8 ms on localhost (executor driver) (26/100)
2018-02-08 15:59:18,026 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 99.0 (TID 305) in 6 ms on localhost (executor driver) (27/100)
2018-02-08 15:59:18,027 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 99.0 (TID 307)
2018-02-08 15:59:18,029 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,029 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,030 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,030 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,030 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 99.0 (TID 306). 2424 bytes result sent to driver
2018-02-08 15:59:18,030 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 99.0 (TID 307). 2424 bytes result sent to driver
2018-02-08 15:59:18,030 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 99.0 (TID 308, localhost, executor driver, partition 60, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,030 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 99.0 (TID 306) in 4 ms on localhost (executor driver) (28/100)
2018-02-08 15:59:18,031 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 99.0 (TID 308)
2018-02-08 15:59:18,031 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 99.0 (TID 307) in 5 ms on localhost (executor driver) (29/100)
2018-02-08 15:59:18,031 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 99.0 (TID 309, localhost, executor driver, partition 61, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,031 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 99.0 (TID 309)
2018-02-08 15:59:18,034 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,034 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,035 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 99.0 (TID 308). 2424 bytes result sent to driver
2018-02-08 15:59:18,035 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,035 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,035 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 99.0 (TID 309). 2381 bytes result sent to driver
2018-02-08 15:59:18,036 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 99.0 (TID 310, localhost, executor driver, partition 62, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,036 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 99.0 (TID 311, localhost, executor driver, partition 63, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,036 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 99.0 (TID 308) in 6 ms on localhost (executor driver) (30/100)
2018-02-08 15:59:18,037 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 99.0 (TID 310)
2018-02-08 15:59:18,037 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 99.0 (TID 309) in 6 ms on localhost (executor driver) (31/100)
2018-02-08 15:59:18,037 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 99.0 (TID 311)
2018-02-08 15:59:18,040 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,040 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,040 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,040 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,040 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 99.0 (TID 311). 2424 bytes result sent to driver
2018-02-08 15:59:18,040 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 99.0 (TID 310). 2424 bytes result sent to driver
2018-02-08 15:59:18,041 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 99.0 (TID 312, localhost, executor driver, partition 64, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,041 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 99.0 (TID 312)
2018-02-08 15:59:18,041 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 99.0 (TID 313, localhost, executor driver, partition 65, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,041 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 99.0 (TID 311) in 5 ms on localhost (executor driver) (32/100)
2018-02-08 15:59:18,041 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 99.0 (TID 313)
2018-02-08 15:59:18,043 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 99.0 (TID 310) in 7 ms on localhost (executor driver) (33/100)
2018-02-08 15:59:18,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,045 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 99.0 (TID 313). 2381 bytes result sent to driver
2018-02-08 15:59:18,045 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,045 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,045 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 99.0 (TID 314, localhost, executor driver, partition 67, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,045 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 99.0 (TID 312). 2424 bytes result sent to driver
2018-02-08 15:59:18,045 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 99.0 (TID 313) in 4 ms on localhost (executor driver) (34/100)
2018-02-08 15:59:18,045 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 99.0 (TID 314)
2018-02-08 15:59:18,045 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 99.0 (TID 315, localhost, executor driver, partition 68, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,046 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 99.0 (TID 312) in 4 ms on localhost (executor driver) (35/100)
2018-02-08 15:59:18,046 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 99.0 (TID 315)
2018-02-08 15:59:18,049 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,049 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,049 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,049 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,050 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 99.0 (TID 314). 2467 bytes result sent to driver
2018-02-08 15:59:18,050 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 99.0 (TID 315). 2424 bytes result sent to driver
2018-02-08 15:59:18,050 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 99.0 (TID 316, localhost, executor driver, partition 70, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,051 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 99.0 (TID 317, localhost, executor driver, partition 71, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,051 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 99.0 (TID 316)
2018-02-08 15:59:18,051 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 99.0 (TID 314) in 6 ms on localhost (executor driver) (36/100)
2018-02-08 15:59:18,051 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 99.0 (TID 315) in 6 ms on localhost (executor driver) (37/100)
2018-02-08 15:59:18,051 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 99.0 (TID 317)
2018-02-08 15:59:18,054 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,055 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,054 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,055 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,055 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 99.0 (TID 317). 2424 bytes result sent to driver
2018-02-08 15:59:18,055 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 99.0 (TID 316). 2424 bytes result sent to driver
2018-02-08 15:59:18,055 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 99.0 (TID 318, localhost, executor driver, partition 72, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,056 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 99.0 (TID 317) in 5 ms on localhost (executor driver) (38/100)
2018-02-08 15:59:18,056 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 99.0 (TID 318)
2018-02-08 15:59:18,056 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 99.0 (TID 316) in 6 ms on localhost (executor driver) (39/100)
2018-02-08 15:59:18,056 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 99.0 (TID 319, localhost, executor driver, partition 73, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,056 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 99.0 (TID 319)
2018-02-08 15:59:18,059 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,059 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,059 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,059 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,059 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 99.0 (TID 318). 2381 bytes result sent to driver
2018-02-08 15:59:18,059 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 99.0 (TID 319). 2424 bytes result sent to driver
2018-02-08 15:59:18,060 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 99.0 (TID 320, localhost, executor driver, partition 74, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,060 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 99.0 (TID 318) in 5 ms on localhost (executor driver) (40/100)
2018-02-08 15:59:18,060 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 99.0 (TID 320)
2018-02-08 15:59:18,060 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 99.0 (TID 321, localhost, executor driver, partition 75, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,060 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 99.0 (TID 321)
2018-02-08 15:59:18,060 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 99.0 (TID 319) in 4 ms on localhost (executor driver) (41/100)
2018-02-08 15:59:18,063 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,063 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,063 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,063 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,063 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 99.0 (TID 320). 2424 bytes result sent to driver
2018-02-08 15:59:18,063 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 99.0 (TID 321). 2424 bytes result sent to driver
2018-02-08 15:59:18,064 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 99.0 (TID 322, localhost, executor driver, partition 76, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,065 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 99.0 (TID 322)
2018-02-08 15:59:18,065 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 99.0 (TID 323, localhost, executor driver, partition 78, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,065 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 99.0 (TID 321) in 5 ms on localhost (executor driver) (42/100)
2018-02-08 15:59:18,065 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 99.0 (TID 323)
2018-02-08 15:59:18,065 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 99.0 (TID 320) in 5 ms on localhost (executor driver) (43/100)
2018-02-08 15:59:18,069 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,069 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,069 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,069 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,070 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 99.0 (TID 322). 2381 bytes result sent to driver
2018-02-08 15:59:18,070 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 99.0 (TID 323). 2381 bytes result sent to driver
2018-02-08 15:59:18,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 99.0 (TID 324, localhost, executor driver, partition 79, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,070 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 99.0 (TID 324)
2018-02-08 15:59:18,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 99.0 (TID 322) in 6 ms on localhost (executor driver) (44/100)
2018-02-08 15:59:18,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 99.0 (TID 323) in 5 ms on localhost (executor driver) (45/100)
2018-02-08 15:59:18,070 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 99.0 (TID 325, localhost, executor driver, partition 80, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,071 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 99.0 (TID 325)
2018-02-08 15:59:18,073 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,073 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,073 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,073 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,073 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 99.0 (TID 324). 2381 bytes result sent to driver
2018-02-08 15:59:18,073 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 99.0 (TID 325). 2381 bytes result sent to driver
2018-02-08 15:59:18,074 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 99.0 (TID 326, localhost, executor driver, partition 81, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,074 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 99.0 (TID 324) in 4 ms on localhost (executor driver) (46/100)
2018-02-08 15:59:18,074 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 99.0 (TID 326)
2018-02-08 15:59:18,074 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 99.0 (TID 325) in 4 ms on localhost (executor driver) (47/100)
2018-02-08 15:59:18,074 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 99.0 (TID 327, localhost, executor driver, partition 82, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,074 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 99.0 (TID 327)
2018-02-08 15:59:18,078 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,078 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,078 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,078 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,079 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 99.0 (TID 327). 2467 bytes result sent to driver
2018-02-08 15:59:18,079 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 99.0 (TID 326). 2467 bytes result sent to driver
2018-02-08 15:59:18,079 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 99.0 (TID 328, localhost, executor driver, partition 83, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,079 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 99.0 (TID 328)
2018-02-08 15:59:18,079 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 99.0 (TID 329, localhost, executor driver, partition 84, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,079 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 99.0 (TID 326) in 5 ms on localhost (executor driver) (48/100)
2018-02-08 15:59:18,079 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 99.0 (TID 329)
2018-02-08 15:59:18,080 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 99.0 (TID 327) in 6 ms on localhost (executor driver) (49/100)
2018-02-08 15:59:18,082 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,082 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,085 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,085 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,086 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 99.0 (TID 329). 2424 bytes result sent to driver
2018-02-08 15:59:18,086 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 99.0 (TID 328). 2424 bytes result sent to driver
2018-02-08 15:59:18,086 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 99.0 (TID 330, localhost, executor driver, partition 85, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,086 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 99.0 (TID 331, localhost, executor driver, partition 86, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,086 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 99.0 (TID 330)
2018-02-08 15:59:18,087 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 99.0 (TID 328) in 8 ms on localhost (executor driver) (50/100)
2018-02-08 15:59:18,091 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,091 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,091 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 99.0 (TID 329) in 12 ms on localhost (executor driver) (51/100)
2018-02-08 15:59:18,091 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 99.0 (TID 331)
2018-02-08 15:59:18,091 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 99.0 (TID 330). 2381 bytes result sent to driver
2018-02-08 15:59:18,092 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 99.0 (TID 332, localhost, executor driver, partition 87, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,093 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 99.0 (TID 330) in 7 ms on localhost (executor driver) (52/100)
2018-02-08 15:59:18,093 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 99.0 (TID 332)
2018-02-08 15:59:18,097 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,097 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,097 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,097 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,097 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 99.0 (TID 331). 2467 bytes result sent to driver
2018-02-08 15:59:18,097 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 99.0 (TID 332). 2381 bytes result sent to driver
2018-02-08 15:59:18,098 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 99.0 (TID 333, localhost, executor driver, partition 88, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,098 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 99.0 (TID 331) in 12 ms on localhost (executor driver) (53/100)
2018-02-08 15:59:18,098 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 99.0 (TID 333)
2018-02-08 15:59:18,098 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 99.0 (TID 332) in 6 ms on localhost (executor driver) (54/100)
2018-02-08 15:59:18,098 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 99.0 (TID 334, localhost, executor driver, partition 90, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,098 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 99.0 (TID 334)
2018-02-08 15:59:18,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,104 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,105 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 99.0 (TID 333). 2424 bytes result sent to driver
2018-02-08 15:59:18,105 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 99.0 (TID 335, localhost, executor driver, partition 91, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,105 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 99.0 (TID 333) in 7 ms on localhost (executor driver) (55/100)
2018-02-08 15:59:18,105 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 99.0 (TID 335)
2018-02-08 15:59:18,105 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,106 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,106 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 99.0 (TID 334). 2424 bytes result sent to driver
2018-02-08 15:59:18,106 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 99.0 (TID 336, localhost, executor driver, partition 92, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,107 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 99.0 (TID 334) in 9 ms on localhost (executor driver) (56/100)
2018-02-08 15:59:18,107 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 99.0 (TID 336)
2018-02-08 15:59:18,110 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,110 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,111 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 99.0 (TID 335). 2467 bytes result sent to driver
2018-02-08 15:59:18,112 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,112 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,112 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 99.0 (TID 337, localhost, executor driver, partition 93, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,113 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 99.0 (TID 335) in 8 ms on localhost (executor driver) (57/100)
2018-02-08 15:59:18,113 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 99.0 (TID 336). 2467 bytes result sent to driver
2018-02-08 15:59:18,113 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 99.0 (TID 337)
2018-02-08 15:59:18,113 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 99.0 (TID 338, localhost, executor driver, partition 94, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 99.0 (TID 336) in 8 ms on localhost (executor driver) (58/100)
2018-02-08 15:59:18,114 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 99.0 (TID 338)
2018-02-08 15:59:18,118 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,118 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,119 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 99.0 (TID 337). 2424 bytes result sent to driver
2018-02-08 15:59:18,119 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,120 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,120 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 99.0 (TID 339, localhost, executor driver, partition 95, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,120 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 99.0 (TID 337) in 8 ms on localhost (executor driver) (59/100)
2018-02-08 15:59:18,120 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 99.0 (TID 338). 2424 bytes result sent to driver
2018-02-08 15:59:18,120 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 99.0 (TID 339)
2018-02-08 15:59:18,121 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 99.0 (TID 340, localhost, executor driver, partition 96, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,121 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 99.0 (TID 340)
2018-02-08 15:59:18,121 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 99.0 (TID 338) in 8 ms on localhost (executor driver) (60/100)
2018-02-08 15:59:18,126 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,126 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,127 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 99.0 (TID 340). 2467 bytes result sent to driver
2018-02-08 15:59:18,128 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,128 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,128 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 99.0 (TID 341, localhost, executor driver, partition 97, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,129 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 99.0 (TID 340) in 8 ms on localhost (executor driver) (61/100)
2018-02-08 15:59:18,129 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 99.0 (TID 339). 2467 bytes result sent to driver
2018-02-08 15:59:18,129 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 99.0 (TID 341)
2018-02-08 15:59:18,129 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 99.0 (TID 342, localhost, executor driver, partition 98, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,130 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 99.0 (TID 339) in 11 ms on localhost (executor driver) (62/100)
2018-02-08 15:59:18,130 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 99.0 (TID 342)
2018-02-08 15:59:18,134 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,134 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,134 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,135 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 99.0 (TID 341). 2381 bytes result sent to driver
2018-02-08 15:59:18,135 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,135 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 99.0 (TID 343, localhost, executor driver, partition 99, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,135 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 99.0 (TID 342). 2424 bytes result sent to driver
2018-02-08 15:59:18,135 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 99.0 (TID 341) in 7 ms on localhost (executor driver) (63/100)
2018-02-08 15:59:18,135 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 99.0 (TID 343)
2018-02-08 15:59:18,137 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 99.0 (TID 344, localhost, executor driver, partition 100, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,137 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 99.0 (TID 342) in 8 ms on localhost (executor driver) (64/100)
2018-02-08 15:59:18,137 INFO[org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 99.0 (TID 344)
2018-02-08 15:59:18,141 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,141 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,141 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,142 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,142 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 99.0 (TID 343). 2467 bytes result sent to driver
2018-02-08 15:59:18,142 INFO[org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 99.0 (TID 344). 2467 bytes result sent to driver
2018-02-08 15:59:18,142 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 99.0 (TID 345, localhost, executor driver, partition 101, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,142 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 99.0 (TID 343) in 7 ms on localhost (executor driver) (65/100)
2018-02-08 15:59:18,142 INFO[org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 99.0 (TID 345)
2018-02-08 15:59:18,143 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 99.0 (TID 346, localhost, executor driver, partition 104, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,143 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 99.0 (TID 344) in 7 ms on localhost (executor driver) (66/100)
2018-02-08 15:59:18,143 INFO[org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 99.0 (TID 346)
2018-02-08 15:59:18,146 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,146 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,147 INFO[org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 99.0 (TID 345). 2424 bytes result sent to driver
2018-02-08 15:59:18,147 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,147 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,147 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 99.0 (TID 347, localhost, executor driver, partition 106, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,149 INFO[org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 99.0 (TID 347)
2018-02-08 15:59:18,149 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 99.0 (TID 345) in 7 ms on localhost (executor driver) (67/100)
2018-02-08 15:59:18,149 INFO[org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 99.0 (TID 346). 2424 bytes result sent to driver
2018-02-08 15:59:18,149 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 99.0 (TID 348, localhost, executor driver, partition 108, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,150 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 99.0 (TID 346) in 7 ms on localhost (executor driver) (68/100)
2018-02-08 15:59:18,150 INFO[org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 99.0 (TID 348)
2018-02-08 15:59:18,153 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,153 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,153 INFO[org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 99.0 (TID 347). 2381 bytes result sent to driver
2018-02-08 15:59:18,153 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,154 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 99.0 (TID 349, localhost, executor driver, partition 109, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 99.0 (TID 347) in 7 ms on localhost (executor driver) (69/100)
2018-02-08 15:59:18,154 INFO[org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 99.0 (TID 348). 2424 bytes result sent to driver
2018-02-08 15:59:18,154 INFO[org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 99.0 (TID 349)
2018-02-08 15:59:18,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 99.0 (TID 350, localhost, executor driver, partition 110, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 99.0 (TID 348) in 5 ms on localhost (executor driver) (70/100)
2018-02-08 15:59:18,154 INFO[org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 99.0 (TID 350)
2018-02-08 15:59:18,157 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,157 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,157 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,157 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,158 INFO[org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 99.0 (TID 349). 2467 bytes result sent to driver
2018-02-08 15:59:18,158 INFO[org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 99.0 (TID 350). 2467 bytes result sent to driver
2018-02-08 15:59:18,158 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 99.0 (TID 351, localhost, executor driver, partition 111, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,158 INFO[org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 99.0 (TID 351)
2018-02-08 15:59:18,158 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 99.0 (TID 349) in 4 ms on localhost (executor driver) (71/100)
2018-02-08 15:59:18,158 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 99.0 (TID 352, localhost, executor driver, partition 112, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,159 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 99.0 (TID 350) in 5 ms on localhost (executor driver) (72/100)
2018-02-08 15:59:18,159 INFO[org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 99.0 (TID 352)
2018-02-08 15:59:18,161 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,161 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,161 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,162 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,162 INFO[org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 99.0 (TID 351). 2424 bytes result sent to driver
2018-02-08 15:59:18,162 INFO[org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 99.0 (TID 352). 2424 bytes result sent to driver
2018-02-08 15:59:18,162 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 99.0 (TID 353, localhost, executor driver, partition 113, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,162 INFO[org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 99.0 (TID 353)
2018-02-08 15:59:18,162 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 99.0 (TID 354, localhost, executor driver, partition 114, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,163 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 99.0 (TID 351) in 5 ms on localhost (executor driver) (73/100)
2018-02-08 15:59:18,163 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 99.0 (TID 352) in 5 ms on localhost (executor driver) (74/100)
2018-02-08 15:59:18,164 INFO[org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 99.0 (TID 354)
2018-02-08 15:59:18,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,167 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,168 INFO[org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 99.0 (TID 354). 2424 bytes result sent to driver
2018-02-08 15:59:18,168 INFO[org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 99.0 (TID 353). 2424 bytes result sent to driver
2018-02-08 15:59:18,168 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 99.0 (TID 355, localhost, executor driver, partition 115, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,168 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 99.0 (TID 354) in 6 ms on localhost (executor driver) (75/100)
2018-02-08 15:59:18,168 INFO[org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 99.0 (TID 355)
2018-02-08 15:59:18,169 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 99.0 (TID 353) in 6 ms on localhost (executor driver) (76/100)
2018-02-08 15:59:18,169 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 99.0 (TID 356, localhost, executor driver, partition 116, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,169 INFO[org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 99.0 (TID 356)
2018-02-08 15:59:18,172 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,172 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,172 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,172 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,173 INFO[org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 99.0 (TID 355). 2424 bytes result sent to driver
2018-02-08 15:59:18,173 INFO[org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 99.0 (TID 356). 2424 bytes result sent to driver
2018-02-08 15:59:18,173 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 99.0 (TID 357, localhost, executor driver, partition 117, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,173 INFO[org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 99.0 (TID 357)
2018-02-08 15:59:18,173 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 99.0 (TID 355) in 5 ms on localhost (executor driver) (77/100)
2018-02-08 15:59:18,173 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 99.0 (TID 358, localhost, executor driver, partition 118, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,173 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 99.0 (TID 356) in 4 ms on localhost (executor driver) (78/100)
2018-02-08 15:59:18,173 INFO[org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 99.0 (TID 358)
2018-02-08 15:59:18,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,176 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,176 INFO[org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 99.0 (TID 357). 2381 bytes result sent to driver
2018-02-08 15:59:18,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 99.0 (TID 359, localhost, executor driver, partition 119, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,184 INFO[org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 99.0 (TID 358). 2424 bytes result sent to driver
2018-02-08 15:59:18,185 INFO[org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 99.0 (TID 359)
2018-02-08 15:59:18,185 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 99.0 (TID 357) in 12 ms on localhost (executor driver) (79/100)
2018-02-08 15:59:18,185 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_20_piece0 on 192.168.11.26:62887 in memory (size: 32.6 KB, free: 631.6 MB)
2018-02-08 15:59:18,185 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 99.0 (TID 360, localhost, executor driver, partition 120, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,186 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 99.0 (TID 358) in 13 ms on localhost (executor driver) (80/100)
2018-02-08 15:59:18,186 INFO[org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 99.0 (TID 360)
2018-02-08 15:59:18,187 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_21_piece0 on 192.168.11.26:62887 in memory (size: 24.7 KB, free: 631.7 MB)
2018-02-08 15:59:18,188 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_23_piece0 on 192.168.11.26:62887 in memory (size: 24.7 KB, free: 631.7 MB)
2018-02-08 15:59:18,189 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_22_piece0 on 192.168.11.26:62887 in memory (size: 24.7 KB, free: 631.7 MB)
2018-02-08 15:59:18,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,205 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,206 INFO[org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 99.0 (TID 359). 2467 bytes result sent to driver
2018-02-08 15:59:18,206 INFO[org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 99.0 (TID 360). 2424 bytes result sent to driver
2018-02-08 15:59:18,206 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 99.0 (TID 361, localhost, executor driver, partition 121, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,206 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 99.0 (TID 359) in 29 ms on localhost (executor driver) (81/100)
2018-02-08 15:59:18,206 INFO[org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 99.0 (TID 361)
2018-02-08 15:59:18,207 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 99.0 (TID 360) in 22 ms on localhost (executor driver) (82/100)
2018-02-08 15:59:18,207 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 99.0 (TID 362, localhost, executor driver, partition 123, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,207 INFO[org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 99.0 (TID 362)
2018-02-08 15:59:18,210 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,210 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,210 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,210 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,211 INFO[org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 99.0 (TID 361). 2424 bytes result sent to driver
2018-02-08 15:59:18,211 INFO[org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 99.0 (TID 362). 2424 bytes result sent to driver
2018-02-08 15:59:18,211 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 99.0 (TID 363, localhost, executor driver, partition 124, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:18,211 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 99.0 (TID 361) in 5 ms on localhost (executor driver) (83/100)
2018-02-08 15:59:18,211 INFO[org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 99.0 (TID 363)
2018-02-08 15:59:18,211 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 99.0 (TID 362) in 4 ms on localhost (executor driver) (84/100)
2018-02-08 15:59:18,212 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 99.0 (TID 364, localhost, executor driver, partition 30, ANY, 4726 bytes)
2018-02-08 15:59:18,212 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 99.0 (TID 364)
2018-02-08 15:59:18,214 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,214 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,214 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,215 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,215 INFO[org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 99.0 (TID 363). 2424 bytes result sent to driver
2018-02-08 15:59:18,215 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 99.0 (TID 365, localhost, executor driver, partition 43, ANY, 4726 bytes)
2018-02-08 15:59:18,216 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 99.0 (TID 363) in 5 ms on localhost (executor driver) (85/100)
2018-02-08 15:59:18,216 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 99.0 (TID 365)
2018-02-08 15:59:18,219 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,219 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,230 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 99.0 (TID 364). 2650 bytes result sent to driver
2018-02-08 15:59:18,230 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 99.0 (TID 366, localhost, executor driver, partition 48, ANY, 4726 bytes)
2018-02-08 15:59:18,231 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 99.0 (TID 364) in 19 ms on localhost (executor driver) (86/100)
2018-02-08 15:59:18,231 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 99.0 (TID 366)
2018-02-08 15:59:18,235 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,235 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,237 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 99.0 (TID 365). 2652 bytes result sent to driver
2018-02-08 15:59:18,237 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 99.0 (TID 367, localhost, executor driver, partition 49, ANY, 4726 bytes)
2018-02-08 15:59:18,238 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 99.0 (TID 365) in 23 ms on localhost (executor driver) (87/100)
2018-02-08 15:59:18,238 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 99.0 (TID 367)
2018-02-08 15:59:18,242 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,242 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,255 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 99.0 (TID 367). 2722 bytes result sent to driver
2018-02-08 15:59:18,259 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 99.0 (TID 368, localhost, executor driver, partition 51, ANY, 4726 bytes)
2018-02-08 15:59:18,259 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 99.0 (TID 366). 2696 bytes result sent to driver
2018-02-08 15:59:18,260 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 99.0 (TID 368)
2018-02-08 15:59:18,260 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 99.0 (TID 367) in 23 ms on localhost (executor driver) (88/100)
2018-02-08 15:59:18,260 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 99.0 (TID 369, localhost, executor driver, partition 53, ANY, 4726 bytes)
2018-02-08 15:59:18,260 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 99.0 (TID 366) in 30 ms on localhost (executor driver) (89/100)
2018-02-08 15:59:18,261 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 99.0 (TID 369)
2018-02-08 15:59:18,264 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,264 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,264 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,265 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,280 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 99.0 (TID 369). 2653 bytes result sent to driver
2018-02-08 15:59:18,284 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 99.0 (TID 368). 2655 bytes result sent to driver
2018-02-08 15:59:18,285 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 99.0 (TID 370, localhost, executor driver, partition 66, ANY, 4726 bytes)
2018-02-08 15:59:18,286 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 99.0 (TID 371, localhost, executor driver, partition 69, ANY, 4726 bytes)
2018-02-08 15:59:18,286 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 99.0 (TID 369) in 26 ms on localhost (executor driver) (90/100)
2018-02-08 15:59:18,286 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 99.0 (TID 368) in 27 ms on localhost (executor driver) (91/100)
2018-02-08 15:59:18,286 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 99.0 (TID 370)
2018-02-08 15:59:18,287 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 99.0 (TID 371)
2018-02-08 15:59:18,290 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,290 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,301 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,301 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,318 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 99.0 (TID 371). 2653 bytes result sent to driver
2018-02-08 15:59:18,319 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 99.0 (TID 372, localhost, executor driver, partition 77, ANY, 4726 bytes)
2018-02-08 15:59:18,319 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 99.0 (TID 371) in 33 ms on localhost (executor driver) (92/100)
2018-02-08 15:59:18,319 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 99.0 (TID 372)
2018-02-08 15:59:18,328 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,328 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:18,336 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 99.0 (TID 370). 2610 bytes result sent to driver
2018-02-08 15:59:18,336 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 99.0 (TID 373, localhost, executor driver, partition 89, ANY, 4726 bytes)
2018-02-08 15:59:18,337 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 99.0 (TID 370) in 52 ms on localhost (executor driver) (93/100)
2018-02-08 15:59:18,337 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 99.0 (TID 373)
2018-02-08 15:59:18,342 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 99.0 (TID 372). 2666 bytes result sent to driver
2018-02-08 15:59:18,343 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 99.0 (TID 374, localhost, executor driver, partition 102, ANY, 4726 bytes)
2018-02-08 15:59:18,343 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 99.0 (TID 372) in 24 ms on localhost (executor driver) (94/100)
2018-02-08 15:59:18,343 INFO[org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 99.0 (TID 374)
2018-02-08 15:59:18,343 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 20 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,343 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,349 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,349 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,368 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 99.0 (TID 373). 2761 bytes result sent to driver
2018-02-08 15:59:18,368 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 99.0 (TID 375, localhost, executor driver, partition 103, ANY, 4726 bytes)
2018-02-08 15:59:18,369 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 99.0 (TID 373) in 33 ms on localhost (executor driver) (95/100)
2018-02-08 15:59:18,369 INFO[org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 99.0 (TID 375)
2018-02-08 15:59:18,376 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,376 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,380 INFO[org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 99.0 (TID 374). 2652 bytes result sent to driver
2018-02-08 15:59:18,380 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 99.0 (TID 376, localhost, executor driver, partition 105, ANY, 4726 bytes)
2018-02-08 15:59:18,381 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 99.0 (TID 374) in 39 ms on localhost (executor driver) (96/100)
2018-02-08 15:59:18,381 INFO[org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 99.0 (TID 376)
2018-02-08 15:59:18,384 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,384 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,389 INFO[org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 99.0 (TID 375). 2653 bytes result sent to driver
2018-02-08 15:59:18,390 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 99.0 (TID 377, localhost, executor driver, partition 107, ANY, 4726 bytes)
2018-02-08 15:59:18,390 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 99.0 (TID 375) in 22 ms on localhost (executor driver) (97/100)
2018-02-08 15:59:18,391 INFO[org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 99.0 (TID 377)
2018-02-08 15:59:18,394 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,394 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,396 INFO[org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 99.0 (TID 376). 2651 bytes result sent to driver
2018-02-08 15:59:18,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 99.0 (TID 378, localhost, executor driver, partition 122, ANY, 4726 bytes)
2018-02-08 15:59:18,397 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 99.0 (TID 376) in 17 ms on localhost (executor driver) (98/100)
2018-02-08 15:59:18,397 INFO[org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 99.0 (TID 378)
2018-02-08 15:59:18,401 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:18,401 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:18,405 INFO[org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 99.0 (TID 377). 2610 bytes result sent to driver
2018-02-08 15:59:18,406 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 99.0 (TID 377) in 16 ms on localhost (executor driver) (99/100)
2018-02-08 15:59:18,412 INFO[org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 99.0 (TID 378). 2648 bytes result sent to driver
2018-02-08 15:59:18,412 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 99.0 (TID 378) in 16 ms on localhost (executor driver) (100/100)
2018-02-08 15:59:18,413 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 99.0, whose tasks have all completed, from pool 
2018-02-08 15:59:18,413 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 99 (show at MachineLeaningFiltering.java:42) finished in 0.454 s
2018-02-08 15:59:18,415 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 8 finished: show at MachineLeaningFiltering.java:42, took 0.470675 s
2018-02-08 15:59:18,432 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.452165 ms
2018-02-08 15:59:18,774 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 15.811525 ms
2018-02-08 15:59:18,802 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 16.317125 ms
2018-02-08 15:59:18,818 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:46
2018-02-08 15:59:18,822 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 161 (show at MachineLeaningFiltering.java:46)
2018-02-08 15:59:18,822 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 9 (show at MachineLeaningFiltering.java:46) with 1 output partitions
2018-02-08 15:59:18,822 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 115 (show at MachineLeaningFiltering.java:46)
2018-02-08 15:59:18,822 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 114)
2018-02-08 15:59:18,822 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 114)
2018-02-08 15:59:18,825 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 114 (MapPartitionsRDD[161] at show at MachineLeaningFiltering.java:46), which has no missing parents
2018-02-08 15:59:18,840 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25 stored as values in memory (estimated size 91.3 KB, free 631.2 MB)
2018-02-08 15:59:18,843 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_25_piece0 stored as bytes in memory (estimated size 32.7 KB, free 631.2 MB)
2018-02-08 15:59:18,844 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_25_piece0 in memory on 192.168.11.26:62887 (size: 32.7 KB, free: 631.7 MB)
2018-02-08 15:59:18,844 INFO[org.apache.spark.SparkContext:54] - Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:18,844 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 100 missing tasks from ShuffleMapStage 114 (MapPartitionsRDD[161] at show at MachineLeaningFiltering.java:46) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2018-02-08 15:59:18,844 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 114.0 with 100 tasks
2018-02-08 15:59:18,845 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 114.0 (TID 379, localhost, executor driver, partition 0, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:18,846 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 114.0 (TID 380, localhost, executor driver, partition 1, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:18,846 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 114.0 (TID 379)
2018-02-08 15:59:18,849 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 114.0 (TID 380)
2018-02-08 15:59:18,851 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:18,854 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:18,854 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:18,854 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:18,871 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.153604 ms
2018-02-08 15:59:18,912 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 114.0 (TID 380). 2594 bytes result sent to driver
2018-02-08 15:59:18,913 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 114.0 (TID 381, localhost, executor driver, partition 2, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:18,913 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 114.0 (TID 380) in 67 ms on localhost (executor driver) (1/100)
2018-02-08 15:59:18,913 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 114.0 (TID 381)
2018-02-08 15:59:18,917 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 114.0 (TID 379). 2637 bytes result sent to driver
2018-02-08 15:59:18,917 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:18,917 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 114.0 (TID 382, localhost, executor driver, partition 3, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:18,918 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:18,919 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 114.0 (TID 379) in 74 ms on localhost (executor driver) (2/100)
2018-02-08 15:59:18,921 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 114.0 (TID 382)
2018-02-08 15:59:18,925 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:18,926 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:18,976 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 114.0 (TID 381). 2594 bytes result sent to driver
2018-02-08 15:59:18,978 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 114.0 (TID 383, localhost, executor driver, partition 4, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:18,993 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 114.0 (TID 381) in 80 ms on localhost (executor driver) (3/100)
2018-02-08 15:59:19,024 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 114.0 (TID 382). 2594 bytes result sent to driver
2018-02-08 15:59:19,024 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 114.0 (TID 383)
2018-02-08 15:59:19,035 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:19,035 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:19,056 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 114.0 (TID 384, localhost, executor driver, partition 5, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,056 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 114.0 (TID 382) in 139 ms on localhost (executor driver) (4/100)
2018-02-08 15:59:19,058 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 114.0 (TID 384)
2018-02-08 15:59:19,068 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:19,069 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:19,142 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 114.0 (TID 384). 2594 bytes result sent to driver
2018-02-08 15:59:19,144 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 114.0 (TID 385, localhost, executor driver, partition 6, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,144 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 114.0 (TID 384) in 89 ms on localhost (executor driver) (5/100)
2018-02-08 15:59:19,147 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 114.0 (TID 385)
2018-02-08 15:59:19,149 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 114.0 (TID 383). 2594 bytes result sent to driver
2018-02-08 15:59:19,150 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:19,151 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:19,152 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 114.0 (TID 386, localhost, executor driver, partition 7, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,154 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 114.0 (TID 383) in 177 ms on localhost (executor driver) (6/100)
2018-02-08 15:59:19,154 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 114.0 (TID 386)
2018-02-08 15:59:19,159 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:19,160 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:19,201 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 114.0 (TID 385). 2594 bytes result sent to driver
2018-02-08 15:59:19,202 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 114.0 (TID 387, localhost, executor driver, partition 8, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,203 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 114.0 (TID 385) in 60 ms on localhost (executor driver) (7/100)
2018-02-08 15:59:19,203 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 114.0 (TID 387)
2018-02-08 15:59:19,209 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:19,210 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:19,261 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 114.0 (TID 386). 2637 bytes result sent to driver
2018-02-08 15:59:19,263 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 114.0 (TID 388, localhost, executor driver, partition 9, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,264 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 114.0 (TID 386) in 112 ms on localhost (executor driver) (8/100)
2018-02-08 15:59:19,264 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 114.0 (TID 388)
2018-02-08 15:59:19,277 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:19,278 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_0 locally
2018-02-08 15:59:19,287 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 114.0 (TID 387). 2594 bytes result sent to driver
2018-02-08 15:59:19,288 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 114.0 (TID 389, localhost, executor driver, partition 10, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,288 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 114.0 (TID 389)
2018-02-08 15:59:19,288 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 114.0 (TID 387) in 86 ms on localhost (executor driver) (9/100)
2018-02-08 15:59:19,295 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:19,295 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:19,361 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 114.0 (TID 389). 2594 bytes result sent to driver
2018-02-08 15:59:19,362 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 114.0 (TID 390, localhost, executor driver, partition 11, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,362 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 114.0 (TID 390)
2018-02-08 15:59:19,362 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 114.0 (TID 389) in 74 ms on localhost (executor driver) (10/100)
2018-02-08 15:59:19,366 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:19,367 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:19,406 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 114.0 (TID 388). 2594 bytes result sent to driver
2018-02-08 15:59:19,406 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 114.0 (TID 391, localhost, executor driver, partition 12, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,407 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 114.0 (TID 391)
2018-02-08 15:59:19,407 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 114.0 (TID 388) in 144 ms on localhost (executor driver) (11/100)
2018-02-08 15:59:19,412 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:19,413 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:19,447 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 114.0 (TID 390). 2594 bytes result sent to driver
2018-02-08 15:59:19,448 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 114.0 (TID 392, localhost, executor driver, partition 13, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,449 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 114.0 (TID 390) in 87 ms on localhost (executor driver) (12/100)
2018-02-08 15:59:19,450 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 114.0 (TID 392)
2018-02-08 15:59:19,455 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:19,456 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:19,485 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 114.0 (TID 391). 2594 bytes result sent to driver
2018-02-08 15:59:19,486 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 114.0 (TID 393, localhost, executor driver, partition 14, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,486 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 114.0 (TID 393)
2018-02-08 15:59:19,486 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 114.0 (TID 391) in 80 ms on localhost (executor driver) (13/100)
2018-02-08 15:59:19,491 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:19,493 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:19,534 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 114.0 (TID 392). 2637 bytes result sent to driver
2018-02-08 15:59:19,534 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 114.0 (TID 394, localhost, executor driver, partition 15, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,534 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 114.0 (TID 394)
2018-02-08 15:59:19,534 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 114.0 (TID 392) in 86 ms on localhost (executor driver) (14/100)
2018-02-08 15:59:19,542 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:19,543 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:19,559 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 114.0 (TID 393). 2637 bytes result sent to driver
2018-02-08 15:59:19,559 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 114.0 (TID 395, localhost, executor driver, partition 16, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,559 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 114.0 (TID 395)
2018-02-08 15:59:19,559 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 114.0 (TID 393) in 73 ms on localhost (executor driver) (15/100)
2018-02-08 15:59:19,564 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:19,565 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:19,621 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 114.0 (TID 395). 2637 bytes result sent to driver
2018-02-08 15:59:19,623 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 114.0 (TID 396, localhost, executor driver, partition 17, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,623 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 114.0 (TID 396)
2018-02-08 15:59:19,623 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 114.0 (TID 395) in 64 ms on localhost (executor driver) (16/100)
2018-02-08 15:59:19,629 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:19,630 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:19,680 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 114.0 (TID 394). 2594 bytes result sent to driver
2018-02-08 15:59:19,682 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 114.0 (TID 397, localhost, executor driver, partition 18, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,683 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 114.0 (TID 394) in 149 ms on localhost (executor driver) (17/100)
2018-02-08 15:59:19,683 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 114.0 (TID 397)
2018-02-08 15:59:19,691 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:19,692 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:19,704 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 114.0 (TID 396). 2594 bytes result sent to driver
2018-02-08 15:59:19,704 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 114.0 (TID 398, localhost, executor driver, partition 19, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,704 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 114.0 (TID 396) in 81 ms on localhost (executor driver) (18/100)
2018-02-08 15:59:19,704 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 114.0 (TID 398)
2018-02-08 15:59:19,710 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:19,710 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_1 locally
2018-02-08 15:59:19,772 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 114.0 (TID 397). 2637 bytes result sent to driver
2018-02-08 15:59:19,772 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 114.0 (TID 399, localhost, executor driver, partition 20, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,773 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 114.0 (TID 397) in 91 ms on localhost (executor driver) (19/100)
2018-02-08 15:59:19,773 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 114.0 (TID 399)
2018-02-08 15:59:19,776 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 114.0 (TID 398). 2594 bytes result sent to driver
2018-02-08 15:59:19,776 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 114.0 (TID 398) in 72 ms on localhost (executor driver) (20/100)
2018-02-08 15:59:19,777 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 114.0 (TID 400, localhost, executor driver, partition 21, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,777 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:19,778 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 114.0 (TID 400)
2018-02-08 15:59:19,779 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:19,783 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:19,784 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:19,855 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 114.0 (TID 399). 2594 bytes result sent to driver
2018-02-08 15:59:19,856 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 114.0 (TID 401, localhost, executor driver, partition 22, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,856 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 114.0 (TID 399) in 84 ms on localhost (executor driver) (21/100)
2018-02-08 15:59:19,856 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 114.0 (TID 401)
2018-02-08 15:59:19,865 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:19,867 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:19,870 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 114.0 (TID 400). 2637 bytes result sent to driver
2018-02-08 15:59:19,871 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 114.0 (TID 402, localhost, executor driver, partition 23, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,871 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 114.0 (TID 400) in 94 ms on localhost (executor driver) (22/100)
2018-02-08 15:59:19,871 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 114.0 (TID 402)
2018-02-08 15:59:19,875 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:19,876 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:19,932 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 114.0 (TID 401). 2637 bytes result sent to driver
2018-02-08 15:59:19,933 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 114.0 (TID 403, localhost, executor driver, partition 24, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,935 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 114.0 (TID 401) in 79 ms on localhost (executor driver) (23/100)
2018-02-08 15:59:19,936 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 114.0 (TID 403)
2018-02-08 15:59:19,942 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:19,943 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:19,981 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 114.0 (TID 402). 2637 bytes result sent to driver
2018-02-08 15:59:19,981 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 114.0 (TID 404, localhost, executor driver, partition 25, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:19,982 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 114.0 (TID 404)
2018-02-08 15:59:19,983 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 114.0 (TID 402) in 113 ms on localhost (executor driver) (24/100)
2018-02-08 15:59:19,986 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:19,987 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:20,009 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 114.0 (TID 403). 2637 bytes result sent to driver
2018-02-08 15:59:20,010 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 114.0 (TID 405, localhost, executor driver, partition 26, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,010 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 114.0 (TID 405)
2018-02-08 15:59:20,010 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 114.0 (TID 403) in 77 ms on localhost (executor driver) (25/100)
2018-02-08 15:59:20,016 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:20,018 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:20,048 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 114.0 (TID 404). 2637 bytes result sent to driver
2018-02-08 15:59:20,049 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 114.0 (TID 406, localhost, executor driver, partition 27, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,049 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 114.0 (TID 406)
2018-02-08 15:59:20,049 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 114.0 (TID 404) in 68 ms on localhost (executor driver) (26/100)
2018-02-08 15:59:20,054 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:20,056 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:20,100 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 114.0 (TID 405). 2680 bytes result sent to driver
2018-02-08 15:59:20,100 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 114.0 (TID 407, localhost, executor driver, partition 28, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,100 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 114.0 (TID 407)
2018-02-08 15:59:20,101 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 114.0 (TID 405) in 91 ms on localhost (executor driver) (27/100)
2018-02-08 15:59:20,106 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:20,107 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:20,123 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 114.0 (TID 406). 2594 bytes result sent to driver
2018-02-08 15:59:20,124 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 114.0 (TID 408, localhost, executor driver, partition 29, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,124 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 114.0 (TID 408)
2018-02-08 15:59:20,124 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 114.0 (TID 406) in 76 ms on localhost (executor driver) (28/100)
2018-02-08 15:59:20,129 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:20,130 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_2 locally
2018-02-08 15:59:20,191 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 114.0 (TID 408). 2594 bytes result sent to driver
2018-02-08 15:59:20,191 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 114.0 (TID 409, localhost, executor driver, partition 30, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,192 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 114.0 (TID 408) in 68 ms on localhost (executor driver) (29/100)
2018-02-08 15:59:20,193 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 114.0 (TID 409)
2018-02-08 15:59:20,202 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:20,203 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:20,204 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 114.0 (TID 407). 2594 bytes result sent to driver
2018-02-08 15:59:20,204 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 114.0 (TID 410, localhost, executor driver, partition 31, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,204 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 114.0 (TID 410)
2018-02-08 15:59:20,204 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 114.0 (TID 407) in 104 ms on localhost (executor driver) (30/100)
2018-02-08 15:59:20,209 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:20,210 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:20,255 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 114.0 (TID 410). 2594 bytes result sent to driver
2018-02-08 15:59:20,255 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 114.0 (TID 411, localhost, executor driver, partition 32, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,256 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 114.0 (TID 411)
2018-02-08 15:59:20,256 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 114.0 (TID 410) in 52 ms on localhost (executor driver) (31/100)
2018-02-08 15:59:20,259 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 114.0 (TID 409). 2594 bytes result sent to driver
2018-02-08 15:59:20,260 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 114.0 (TID 412, localhost, executor driver, partition 33, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,260 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:20,260 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 114.0 (TID 409) in 69 ms on localhost (executor driver) (32/100)
2018-02-08 15:59:20,260 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 114.0 (TID 412)
2018-02-08 15:59:20,261 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:20,264 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:20,265 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:20,310 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 114.0 (TID 411). 2594 bytes result sent to driver
2018-02-08 15:59:20,313 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 114.0 (TID 413, localhost, executor driver, partition 34, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,315 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 114.0 (TID 411) in 60 ms on localhost (executor driver) (33/100)
2018-02-08 15:59:20,315 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 114.0 (TID 413)
2018-02-08 15:59:20,319 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 114.0 (TID 412). 2594 bytes result sent to driver
2018-02-08 15:59:20,320 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 35.0 in stage 114.0 (TID 414, localhost, executor driver, partition 35, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,320 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:20,321 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 114.0 (TID 412) in 61 ms on localhost (executor driver) (34/100)
2018-02-08 15:59:20,321 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:20,321 INFO[org.apache.spark.executor.Executor:54] - Running task 35.0 in stage 114.0 (TID 414)
2018-02-08 15:59:20,327 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:20,328 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:20,373 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 114.0 (TID 413). 2594 bytes result sent to driver
2018-02-08 15:59:20,376 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 36.0 in stage 114.0 (TID 415, localhost, executor driver, partition 36, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,377 INFO[org.apache.spark.executor.Executor:54] - Running task 36.0 in stage 114.0 (TID 415)
2018-02-08 15:59:20,377 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 114.0 (TID 413) in 65 ms on localhost (executor driver) (35/100)
2018-02-08 15:59:20,381 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:20,383 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:20,396 INFO[org.apache.spark.executor.Executor:54] - Finished task 35.0 in stage 114.0 (TID 414). 2637 bytes result sent to driver
2018-02-08 15:59:20,396 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 37.0 in stage 114.0 (TID 416, localhost, executor driver, partition 37, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,396 INFO[org.apache.spark.executor.Executor:54] - Running task 37.0 in stage 114.0 (TID 416)
2018-02-08 15:59:20,396 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 35.0 in stage 114.0 (TID 414) in 76 ms on localhost (executor driver) (36/100)
2018-02-08 15:59:20,401 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:20,402 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:20,439 INFO[org.apache.spark.executor.Executor:54] - Finished task 36.0 in stage 114.0 (TID 415). 2594 bytes result sent to driver
2018-02-08 15:59:20,440 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 38.0 in stage 114.0 (TID 417, localhost, executor driver, partition 38, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,440 INFO[org.apache.spark.executor.Executor:54] - Running task 38.0 in stage 114.0 (TID 417)
2018-02-08 15:59:20,440 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 36.0 in stage 114.0 (TID 415) in 64 ms on localhost (executor driver) (37/100)
2018-02-08 15:59:20,443 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:20,444 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:20,453 INFO[org.apache.spark.executor.Executor:54] - Finished task 37.0 in stage 114.0 (TID 416). 2594 bytes result sent to driver
2018-02-08 15:59:20,454 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 39.0 in stage 114.0 (TID 418, localhost, executor driver, partition 39, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,454 INFO[org.apache.spark.executor.Executor:54] - Running task 39.0 in stage 114.0 (TID 418)
2018-02-08 15:59:20,454 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 37.0 in stage 114.0 (TID 416) in 58 ms on localhost (executor driver) (38/100)
2018-02-08 15:59:20,458 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:20,459 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_3 locally
2018-02-08 15:59:20,483 INFO[org.apache.spark.executor.Executor:54] - Finished task 38.0 in stage 114.0 (TID 417). 2594 bytes result sent to driver
2018-02-08 15:59:20,483 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 40.0 in stage 114.0 (TID 419, localhost, executor driver, partition 40, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,484 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 38.0 in stage 114.0 (TID 417) in 45 ms on localhost (executor driver) (39/100)
2018-02-08 15:59:20,484 INFO[org.apache.spark.executor.Executor:54] - Running task 40.0 in stage 114.0 (TID 419)
2018-02-08 15:59:20,489 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:20,490 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:20,503 INFO[org.apache.spark.executor.Executor:54] - Finished task 39.0 in stage 114.0 (TID 418). 2594 bytes result sent to driver
2018-02-08 15:59:20,504 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 41.0 in stage 114.0 (TID 420, localhost, executor driver, partition 41, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,505 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 39.0 in stage 114.0 (TID 418) in 51 ms on localhost (executor driver) (40/100)
2018-02-08 15:59:20,505 INFO[org.apache.spark.executor.Executor:54] - Running task 41.0 in stage 114.0 (TID 420)
2018-02-08 15:59:20,509 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:20,510 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:20,537 INFO[org.apache.spark.executor.Executor:54] - Finished task 40.0 in stage 114.0 (TID 419). 2594 bytes result sent to driver
2018-02-08 15:59:20,537 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 42.0 in stage 114.0 (TID 421, localhost, executor driver, partition 42, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,538 INFO[org.apache.spark.executor.Executor:54] - Running task 42.0 in stage 114.0 (TID 421)
2018-02-08 15:59:20,538 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 40.0 in stage 114.0 (TID 419) in 55 ms on localhost (executor driver) (41/100)
2018-02-08 15:59:20,543 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:20,544 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:20,579 INFO[org.apache.spark.executor.Executor:54] - Finished task 41.0 in stage 114.0 (TID 420). 2594 bytes result sent to driver
2018-02-08 15:59:20,579 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 43.0 in stage 114.0 (TID 422, localhost, executor driver, partition 43, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,579 INFO[org.apache.spark.executor.Executor:54] - Running task 43.0 in stage 114.0 (TID 422)
2018-02-08 15:59:20,579 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 41.0 in stage 114.0 (TID 420) in 75 ms on localhost (executor driver) (42/100)
2018-02-08 15:59:20,585 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:20,586 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:20,632 INFO[org.apache.spark.executor.Executor:54] - Finished task 42.0 in stage 114.0 (TID 421). 2594 bytes result sent to driver
2018-02-08 15:59:20,633 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 44.0 in stage 114.0 (TID 423, localhost, executor driver, partition 44, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,634 INFO[org.apache.spark.executor.Executor:54] - Running task 44.0 in stage 114.0 (TID 423)
2018-02-08 15:59:20,634 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 42.0 in stage 114.0 (TID 421) in 97 ms on localhost (executor driver) (43/100)
2018-02-08 15:59:20,639 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:20,639 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:20,664 INFO[org.apache.spark.executor.Executor:54] - Finished task 43.0 in stage 114.0 (TID 422). 2637 bytes result sent to driver
2018-02-08 15:59:20,664 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 45.0 in stage 114.0 (TID 424, localhost, executor driver, partition 45, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,665 INFO[org.apache.spark.executor.Executor:54] - Running task 45.0 in stage 114.0 (TID 424)
2018-02-08 15:59:20,665 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 43.0 in stage 114.0 (TID 422) in 86 ms on localhost (executor driver) (44/100)
2018-02-08 15:59:20,668 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:20,669 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:20,696 INFO[org.apache.spark.executor.Executor:54] - Finished task 44.0 in stage 114.0 (TID 423). 2594 bytes result sent to driver
2018-02-08 15:59:20,696 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 46.0 in stage 114.0 (TID 425, localhost, executor driver, partition 46, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,697 INFO[org.apache.spark.executor.Executor:54] - Running task 46.0 in stage 114.0 (TID 425)
2018-02-08 15:59:20,697 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 44.0 in stage 114.0 (TID 423) in 64 ms on localhost (executor driver) (45/100)
2018-02-08 15:59:20,701 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:20,701 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:20,716 INFO[org.apache.spark.executor.Executor:54] - Finished task 45.0 in stage 114.0 (TID 424). 2594 bytes result sent to driver
2018-02-08 15:59:20,716 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 47.0 in stage 114.0 (TID 426, localhost, executor driver, partition 47, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,716 INFO[org.apache.spark.executor.Executor:54] - Running task 47.0 in stage 114.0 (TID 426)
2018-02-08 15:59:20,716 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 45.0 in stage 114.0 (TID 424) in 52 ms on localhost (executor driver) (46/100)
2018-02-08 15:59:20,720 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:20,720 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:20,787 INFO[org.apache.spark.executor.Executor:54] - Finished task 46.0 in stage 114.0 (TID 425). 2594 bytes result sent to driver
2018-02-08 15:59:20,787 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 48.0 in stage 114.0 (TID 427, localhost, executor driver, partition 48, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,788 INFO[org.apache.spark.executor.Executor:54] - Finished task 47.0 in stage 114.0 (TID 426). 2637 bytes result sent to driver
2018-02-08 15:59:20,788 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 46.0 in stage 114.0 (TID 425) in 92 ms on localhost (executor driver) (47/100)
2018-02-08 15:59:20,788 INFO[org.apache.spark.executor.Executor:54] - Running task 48.0 in stage 114.0 (TID 427)
2018-02-08 15:59:20,788 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 49.0 in stage 114.0 (TID 428, localhost, executor driver, partition 49, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,788 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 47.0 in stage 114.0 (TID 426) in 72 ms on localhost (executor driver) (48/100)
2018-02-08 15:59:20,788 INFO[org.apache.spark.executor.Executor:54] - Running task 49.0 in stage 114.0 (TID 428)
2018-02-08 15:59:20,794 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:20,795 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:20,799 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:20,800 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_4 locally
2018-02-08 15:59:20,867 INFO[org.apache.spark.executor.Executor:54] - Finished task 48.0 in stage 114.0 (TID 427). 2594 bytes result sent to driver
2018-02-08 15:59:20,868 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 50.0 in stage 114.0 (TID 429, localhost, executor driver, partition 50, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,868 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 48.0 in stage 114.0 (TID 427) in 81 ms on localhost (executor driver) (49/100)
2018-02-08 15:59:20,868 INFO[org.apache.spark.executor.Executor:54] - Running task 50.0 in stage 114.0 (TID 429)
2018-02-08 15:59:20,869 INFO[org.apache.spark.executor.Executor:54] - Finished task 49.0 in stage 114.0 (TID 428). 2594 bytes result sent to driver
2018-02-08 15:59:20,870 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 51.0 in stage 114.0 (TID 430, localhost, executor driver, partition 51, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,871 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 49.0 in stage 114.0 (TID 428) in 83 ms on localhost (executor driver) (50/100)
2018-02-08 15:59:20,872 INFO[org.apache.spark.executor.Executor:54] - Running task 51.0 in stage 114.0 (TID 430)
2018-02-08 15:59:20,875 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:20,876 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:20,877 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:20,877 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:20,949 INFO[org.apache.spark.executor.Executor:54] - Finished task 51.0 in stage 114.0 (TID 430). 2637 bytes result sent to driver
2018-02-08 15:59:20,950 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 52.0 in stage 114.0 (TID 431, localhost, executor driver, partition 52, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,950 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 51.0 in stage 114.0 (TID 430) in 80 ms on localhost (executor driver) (51/100)
2018-02-08 15:59:20,951 INFO[org.apache.spark.executor.Executor:54] - Running task 52.0 in stage 114.0 (TID 431)
2018-02-08 15:59:20,952 INFO[org.apache.spark.executor.Executor:54] - Finished task 50.0 in stage 114.0 (TID 429). 2637 bytes result sent to driver
2018-02-08 15:59:20,954 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 53.0 in stage 114.0 (TID 432, localhost, executor driver, partition 53, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:20,955 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 50.0 in stage 114.0 (TID 429) in 88 ms on localhost (executor driver) (52/100)
2018-02-08 15:59:20,955 INFO[org.apache.spark.executor.Executor:54] - Running task 53.0 in stage 114.0 (TID 432)
2018-02-08 15:59:20,955 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:20,956 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:20,959 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:20,961 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:21,023 INFO[org.apache.spark.executor.Executor:54] - Finished task 52.0 in stage 114.0 (TID 431). 2637 bytes result sent to driver
2018-02-08 15:59:21,024 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 54.0 in stage 114.0 (TID 433, localhost, executor driver, partition 54, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,025 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 52.0 in stage 114.0 (TID 431) in 76 ms on localhost (executor driver) (53/100)
2018-02-08 15:59:21,025 INFO[org.apache.spark.executor.Executor:54] - Running task 54.0 in stage 114.0 (TID 433)
2018-02-08 15:59:21,025 INFO[org.apache.spark.executor.Executor:54] - Finished task 53.0 in stage 114.0 (TID 432). 2594 bytes result sent to driver
2018-02-08 15:59:21,027 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 55.0 in stage 114.0 (TID 434, localhost, executor driver, partition 55, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,027 INFO[org.apache.spark.executor.Executor:54] - Running task 55.0 in stage 114.0 (TID 434)
2018-02-08 15:59:21,027 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 53.0 in stage 114.0 (TID 432) in 73 ms on localhost (executor driver) (54/100)
2018-02-08 15:59:21,029 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:21,030 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:21,032 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:21,033 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:21,097 INFO[org.apache.spark.executor.Executor:54] - Finished task 55.0 in stage 114.0 (TID 434). 2637 bytes result sent to driver
2018-02-08 15:59:21,097 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 56.0 in stage 114.0 (TID 435, localhost, executor driver, partition 56, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,098 INFO[org.apache.spark.executor.Executor:54] - Running task 56.0 in stage 114.0 (TID 435)
2018-02-08 15:59:21,098 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 55.0 in stage 114.0 (TID 434) in 71 ms on localhost (executor driver) (55/100)
2018-02-08 15:59:21,103 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:21,104 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:21,117 INFO[org.apache.spark.executor.Executor:54] - Finished task 54.0 in stage 114.0 (TID 433). 2594 bytes result sent to driver
2018-02-08 15:59:21,118 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 57.0 in stage 114.0 (TID 436, localhost, executor driver, partition 57, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,118 INFO[org.apache.spark.executor.Executor:54] - Running task 57.0 in stage 114.0 (TID 436)
2018-02-08 15:59:21,118 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 54.0 in stage 114.0 (TID 433) in 94 ms on localhost (executor driver) (56/100)
2018-02-08 15:59:21,124 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:21,126 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:21,168 INFO[org.apache.spark.executor.Executor:54] - Finished task 56.0 in stage 114.0 (TID 435). 2594 bytes result sent to driver
2018-02-08 15:59:21,169 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 58.0 in stage 114.0 (TID 437, localhost, executor driver, partition 58, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,169 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 56.0 in stage 114.0 (TID 435) in 72 ms on localhost (executor driver) (57/100)
2018-02-08 15:59:21,169 INFO[org.apache.spark.executor.Executor:54] - Running task 58.0 in stage 114.0 (TID 437)
2018-02-08 15:59:21,174 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:21,175 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:21,199 INFO[org.apache.spark.executor.Executor:54] - Finished task 57.0 in stage 114.0 (TID 436). 2637 bytes result sent to driver
2018-02-08 15:59:21,200 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 59.0 in stage 114.0 (TID 438, localhost, executor driver, partition 59, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,200 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 57.0 in stage 114.0 (TID 436) in 83 ms on localhost (executor driver) (58/100)
2018-02-08 15:59:21,200 INFO[org.apache.spark.executor.Executor:54] - Running task 59.0 in stage 114.0 (TID 438)
2018-02-08 15:59:21,205 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:21,206 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_5 locally
2018-02-08 15:59:21,222 INFO[org.apache.spark.executor.Executor:54] - Finished task 58.0 in stage 114.0 (TID 437). 2637 bytes result sent to driver
2018-02-08 15:59:21,223 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 60.0 in stage 114.0 (TID 439, localhost, executor driver, partition 60, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,223 INFO[org.apache.spark.executor.Executor:54] - Running task 60.0 in stage 114.0 (TID 439)
2018-02-08 15:59:21,223 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 58.0 in stage 114.0 (TID 437) in 54 ms on localhost (executor driver) (59/100)
2018-02-08 15:59:21,252 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 497
2018-02-08 15:59:21,253 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 495
2018-02-08 15:59:21,253 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 496
2018-02-08 15:59:21,253 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 493
2018-02-08 15:59:21,253 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 494
2018-02-08 15:59:21,253 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 618
2018-02-08 15:59:21,253 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 488
2018-02-08 15:59:21,253 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 490
2018-02-08 15:59:21,253 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:21,255 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:21,265 INFO[org.apache.spark.ContextCleaner:54] - Cleaned shuffle 14
2018-02-08 15:59:21,266 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 489
2018-02-08 15:59:21,283 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_24_piece0 on 192.168.11.26:62887 in memory (size: 24.7 KB, free: 631.7 MB)
2018-02-08 15:59:21,305 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 491
2018-02-08 15:59:21,305 INFO[org.apache.spark.ContextCleaner:54] - Cleaned accumulator 492
2018-02-08 15:59:21,331 INFO[org.apache.spark.executor.Executor:54] - Finished task 59.0 in stage 114.0 (TID 438). 2680 bytes result sent to driver
2018-02-08 15:59:21,332 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 61.0 in stage 114.0 (TID 440, localhost, executor driver, partition 61, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,333 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 59.0 in stage 114.0 (TID 438) in 133 ms on localhost (executor driver) (60/100)
2018-02-08 15:59:21,337 INFO[org.apache.spark.executor.Executor:54] - Running task 61.0 in stage 114.0 (TID 440)
2018-02-08 15:59:21,350 INFO[org.apache.spark.executor.Executor:54] - Finished task 60.0 in stage 114.0 (TID 439). 2637 bytes result sent to driver
2018-02-08 15:59:21,352 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 62.0 in stage 114.0 (TID 441, localhost, executor driver, partition 62, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,353 INFO[org.apache.spark.executor.Executor:54] - Running task 62.0 in stage 114.0 (TID 441)
2018-02-08 15:59:21,353 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 60.0 in stage 114.0 (TID 439) in 130 ms on localhost (executor driver) (61/100)
2018-02-08 15:59:21,360 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:21,361 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:21,371 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:21,372 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:21,415 INFO[org.apache.spark.executor.Executor:54] - Finished task 61.0 in stage 114.0 (TID 440). 2594 bytes result sent to driver
2018-02-08 15:59:21,417 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 63.0 in stage 114.0 (TID 442, localhost, executor driver, partition 63, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,418 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 61.0 in stage 114.0 (TID 440) in 87 ms on localhost (executor driver) (62/100)
2018-02-08 15:59:21,418 INFO[org.apache.spark.executor.Executor:54] - Running task 63.0 in stage 114.0 (TID 442)
2018-02-08 15:59:21,423 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:21,424 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:21,429 INFO[org.apache.spark.executor.Executor:54] - Finished task 62.0 in stage 114.0 (TID 441). 2594 bytes result sent to driver
2018-02-08 15:59:21,430 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 64.0 in stage 114.0 (TID 443, localhost, executor driver, partition 64, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,430 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 62.0 in stage 114.0 (TID 441) in 78 ms on localhost (executor driver) (63/100)
2018-02-08 15:59:21,431 INFO[org.apache.spark.executor.Executor:54] - Running task 64.0 in stage 114.0 (TID 443)
2018-02-08 15:59:21,434 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:21,435 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:21,476 INFO[org.apache.spark.executor.Executor:54] - Finished task 63.0 in stage 114.0 (TID 442). 2637 bytes result sent to driver
2018-02-08 15:59:21,477 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 65.0 in stage 114.0 (TID 444, localhost, executor driver, partition 65, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,477 INFO[org.apache.spark.executor.Executor:54] - Running task 65.0 in stage 114.0 (TID 444)
2018-02-08 15:59:21,477 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 63.0 in stage 114.0 (TID 442) in 60 ms on localhost (executor driver) (64/100)
2018-02-08 15:59:21,483 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:21,484 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:21,505 INFO[org.apache.spark.executor.Executor:54] - Finished task 64.0 in stage 114.0 (TID 443). 2594 bytes result sent to driver
2018-02-08 15:59:21,506 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 66.0 in stage 114.0 (TID 445, localhost, executor driver, partition 66, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,506 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 64.0 in stage 114.0 (TID 443) in 77 ms on localhost (executor driver) (65/100)
2018-02-08 15:59:21,507 INFO[org.apache.spark.executor.Executor:54] - Running task 66.0 in stage 114.0 (TID 445)
2018-02-08 15:59:21,512 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:21,513 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:21,564 INFO[org.apache.spark.executor.Executor:54] - Finished task 65.0 in stage 114.0 (TID 444). 2594 bytes result sent to driver
2018-02-08 15:59:21,564 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 67.0 in stage 114.0 (TID 446, localhost, executor driver, partition 67, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,564 INFO[org.apache.spark.executor.Executor:54] - Running task 67.0 in stage 114.0 (TID 446)
2018-02-08 15:59:21,564 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 65.0 in stage 114.0 (TID 444) in 87 ms on localhost (executor driver) (66/100)
2018-02-08 15:59:21,569 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:21,570 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:21,597 INFO[org.apache.spark.executor.Executor:54] - Finished task 66.0 in stage 114.0 (TID 445). 2594 bytes result sent to driver
2018-02-08 15:59:21,598 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 68.0 in stage 114.0 (TID 447, localhost, executor driver, partition 68, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,598 INFO[org.apache.spark.executor.Executor:54] - Running task 68.0 in stage 114.0 (TID 447)
2018-02-08 15:59:21,598 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 66.0 in stage 114.0 (TID 445) in 92 ms on localhost (executor driver) (67/100)
2018-02-08 15:59:21,602 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:21,602 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:21,628 INFO[org.apache.spark.executor.Executor:54] - Finished task 67.0 in stage 114.0 (TID 446). 2594 bytes result sent to driver
2018-02-08 15:59:21,628 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 69.0 in stage 114.0 (TID 448, localhost, executor driver, partition 69, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,629 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 67.0 in stage 114.0 (TID 446) in 65 ms on localhost (executor driver) (68/100)
2018-02-08 15:59:21,629 INFO[org.apache.spark.executor.Executor:54] - Running task 69.0 in stage 114.0 (TID 448)
2018-02-08 15:59:21,632 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:21,633 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_6 locally
2018-02-08 15:59:21,665 INFO[org.apache.spark.executor.Executor:54] - Finished task 68.0 in stage 114.0 (TID 447). 2594 bytes result sent to driver
2018-02-08 15:59:21,665 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 70.0 in stage 114.0 (TID 449, localhost, executor driver, partition 70, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,666 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 68.0 in stage 114.0 (TID 447) in 69 ms on localhost (executor driver) (69/100)
2018-02-08 15:59:21,666 INFO[org.apache.spark.executor.Executor:54] - Running task 70.0 in stage 114.0 (TID 449)
2018-02-08 15:59:21,670 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:21,670 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:21,686 INFO[org.apache.spark.executor.Executor:54] - Finished task 69.0 in stage 114.0 (TID 448). 2594 bytes result sent to driver
2018-02-08 15:59:21,686 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 71.0 in stage 114.0 (TID 450, localhost, executor driver, partition 71, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,689 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 69.0 in stage 114.0 (TID 448) in 60 ms on localhost (executor driver) (70/100)
2018-02-08 15:59:21,689 INFO[org.apache.spark.executor.Executor:54] - Running task 71.0 in stage 114.0 (TID 450)
2018-02-08 15:59:21,694 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:21,694 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:21,753 INFO[org.apache.spark.executor.Executor:54] - Finished task 70.0 in stage 114.0 (TID 449). 2594 bytes result sent to driver
2018-02-08 15:59:21,754 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 72.0 in stage 114.0 (TID 451, localhost, executor driver, partition 72, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,755 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 70.0 in stage 114.0 (TID 449) in 90 ms on localhost (executor driver) (71/100)
2018-02-08 15:59:21,755 INFO[org.apache.spark.executor.Executor:54] - Running task 72.0 in stage 114.0 (TID 451)
2018-02-08 15:59:21,760 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:21,760 INFO[org.apache.spark.executor.Executor:54] - Finished task 71.0 in stage 114.0 (TID 450). 2594 bytes result sent to driver
2018-02-08 15:59:21,760 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:21,760 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 73.0 in stage 114.0 (TID 452, localhost, executor driver, partition 73, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,761 INFO[org.apache.spark.executor.Executor:54] - Running task 73.0 in stage 114.0 (TID 452)
2018-02-08 15:59:21,761 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 71.0 in stage 114.0 (TID 450) in 75 ms on localhost (executor driver) (72/100)
2018-02-08 15:59:21,766 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:21,768 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:21,817 INFO[org.apache.spark.executor.Executor:54] - Finished task 73.0 in stage 114.0 (TID 452). 2637 bytes result sent to driver
2018-02-08 15:59:21,818 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 74.0 in stage 114.0 (TID 453, localhost, executor driver, partition 74, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,818 INFO[org.apache.spark.executor.Executor:54] - Running task 74.0 in stage 114.0 (TID 453)
2018-02-08 15:59:21,818 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 73.0 in stage 114.0 (TID 452) in 58 ms on localhost (executor driver) (73/100)
2018-02-08 15:59:21,822 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:21,822 INFO[org.apache.spark.executor.Executor:54] - Finished task 72.0 in stage 114.0 (TID 451). 2594 bytes result sent to driver
2018-02-08 15:59:21,823 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:21,823 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 75.0 in stage 114.0 (TID 454, localhost, executor driver, partition 75, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,823 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 72.0 in stage 114.0 (TID 451) in 69 ms on localhost (executor driver) (74/100)
2018-02-08 15:59:21,823 INFO[org.apache.spark.executor.Executor:54] - Running task 75.0 in stage 114.0 (TID 454)
2018-02-08 15:59:21,827 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:21,828 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:21,862 INFO[org.apache.spark.executor.Executor:54] - Finished task 74.0 in stage 114.0 (TID 453). 2594 bytes result sent to driver
2018-02-08 15:59:21,862 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 76.0 in stage 114.0 (TID 455, localhost, executor driver, partition 76, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,862 INFO[org.apache.spark.executor.Executor:54] - Running task 76.0 in stage 114.0 (TID 455)
2018-02-08 15:59:21,862 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 74.0 in stage 114.0 (TID 453) in 44 ms on localhost (executor driver) (75/100)
2018-02-08 15:59:21,864 INFO[org.apache.spark.executor.Executor:54] - Finished task 75.0 in stage 114.0 (TID 454). 2594 bytes result sent to driver
2018-02-08 15:59:21,865 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 77.0 in stage 114.0 (TID 456, localhost, executor driver, partition 77, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,865 INFO[org.apache.spark.executor.Executor:54] - Running task 77.0 in stage 114.0 (TID 456)
2018-02-08 15:59:21,865 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 75.0 in stage 114.0 (TID 454) in 42 ms on localhost (executor driver) (76/100)
2018-02-08 15:59:21,867 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:21,868 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:21,868 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:21,868 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:21,905 INFO[org.apache.spark.executor.Executor:54] - Finished task 76.0 in stage 114.0 (TID 455). 2594 bytes result sent to driver
2018-02-08 15:59:21,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 78.0 in stage 114.0 (TID 457, localhost, executor driver, partition 78, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,906 INFO[org.apache.spark.executor.Executor:54] - Running task 78.0 in stage 114.0 (TID 457)
2018-02-08 15:59:21,906 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 76.0 in stage 114.0 (TID 455) in 44 ms on localhost (executor driver) (77/100)
2018-02-08 15:59:21,910 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:21,911 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:21,922 INFO[org.apache.spark.executor.Executor:54] - Finished task 77.0 in stage 114.0 (TID 456). 2594 bytes result sent to driver
2018-02-08 15:59:21,922 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 79.0 in stage 114.0 (TID 458, localhost, executor driver, partition 79, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,923 INFO[org.apache.spark.executor.Executor:54] - Running task 79.0 in stage 114.0 (TID 458)
2018-02-08 15:59:21,923 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 77.0 in stage 114.0 (TID 456) in 58 ms on localhost (executor driver) (78/100)
2018-02-08 15:59:21,929 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:21,930 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_7 locally
2018-02-08 15:59:21,998 INFO[org.apache.spark.executor.Executor:54] - Finished task 78.0 in stage 114.0 (TID 457). 2594 bytes result sent to driver
2018-02-08 15:59:21,998 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 80.0 in stage 114.0 (TID 459, localhost, executor driver, partition 80, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:21,999 INFO[org.apache.spark.executor.Executor:54] - Running task 80.0 in stage 114.0 (TID 459)
2018-02-08 15:59:21,999 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 78.0 in stage 114.0 (TID 457) in 93 ms on localhost (executor driver) (79/100)
2018-02-08 15:59:22,004 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:22,005 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:22,037 INFO[org.apache.spark.executor.Executor:54] - Finished task 79.0 in stage 114.0 (TID 458). 2551 bytes result sent to driver
2018-02-08 15:59:22,037 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 81.0 in stage 114.0 (TID 460, localhost, executor driver, partition 81, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,037 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 79.0 in stage 114.0 (TID 458) in 115 ms on localhost (executor driver) (80/100)
2018-02-08 15:59:22,038 INFO[org.apache.spark.executor.Executor:54] - Running task 81.0 in stage 114.0 (TID 460)
2018-02-08 15:59:22,041 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:22,042 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:22,048 INFO[org.apache.spark.executor.Executor:54] - Finished task 80.0 in stage 114.0 (TID 459). 2594 bytes result sent to driver
2018-02-08 15:59:22,048 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 82.0 in stage 114.0 (TID 461, localhost, executor driver, partition 82, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,049 INFO[org.apache.spark.executor.Executor:54] - Running task 82.0 in stage 114.0 (TID 461)
2018-02-08 15:59:22,049 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 80.0 in stage 114.0 (TID 459) in 51 ms on localhost (executor driver) (81/100)
2018-02-08 15:59:22,052 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:22,052 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:22,077 INFO[org.apache.spark.executor.Executor:54] - Finished task 81.0 in stage 114.0 (TID 460). 2594 bytes result sent to driver
2018-02-08 15:59:22,077 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 83.0 in stage 114.0 (TID 462, localhost, executor driver, partition 83, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,078 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 81.0 in stage 114.0 (TID 460) in 41 ms on localhost (executor driver) (82/100)
2018-02-08 15:59:22,078 INFO[org.apache.spark.executor.Executor:54] - Running task 83.0 in stage 114.0 (TID 462)
2018-02-08 15:59:22,082 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:22,083 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:22,096 INFO[org.apache.spark.executor.Executor:54] - Finished task 82.0 in stage 114.0 (TID 461). 2594 bytes result sent to driver
2018-02-08 15:59:22,097 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 84.0 in stage 114.0 (TID 463, localhost, executor driver, partition 84, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,099 INFO[org.apache.spark.executor.Executor:54] - Running task 84.0 in stage 114.0 (TID 463)
2018-02-08 15:59:22,099 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 82.0 in stage 114.0 (TID 461) in 51 ms on localhost (executor driver) (83/100)
2018-02-08 15:59:22,103 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:22,104 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:22,156 INFO[org.apache.spark.executor.Executor:54] - Finished task 84.0 in stage 114.0 (TID 463). 2594 bytes result sent to driver
2018-02-08 15:59:22,157 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 85.0 in stage 114.0 (TID 464, localhost, executor driver, partition 85, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,158 INFO[org.apache.spark.executor.Executor:54] - Running task 85.0 in stage 114.0 (TID 464)
2018-02-08 15:59:22,158 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 84.0 in stage 114.0 (TID 463) in 61 ms on localhost (executor driver) (84/100)
2018-02-08 15:59:22,161 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:22,162 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:22,176 INFO[org.apache.spark.executor.Executor:54] - Finished task 83.0 in stage 114.0 (TID 462). 2594 bytes result sent to driver
2018-02-08 15:59:22,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 86.0 in stage 114.0 (TID 465, localhost, executor driver, partition 86, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,177 INFO[org.apache.spark.executor.Executor:54] - Running task 86.0 in stage 114.0 (TID 465)
2018-02-08 15:59:22,177 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 83.0 in stage 114.0 (TID 462) in 100 ms on localhost (executor driver) (85/100)
2018-02-08 15:59:22,183 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:22,185 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:22,229 INFO[org.apache.spark.executor.Executor:54] - Finished task 85.0 in stage 114.0 (TID 464). 2594 bytes result sent to driver
2018-02-08 15:59:22,230 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 87.0 in stage 114.0 (TID 466, localhost, executor driver, partition 87, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,230 INFO[org.apache.spark.executor.Executor:54] - Running task 87.0 in stage 114.0 (TID 466)
2018-02-08 15:59:22,230 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 85.0 in stage 114.0 (TID 464) in 73 ms on localhost (executor driver) (86/100)
2018-02-08 15:59:22,237 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:22,237 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:22,252 INFO[org.apache.spark.executor.Executor:54] - Finished task 86.0 in stage 114.0 (TID 465). 2594 bytes result sent to driver
2018-02-08 15:59:22,252 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 88.0 in stage 114.0 (TID 467, localhost, executor driver, partition 88, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,253 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 86.0 in stage 114.0 (TID 465) in 76 ms on localhost (executor driver) (87/100)
2018-02-08 15:59:22,264 INFO[org.apache.spark.executor.Executor:54] - Running task 88.0 in stage 114.0 (TID 467)
2018-02-08 15:59:22,272 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:22,273 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:22,282 INFO[org.apache.spark.executor.Executor:54] - Finished task 87.0 in stage 114.0 (TID 466). 2637 bytes result sent to driver
2018-02-08 15:59:22,282 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 89.0 in stage 114.0 (TID 468, localhost, executor driver, partition 89, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,283 INFO[org.apache.spark.executor.Executor:54] - Running task 89.0 in stage 114.0 (TID 468)
2018-02-08 15:59:22,283 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 87.0 in stage 114.0 (TID 466) in 53 ms on localhost (executor driver) (88/100)
2018-02-08 15:59:22,287 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:22,287 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_8 locally
2018-02-08 15:59:22,320 INFO[org.apache.spark.executor.Executor:54] - Finished task 88.0 in stage 114.0 (TID 467). 2594 bytes result sent to driver
2018-02-08 15:59:22,321 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 90.0 in stage 114.0 (TID 469, localhost, executor driver, partition 90, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,321 INFO[org.apache.spark.executor.Executor:54] - Running task 90.0 in stage 114.0 (TID 469)
2018-02-08 15:59:22,321 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 88.0 in stage 114.0 (TID 467) in 69 ms on localhost (executor driver) (89/100)
2018-02-08 15:59:22,325 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_0 locally
2018-02-08 15:59:22,325 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:22,345 INFO[org.apache.spark.executor.Executor:54] - Finished task 89.0 in stage 114.0 (TID 468). 2594 bytes result sent to driver
2018-02-08 15:59:22,346 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 91.0 in stage 114.0 (TID 470, localhost, executor driver, partition 91, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,347 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 89.0 in stage 114.0 (TID 468) in 65 ms on localhost (executor driver) (90/100)
2018-02-08 15:59:22,347 INFO[org.apache.spark.executor.Executor:54] - Running task 91.0 in stage 114.0 (TID 470)
2018-02-08 15:59:22,351 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_1 locally
2018-02-08 15:59:22,351 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:22,397 INFO[org.apache.spark.executor.Executor:54] - Finished task 90.0 in stage 114.0 (TID 469). 2594 bytes result sent to driver
2018-02-08 15:59:22,398 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 92.0 in stage 114.0 (TID 471, localhost, executor driver, partition 92, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,398 INFO[org.apache.spark.executor.Executor:54] - Running task 92.0 in stage 114.0 (TID 471)
2018-02-08 15:59:22,398 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 90.0 in stage 114.0 (TID 469) in 77 ms on localhost (executor driver) (91/100)
2018-02-08 15:59:22,402 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_2 locally
2018-02-08 15:59:22,402 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:22,428 INFO[org.apache.spark.executor.Executor:54] - Finished task 91.0 in stage 114.0 (TID 470). 2594 bytes result sent to driver
2018-02-08 15:59:22,429 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 93.0 in stage 114.0 (TID 472, localhost, executor driver, partition 93, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,430 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 91.0 in stage 114.0 (TID 470) in 85 ms on localhost (executor driver) (92/100)
2018-02-08 15:59:22,430 INFO[org.apache.spark.executor.Executor:54] - Running task 93.0 in stage 114.0 (TID 472)
2018-02-08 15:59:22,434 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_3 locally
2018-02-08 15:59:22,435 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:22,461 INFO[org.apache.spark.executor.Executor:54] - Finished task 92.0 in stage 114.0 (TID 471). 2594 bytes result sent to driver
2018-02-08 15:59:22,461 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 94.0 in stage 114.0 (TID 473, localhost, executor driver, partition 94, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,462 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 92.0 in stage 114.0 (TID 471) in 64 ms on localhost (executor driver) (93/100)
2018-02-08 15:59:22,462 INFO[org.apache.spark.executor.Executor:54] - Running task 94.0 in stage 114.0 (TID 473)
2018-02-08 15:59:22,468 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_4 locally
2018-02-08 15:59:22,469 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:22,488 INFO[org.apache.spark.executor.Executor:54] - Finished task 93.0 in stage 114.0 (TID 472). 2594 bytes result sent to driver
2018-02-08 15:59:22,489 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 95.0 in stage 114.0 (TID 474, localhost, executor driver, partition 95, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,489 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 93.0 in stage 114.0 (TID 472) in 60 ms on localhost (executor driver) (94/100)
2018-02-08 15:59:22,489 INFO[org.apache.spark.executor.Executor:54] - Running task 95.0 in stage 114.0 (TID 474)
2018-02-08 15:59:22,493 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_5 locally
2018-02-08 15:59:22,493 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:22,525 INFO[org.apache.spark.executor.Executor:54] - Finished task 94.0 in stage 114.0 (TID 473). 2637 bytes result sent to driver
2018-02-08 15:59:22,525 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 96.0 in stage 114.0 (TID 475, localhost, executor driver, partition 96, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,525 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 94.0 in stage 114.0 (TID 473) in 64 ms on localhost (executor driver) (95/100)
2018-02-08 15:59:22,525 INFO[org.apache.spark.executor.Executor:54] - Running task 96.0 in stage 114.0 (TID 475)
2018-02-08 15:59:22,531 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_6 locally
2018-02-08 15:59:22,532 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:22,542 INFO[org.apache.spark.executor.Executor:54] - Finished task 95.0 in stage 114.0 (TID 474). 2594 bytes result sent to driver
2018-02-08 15:59:22,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 97.0 in stage 114.0 (TID 476, localhost, executor driver, partition 97, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,542 INFO[org.apache.spark.executor.Executor:54] - Running task 97.0 in stage 114.0 (TID 476)
2018-02-08 15:59:22,542 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 95.0 in stage 114.0 (TID 474) in 54 ms on localhost (executor driver) (96/100)
2018-02-08 15:59:22,546 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_7 locally
2018-02-08 15:59:22,547 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:22,596 INFO[org.apache.spark.executor.Executor:54] - Finished task 96.0 in stage 114.0 (TID 475). 2637 bytes result sent to driver
2018-02-08 15:59:22,596 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 98.0 in stage 114.0 (TID 477, localhost, executor driver, partition 98, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,597 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 96.0 in stage 114.0 (TID 475) in 72 ms on localhost (executor driver) (97/100)
2018-02-08 15:59:22,597 INFO[org.apache.spark.executor.Executor:54] - Running task 98.0 in stage 114.0 (TID 477)
2018-02-08 15:59:22,601 INFO[org.apache.spark.executor.Executor:54] - Finished task 97.0 in stage 114.0 (TID 476). 2680 bytes result sent to driver
2018-02-08 15:59:22,601 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_8 locally
2018-02-08 15:59:22,601 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 99.0 in stage 114.0 (TID 478, localhost, executor driver, partition 99, PROCESS_LOCAL, 5224 bytes)
2018-02-08 15:59:22,602 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:22,602 INFO[org.apache.spark.executor.Executor:54] - Running task 99.0 in stage 114.0 (TID 478)
2018-02-08 15:59:22,602 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 97.0 in stage 114.0 (TID 476) in 60 ms on localhost (executor driver) (98/100)
2018-02-08 15:59:22,609 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_119_9 locally
2018-02-08 15:59:22,610 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_124_9 locally
2018-02-08 15:59:22,669 INFO[org.apache.spark.executor.Executor:54] - Finished task 98.0 in stage 114.0 (TID 477). 2594 bytes result sent to driver
2018-02-08 15:59:22,670 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 98.0 in stage 114.0 (TID 477) in 74 ms on localhost (executor driver) (99/100)
2018-02-08 15:59:22,683 INFO[org.apache.spark.executor.Executor:54] - Finished task 99.0 in stage 114.0 (TID 478). 2594 bytes result sent to driver
2018-02-08 15:59:22,684 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 99.0 in stage 114.0 (TID 478) in 83 ms on localhost (executor driver) (100/100)
2018-02-08 15:59:22,684 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2018-02-08 15:59:22,684 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 114 (show at MachineLeaningFiltering.java:46) finished in 3.839 s
2018-02-08 15:59:22,685 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 15:59:22,685 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 15:59:22,685 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 115)
2018-02-08 15:59:22,685 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 15:59:22,685 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 115 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46), which has no missing parents
2018-02-08 15:59:22,693 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_26 stored as values in memory (estimated size 59.6 KB, free 631.2 MB)
2018-02-08 15:59:22,696 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_26_piece0 stored as bytes in memory (estimated size 24.8 KB, free 631.2 MB)
2018-02-08 15:59:22,697 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_26_piece0 in memory on 192.168.11.26:62887 (size: 24.8 KB, free: 631.7 MB)
2018-02-08 15:59:22,698 INFO[org.apache.spark.SparkContext:54] - Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:22,699 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 115 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46) (first 15 tasks are for partitions Vector(0))
2018-02-08 15:59:22,699 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 115.0 with 1 tasks
2018-02-08 15:59:22,700 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 115.0 (TID 479, localhost, executor driver, partition 0, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,700 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 115.0 (TID 479)
2018-02-08 15:59:22,704 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,705 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,705 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 115.0 (TID 479). 2467 bytes result sent to driver
2018-02-08 15:59:22,706 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 115.0 (TID 479) in 6 ms on localhost (executor driver) (1/1)
2018-02-08 15:59:22,706 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 115.0, whose tasks have all completed, from pool 
2018-02-08 15:59:22,706 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 115 (show at MachineLeaningFiltering.java:46) finished in 0.007 s
2018-02-08 15:59:22,707 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 9 finished: show at MachineLeaningFiltering.java:46, took 3.888845 s
2018-02-08 15:59:22,709 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:46
2018-02-08 15:59:22,710 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 1 is 149 bytes
2018-02-08 15:59:22,711 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 155 bytes
2018-02-08 15:59:22,713 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 13 is 197 bytes
2018-02-08 15:59:22,714 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 12 is 161 bytes
2018-02-08 15:59:22,714 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 2 is 156 bytes
2018-02-08 15:59:22,715 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 11 is 238 bytes
2018-02-08 15:59:22,715 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 10 is 161 bytes
2018-02-08 15:59:22,716 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 9 is 240 bytes
2018-02-08 15:59:22,716 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 8 is 161 bytes
2018-02-08 15:59:22,717 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 7 is 238 bytes
2018-02-08 15:59:22,717 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 6 is 161 bytes
2018-02-08 15:59:22,717 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 5 is 240 bytes
2018-02-08 15:59:22,718 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 4 is 161 bytes
2018-02-08 15:59:22,718 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 3 is 240 bytes
2018-02-08 15:59:22,719 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 15 is 556 bytes
2018-02-08 15:59:22,720 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 10 (show at MachineLeaningFiltering.java:46) with 4 output partitions
2018-02-08 15:59:22,720 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 131 (show at MachineLeaningFiltering.java:46)
2018-02-08 15:59:22,720 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 130)
2018-02-08 15:59:22,720 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:59:22,721 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 131 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46), which has no missing parents
2018-02-08 15:59:22,724 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_27 stored as values in memory (estimated size 59.6 KB, free 631.1 MB)
2018-02-08 15:59:22,726 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_27_piece0 stored as bytes in memory (estimated size 24.8 KB, free 631.1 MB)
2018-02-08 15:59:22,727 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_27_piece0 in memory on 192.168.11.26:62887 (size: 24.8 KB, free: 631.7 MB)
2018-02-08 15:59:22,727 INFO[org.apache.spark.SparkContext:54] - Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:22,729 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 4 missing tasks from ResultStage 131 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
2018-02-08 15:59:22,729 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 131.0 with 4 tasks
2018-02-08 15:59:22,729 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 131.0 (TID 480, localhost, executor driver, partition 1, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,730 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 131.0 (TID 481, localhost, executor driver, partition 2, ANY, 4726 bytes)
2018-02-08 15:59:22,730 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 131.0 (TID 480)
2018-02-08 15:59:22,730 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 131.0 (TID 481)
2018-02-08 15:59:22,733 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,733 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,733 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,733 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,734 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 131.0 (TID 480). 2467 bytes result sent to driver
2018-02-08 15:59:22,734 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 131.0 (TID 482, localhost, executor driver, partition 3, ANY, 4726 bytes)
2018-02-08 15:59:22,734 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 131.0 (TID 480) in 5 ms on localhost (executor driver) (1/4)
2018-02-08 15:59:22,734 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 131.0 (TID 482)
2018-02-08 15:59:22,738 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,738 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,759 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 14.226885 ms
2018-02-08 15:59:22,762 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 131.0 (TID 482). 2652 bytes result sent to driver
2018-02-08 15:59:22,762 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 131.0 (TID 481). 2659 bytes result sent to driver
2018-02-08 15:59:22,762 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 131.0 (TID 483, localhost, executor driver, partition 4, ANY, 4726 bytes)
2018-02-08 15:59:22,762 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 131.0 (TID 482) in 28 ms on localhost (executor driver) (2/4)
2018-02-08 15:59:22,762 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 131.0 (TID 483)
2018-02-08 15:59:22,762 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 131.0 (TID 481) in 32 ms on localhost (executor driver) (3/4)
2018-02-08 15:59:22,765 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,766 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,773 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 131.0 (TID 483). 2662 bytes result sent to driver
2018-02-08 15:59:22,774 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 131.0 (TID 483) in 12 ms on localhost (executor driver) (4/4)
2018-02-08 15:59:22,774 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 131.0, whose tasks have all completed, from pool 
2018-02-08 15:59:22,774 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 131 (show at MachineLeaningFiltering.java:46) finished in 0.045 s
2018-02-08 15:59:22,775 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 10 finished: show at MachineLeaningFiltering.java:46, took 0.065176 s
2018-02-08 15:59:22,777 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:46
2018-02-08 15:59:22,780 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 11 (show at MachineLeaningFiltering.java:46) with 20 output partitions
2018-02-08 15:59:22,780 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 147 (show at MachineLeaningFiltering.java:46)
2018-02-08 15:59:22,780 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 146)
2018-02-08 15:59:22,780 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:59:22,781 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 147 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46), which has no missing parents
2018-02-08 15:59:22,783 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_28 stored as values in memory (estimated size 59.6 KB, free 631.0 MB)
2018-02-08 15:59:22,785 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_28_piece0 stored as bytes in memory (estimated size 24.8 KB, free 631.0 MB)
2018-02-08 15:59:22,786 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_28_piece0 in memory on 192.168.11.26:62887 (size: 24.8 KB, free: 631.6 MB)
2018-02-08 15:59:22,786 INFO[org.apache.spark.SparkContext:54] - Created broadcast 28 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:22,786 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 20 missing tasks from ResultStage 147 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19))
2018-02-08 15:59:22,786 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 147.0 with 20 tasks
2018-02-08 15:59:22,787 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 147.0 (TID 484, localhost, executor driver, partition 6, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,787 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 147.0 (TID 485, localhost, executor driver, partition 8, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,787 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 147.0 (TID 485)
2018-02-08 15:59:22,787 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 147.0 (TID 484)
2018-02-08 15:59:22,790 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,790 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,791 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,791 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,791 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 147.0 (TID 484). 2424 bytes result sent to driver
2018-02-08 15:59:22,791 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 147.0 (TID 485). 2424 bytes result sent to driver
2018-02-08 15:59:22,792 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 147.0 (TID 486, localhost, executor driver, partition 9, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,792 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 147.0 (TID 487, localhost, executor driver, partition 10, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,792 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 147.0 (TID 486)
2018-02-08 15:59:22,793 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 147.0 (TID 485) in 6 ms on localhost (executor driver) (1/20)
2018-02-08 15:59:22,793 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 147.0 (TID 487)
2018-02-08 15:59:22,794 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 147.0 (TID 484) in 7 ms on localhost (executor driver) (2/20)
2018-02-08 15:59:22,797 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,797 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,798 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 147.0 (TID 486). 2424 bytes result sent to driver
2018-02-08 15:59:22,798 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 147.0 (TID 488, localhost, executor driver, partition 12, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,798 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,798 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 147.0 (TID 488)
2018-02-08 15:59:22,798 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,799 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 147.0 (TID 487). 2467 bytes result sent to driver
2018-02-08 15:59:22,798 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 147.0 (TID 486) in 6 ms on localhost (executor driver) (3/20)
2018-02-08 15:59:22,799 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 147.0 (TID 489, localhost, executor driver, partition 15, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,800 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 147.0 (TID 487) in 7 ms on localhost (executor driver) (4/20)
2018-02-08 15:59:22,800 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 147.0 (TID 489)
2018-02-08 15:59:22,802 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,802 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,802 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 147.0 (TID 488). 2424 bytes result sent to driver
2018-02-08 15:59:22,803 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 147.0 (TID 490, localhost, executor driver, partition 16, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,803 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,803 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,803 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 147.0 (TID 490)
2018-02-08 15:59:22,803 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 147.0 (TID 488) in 5 ms on localhost (executor driver) (5/20)
2018-02-08 15:59:22,803 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 147.0 (TID 489). 2424 bytes result sent to driver
2018-02-08 15:59:22,804 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 147.0 (TID 491, localhost, executor driver, partition 17, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,805 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 147.0 (TID 489) in 6 ms on localhost (executor driver) (6/20)
2018-02-08 15:59:22,805 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 147.0 (TID 491)
2018-02-08 15:59:22,806 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,806 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,807 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 147.0 (TID 490). 2424 bytes result sent to driver
2018-02-08 15:59:22,807 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 147.0 (TID 492, localhost, executor driver, partition 20, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,807 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 147.0 (TID 490) in 4 ms on localhost (executor driver) (7/20)
2018-02-08 15:59:22,807 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,807 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 147.0 (TID 492)
2018-02-08 15:59:22,807 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,808 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 147.0 (TID 491). 2424 bytes result sent to driver
2018-02-08 15:59:22,808 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 147.0 (TID 493, localhost, executor driver, partition 22, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,808 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 147.0 (TID 493)
2018-02-08 15:59:22,808 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 147.0 (TID 491) in 4 ms on localhost (executor driver) (8/20)
2018-02-08 15:59:22,810 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,810 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,810 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,810 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,811 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 147.0 (TID 492). 2381 bytes result sent to driver
2018-02-08 15:59:22,811 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 147.0 (TID 493). 2381 bytes result sent to driver
2018-02-08 15:59:22,811 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 147.0 (TID 494, localhost, executor driver, partition 23, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,811 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 147.0 (TID 492) in 4 ms on localhost (executor driver) (9/20)
2018-02-08 15:59:22,811 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 147.0 (TID 494)
2018-02-08 15:59:22,811 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 147.0 (TID 493) in 3 ms on localhost (executor driver) (10/20)
2018-02-08 15:59:22,811 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 147.0 (TID 495, localhost, executor driver, partition 5, ANY, 4726 bytes)
2018-02-08 15:59:22,811 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 147.0 (TID 495)
2018-02-08 15:59:22,814 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,814 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,814 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,814 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,815 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 147.0 (TID 494). 2424 bytes result sent to driver
2018-02-08 15:59:22,815 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 147.0 (TID 496, localhost, executor driver, partition 7, ANY, 4726 bytes)
2018-02-08 15:59:22,815 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 147.0 (TID 494) in 4 ms on localhost (executor driver) (11/20)
2018-02-08 15:59:22,815 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 147.0 (TID 496)
2018-02-08 15:59:22,819 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,819 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,827 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 147.0 (TID 495). 2669 bytes result sent to driver
2018-02-08 15:59:22,827 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 147.0 (TID 497, localhost, executor driver, partition 11, ANY, 4726 bytes)
2018-02-08 15:59:22,827 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 147.0 (TID 497)
2018-02-08 15:59:22,827 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 147.0 (TID 495) in 16 ms on localhost (executor driver) (12/20)
2018-02-08 15:59:22,830 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,830 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,832 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 147.0 (TID 496). 2663 bytes result sent to driver
2018-02-08 15:59:22,832 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 147.0 (TID 498, localhost, executor driver, partition 13, ANY, 4726 bytes)
2018-02-08 15:59:22,832 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 147.0 (TID 498)
2018-02-08 15:59:22,832 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 147.0 (TID 496) in 17 ms on localhost (executor driver) (13/20)
2018-02-08 15:59:22,836 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,836 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,843 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 147.0 (TID 497). 2658 bytes result sent to driver
2018-02-08 15:59:22,843 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 147.0 (TID 499, localhost, executor driver, partition 14, ANY, 4726 bytes)
2018-02-08 15:59:22,843 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 147.0 (TID 497) in 16 ms on localhost (executor driver) (14/20)
2018-02-08 15:59:22,843 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 147.0 (TID 499)
2018-02-08 15:59:22,847 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 147.0 (TID 498). 2651 bytes result sent to driver
2018-02-08 15:59:22,847 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 147.0 (TID 500, localhost, executor driver, partition 18, ANY, 4726 bytes)
2018-02-08 15:59:22,847 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,848 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 147.0 (TID 498) in 16 ms on localhost (executor driver) (15/20)
2018-02-08 15:59:22,848 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 147.0 (TID 500)
2018-02-08 15:59:22,848 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,851 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,851 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,856 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 147.0 (TID 499). 2618 bytes result sent to driver
2018-02-08 15:59:22,858 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 147.0 (TID 501, localhost, executor driver, partition 19, ANY, 4726 bytes)
2018-02-08 15:59:22,859 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 147.0 (TID 499) in 15 ms on localhost (executor driver) (16/20)
2018-02-08 15:59:22,859 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 147.0 (TID 501)
2018-02-08 15:59:22,863 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 147.0 (TID 500). 2652 bytes result sent to driver
2018-02-08 15:59:22,863 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 147.0 (TID 502, localhost, executor driver, partition 21, ANY, 4726 bytes)
2018-02-08 15:59:22,863 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 20 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,863 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 147.0 (TID 500) in 16 ms on localhost (executor driver) (17/20)
2018-02-08 15:59:22,863 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 147.0 (TID 502)
2018-02-08 15:59:22,863 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,866 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,867 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,877 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 147.0 (TID 501). 2778 bytes result sent to driver
2018-02-08 15:59:22,877 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 147.0 (TID 503, localhost, executor driver, partition 24, ANY, 4726 bytes)
2018-02-08 15:59:22,878 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 147.0 (TID 501) in 20 ms on localhost (executor driver) (18/20)
2018-02-08 15:59:22,878 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 147.0 (TID 503)
2018-02-08 15:59:22,880 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 147.0 (TID 502). 2626 bytes result sent to driver
2018-02-08 15:59:22,880 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 147.0 (TID 502) in 17 ms on localhost (executor driver) (19/20)
2018-02-08 15:59:22,881 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,881 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,890 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 147.0 (TID 503). 2657 bytes result sent to driver
2018-02-08 15:59:22,890 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 147.0 (TID 503) in 13 ms on localhost (executor driver) (20/20)
2018-02-08 15:59:22,890 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 147.0, whose tasks have all completed, from pool 
2018-02-08 15:59:22,891 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 147 (show at MachineLeaningFiltering.java:46) finished in 0.105 s
2018-02-08 15:59:22,891 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 11 finished: show at MachineLeaningFiltering.java:46, took 0.112725 s
2018-02-08 15:59:22,893 INFO[org.apache.spark.SparkContext:54] - Starting job: show at MachineLeaningFiltering.java:46
2018-02-08 15:59:22,896 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 12 (show at MachineLeaningFiltering.java:46) with 35 output partitions
2018-02-08 15:59:22,896 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 163 (show at MachineLeaningFiltering.java:46)
2018-02-08 15:59:22,896 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 162)
2018-02-08 15:59:22,897 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 15:59:22,897 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 163 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46), which has no missing parents
2018-02-08 15:59:22,900 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_29 stored as values in memory (estimated size 59.6 KB, free 630.9 MB)
2018-02-08 15:59:22,902 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_29_piece0 stored as bytes in memory (estimated size 24.8 KB, free 630.9 MB)
2018-02-08 15:59:22,902 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_29_piece0 in memory on 192.168.11.26:62887 (size: 24.8 KB, free: 631.6 MB)
2018-02-08 15:59:22,903 INFO[org.apache.spark.SparkContext:54] - Created broadcast 29 from broadcast at DAGScheduler.scala:1006
2018-02-08 15:59:22,903 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 35 missing tasks from ResultStage 163 (MapPartitionsRDD[164] at show at MachineLeaningFiltering.java:46) (first 15 tasks are for partitions Vector(25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39))
2018-02-08 15:59:22,903 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 163.0 with 35 tasks
2018-02-08 15:59:22,904 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 163.0 (TID 504, localhost, executor driver, partition 25, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,904 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 163.0 (TID 505, localhost, executor driver, partition 26, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,904 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 163.0 (TID 504)
2018-02-08 15:59:22,907 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 163.0 (TID 505)
2018-02-08 15:59:22,911 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,912 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,912 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,912 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,912 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 163.0 (TID 504). 2424 bytes result sent to driver
2018-02-08 15:59:22,912 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 163.0 (TID 505). 2381 bytes result sent to driver
2018-02-08 15:59:22,912 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 3.0 in stage 163.0 (TID 506, localhost, executor driver, partition 28, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,913 INFO[org.apache.spark.executor.Executor:54] - Running task 3.0 in stage 163.0 (TID 506)
2018-02-08 15:59:22,913 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 4.0 in stage 163.0 (TID 507, localhost, executor driver, partition 29, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,913 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 163.0 (TID 504) in 9 ms on localhost (executor driver) (1/35)
2018-02-08 15:59:22,913 INFO[org.apache.spark.executor.Executor:54] - Running task 4.0 in stage 163.0 (TID 507)
2018-02-08 15:59:22,913 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 163.0 (TID 505) in 9 ms on localhost (executor driver) (2/35)
2018-02-08 15:59:22,916 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,916 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,916 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,916 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,916 INFO[org.apache.spark.executor.Executor:54] - Finished task 3.0 in stage 163.0 (TID 506). 2424 bytes result sent to driver
2018-02-08 15:59:22,916 INFO[org.apache.spark.executor.Executor:54] - Finished task 4.0 in stage 163.0 (TID 507). 2424 bytes result sent to driver
2018-02-08 15:59:22,916 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 6.0 in stage 163.0 (TID 508, localhost, executor driver, partition 31, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,917 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 3.0 in stage 163.0 (TID 506) in 5 ms on localhost (executor driver) (3/35)
2018-02-08 15:59:22,917 INFO[org.apache.spark.executor.Executor:54] - Running task 6.0 in stage 163.0 (TID 508)
2018-02-08 15:59:22,917 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 4.0 in stage 163.0 (TID 507) in 4 ms on localhost (executor driver) (4/35)
2018-02-08 15:59:22,917 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 8.0 in stage 163.0 (TID 509, localhost, executor driver, partition 33, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,917 INFO[org.apache.spark.executor.Executor:54] - Running task 8.0 in stage 163.0 (TID 509)
2018-02-08 15:59:22,925 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,925 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,925 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,926 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,926 INFO[org.apache.spark.executor.Executor:54] - Finished task 8.0 in stage 163.0 (TID 509). 2424 bytes result sent to driver
2018-02-08 15:59:22,926 INFO[org.apache.spark.executor.Executor:54] - Finished task 6.0 in stage 163.0 (TID 508). 2424 bytes result sent to driver
2018-02-08 15:59:22,926 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 9.0 in stage 163.0 (TID 510, localhost, executor driver, partition 34, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,926 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 8.0 in stage 163.0 (TID 509) in 9 ms on localhost (executor driver) (5/35)
2018-02-08 15:59:22,926 INFO[org.apache.spark.executor.Executor:54] - Running task 9.0 in stage 163.0 (TID 510)
2018-02-08 15:59:22,927 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 11.0 in stage 163.0 (TID 511, localhost, executor driver, partition 36, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,927 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 6.0 in stage 163.0 (TID 508) in 11 ms on localhost (executor driver) (6/35)
2018-02-08 15:59:22,927 INFO[org.apache.spark.executor.Executor:54] - Running task 11.0 in stage 163.0 (TID 511)
2018-02-08 15:59:22,930 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,930 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,930 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,930 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,930 INFO[org.apache.spark.executor.Executor:54] - Finished task 11.0 in stage 163.0 (TID 511). 2424 bytes result sent to driver
2018-02-08 15:59:22,930 INFO[org.apache.spark.executor.Executor:54] - Finished task 9.0 in stage 163.0 (TID 510). 2424 bytes result sent to driver
2018-02-08 15:59:22,931 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 12.0 in stage 163.0 (TID 512, localhost, executor driver, partition 37, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,931 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 13.0 in stage 163.0 (TID 513, localhost, executor driver, partition 38, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,931 INFO[org.apache.spark.executor.Executor:54] - Running task 12.0 in stage 163.0 (TID 512)
2018-02-08 15:59:22,931 INFO[org.apache.spark.executor.Executor:54] - Running task 13.0 in stage 163.0 (TID 513)
2018-02-08 15:59:22,931 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 11.0 in stage 163.0 (TID 511) in 4 ms on localhost (executor driver) (7/35)
2018-02-08 15:59:22,932 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 9.0 in stage 163.0 (TID 510) in 6 ms on localhost (executor driver) (8/35)
2018-02-08 15:59:22,934 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,934 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,934 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,934 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,935 INFO[org.apache.spark.executor.Executor:54] - Finished task 12.0 in stage 163.0 (TID 512). 2467 bytes result sent to driver
2018-02-08 15:59:22,935 INFO[org.apache.spark.executor.Executor:54] - Finished task 13.0 in stage 163.0 (TID 513). 2424 bytes result sent to driver
2018-02-08 15:59:22,935 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 14.0 in stage 163.0 (TID 514, localhost, executor driver, partition 39, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,935 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 12.0 in stage 163.0 (TID 512) in 4 ms on localhost (executor driver) (9/35)
2018-02-08 15:59:22,935 INFO[org.apache.spark.executor.Executor:54] - Running task 14.0 in stage 163.0 (TID 514)
2018-02-08 15:59:22,935 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 13.0 in stage 163.0 (TID 513) in 4 ms on localhost (executor driver) (10/35)
2018-02-08 15:59:22,935 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 15.0 in stage 163.0 (TID 515, localhost, executor driver, partition 40, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,936 INFO[org.apache.spark.executor.Executor:54] - Running task 15.0 in stage 163.0 (TID 515)
2018-02-08 15:59:22,940 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,940 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,940 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,940 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,941 INFO[org.apache.spark.executor.Executor:54] - Finished task 14.0 in stage 163.0 (TID 514). 2467 bytes result sent to driver
2018-02-08 15:59:22,941 INFO[org.apache.spark.executor.Executor:54] - Finished task 15.0 in stage 163.0 (TID 515). 2467 bytes result sent to driver
2018-02-08 15:59:22,941 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 16.0 in stage 163.0 (TID 516, localhost, executor driver, partition 41, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,941 INFO[org.apache.spark.executor.Executor:54] - Running task 16.0 in stage 163.0 (TID 516)
2018-02-08 15:59:22,941 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 17.0 in stage 163.0 (TID 517, localhost, executor driver, partition 42, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,941 INFO[org.apache.spark.executor.Executor:54] - Running task 17.0 in stage 163.0 (TID 517)
2018-02-08 15:59:22,941 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 15.0 in stage 163.0 (TID 515) in 6 ms on localhost (executor driver) (11/35)
2018-02-08 15:59:22,942 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 14.0 in stage 163.0 (TID 514) in 7 ms on localhost (executor driver) (12/35)
2018-02-08 15:59:22,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,944 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,945 INFO[org.apache.spark.executor.Executor:54] - Finished task 17.0 in stage 163.0 (TID 517). 2424 bytes result sent to driver
2018-02-08 15:59:22,945 INFO[org.apache.spark.executor.Executor:54] - Finished task 16.0 in stage 163.0 (TID 516). 2381 bytes result sent to driver
2018-02-08 15:59:22,945 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 20.0 in stage 163.0 (TID 518, localhost, executor driver, partition 45, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,945 INFO[org.apache.spark.executor.Executor:54] - Running task 20.0 in stage 163.0 (TID 518)
2018-02-08 15:59:22,945 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 21.0 in stage 163.0 (TID 519, localhost, executor driver, partition 46, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,945 INFO[org.apache.spark.executor.Executor:54] - Running task 21.0 in stage 163.0 (TID 519)
2018-02-08 15:59:22,945 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 16.0 in stage 163.0 (TID 516) in 4 ms on localhost (executor driver) (13/35)
2018-02-08 15:59:22,945 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 17.0 in stage 163.0 (TID 517) in 4 ms on localhost (executor driver) (14/35)
2018-02-08 15:59:22,948 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,948 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,948 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,948 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,948 INFO[org.apache.spark.executor.Executor:54] - Finished task 21.0 in stage 163.0 (TID 519). 2381 bytes result sent to driver
2018-02-08 15:59:22,948 INFO[org.apache.spark.executor.Executor:54] - Finished task 20.0 in stage 163.0 (TID 518). 2381 bytes result sent to driver
2018-02-08 15:59:22,949 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 22.0 in stage 163.0 (TID 520, localhost, executor driver, partition 47, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,949 INFO[org.apache.spark.executor.Executor:54] - Running task 22.0 in stage 163.0 (TID 520)
2018-02-08 15:59:22,949 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 21.0 in stage 163.0 (TID 519) in 4 ms on localhost (executor driver) (15/35)
2018-02-08 15:59:22,949 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 25.0 in stage 163.0 (TID 521, localhost, executor driver, partition 50, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,949 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 20.0 in stage 163.0 (TID 518) in 4 ms on localhost (executor driver) (16/35)
2018-02-08 15:59:22,949 INFO[org.apache.spark.executor.Executor:54] - Running task 25.0 in stage 163.0 (TID 521)
2018-02-08 15:59:22,951 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,951 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,952 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,952 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,952 INFO[org.apache.spark.executor.Executor:54] - Finished task 25.0 in stage 163.0 (TID 521). 2424 bytes result sent to driver
2018-02-08 15:59:22,952 INFO[org.apache.spark.executor.Executor:54] - Finished task 22.0 in stage 163.0 (TID 520). 2424 bytes result sent to driver
2018-02-08 15:59:22,953 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 27.0 in stage 163.0 (TID 522, localhost, executor driver, partition 52, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,953 INFO[org.apache.spark.executor.Executor:54] - Running task 27.0 in stage 163.0 (TID 522)
2018-02-08 15:59:22,953 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 29.0 in stage 163.0 (TID 523, localhost, executor driver, partition 54, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,953 INFO[org.apache.spark.executor.Executor:54] - Running task 29.0 in stage 163.0 (TID 523)
2018-02-08 15:59:22,953 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 22.0 in stage 163.0 (TID 520) in 4 ms on localhost (executor driver) (17/35)
2018-02-08 15:59:22,953 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 25.0 in stage 163.0 (TID 521) in 4 ms on localhost (executor driver) (18/35)
2018-02-08 15:59:22,956 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,956 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,956 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,956 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,956 INFO[org.apache.spark.executor.Executor:54] - Finished task 29.0 in stage 163.0 (TID 523). 2381 bytes result sent to driver
2018-02-08 15:59:22,956 INFO[org.apache.spark.executor.Executor:54] - Finished task 27.0 in stage 163.0 (TID 522). 2381 bytes result sent to driver
2018-02-08 15:59:22,957 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 30.0 in stage 163.0 (TID 524, localhost, executor driver, partition 55, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,957 INFO[org.apache.spark.executor.Executor:54] - Running task 30.0 in stage 163.0 (TID 524)
2018-02-08 15:59:22,957 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 31.0 in stage 163.0 (TID 525, localhost, executor driver, partition 56, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,957 INFO[org.apache.spark.executor.Executor:54] - Running task 31.0 in stage 163.0 (TID 525)
2018-02-08 15:59:22,957 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 29.0 in stage 163.0 (TID 523) in 4 ms on localhost (executor driver) (19/35)
2018-02-08 15:59:22,957 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 27.0 in stage 163.0 (TID 522) in 4 ms on localhost (executor driver) (20/35)
2018-02-08 15:59:22,959 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,959 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,959 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,960 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,960 INFO[org.apache.spark.executor.Executor:54] - Finished task 31.0 in stage 163.0 (TID 525). 2424 bytes result sent to driver
2018-02-08 15:59:22,960 INFO[org.apache.spark.executor.Executor:54] - Finished task 30.0 in stage 163.0 (TID 524). 2424 bytes result sent to driver
2018-02-08 15:59:22,960 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 34.0 in stage 163.0 (TID 526, localhost, executor driver, partition 59, PROCESS_LOCAL, 4726 bytes)
2018-02-08 15:59:22,960 INFO[org.apache.spark.executor.Executor:54] - Running task 34.0 in stage 163.0 (TID 526)
2018-02-08 15:59:22,960 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 2.0 in stage 163.0 (TID 527, localhost, executor driver, partition 27, ANY, 4726 bytes)
2018-02-08 15:59:22,960 INFO[org.apache.spark.executor.Executor:54] - Running task 2.0 in stage 163.0 (TID 527)
2018-02-08 15:59:22,960 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 31.0 in stage 163.0 (TID 525) in 3 ms on localhost (executor driver) (21/35)
2018-02-08 15:59:22,961 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 30.0 in stage 163.0 (TID 524) in 4 ms on localhost (executor driver) (22/35)
2018-02-08 15:59:22,963 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,963 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 0 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,963 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,963 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,964 INFO[org.apache.spark.executor.Executor:54] - Finished task 34.0 in stage 163.0 (TID 526). 2424 bytes result sent to driver
2018-02-08 15:59:22,964 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 5.0 in stage 163.0 (TID 528, localhost, executor driver, partition 30, ANY, 4726 bytes)
2018-02-08 15:59:22,964 INFO[org.apache.spark.executor.Executor:54] - Running task 5.0 in stage 163.0 (TID 528)
2018-02-08 15:59:22,964 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 34.0 in stage 163.0 (TID 526) in 4 ms on localhost (executor driver) (23/35)
2018-02-08 15:59:22,967 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,967 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,972 INFO[org.apache.spark.executor.Executor:54] - Finished task 2.0 in stage 163.0 (TID 527). 2652 bytes result sent to driver
2018-02-08 15:59:22,972 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 7.0 in stage 163.0 (TID 529, localhost, executor driver, partition 32, ANY, 4726 bytes)
2018-02-08 15:59:22,973 INFO[org.apache.spark.executor.Executor:54] - Running task 7.0 in stage 163.0 (TID 529)
2018-02-08 15:59:22,973 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 2.0 in stage 163.0 (TID 527) in 13 ms on localhost (executor driver) (24/35)
2018-02-08 15:59:22,976 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,977 INFO[org.apache.spark.executor.Executor:54] - Finished task 5.0 in stage 163.0 (TID 528). 2651 bytes result sent to driver
2018-02-08 15:59:22,977 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,977 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 10.0 in stage 163.0 (TID 530, localhost, executor driver, partition 35, ANY, 4726 bytes)
2018-02-08 15:59:22,977 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 5.0 in stage 163.0 (TID 528) in 13 ms on localhost (executor driver) (25/35)
2018-02-08 15:59:22,977 INFO[org.apache.spark.executor.Executor:54] - Running task 10.0 in stage 163.0 (TID 530)
2018-02-08 15:59:22,980 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,980 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:22,987 INFO[org.apache.spark.executor.Executor:54] - Finished task 7.0 in stage 163.0 (TID 529). 2659 bytes result sent to driver
2018-02-08 15:59:22,988 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 18.0 in stage 163.0 (TID 531, localhost, executor driver, partition 43, ANY, 4726 bytes)
2018-02-08 15:59:22,988 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 7.0 in stage 163.0 (TID 529) in 16 ms on localhost (executor driver) (26/35)
2018-02-08 15:59:22,988 INFO[org.apache.spark.executor.Executor:54] - Running task 18.0 in stage 163.0 (TID 531)
2018-02-08 15:59:22,991 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:22,992 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 15:59:22,992 INFO[org.apache.spark.executor.Executor:54] - Finished task 10.0 in stage 163.0 (TID 530). 2659 bytes result sent to driver
2018-02-08 15:59:22,993 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 19.0 in stage 163.0 (TID 532, localhost, executor driver, partition 44, ANY, 4726 bytes)
2018-02-08 15:59:22,994 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 10.0 in stage 163.0 (TID 530) in 17 ms on localhost (executor driver) (27/35)
2018-02-08 15:59:22,996 INFO[org.apache.spark.executor.Executor:54] - Running task 19.0 in stage 163.0 (TID 532)
2018-02-08 15:59:23,002 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:23,002 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:23,004 INFO[org.apache.spark.executor.Executor:54] - Finished task 18.0 in stage 163.0 (TID 531). 2667 bytes result sent to driver
2018-02-08 15:59:23,005 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 23.0 in stage 163.0 (TID 533, localhost, executor driver, partition 48, ANY, 4726 bytes)
2018-02-08 15:59:23,005 INFO[org.apache.spark.executor.Executor:54] - Running task 23.0 in stage 163.0 (TID 533)
2018-02-08 15:59:23,005 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 18.0 in stage 163.0 (TID 531) in 17 ms on localhost (executor driver) (28/35)
2018-02-08 15:59:23,008 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:23,008 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:23,016 INFO[org.apache.spark.executor.Executor:54] - Finished task 23.0 in stage 163.0 (TID 533). 2610 bytes result sent to driver
2018-02-08 15:59:23,016 INFO[org.apache.spark.executor.Executor:54] - Finished task 19.0 in stage 163.0 (TID 532). 2712 bytes result sent to driver
2018-02-08 15:59:23,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 24.0 in stage 163.0 (TID 534, localhost, executor driver, partition 49, ANY, 4726 bytes)
2018-02-08 15:59:23,017 INFO[org.apache.spark.executor.Executor:54] - Running task 24.0 in stage 163.0 (TID 534)
2018-02-08 15:59:23,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 23.0 in stage 163.0 (TID 533) in 12 ms on localhost (executor driver) (29/35)
2018-02-08 15:59:23,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 26.0 in stage 163.0 (TID 535, localhost, executor driver, partition 51, ANY, 4726 bytes)
2018-02-08 15:59:23,017 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 19.0 in stage 163.0 (TID 532) in 24 ms on localhost (executor driver) (30/35)
2018-02-08 15:59:23,017 INFO[org.apache.spark.executor.Executor:54] - Running task 26.0 in stage 163.0 (TID 535)
2018-02-08 15:59:23,020 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:23,020 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:23,020 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:23,020 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:23,028 INFO[org.apache.spark.executor.Executor:54] - Finished task 26.0 in stage 163.0 (TID 535). 2616 bytes result sent to driver
2018-02-08 15:59:23,028 INFO[org.apache.spark.executor.Executor:54] - Finished task 24.0 in stage 163.0 (TID 534). 2855 bytes result sent to driver
2018-02-08 15:59:23,028 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 28.0 in stage 163.0 (TID 536, localhost, executor driver, partition 53, ANY, 4726 bytes)
2018-02-08 15:59:23,028 INFO[org.apache.spark.executor.Executor:54] - Running task 28.0 in stage 163.0 (TID 536)
2018-02-08 15:59:23,028 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 32.0 in stage 163.0 (TID 537, localhost, executor driver, partition 57, ANY, 4726 bytes)
2018-02-08 15:59:23,029 INFO[org.apache.spark.executor.Executor:54] - Running task 32.0 in stage 163.0 (TID 537)
2018-02-08 15:59:23,029 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 24.0 in stage 163.0 (TID 534) in 12 ms on localhost (executor driver) (31/35)
2018-02-08 15:59:23,029 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 26.0 in stage 163.0 (TID 535) in 12 ms on localhost (executor driver) (32/35)
2018-02-08 15:59:23,032 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:23,032 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:23,032 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:23,032 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:23,041 INFO[org.apache.spark.executor.Executor:54] - Finished task 32.0 in stage 163.0 (TID 537). 2652 bytes result sent to driver
2018-02-08 15:59:23,041 INFO[org.apache.spark.executor.Executor:54] - Finished task 28.0 in stage 163.0 (TID 536). 2778 bytes result sent to driver
2018-02-08 15:59:23,041 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 33.0 in stage 163.0 (TID 538, localhost, executor driver, partition 58, ANY, 4726 bytes)
2018-02-08 15:59:23,041 INFO[org.apache.spark.executor.Executor:54] - Running task 33.0 in stage 163.0 (TID 538)
2018-02-08 15:59:23,041 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 32.0 in stage 163.0 (TID 537) in 13 ms on localhost (executor driver) (33/35)
2018-02-08 15:59:23,041 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 28.0 in stage 163.0 (TID 536) in 13 ms on localhost (executor driver) (34/35)
2018-02-08 15:59:23,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 10 non-empty blocks out of 100 blocks
2018-02-08 15:59:23,044 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 15:59:23,052 INFO[org.apache.spark.executor.Executor:54] - Finished task 33.0 in stage 163.0 (TID 538). 2658 bytes result sent to driver
2018-02-08 15:59:23,053 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 33.0 in stage 163.0 (TID 538) in 12 ms on localhost (executor driver) (35/35)
2018-02-08 15:59:23,053 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 163.0, whose tasks have all completed, from pool 
2018-02-08 15:59:23,053 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 163 (show at MachineLeaningFiltering.java:46) finished in 0.150 s
2018-02-08 15:59:23,053 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 12 finished: show at MachineLeaningFiltering.java:46, took 0.160018 s
2018-02-08 15:59:23,067 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 12.960004 ms
2018-02-08 15:59:23,079 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 15:59:23,086 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@44785b6f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 15:59:23,088 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 15:59:23,098 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 15:59:23,621 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 15:59:23,621 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 15:59:23,622 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 15:59:23,625 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 15:59:23,628 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 15:59:23,629 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 15:59:23,629 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-c7df5333-621b-4e7b-a6c9-8374000105cc
2018-02-08 16:11:51,808 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 16:11:52,409 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 16:11:52,429 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 16:11:52,430 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 16:11:52,431 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 16:11:52,431 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 16:11:52,432 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 16:11:52,778 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 63005.
2018-02-08 16:11:52,795 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 16:11:52,838 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 16:11:52,840 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 16:11:52,841 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 16:11:52,849 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-8f04c406-6f97-4918-9d17-7e16fc1107f3
2018-02-08 16:11:52,869 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 16:11:52,914 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 16:11:52,977 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2685ms
2018-02-08 16:11:53,047 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 16:11:53,059 INFO[org.spark_project.jetty.server.Server:403] - Started @2768ms
2018-02-08 16:11:53,076 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@18264418{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 16:11:53,076 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 16:11:53,098 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6722db6e{/jobs,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,100 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,100 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,101 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,102 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,102 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,103 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,105 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,106 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,107 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,107 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,108 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,108 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,110 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,111 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/environment,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,112 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,112 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,113 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,114 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410ae9a3{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,114 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@d5ae57e{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,121 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e242b4d{/static,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,121 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3c0fae6c{/,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,122 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@52b56a3e{/api,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,123 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6326d182{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,123 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@716a7124{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,125 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 16:11:53,196 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 16:11:53,220 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63018.
2018-02-08 16:11:53,221 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:63018
2018-02-08 16:11:53,222 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 16:11:53,224 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 63018, None)
2018-02-08 16:11:53,230 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:63018 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 63018, None)
2018-02-08 16:11:53,235 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 63018, None)
2018-02-08 16:11:53,236 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 63018, None)
2018-02-08 16:11:53,398 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c1a4620{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,455 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 16:11:53,456 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 16:11:53,463 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d691f3d{/SQL,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,464 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1e7f2e0f{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,465 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@71154f21{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,466 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2516fc68{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 16:11:53,470 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d140a7{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 16:11:54,436 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 16:11:56,174 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 174.304376 ms
2018-02-08 16:11:56,323 INFO[org.apache.spark.SparkContext:54] - Starting job: first at RowMatrix.scala:61
2018-02-08 16:11:56,339 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (first at RowMatrix.scala:61) with 1 output partitions
2018-02-08 16:11:56,339 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (first at RowMatrix.scala:61)
2018-02-08 16:11:56,339 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 16:11:56,341 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 16:11:56,345 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[4] at map at Correlation.scala:70), which has no missing parents
2018-02-08 16:11:56,522 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 8.1 KB, free 631.8 MB)
2018-02-08 16:11:56,550 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 631.8 MB)
2018-02-08 16:11:56,552 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:63018 (size: 4.2 KB, free: 631.8 MB)
2018-02-08 16:11:56,554 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 16:11:56,564 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at Correlation.scala:70) (first 15 tasks are for partitions Vector(0))
2018-02-08 16:11:56,565 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
2018-02-08 16:11:56,595 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5220 bytes)
2018-02-08 16:11:56,601 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 16:11:56,669 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 8.093443 ms
2018-02-08 16:11:56,689 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1202 bytes result sent to driver
2018-02-08 16:11:56,695 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 108 ms on localhost (executor driver) (1/1)
2018-02-08 16:11:56,697 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 16:11:56,701 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (first at RowMatrix.scala:61) finished in 0.122 s
2018-02-08 16:11:56,705 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: first at RowMatrix.scala:61, took 0.381711 s
2018-02-08 16:11:56,739 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at RowMatrix.scala:419
2018-02-08 16:11:56,743 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (treeAggregate at RowMatrix.scala:419) with 2 output partitions
2018-02-08 16:11:56,743 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (treeAggregate at RowMatrix.scala:419)
2018-02-08 16:11:56,743 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 16:11:56,744 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 16:11:56,745 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:419), which has no missing parents
2018-02-08 16:11:56,749 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 9.0 KB, free 631.8 MB)
2018-02-08 16:11:56,754 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 631.8 MB)
2018-02-08 16:11:56,755 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:63018 (size: 4.6 KB, free: 631.8 MB)
2018-02-08 16:11:56,756 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 16:11:56,757 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:419) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 16:11:56,757 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 16:11:56,758 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5220 bytes)
2018-02-08 16:11:56,758 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 5220 bytes)
2018-02-08 16:11:56,759 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
2018-02-08 16:11:56,759 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 2)
2018-02-08 16:11:56,777 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 2). 1614 bytes result sent to driver
2018-02-08 16:11:56,777 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1614 bytes result sent to driver
2018-02-08 16:11:56,780 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 22 ms on localhost (executor driver) (1/2)
2018-02-08 16:11:56,785 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 2) in 27 ms on localhost (executor driver) (2/2)
2018-02-08 16:11:56,786 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 16:11:56,787 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (treeAggregate at RowMatrix.scala:419) finished in 0.029 s
2018-02-08 16:11:56,788 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: treeAggregate at RowMatrix.scala:419, took 0.046436 s
2018-02-08 16:11:57,392 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at RowMatrix.scala:122
2018-02-08 16:11:57,393 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (treeAggregate at RowMatrix.scala:122) with 2 output partitions
2018-02-08 16:11:57,394 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (treeAggregate at RowMatrix.scala:122)
2018-02-08 16:11:57,394 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 16:11:57,394 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 16:11:57,394 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:122), which has no missing parents
2018-02-08 16:11:57,397 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 631.8 MB)
2018-02-08 16:11:57,399 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 631.8 MB)
2018-02-08 16:11:57,400 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:63018 (size: 4.5 KB, free: 631.8 MB)
2018-02-08 16:11:57,401 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 16:11:57,402 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:122) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 16:11:57,402 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 2 tasks
2018-02-08 16:11:57,404 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5220 bytes)
2018-02-08 16:11:57,404 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 5220 bytes)
2018-02-08 16:11:57,404 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 16:11:57,406 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 4)
2018-02-08 16:11:57,422 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 16:11:57,422 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 16:11:57,426 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 1223 bytes result sent to driver
2018-02-08 16:11:57,427 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 4). 1137 bytes result sent to driver
2018-02-08 16:11:57,428 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 4) in 24 ms on localhost (executor driver) (1/2)
2018-02-08 16:11:57,429 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 26 ms on localhost (executor driver) (2/2)
2018-02-08 16:11:57,429 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 16:11:57,430 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (treeAggregate at RowMatrix.scala:122) finished in 0.027 s
2018-02-08 16:11:57,431 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: treeAggregate at RowMatrix.scala:122, took 0.037988 s
2018-02-08 16:11:57,800 WARN[org.apache.spark.mllib.stat.correlation.PearsonCorrelation:66] - Pearson correlation matrix contains NaN values.
2018-02-08 16:11:57,859 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 22.099207 ms
2018-02-08 16:11:57,869 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 7.526083 ms
2018-02-08 16:11:57,879 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 16:11:57,883 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@18264418{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 16:11:57,885 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 16:11:57,893 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 16:11:57,904 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 16:11:57,904 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 16:11:57,908 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 16:11:57,910 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 16:11:57,923 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 16:11:57,924 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 16:11:57,925 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-f55b5321-7f06-4f00-8596-b4d03807f2a4
2018-02-08 16:16:22,593 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 16:16:23,184 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 16:16:23,204 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 16:16:23,204 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 16:16:23,205 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 16:16:23,206 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 16:16:23,206 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 16:16:23,540 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 63079.
2018-02-08 16:16:23,584 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 16:16:23,599 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 16:16:23,603 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 16:16:23,603 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 16:16:23,613 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-6788ae3d-dae9-4f3e-ba09-5cdb5218ded6
2018-02-08 16:16:23,636 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 16:16:23,673 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 16:16:23,744 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2774ms
2018-02-08 16:16:23,815 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 16:16:23,830 INFO[org.spark_project.jetty.server.Server:403] - Started @2860ms
2018-02-08 16:16:23,850 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@6d5fb476{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 16:16:23,851 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 16:16:23,871 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6722db6e{/jobs,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,872 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@267f474e{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,873 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@28276e50{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,874 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@675d8c96{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,876 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ed3b1f5{/stages,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,876 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@68d6972f{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,877 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7651218e{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,878 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@24faea88{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,878 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64beebb7{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,879 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@bcec031{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,879 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@32f0fba8{/storage,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,880 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@29ef6856{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,880 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3faf2e7d{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,881 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@569bf9eb{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,882 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@274872f8{/environment,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,882 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@eb6449b{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,883 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@180e6ac4{/executors,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,884 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e985ce9{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,884 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@410ae9a3{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,885 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@d5ae57e{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,891 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7e242b4d{/static,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,892 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3c0fae6c{/,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,893 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@52b56a3e{/api,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,894 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6326d182{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,894 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@716a7124{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 16:16:23,896 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 16:16:23,966 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 16:16:23,991 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63092.
2018-02-08 16:16:23,992 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:63092
2018-02-08 16:16:23,998 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 16:16:24,003 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 63092, None)
2018-02-08 16:16:24,007 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:63092 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 63092, None)
2018-02-08 16:16:24,015 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 63092, None)
2018-02-08 16:16:24,017 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 63092, None)
2018-02-08 16:16:24,166 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@c1a4620{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:24,226 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 16:16:24,227 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 16:16:24,232 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d691f3d{/SQL,null,AVAILABLE,@Spark}
2018-02-08 16:16:24,234 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1e7f2e0f{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:24,235 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@71154f21{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 16:16:24,235 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2516fc68{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 16:16:24,237 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2d140a7{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 16:16:25,231 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 16:16:27,067 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 187.22438 ms
2018-02-08 16:16:27,204 INFO[org.apache.spark.SparkContext:54] - Starting job: first at RowMatrix.scala:61
2018-02-08 16:16:27,220 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (first at RowMatrix.scala:61) with 1 output partitions
2018-02-08 16:16:27,220 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (first at RowMatrix.scala:61)
2018-02-08 16:16:27,221 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 16:16:27,222 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 16:16:27,226 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (MapPartitionsRDD[4] at map at Correlation.scala:70), which has no missing parents
2018-02-08 16:16:27,414 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 8.1 KB, free 631.8 MB)
2018-02-08 16:16:27,443 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 631.8 MB)
2018-02-08 16:16:27,445 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:63092 (size: 4.2 KB, free: 631.8 MB)
2018-02-08 16:16:27,447 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
2018-02-08 16:16:27,457 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at Correlation.scala:70) (first 15 tasks are for partitions Vector(0))
2018-02-08 16:16:27,458 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 1 tasks
2018-02-08 16:16:27,493 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 5220 bytes)
2018-02-08 16:16:27,500 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 16:16:27,565 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.549123 ms
2018-02-08 16:16:27,587 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1159 bytes result sent to driver
2018-02-08 16:16:27,593 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 110 ms on localhost (executor driver) (1/1)
2018-02-08 16:16:27,595 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 16:16:27,599 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (first at RowMatrix.scala:61) finished in 0.126 s
2018-02-08 16:16:27,603 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: first at RowMatrix.scala:61, took 0.398399 s
2018-02-08 16:16:27,629 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at RowMatrix.scala:419
2018-02-08 16:16:27,630 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (treeAggregate at RowMatrix.scala:419) with 2 output partitions
2018-02-08 16:16:27,630 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (treeAggregate at RowMatrix.scala:419)
2018-02-08 16:16:27,630 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 16:16:27,631 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 16:16:27,631 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:419), which has no missing parents
2018-02-08 16:16:27,633 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 9.0 KB, free 631.8 MB)
2018-02-08 16:16:27,638 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 631.8 MB)
2018-02-08 16:16:27,639 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:63092 (size: 4.6 KB, free: 631.8 MB)
2018-02-08 16:16:27,640 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 16:16:27,641 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at treeAggregate at RowMatrix.scala:419) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 16:16:27,641 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 2 tasks
2018-02-08 16:16:27,642 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 5220 bytes)
2018-02-08 16:16:27,642 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 5220 bytes)
2018-02-08 16:16:27,643 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 1)
2018-02-08 16:16:27,643 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 1.0 (TID 2)
2018-02-08 16:16:27,671 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 1.0 (TID 2). 1657 bytes result sent to driver
2018-02-08 16:16:27,675 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 1). 1657 bytes result sent to driver
2018-02-08 16:16:27,678 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 1.0 (TID 2) in 36 ms on localhost (executor driver) (1/2)
2018-02-08 16:16:27,679 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (executor driver) (2/2)
2018-02-08 16:16:27,679 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 16:16:27,679 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (treeAggregate at RowMatrix.scala:419) finished in 0.038 s
2018-02-08 16:16:27,680 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: treeAggregate at RowMatrix.scala:419, took 0.050035 s
2018-02-08 16:16:28,100 INFO[org.apache.spark.SparkContext:54] - Starting job: treeAggregate at RowMatrix.scala:122
2018-02-08 16:16:28,101 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (treeAggregate at RowMatrix.scala:122) with 2 output partitions
2018-02-08 16:16:28,101 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 2 (treeAggregate at RowMatrix.scala:122)
2018-02-08 16:16:28,101 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 16:16:28,101 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 16:16:28,102 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 2 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:122), which has no missing parents
2018-02-08 16:16:28,106 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 631.8 MB)
2018-02-08 16:16:28,108 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 631.8 MB)
2018-02-08 16:16:28,111 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:63092 (size: 4.5 KB, free: 631.8 MB)
2018-02-08 16:16:28,112 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 16:16:28,113 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at treeAggregate at RowMatrix.scala:122) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 16:16:28,113 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 2 tasks
2018-02-08 16:16:28,114 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 5220 bytes)
2018-02-08 16:16:28,115 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 5220 bytes)
2018-02-08 16:16:28,115 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 16:16:28,117 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 4)
2018-02-08 16:16:28,136 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2018-02-08 16:16:28,137 WARN[com.github.fommil.netlib.BLAS:61] - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2018-02-08 16:16:28,140 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 1223 bytes result sent to driver
2018-02-08 16:16:28,140 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 4). 1180 bytes result sent to driver
2018-02-08 16:16:28,142 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 4) in 27 ms on localhost (executor driver) (1/2)
2018-02-08 16:16:28,142 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 28 ms on localhost (executor driver) (2/2)
2018-02-08 16:16:28,143 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 2 (treeAggregate at RowMatrix.scala:122) finished in 0.029 s
2018-02-08 16:16:28,144 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: treeAggregate at RowMatrix.scala:122, took 0.043531 s
2018-02-08 16:16:28,147 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 16:16:28,401 WARN[org.apache.spark.mllib.stat.correlation.PearsonCorrelation:66] - Pearson correlation matrix contains NaN values.
2018-02-08 16:16:28,463 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 17.623366 ms
2018-02-08 16:16:28,475 INFO[org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator:54] - Code generated in 9.518403 ms
2018-02-08 16:16:28,503 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 16:16:28,507 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@6d5fb476{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 16:16:28,509 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 16:16:28,516 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 16:16:28,527 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 16:16:28,528 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 16:16:28,532 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 16:16:28,534 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 16:16:28,536 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 16:16:28,537 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 16:16:28,537 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-da773929-7503-4e9e-89af-b7b12eddf286
2018-02-08 17:12:58,745 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 17:12:59,354 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 17:12:59,390 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 17:12:59,390 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 17:12:59,391 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 17:12:59,392 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 17:12:59,392 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 17:12:59,794 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 63626.
2018-02-08 17:12:59,820 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 17:12:59,848 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 17:12:59,852 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 17:12:59,853 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 17:12:59,864 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-bfe824ee-59fb-4264-aaa8-5b782f4fc222
2018-02-08 17:12:59,918 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 17:12:59,962 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 17:13:00,077 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2675ms
2018-02-08 17:13:00,156 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 17:13:00,168 INFO[org.spark_project.jetty.server.Server:403] - Started @2767ms
2018-02-08 17:13:00,187 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@3fffff43{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 17:13:00,187 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 17:13:00,213 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@590c73d3{/jobs,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,214 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3dddefd8{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,215 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@12bfd80d{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,216 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5316e95f{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,216 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6c6c5427{/stages,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,217 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b40ceb{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,217 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d8062d2{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,218 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@285c08c8{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,219 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3918c187{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,220 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@64dafeed{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,220 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@47605f2f{/storage,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,221 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1dd0e7c4{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,221 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3d484181{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,222 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7be58f16{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,222 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5b11a194{/environment,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,223 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@60f7cc1d{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,223 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4721d212{/executors,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,224 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@45cff11c{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,225 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4bff1903{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,225 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5827af16{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,234 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@56c9bbd8{/static,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,235 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@f0e995e{/,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,236 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@73db4768{/api,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,237 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3a62c01e{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,237 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5ce33a58{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,240 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 17:13:00,414 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 17:13:00,443 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63639.
2018-02-08 17:13:00,444 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:63639
2018-02-08 17:13:00,446 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 17:13:00,448 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 63639, None)
2018-02-08 17:13:00,456 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:63639 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 63639, None)
2018-02-08 17:13:00,463 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 63639, None)
2018-02-08 17:13:00,464 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 63639, None)
2018-02-08 17:13:00,643 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2b46a8c1{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,730 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 17:13:00,731 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 17:13:00,738 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@e27ba81{/SQL,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,739 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1556f2dd{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,740 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@772485dd{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,740 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@79ab3a71{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 17:13:00,742 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@492fc69e{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 17:13:01,879 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 17:13:01,891 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 17:13:01,896 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@3fffff43{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 17:13:01,897 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 17:13:01,905 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 17:13:01,912 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 17:13:01,912 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 17:13:01,918 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 17:13:01,921 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 17:13:01,924 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 17:13:01,924 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 17:13:01,925 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-30ce06fe-e63a-4448-925b-03bcb8374c3e
2018-02-08 17:14:18,712 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 17:14:19,447 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 17:14:19,472 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 17:14:19,472 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 17:14:19,473 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 17:14:19,474 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 17:14:19,474 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 17:14:19,802 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 63677.
2018-02-08 17:14:19,818 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 17:14:19,841 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 17:14:19,844 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 17:14:19,844 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 17:14:19,851 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-52d984ff-bbd3-4f73-9cae-08d365e2b023
2018-02-08 17:14:19,896 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 17:14:19,931 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 17:14:19,993 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2434ms
2018-02-08 17:14:20,042 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 17:14:20,055 INFO[org.spark_project.jetty.server.Server:403] - Started @2496ms
2018-02-08 17:14:20,071 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@2c65d593{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 17:14:20,071 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 17:14:20,090 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6b9ce1bf{/jobs,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,091 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@160ac7fb{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,092 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41925502{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,094 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3f053c80{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,095 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@618c5d94{/stages,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,096 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@13c3c1e1{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,096 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1e63ec0b{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,098 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@295eaa7c{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,099 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c88b9fc{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,100 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@388ba540{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,101 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ece4966{/storage,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,101 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7894f09b{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,102 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6111ba37{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,103 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,103 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,104 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@11eadcba{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,105 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1b065145{/executors,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,105 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@207ea13{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,106 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62dae540{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,106 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@654d8173{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,113 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@630cb4a4{/static,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,113 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4c37b5b{/,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,114 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@71b3bc45{/api,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,115 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a8fa663{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,115 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@78a287ed{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,117 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 17:14:20,184 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 17:14:20,205 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63690.
2018-02-08 17:14:20,205 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:63690
2018-02-08 17:14:20,206 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 17:14:20,208 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 63690, None)
2018-02-08 17:14:20,212 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:63690 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 63690, None)
2018-02-08 17:14:20,214 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 63690, None)
2018-02-08 17:14:20,214 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 63690, None)
2018-02-08 17:14:20,407 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d572e62{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,456 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 17:14:20,457 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 17:14:20,462 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@54336c81{/SQL,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,463 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@35e52059{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,464 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5a12c728{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,464 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6e5bfdfc{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 17:14:20,466 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@117632cf{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 17:14:21,410 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 17:14:21,770 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 17:14:21,846 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 17:14:21,849 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:63690 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 17:14:21,853 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at GraphLoader.scala:73
2018-02-08 17:14:21,956 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 17:14:21,973 INFO[org.apache.spark.SparkContext:54] - Starting job: count at GraphLoader.scala:94
2018-02-08 17:14:21,999 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (count at GraphLoader.scala:94) with 2 output partitions
2018-02-08 17:14:21,999 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (count at GraphLoader.scala:94)
2018-02-08 17:14:22,000 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 17:14:22,004 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 17:14:22,011 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (GraphLoader.edgeListFile - edges (data/graphx/followers.txt) MapPartitionsRDD[2] at mapPartitionsWithIndex at GraphLoader.scala:75), which has no missing parents
2018-02-08 17:14:22,059 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 3.4 KB, free 631.5 MB)
2018-02-08 17:14:22,062 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2039.0 B, free 631.5 MB)
2018-02-08 17:14:22,063 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:63690 (size: 2039.0 B, free: 631.8 MB)
2018-02-08 17:14:22,064 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 17:14:22,078 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (GraphLoader.edgeListFile - edges (data/graphx/followers.txt) MapPartitionsRDD[2] at mapPartitionsWithIndex at GraphLoader.scala:75) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 17:14:22,079 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 17:14:22,118 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4886 bytes)
2018-02-08 17:14:22,121 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4886 bytes)
2018-02-08 17:14:22,128 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 17:14:22,129 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 17:14:22,216 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/graphx/followers.txt:0+16
2018-02-08 17:14:22,216 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/graphx/followers.txt:16+16
2018-02-08 17:14:22,269 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_2_1 stored as values in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 17:14:22,269 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_2_0 stored as values in memory (estimated size 2.4 KB, free 631.5 MB)
2018-02-08 17:14:22,270 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_2_1 in memory on 192.168.11.26:63690 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 17:14:22,271 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_2_0 in memory on 192.168.11.26:63690 (size: 2.4 KB, free: 631.8 MB)
2018-02-08 17:14:22,288 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1572 bytes result sent to driver
2018-02-08 17:14:22,288 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1529 bytes result sent to driver
2018-02-08 17:14:22,295 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 174 ms on localhost (executor driver) (1/2)
2018-02-08 17:14:22,297 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 193 ms on localhost (executor driver) (2/2)
2018-02-08 17:14:22,298 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 17:14:22,302 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (count at GraphLoader.scala:94) finished in 0.209 s
2018-02-08 17:14:22,308 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: count at GraphLoader.scala:94, took 0.333865 s
2018-02-08 17:14:22,311 INFO[org.apache.spark.graphx.GraphLoader:54] - It took 891 ms to load the edges
2018-02-08 17:14:22,346 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 17:14:22,350 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@2c65d593{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 17:14:22,352 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 17:14:22,358 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 17:14:22,367 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 17:14:22,367 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 17:14:22,370 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 17:14:22,372 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 17:14:22,375 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 17:14:22,375 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 17:14:22,376 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-3918a4a5-2aae-4e80-be06-0d51e3c38291
2018-02-08 17:15:36,636 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 17:15:37,126 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 17:15:37,146 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 17:15:37,147 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 17:15:37,147 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 17:15:37,148 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 17:15:37,148 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 17:15:37,473 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 63722.
2018-02-08 17:15:37,489 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 17:15:37,512 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 17:15:37,514 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 17:15:37,515 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 17:15:37,522 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-0ddea0c2-4ba3-4223-a5b1-e23d47a25208
2018-02-08 17:15:37,567 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 17:15:37,604 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 17:15:37,676 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2359ms
2018-02-08 17:15:37,725 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 17:15:37,736 INFO[org.spark_project.jetty.server.Server:403] - Started @2420ms
2018-02-08 17:15:37,751 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@7eb2b21b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 17:15:37,752 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 17:15:37,770 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6b9ce1bf{/jobs,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,771 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@160ac7fb{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,772 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41925502{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,773 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3f053c80{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,774 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@618c5d94{/stages,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,774 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@13c3c1e1{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,775 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1e63ec0b{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,776 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@295eaa7c{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,776 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c88b9fc{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,777 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@388ba540{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,777 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ece4966{/storage,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,778 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7894f09b{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,779 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6111ba37{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,779 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,780 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,780 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@11eadcba{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,781 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1b065145{/executors,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,782 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@207ea13{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,783 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62dae540{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,784 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@654d8173{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,789 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@630cb4a4{/static,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,790 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4c37b5b{/,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,791 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@71b3bc45{/api,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,791 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a8fa663{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,792 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@78a287ed{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 17:15:37,794 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 17:15:37,864 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 17:15:37,886 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63735.
2018-02-08 17:15:37,888 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:63735
2018-02-08 17:15:37,889 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 17:15:37,891 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 63735, None)
2018-02-08 17:15:37,894 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:63735 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 63735, None)
2018-02-08 17:15:37,897 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 63735, None)
2018-02-08 17:15:37,898 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 63735, None)
2018-02-08 17:15:38,090 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d572e62{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:38,141 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 17:15:38,142 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 17:15:38,148 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@54336c81{/SQL,null,AVAILABLE,@Spark}
2018-02-08 17:15:38,148 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@35e52059{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:38,149 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5a12c728{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 17:15:38,149 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6e5bfdfc{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 17:15:38,150 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@117632cf{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 17:15:39,100 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 17:15:39,342 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 17:15:39,397 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 17:15:39,399 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:63735 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 17:15:39,403 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at GraphLoader.scala:73
2018-02-08 17:15:39,482 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 17:15:39,494 INFO[org.apache.spark.SparkContext:54] - Starting job: count at GraphLoader.scala:94
2018-02-08 17:15:39,508 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (count at GraphLoader.scala:94) with 2 output partitions
2018-02-08 17:15:39,508 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (count at GraphLoader.scala:94)
2018-02-08 17:15:39,508 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 17:15:39,511 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 17:15:39,515 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (GraphLoader.edgeListFile - edges (data/graphx/followers.txt) MapPartitionsRDD[2] at mapPartitionsWithIndex at GraphLoader.scala:75), which has no missing parents
2018-02-08 17:15:39,551 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 3.4 KB, free 631.5 MB)
2018-02-08 17:15:39,555 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2038.0 B, free 631.5 MB)
2018-02-08 17:15:39,556 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:63735 (size: 2038.0 B, free: 631.8 MB)
2018-02-08 17:15:39,556 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 17:15:39,572 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (GraphLoader.edgeListFile - edges (data/graphx/followers.txt) MapPartitionsRDD[2] at mapPartitionsWithIndex at GraphLoader.scala:75) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 17:15:39,573 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 17:15:39,612 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4886 bytes)
2018-02-08 17:15:39,615 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4886 bytes)
2018-02-08 17:15:39,620 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 17:15:39,651 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 17:15:39,692 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/graphx/followers.txt:0+16
2018-02-08 17:15:39,692 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/graphx/followers.txt:16+16
2018-02-08 17:15:39,741 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_2_1 stored as values in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 17:15:39,741 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_2_0 stored as values in memory (estimated size 2.4 KB, free 631.5 MB)
2018-02-08 17:15:39,741 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_2_1 in memory on 192.168.11.26:63735 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 17:15:39,742 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_2_0 in memory on 192.168.11.26:63735 (size: 2.4 KB, free: 631.8 MB)
2018-02-08 17:15:39,756 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1529 bytes result sent to driver
2018-02-08 17:15:39,756 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1529 bytes result sent to driver
2018-02-08 17:15:39,764 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 165 ms on localhost (executor driver) (1/2)
2018-02-08 17:15:39,766 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 152 ms on localhost (executor driver) (2/2)
2018-02-08 17:15:39,768 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 17:15:39,774 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (count at GraphLoader.scala:94) finished in 0.186 s
2018-02-08 17:15:39,778 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: count at GraphLoader.scala:94, took 0.284239 s
2018-02-08 17:15:39,784 INFO[org.apache.spark.graphx.GraphLoader:54] - It took 677 ms to load the edges
2018-02-08 17:15:39,820 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 17:15:39,824 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@7eb2b21b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 17:15:39,826 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 17:15:39,835 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 17:15:39,844 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 17:15:39,845 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 17:15:39,848 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 17:15:39,851 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 17:15:39,854 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 17:15:39,855 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 17:15:39,855 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-30975da5-1b61-49eb-bdc2-af10a6236cf3
2018-02-08 17:20:16,288 INFO[org.apache.spark.SparkContext:54] - Running Spark version 2.2.0
2018-02-08 17:20:16,986 INFO[org.apache.spark.SparkContext:54] - Submitted application: mumuSpark
2018-02-08 17:20:17,007 INFO[org.apache.spark.SecurityManager:54] - Changing view acls to: Administrator
2018-02-08 17:20:17,008 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls to: Administrator
2018-02-08 17:20:17,008 INFO[org.apache.spark.SecurityManager:54] - Changing view acls groups to: 
2018-02-08 17:20:17,009 INFO[org.apache.spark.SecurityManager:54] - Changing modify acls groups to: 
2018-02-08 17:20:17,009 INFO[org.apache.spark.SecurityManager:54] - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Administrator); groups with view permissions: Set(); users  with modify permissions: Set(Administrator); groups with modify permissions: Set()
2018-02-08 17:20:17,348 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'sparkDriver' on port 63794.
2018-02-08 17:20:17,363 INFO[org.apache.spark.SparkEnv:54] - Registering MapOutputTracker
2018-02-08 17:20:17,386 INFO[org.apache.spark.SparkEnv:54] - Registering BlockManagerMaster
2018-02-08 17:20:17,389 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-02-08 17:20:17,389 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - BlockManagerMasterEndpoint up
2018-02-08 17:20:17,397 INFO[org.apache.spark.storage.DiskBlockManager:54] - Created local directory at C:\Users\Administrator\AppData\Local\Temp\blockmgr-684492aa-5e9e-42a6-8915-93cf62e9c8f1
2018-02-08 17:20:17,440 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore started with capacity 631.8 MB
2018-02-08 17:20:17,477 INFO[org.apache.spark.SparkEnv:54] - Registering OutputCommitCoordinator
2018-02-08 17:20:17,540 INFO[org.spark_project.jetty.util.log:192] - Logging initialized @2463ms
2018-02-08 17:20:17,592 INFO[org.spark_project.jetty.server.Server:345] - jetty-9.3.z-SNAPSHOT
2018-02-08 17:20:17,603 INFO[org.spark_project.jetty.server.Server:403] - Started @2527ms
2018-02-08 17:20:17,618 INFO[org.spark_project.jetty.server.AbstractConnector:270] - Started ServerConnector@32cee45f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 17:20:17,618 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'SparkUI' on port 4040.
2018-02-08 17:20:17,644 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6b9ce1bf{/jobs,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,645 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@160ac7fb{/jobs/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,645 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@41925502{/jobs/job,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,647 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@3f053c80{/jobs/job/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,648 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@618c5d94{/stages,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,649 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@13c3c1e1{/stages/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,650 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1e63ec0b{/stages/stage,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,652 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@295eaa7c{/stages/stage/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,653 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2c88b9fc{/stages/pool,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,653 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@388ba540{/stages/pool/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,654 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@2ece4966{/storage,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,654 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7894f09b{/storage/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,655 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6111ba37{/storage/rdd,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,656 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@242aa8d9{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,657 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@37bd68c3{/environment,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,658 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@11eadcba{/environment/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,658 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1b065145{/executors,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,659 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@207ea13{/executors/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,660 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@62dae540{/executors/threadDump,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,660 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@654d8173{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,666 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@630cb4a4{/static,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,667 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@4c37b5b{/,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,668 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@71b3bc45{/api,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,668 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@7a8fa663{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,669 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@78a287ed{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-02-08 17:20:17,670 INFO[org.apache.spark.ui.SparkUI:54] - Bound SparkUI to 0.0.0.0, and started at http://192.168.11.26:4040
2018-02-08 17:20:17,743 INFO[org.apache.spark.executor.Executor:54] - Starting executor ID driver on host localhost
2018-02-08 17:20:17,768 INFO[org.apache.spark.util.Utils:54] - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63807.
2018-02-08 17:20:17,769 INFO[org.apache.spark.network.netty.NettyBlockTransferService:54] - Server created on 192.168.11.26:63807
2018-02-08 17:20:17,771 INFO[org.apache.spark.storage.BlockManager:54] - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-02-08 17:20:17,772 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registering BlockManager BlockManagerId(driver, 192.168.11.26, 63807, None)
2018-02-08 17:20:17,775 INFO[org.apache.spark.storage.BlockManagerMasterEndpoint:54] - Registering block manager 192.168.11.26:63807 with 631.8 MB RAM, BlockManagerId(driver, 192.168.11.26, 63807, None)
2018-02-08 17:20:17,777 INFO[org.apache.spark.storage.BlockManagerMaster:54] - Registered BlockManager BlockManagerId(driver, 192.168.11.26, 63807, None)
2018-02-08 17:20:17,777 INFO[org.apache.spark.storage.BlockManager:54] - Initialized BlockManager: BlockManagerId(driver, 192.168.11.26, 63807, None)
2018-02-08 17:20:17,971 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@1d572e62{/metrics/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:18,036 INFO[org.apache.spark.sql.internal.SharedState:54] - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse').
2018-02-08 17:20:18,037 INFO[org.apache.spark.sql.internal.SharedState:54] - Warehouse path is 'E:\IntelliJWorkspaceMumu\mumu-spark\spark-warehouse'.
2018-02-08 17:20:18,042 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@54336c81{/SQL,null,AVAILABLE,@Spark}
2018-02-08 17:20:18,043 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@35e52059{/SQL/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:18,043 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@5a12c728{/SQL/execution,null,AVAILABLE,@Spark}
2018-02-08 17:20:18,044 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@6e5bfdfc{/SQL/execution/json,null,AVAILABLE,@Spark}
2018-02-08 17:20:18,045 INFO[org.spark_project.jetty.server.handler.ContextHandler:781] - Started o.s.j.s.ServletContextHandler@117632cf{/static/sql,null,AVAILABLE,@Spark}
2018-02-08 17:20:18,994 INFO[org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef:54] - Registered StateStoreCoordinator endpoint
2018-02-08 17:20:19,241 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0 stored as values in memory (estimated size 316.4 KB, free 631.5 MB)
2018-02-08 17:20:19,298 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.3 KB, free 631.5 MB)
2018-02-08 17:20:19,301 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_0_piece0 in memory on 192.168.11.26:63807 (size: 27.3 KB, free: 631.8 MB)
2018-02-08 17:20:19,305 INFO[org.apache.spark.SparkContext:54] - Created broadcast 0 from textFile at GraphLoader.scala:73
2018-02-08 17:20:19,384 INFO[org.apache.hadoop.mapred.FileInputFormat:256] - Total input files to process : 1
2018-02-08 17:20:19,397 INFO[org.apache.spark.SparkContext:54] - Starting job: count at GraphLoader.scala:94
2018-02-08 17:20:19,411 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 0 (count at GraphLoader.scala:94) with 2 output partitions
2018-02-08 17:20:19,412 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 0 (count at GraphLoader.scala:94)
2018-02-08 17:20:19,412 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 17:20:19,415 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 17:20:19,418 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 0 (GraphLoader.edgeListFile - edges (data/graphx/followers.txt) MapPartitionsRDD[2] at mapPartitionsWithIndex at GraphLoader.scala:75), which has no missing parents
2018-02-08 17:20:19,457 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1 stored as values in memory (estimated size 3.4 KB, free 631.5 MB)
2018-02-08 17:20:19,460 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2038.0 B, free 631.5 MB)
2018-02-08 17:20:19,460 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_1_piece0 in memory on 192.168.11.26:63807 (size: 2038.0 B, free: 631.8 MB)
2018-02-08 17:20:19,461 INFO[org.apache.spark.SparkContext:54] - Created broadcast 1 from broadcast at DAGScheduler.scala:1006
2018-02-08 17:20:19,475 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ResultStage 0 (GraphLoader.edgeListFile - edges (data/graphx/followers.txt) MapPartitionsRDD[2] at mapPartitionsWithIndex at GraphLoader.scala:75) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 17:20:19,476 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 0.0 with 2 tasks
2018-02-08 17:20:19,516 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4886 bytes)
2018-02-08 17:20:19,518 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4886 bytes)
2018-02-08 17:20:19,530 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 0.0 (TID 0)
2018-02-08 17:20:19,530 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 0.0 (TID 1)
2018-02-08 17:20:19,608 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/graphx/followers.txt:16+16
2018-02-08 17:20:19,613 INFO[org.apache.spark.rdd.HadoopRDD:54] - Input split: file:/E:/IntelliJWorkspaceMumu/mumu-spark/data/graphx/followers.txt:0+16
2018-02-08 17:20:19,665 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_2_1 stored as values in memory (estimated size 2.3 KB, free 631.5 MB)
2018-02-08 17:20:19,667 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block rdd_2_0 stored as values in memory (estimated size 2.4 KB, free 631.5 MB)
2018-02-08 17:20:19,670 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_2_1 in memory on 192.168.11.26:63807 (size: 2.3 KB, free: 631.8 MB)
2018-02-08 17:20:19,672 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added rdd_2_0 in memory on 192.168.11.26:63807 (size: 2.4 KB, free: 631.8 MB)
2018-02-08 17:20:19,689 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 0.0 (TID 1). 1572 bytes result sent to driver
2018-02-08 17:20:19,689 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 0.0 (TID 0). 1572 bytes result sent to driver
2018-02-08 17:20:19,699 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 0.0 (TID 1) in 179 ms on localhost (executor driver) (1/2)
2018-02-08 17:20:19,700 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 0.0 (TID 0) in 197 ms on localhost (executor driver) (2/2)
2018-02-08 17:20:19,704 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-02-08 17:20:19,710 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 0 (count at GraphLoader.scala:94) finished in 0.217 s
2018-02-08 17:20:19,714 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 0 finished: count at GraphLoader.scala:94, took 0.317439 s
2018-02-08 17:20:19,726 INFO[org.apache.spark.graphx.GraphLoader:54] - It took 724 ms to load the edges
2018-02-08 17:20:19,882 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at NativeMethodAccessorImpl.java:0
2018-02-08 17:20:19,883 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 1 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
2018-02-08 17:20:19,883 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 1 (isEmpty at NativeMethodAccessorImpl.java:0)
2018-02-08 17:20:19,884 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List()
2018-02-08 17:20:19,886 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List()
2018-02-08 17:20:19,887 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 1 (EdgeRDDImpl[4] at RDD at EdgeRDD.scala:41), which has no missing parents
2018-02-08 17:20:19,889 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2 stored as values in memory (estimated size 4.1 KB, free 631.5 MB)
2018-02-08 17:20:19,893 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.4 KB, free 631.4 MB)
2018-02-08 17:20:19,895 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_2_piece0 in memory on 192.168.11.26:63807 (size: 2.4 KB, free: 631.8 MB)
2018-02-08 17:20:19,896 INFO[org.apache.spark.SparkContext:54] - Created broadcast 2 from broadcast at DAGScheduler.scala:1006
2018-02-08 17:20:19,897 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 1 (EdgeRDDImpl[4] at RDD at EdgeRDD.scala:41) (first 15 tasks are for partitions Vector(0))
2018-02-08 17:20:19,898 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 1.0 with 1 tasks
2018-02-08 17:20:19,902 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 4886 bytes)
2018-02-08 17:20:19,903 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 1.0 (TID 2)
2018-02-08 17:20:19,909 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_2_0 locally
2018-02-08 17:20:19,922 INFO[org.apache.spark.executor.Executor:54] - 1 block locks were not released by TID = 2:
[rdd_2_0]
2018-02-08 17:20:19,924 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 1.0 (TID 2). 945 bytes result sent to driver
2018-02-08 17:20:19,925 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 1.0 (TID 2) in 24 ms on localhost (executor driver) (1/1)
2018-02-08 17:20:19,925 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-02-08 17:20:19,927 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 1 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.026 s
2018-02-08 17:20:19,928 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 1 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.046212 s
2018-02-08 17:20:20,010 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at NativeMethodAccessorImpl.java:0
2018-02-08 17:20:20,016 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 5 (mapPartitions at VertexRDD.scala:356)
2018-02-08 17:20:20,016 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 2 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
2018-02-08 17:20:20,017 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 3 (isEmpty at NativeMethodAccessorImpl.java:0)
2018-02-08 17:20:20,017 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 2)
2018-02-08 17:20:20,017 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 2)
2018-02-08 17:20:20,019 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 2 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[5] at mapPartitions at VertexRDD.scala:356), which has no missing parents
2018-02-08 17:20:20,026 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3 stored as values in memory (estimated size 4.7 KB, free 631.4 MB)
2018-02-08 17:20:20,030 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.8 KB, free 631.4 MB)
2018-02-08 17:20:20,030 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_3_piece0 in memory on 192.168.11.26:63807 (size: 2.8 KB, free: 631.8 MB)
2018-02-08 17:20:20,031 INFO[org.apache.spark.SparkContext:54] - Created broadcast 3 from broadcast at DAGScheduler.scala:1006
2018-02-08 17:20:20,034 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 2 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[5] at mapPartitions at VertexRDD.scala:356) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 17:20:20,034 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 2.0 with 2 tasks
2018-02-08 17:20:20,036 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 2.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 4875 bytes)
2018-02-08 17:20:20,036 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 2.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 4875 bytes)
2018-02-08 17:20:20,036 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 2.0 (TID 3)
2018-02-08 17:20:20,036 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 2.0 (TID 4)
2018-02-08 17:20:20,043 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_2_1 locally
2018-02-08 17:20:20,043 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_2_0 locally
2018-02-08 17:20:20,125 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_1_piece0 on 192.168.11.26:63807 in memory (size: 2038.0 B, free: 631.8 MB)
2018-02-08 17:20:20,132 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Removed broadcast_2_piece0 on 192.168.11.26:63807 in memory (size: 2.4 KB, free: 631.8 MB)
2018-02-08 17:20:20,264 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 2.0 (TID 3). 1026 bytes result sent to driver
2018-02-08 17:20:20,264 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 2.0 (TID 4). 1026 bytes result sent to driver
2018-02-08 17:20:20,266 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 2.0 (TID 4) in 230 ms on localhost (executor driver) (1/2)
2018-02-08 17:20:20,266 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 2.0 (TID 3) in 231 ms on localhost (executor driver) (2/2)
2018-02-08 17:20:20,266 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-02-08 17:20:20,267 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 2 (mapPartitions at VertexRDD.scala:356) finished in 0.233 s
2018-02-08 17:20:20,268 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 17:20:20,268 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 17:20:20,268 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 3)
2018-02-08 17:20:20,269 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 17:20:20,272 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 3 (VertexRDDImpl[10] at RDD at VertexRDD.scala:57), which has no missing parents
2018-02-08 17:20:20,275 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4 stored as values in memory (estimated size 4.5 KB, free 631.4 MB)
2018-02-08 17:20:20,278 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.6 KB, free 631.4 MB)
2018-02-08 17:20:20,278 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_4_piece0 in memory on 192.168.11.26:63807 (size: 2.6 KB, free: 631.8 MB)
2018-02-08 17:20:20,279 INFO[org.apache.spark.SparkContext:54] - Created broadcast 4 from broadcast at DAGScheduler.scala:1006
2018-02-08 17:20:20,279 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 3 (VertexRDDImpl[10] at RDD at VertexRDD.scala:57) (first 15 tasks are for partitions Vector(0))
2018-02-08 17:20:20,280 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 3.0 with 1 tasks
2018-02-08 17:20:20,281 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 3.0 (TID 5, localhost, executor driver, partition 0, ANY, 4621 bytes)
2018-02-08 17:20:20,282 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 3.0 (TID 5)
2018-02-08 17:20:20,294 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 2 blocks
2018-02-08 17:20:20,295 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 3 ms
2018-02-08 17:20:20,322 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 3.0 (TID 5). 1155 bytes result sent to driver
2018-02-08 17:20:20,325 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 3.0 (TID 5) in 45 ms on localhost (executor driver) (1/1)
2018-02-08 17:20:20,325 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-02-08 17:20:20,326 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 3 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.045 s
2018-02-08 17:20:20,327 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 2 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.316769 s
2018-02-08 17:20:20,385 INFO[org.apache.spark.SparkContext:54] - Starting job: isEmpty at NativeMethodAccessorImpl.java:0
2018-02-08 17:20:20,394 INFO[org.apache.spark.MapOutputTrackerMaster:54] - Size of output statuses for shuffle 0 is 161 bytes
2018-02-08 17:20:20,396 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Registering RDD 11 (mapPartitions at VertexRDDImpl.scala:247)
2018-02-08 17:20:20,396 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Got job 3 (isEmpty at NativeMethodAccessorImpl.java:0) with 1 output partitions
2018-02-08 17:20:20,396 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Final stage: ResultStage 6 (isEmpty at NativeMethodAccessorImpl.java:0)
2018-02-08 17:20:20,397 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Parents of final stage: List(ShuffleMapStage 5)
2018-02-08 17:20:20,399 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Missing parents: List(ShuffleMapStage 5)
2018-02-08 17:20:20,400 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ShuffleMapStage 5 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[11] at mapPartitions at VertexRDDImpl.scala:247), which has no missing parents
2018-02-08 17:20:20,404 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5 stored as values in memory (estimated size 4.3 KB, free 631.4 MB)
2018-02-08 17:20:20,409 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.5 KB, free 631.4 MB)
2018-02-08 17:20:20,411 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_5_piece0 in memory on 192.168.11.26:63807 (size: 2.5 KB, free: 631.8 MB)
2018-02-08 17:20:20,412 INFO[org.apache.spark.SparkContext:54] - Created broadcast 5 from broadcast at DAGScheduler.scala:1006
2018-02-08 17:20:20,414 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 2 missing tasks from ShuffleMapStage 5 (ReplicatedVertexView.upgrade(true, true) - shippedVerts true true (broadcast) MapPartitionsRDD[11] at mapPartitions at VertexRDDImpl.scala:247) (first 15 tasks are for partitions Vector(0, 1))
2018-02-08 17:20:20,414 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 5.0 with 2 tasks
2018-02-08 17:20:20,415 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, ANY, 4610 bytes)
2018-02-08 17:20:20,415 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 1.0 in stage 5.0 (TID 7, localhost, executor driver, partition 1, ANY, 4610 bytes)
2018-02-08 17:20:20,415 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 5.0 (TID 6)
2018-02-08 17:20:20,416 INFO[org.apache.spark.executor.Executor:54] - Running task 1.0 in stage 5.0 (TID 7)
2018-02-08 17:20:20,419 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 2 blocks
2018-02-08 17:20:20,419 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 17:20:20,426 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 2 blocks
2018-02-08 17:20:20,427 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 1 ms
2018-02-08 17:20:20,447 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 5.0 (TID 6). 1155 bytes result sent to driver
2018-02-08 17:20:20,448 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 5.0 (TID 6) in 33 ms on localhost (executor driver) (1/2)
2018-02-08 17:20:20,449 INFO[org.apache.spark.executor.Executor:54] - Finished task 1.0 in stage 5.0 (TID 7). 1069 bytes result sent to driver
2018-02-08 17:20:20,450 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 1.0 in stage 5.0 (TID 7) in 35 ms on localhost (executor driver) (2/2)
2018-02-08 17:20:20,450 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2018-02-08 17:20:20,451 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ShuffleMapStage 5 (mapPartitions at VertexRDDImpl.scala:247) finished in 0.037 s
2018-02-08 17:20:20,451 INFO[org.apache.spark.scheduler.DAGScheduler:54] - looking for newly runnable stages
2018-02-08 17:20:20,451 INFO[org.apache.spark.scheduler.DAGScheduler:54] - running: Set()
2018-02-08 17:20:20,451 INFO[org.apache.spark.scheduler.DAGScheduler:54] - waiting: Set(ResultStage 6)
2018-02-08 17:20:20,452 INFO[org.apache.spark.scheduler.DAGScheduler:54] - failed: Set()
2018-02-08 17:20:20,452 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting ResultStage 6 (MapPartitionsRDD[15] at mapPartitions at GraphImpl.scala:48), which has no missing parents
2018-02-08 17:20:20,455 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6 stored as values in memory (estimated size 5.8 KB, free 631.4 MB)
2018-02-08 17:20:20,458 INFO[org.apache.spark.storage.memory.MemoryStore:54] - Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.2 KB, free 631.4 MB)
2018-02-08 17:20:20,459 INFO[org.apache.spark.storage.BlockManagerInfo:54] - Added broadcast_6_piece0 in memory on 192.168.11.26:63807 (size: 3.2 KB, free: 631.8 MB)
2018-02-08 17:20:20,460 INFO[org.apache.spark.SparkContext:54] - Created broadcast 6 from broadcast at DAGScheduler.scala:1006
2018-02-08 17:20:20,460 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[15] at mapPartitions at GraphImpl.scala:48) (first 15 tasks are for partitions Vector(0))
2018-02-08 17:20:20,460 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Adding task set 6.0 with 1 tasks
2018-02-08 17:20:20,463 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Starting task 0.0 in stage 6.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 5272 bytes)
2018-02-08 17:20:20,463 INFO[org.apache.spark.executor.Executor:54] - Running task 0.0 in stage 6.0 (TID 8)
2018-02-08 17:20:20,466 INFO[org.apache.spark.storage.BlockManager:54] - Found block rdd_2_0 locally
2018-02-08 17:20:20,466 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Getting 2 non-empty blocks out of 2 blocks
2018-02-08 17:20:20,466 INFO[org.apache.spark.storage.ShuffleBlockFetcherIterator:54] - Started 0 remote fetches in 0 ms
2018-02-08 17:20:20,472 INFO[org.apache.spark.executor.Executor:54] - 1 block locks were not released by TID = 8:
[rdd_2_0]
2018-02-08 17:20:20,472 INFO[org.apache.spark.executor.Executor:54] - Finished task 0.0 in stage 6.0 (TID 8). 1260 bytes result sent to driver
2018-02-08 17:20:20,473 INFO[org.apache.spark.scheduler.TaskSetManager:54] - Finished task 0.0 in stage 6.0 (TID 8) in 12 ms on localhost (executor driver) (1/1)
2018-02-08 17:20:20,473 INFO[org.apache.spark.scheduler.TaskSchedulerImpl:54] - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2018-02-08 17:20:20,474 INFO[org.apache.spark.scheduler.DAGScheduler:54] - ResultStage 6 (isEmpty at NativeMethodAccessorImpl.java:0) finished in 0.012 s
2018-02-08 17:20:20,474 INFO[org.apache.spark.scheduler.DAGScheduler:54] - Job 3 finished: isEmpty at NativeMethodAccessorImpl.java:0, took 0.088857 s
2018-02-08 17:20:20,479 INFO[org.apache.spark.SparkContext:54] - Invoking stop() from shutdown hook
2018-02-08 17:20:20,482 INFO[org.spark_project.jetty.server.AbstractConnector:310] - Stopped Spark@32cee45f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-02-08 17:20:20,484 INFO[org.apache.spark.ui.SparkUI:54] - Stopped Spark web UI at http://192.168.11.26:4040
2018-02-08 17:20:20,496 INFO[org.apache.spark.MapOutputTrackerMasterEndpoint:54] - MapOutputTrackerMasterEndpoint stopped!
2018-02-08 17:20:20,531 INFO[org.apache.spark.storage.memory.MemoryStore:54] - MemoryStore cleared
2018-02-08 17:20:20,531 INFO[org.apache.spark.storage.BlockManager:54] - BlockManager stopped
2018-02-08 17:20:20,533 INFO[org.apache.spark.storage.BlockManagerMaster:54] - BlockManagerMaster stopped
2018-02-08 17:20:20,534 INFO[org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54] - OutputCommitCoordinator stopped!
2018-02-08 17:20:20,537 INFO[org.apache.spark.SparkContext:54] - Successfully stopped SparkContext
2018-02-08 17:20:20,538 INFO[org.apache.spark.util.ShutdownHookManager:54] - Shutdown hook called
2018-02-08 17:20:20,539 INFO[org.apache.spark.util.ShutdownHookManager:54] - Deleting directory C:\Users\Administrator\AppData\Local\Temp\spark-63567ced-30a3-48b8-9422-cce86ecc153a
